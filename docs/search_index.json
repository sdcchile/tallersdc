[["index.html", "Guía para el Control de Divulgación Estadística en Microdatos Capítulo 1 Prefacio 1.1 Autores de esta guía 1.2 Reconocimientos 1.3 Citar este documento", " Guía para el Control de Divulgación Estadística en Microdatos Subdepartamento de Investigación Estadística 2023-10-19 Capítulo 1 Prefacio Los datos son un recurso valioso que proporciona información crítica para estadísticos, científicos sociales y científicos de datos. Estos datos se utilizan para generar perspectivas detalladas y oportunas que responden a las necesidades de información de una amplia gama de partes interesadas. En un mundo donde cada vez más grandes volúmenes de datos provienen de un número creciente de proveedores, las Oficinas Nacionales de Estadística (ONE) están utilizando enfoques innovadores para mantener estándares y definiciones de datos, sistemas de gestión de privacidad y confidencialidad, e intercambio responsable de datos. Las ONE tienen un papel de liderazgo que desempeñar en el establecimiento de formas seguras y transparentes de compartir datos, experiencias y mejores prácticas para respaldar el uso de datos con fines de prueba, evaluación, educación y desarrollo. Con la integridad y la confidencialidad de los datos a la vanguardia, las ONE están posicionandose cada vez más para proporcionar herramientas, métodos y enfoques para promover el intercambio responsable de datos, a fin de satisfacer las necesidades de un número creciente de partes interesadas en este ámbito que está en constante cambio. Las ONE reconocen que se debe cumplir con el llamado a una mayor apertura y transparencia de los datos. Sin embargo, también se comprometen a proteger la confidencialidad y la privacidad integradas en sus tenencias de datos. Se reconoce ampliamente que la difusión de información que es a la vez útil y completamente segura, no puede lograrse en su totalidad. Por lo tanto, la seguridad es un concepto relativo, no absoluto, y se debe entender como una métrica, no un estado. Es dentro de este contexto que las ONE deben establecer protocolos para la difusión segura de datos y métricas para medir la utilidad de la información estadística publicada y el grado de protección de las unidades, ya sean personas naturales o jurídicas, e información recopilada de la cual se deriva. Esta guía es para aquellos que trabajan en una ONE u oficina estatal que están involucrados en la gestión del acceso a datos estadísticos, y que deseen explorar herramientas de protección de datos para que los usuarios accedan a ellos. La guía destaca algunas aplicaciones exitosas recientes de control a la divulgación estadística en microdatos en el Instituto Nacional de Estadísticas de Chile (INE), y presenta un marco general sobre medición y evaluación de riesgos, técnicas para generar datos anonimizados, y sobre las medidas de utilidad que se pueden usar para evaluar qué tan bien los datos anonimizados satisfacen las necesidades analíticas de los usuarios. La guía también incluye recomendaciones sobre qué enfoques utilizar en diferentes situaciones, así como consejos prácticos y recursos para que los profesionales comiencen su experiencia en la implementación de proceso de control a la divulgación estadística. Esta guía se basa en Statistical Disclosure Control: A Practice Guide Benschop, Machingauta, and Welch (2019) y en la Guía para el control de divulgación estadística en microdatos, elaborada por el INE en 2021, que es el primer esfuerzo en esta materia en instituciones del Estado en Chile. Sin embargo, aún puede enriquecerse a partir de nuevos conocimientos y experiencias que tanto investigadores como profesionales puedan aportar. ¡Esperamos que esta guía lo ayude en su viaje hacia la implementación de procesos de control a la divulgación estadística en su organización! 1.1 Autores de esta guía Jonathan González Mejías, Subdepartamento de Estadísticas Socioeconómicas, Subdirección Técnica en Instituto Nacional de Estadísticas de Chile. José Bustos Melo, Subdepartamento de Investigación Estadística, Departamento de Metodologías e Innovación Estadística en Instituto Nacional de Estadísticas de Chile. Julio Guerrero Rojas, Subdepartamento de Investigación Estadística, Departamento de Metodologías e Innovación Estadística en Instituto Nacional de Estadísticas de Chile. Lissette Bastías Navarro, Subdepartamento de Calidad y Estándares, Departamento de Metodologías e Innovación Estadística en Instituto Nacional de Estadísticas de Chile. Nicolás Berhó Montalvo, Subdepartamento de Estadísticas de Condiciones de Vida, Subdirección Técnica en Instituto Nacional de Estadísticas de Chile. 1.2 Reconocimientos Este proyecto conjunto es un testimonio del esfuerzo colaborativo que comenzó a gestarse a finales de 2019, en el cual participaron activamente los analistas de la Subdirección Técnica (SDT) y del Departamento de Metodologías e Innovación Estadística (DMIE). Durante esta travesía, se realizaron reuniones estratégicas que permitieron explorar y analizar las diversas formas de anonimización históricamente empleadas por nuestros equipos. Estas discusiones fueron fundamentales para identificar puntos comunes y optimizar nuestros esfuerzos, evitando la duplicación de tareas y enfocando nuestros recursos de manera eficiente. La coordinación y organización de este arduo trabajo estuvieron a cargo del DMIE, bajo la hábil dirección de Denisse López. Reconocemos su liderazgo y dedicación en la conducción de este proyecto. Este logro no habría sido posible sin la valiosa colaboración de cada persona involucrada en el proceso, ya sea de forma directa o indirecta. Valoramos y agradecemos profundamente a todos los miembros del equipo y a nuestro Instituto Nacional de Estadísticas (INE) en su conjunto. Sin duda, este es un esfuerzo colectivo que fortalece nuestra institución y enriquece nuestro compromiso con la excelencia en estadísticas. Aunque no es posible mencionar a cada analista en particular, queremos expresar nuestra sincera gratitud a todos aquellos que aportaron su tiempo, conocimientos y dedicación para hacer de este proyecto una realidad. Cada contribución, por pequeña que parezca, ha sido fundamental en la consecución de este importante trabajo. Juntos, hemos construido un proyecto sólido que nos impulsa hacia adelante en nuestra misión de generar datos precisos y relevantes para nuestra sociedad. Nuestro agradecimiento se extiende a cada uno de ustedes y a todas las personas que, de una u otra manera, han contribuido a este proyecto. Su esfuerzo y colaboración han sido esenciales y apreciadas en todo momento. Seguimos comprometidos con nuestra labor y esperamos seguir trabajando juntos en futuros proyectos que beneficien a nuestra institución y a la comunidad en general. 1.3 Citar este documento Si decide utilizar este material, le pedimos que lo cite adecuadamente. En ese caso, ponemos a su disposición el código LaTeX para que pueda incluirlo en las referencias de su documento. @Manual{guia_sdc_ine, title = {Guia para el Control de la Divulgacion Estadistica: Taller practico}, author = {{Gonzalez, Jonathan &amp; Bustos, Jose &amp; Guerrero, Julio &amp; Bastias, Lissete &amp; Berho, Nicolas}}, organization = {Instituto Nacional de Estadísticas}, address = {Santiago, Chile}, year = {2021}, url = {https://sdcchile.github.io/tallersdc/}, Referencias "],["introducción.html", "Capítulo 2 Introducción 2.1 Estableciendo una base de conocimiento 2.2 Propósito de esta guía 2.3 Esquema de esta guía", " Capítulo 2 Introducción Como Instituto Nacional de Estadística (en adelante, INE) tenemos la responsabilidad de la recopilación y difusión de estadísticas oficiales, tomando resguardos para cumplir con la Ley de Secreto Estadístico (Art.29, Ley 17.374 (Ley N° 17374 1970)), la Ley sobre Protección de la Vida Privada (Art.2e, Ley 19.628 (Ley N° 19628 1999)) y la legislación propia de las entidades públicas, todas en la línea de la protección y privacidad de la información difundida. Por otro lado, a nivel país, en los últimos años, ha existido un aumento constante en transparentar y disponer información tanto a nivel privado como público, mediante la “ley de transparencia” (Ley 20.285 (Ley 20.285 2008)), promulgada en año 2008. Es en esta misma línea que las Naciones Unidas también abogan por la libre difusión de los microdatos. Lo que permite a los usuarios contribuir con investigación, aumenta la transparencia y la responsabilidad de los institutos nacionales de estadística y permite mejoras en la calidad a través de la retroalimentación de los usuarios (Naciones Unidas s.f.). En paralelo la comunidad estadística ha reconocido la importancia de asegurar la información para mantener la confianza de las poblaciones a las que servimos. En este sentido, el Código Nacional de Buenas Prácticas Estadísticas del INE, en su principio 4 sobre confidencialidad estadística, establece que el “INE y los demás miembros del Sistema Estadístico Nacional (SEN) deben garantizar la protección y confidencialidad de la información con la que se producen las estadísticas oficiales, así como evitar la identificación de las fuentes” (Instituto Nacional de Estadísticas 2015). Los principios en competencia de la seguridad de los datos y la difusión de microdatos se someten a arbitraje a través de un dominio de estadísticas llamado Control de Divulgación Estadística (SDC, por su sigla en inglés). Los métodos SDC permiten proteger un conjunto de datos mediante la aplicación de herramientas estadísticas, lo que posibilita a la institución difundir de manera segura el conjunto de datos. La experiencia del INE en términos de control de divulgación estadística ha ido avanzando, iniciando en junio del año 2009, bajo la Resolución exenta N° 1918, emitida en Santiago el 10 de junio de 2009, expone acerca de una experiencia localizada, sobre el tratamiento que se buscaba dar a datos económicos, luego en 2019, un equipo multidisciplinario de la producción estadística institucional, define los lineamientos para desarrollar un proceso estandarizado de control de divulgación en las operaciones estadísticas que desarrolla el INE, entregando como resultado una primera versión de la “Guía para el control de divulgación estadística en microdatos”. En diciembre del 2021 se transforma en un estándar institucional disponible en la página web institucional https://www.ine.gob.cl/calidad-estadistica/directrices-metodologicas (Instituto Nacional de Estadísticas 2021a). Este documento exige normar el subproceso de control a la divulgación estadística o anonimización, a fin de responder de manera adecuada, oportuna y segura a los usuarios que requieren información de interés y que solicitan las bases de microdatos, al mismo tiempo de tener procedimientos estandarizados en la producción de estadísticas oficiales. Esta guía busca brindar pasos prácticos bajo lineamientos institucionales para aquellas operaciones estadísticas que requieran desbloquear el acceso a sus datos de manera segura y garantizar que los datos sigan siendo aptos para su propósito. 2.1 Estableciendo una base de conocimiento La publicación de datos es importante, ya que permite a los investigadores y responsables políticos replicar los resultados publicados oficialmente, generar nuevos conocimientos sobre los problemas, evitar la duplicación de encuestas y proporcionar mayores retornos a la inversión en el proceso de encuesta. Tanto la producción de informes, con tablas agregadas de indicadores y estadísticas, como la publicación de microdatos resultan en desafíos de privacidad para el productor. En el pasado, para muchas ONE, el único requisito era publicar un informe y algunos indicadores clave. El reciente movimiento en torno a los datos abiertos, el gobierno abierto y la transparencia significa que las ONE están bajo una mayor presión para liberar sus microdatos, para permitir un uso más amplio de los datos recopilados a través de fondos públicos. Esta guía se centra en los métodos y procesos para la liberación de microdatos, ya sea que estos provengan de encuestas, censos o registros estadísticos generados por el INE. Por tanto, el alcance de los procesos que se describen en esta guía se ciñe a proveer directriz circunscrita al campo de los microdatos, por lo que se excluyen los procesos de control de divulgación estadística orientados a tabulados, estadísticas geoespaciales, publicaciones web o visualizaciones de mapas, etc., que requieren enfoques diferentes al propuesto en esta guía. Asimismo, se distingue la necesidad de establecer lineamientos para el control de divulgación estadística en la publicación de tablas y publicaciones web, con el fin de cubrir más ámbitos de la producción estadística del INE. Se requiere la difusión de datos de manera segura para proteger la integridad del sistema estadístico, al garantizar que el INE cumpla con su compromiso con los encuestados de proteger su identidad. Las ONE no comparten ampliamente, en detalle sustancial, su conocimiento y experiencia usando SDC y los procesos para crear datos seguros con otras ONE. Esto lo hace difícil para las instituciones nuevas en el proceso para implementar soluciones. Para llenar esta brecha de experiencia y conocimiento, el equipo de la mesa de trabajo INE (en adelante mesa) evaluó el uso de un amplio conjunto de métodos de SDC en una gama de microdatos de encuestas que cubren importantes temas de desarrollo relacionados con trabajo, seguridad ciudadana, empresas de ferrocarriles, trámites de circulación. Dado que sus productores ya habían tratado estos datos, no era posible, ni era objetivo de la mesa, emitir un juicio sobre la seguridad de estos datos, los cuales son de dominio público. El enfoque se centró más bien en medir los efectos que varios de los métodos tendrían que ver con la relación riesgo – utilidad para los microdatos producidos para medir indicadores comunes de desarrollo. La experiencia de esta experimentación es útil para informar la discusión de los procesos y métodos en esta guía. 2.2 Propósito de esta guía Esta guía tiene como propósito presentar los lineamientos para la aplicación del control de divulgación estadística en microdatos derivados de censos, registros estadísticos y encuestas por muestreo desarrollados por el INE, permitiendo establecer qué microdatos pueden ser liberados y bajo qué condiciones. Esta guía no pretende prescribir o abogar por cambios en los métodos que los productores de datos específicos ya están utilizando y que han diseñado para ajustarse y cumplir con sus políticas de difusión de datos existentes, empero, ordenarlos. Los métodos discutidos en esta guía provienen de una gran cantidad de literatura sobre SDC. Los procesos que subyacen a muchos de los métodos son objeto de una extensa investigación académica y muchos, si no todos, son utilizados ampliamente por ONE con experiencia en la preparación de microdatos para su publicación. Siempre que sea posible, para cada método y tema, se proporciona ejemplos elaborados, referencias al trabajo original o seminal que describe los métodos y algoritmos en detalle y las lecturas recomendadas. Esto, cuando se combina con la discusión del método y las consideraciones prácticas en esta guía, debería permitir al lector comprender los métodos y sus fortalezas y debilidades. También proporciona suficientes detalles para que los lectores usen una solución de software adecuada para implementar los métodos. Para los ejercicios de esta guía, se ha utilizado el paquete de código abierto y gratuito para SDC llamado sdcMicro, así como el lenguaje y entorno de programación estadístico R. sdcMicro es un paquete adicional para el lenguaje R. El paquete fue desarrollado y es mantenido por Matthias Templ, Alexander Kowarik y Bernhard Meindl[1]. El lenguaje estadístico R y el paquete sdcMicro, así como cualquier otro paquete necesario para el proceso SDC, están disponibles gratuitamente en los mirrors de la Red Integral de Archivos R (CRAN[2]) (http://cran.r-project.org/). El lenguaje está disponible para los sistemas operativos Linux, Windows y Macintosh. Se ha elegido usar R y sdcMicro porque está disponible gratuitamente, admite todos los formatos de datos principales y es fácil de adaptar por el usuario. El Banco Mundial, a través de IHSN[3], también ha proporcionado fondos para el desarrollo del paquete sdcMicro para garantizar que cumpla con los requisitos de las ONE. Esta guía no proporciona una revisión de todos los demás paquetes disponibles para implementar el proceso SDC, pues se trata más de proporcionar información práctica sobre la aplicación de los métodos. Sin embargo, cabe destacar otro paquete de software en particular que las ONE utilizan comúnmente: -ARGUS[4]. -ARGUS es desarrollado por Statistics Netherlands. sdcMicro y -ARGUS son ampliamente utilizados en oficinas de estadística en la Unión Europea e implementan muchos de los mismos métodos. Las necesidades de usuario acerca de algún conocimiento de R para usar sdcMicro está más allá del alcance de esta guía, así como enseñar el uso de R, pero se presenta una serie de estudios de casos que incluyen el código para el anonimato de una serie de conjuntos de datos de demostración con R. A través de estos estudios de caso, se demuestra una serie de enfoques para el proceso de anonimización en R. 2.3 Esquema de esta guía Esta guía está dividida en las siguientes secciones principales: Introducción a sdcMicro: donde se visualiza la necesidad de aplicar los métodos SDC y el trade off que se produce entre el riesgo versus la utilidad. Tipos de liberación de datos: en este apartado encontrarán los tres tipos de métodos de divulgación, archivos de uso público (PUF, por sus siglas en inglés), archivos de uso científico (SUF, por sus siglas en inglés) y microdatos disponibles en un centro de datos de investigación controlado. Medición de riesgos: las medidas de riesgo que se utilizan y la determinación si un archivo de datos es lo suficientemente seguro para su divulgación. Métodos SDC: una descripción de los métodos más utilizados para anonimizar. Medición de utilidad y pérdida de información: en este apartado se profundiza acerca del trade off entre la medición de la utilidad y la pérdida de información. Procesos SDC INE 2021: caso práctico implementado en el INE en la mesa de anonimización institucional. Caso de estudio: Enusc: caso práctico para aplicar el método SDC en la Encuesta Nacional Urbana de Seguridad Ciudadana (ENUSC) con datos sintéticos. [1] Matthias Templ, Alexander Kowarik, Bernhard Meindl (2015). Statistical Disclosure Control for Micro-Data Using the R Package sdcMicro. Journal of Statistical Software 67 (October): 1–36. https://doi.org/10.18637/jss.v067.i04. [2] En inglés, Comprehensive R Archive Network. [3] En inglés, International Household Survey Network. [4] \\(\\mu\\)- ARGUS está disponible en: https://research.cbs.nl/casc/mu.htm Referencias "],["acrónimos-y-glosario.html", "Capítulo 3 Acrónimos y glosario 3.1 Acrónimos 3.2 Glosario", " Capítulo 3 Acrónimos y glosario 3.1 Acrónimos Tabla 3.1: Lista de acrónimos Acrónimo Descripción AEPD Agencia Española de Protección de Datos Bloque Trozo de código en R que permite cargar y procesar datos, realizar los análisis estadísticos e imprimir los resultados CEPAL Comisión Económica para América Latina y el Caribe DANE Departamento Administrativo Nacional de Estadística ENUSC Encuesta Nacional Urbana de Seguridad Ciudadana FCYTE Fundación Española de Ciencia y Tecnología GSBPM [1] Modelo Genérico del Proceso Estadístico IHSN [2] Red Internacional de Encuestas de Hogares INE Instituto Nacional de Estadísticas INEGI Instituto Nacional de Estadística y Geografía MINSEGPRES Ministerio Secretaría General de la Presidencia OCDE Organización para la Cooperación y el Desarrollo Económicos ONE Oficina Nacional de Estadística PITEC Panel de Innovación tecnológica PRAM [3] Método de Post-Aleatorización PUF [4] Archivo de Uso Público RUT Rol Único Tributario ROL Identifica a una propiedad o bien raíz SEN Sistema Estadístico Nacional SDC [5] Control de Divulgación Estadística sdcMicro Paquete de implementación bajo el software R STATCAN [6] Estadísticas de Canadá SUF [7] Archivo de Uso Científico UNECE [8] Comisión Económica de las Naciones Unidas para Europa [1] En inglés, Generic Statistical Business Process Model. [2] En inglés, International Household Survey Network. [3] En inglés, Post Randomization Method. [4] En inglés, Public Use File. [5] En inglés, Statistical Disclosure Control. [6] En inglés, Statistics Canada. [7] En inglés, Scientific Use File. [8] En inglés, United Nations Economic Commission for Europe. 3.2 Glosario Respecto a los términos, conceptos o categorías utilizadas en esta guía se detallan aquellos que son relevantes para la comprensión del subproceso. Tabla 3.2: Glosario de términos y conceptos Término Definición Referencia Adición de ruido Método basado en agregar o multiplicar un número aleatorio a los valores originales para proteger los datos de la coincidencia exacta con archivos externos. La adición de ruido se aplica típicamente a variables continuas. (Benschop and Welch 2021), pág. 9 Anonimización Proceso técnico que consiste en transformar los datos individuales de las unidades de observación, de tal modo que no sea posible identificar sujetos o características individuales de la fuente de información, preservando así las propiedades estadísticas en los resultados. (Instituto Nacional de Estadísticas 2022) Archivo de datos para uso científico Archivo de uso científico (SUF, por su sigla en inglés, Scientific Use File), es un tipo de publicación del archivo de microdatos, que solo está disponible para investigadores seleccionados bajo un acuerdo. También conocido como “archivo con licencia”, “microdatos bajo contrato” o “archivo de investigación”. (Benschop and Welch 2021), pág. 10 Archivo de datos para uso en centro de datos de investigación controlado o enclave Son los archivos que pueden ofrecerse a los usuarios bajo condiciones estrictas en un enclave de datos. Se trata de una sala equipada con computadores que no están conectados a Internet ni a una red externa, y del que no se puede descargar información a través de puertos USB u otras unidades. Los enclaves de datos contienen datos que son particularmente sensibles o permiten la identificación directa o fácil de los informantes. Los ejemplos incluyen conjuntos de datos completos de censos de población, encuestas empresariales, etc. Adaptado de (Benschop and Welch 2021), pág. 20 Archivo de datos para uso público Archivo de uso público (PUF, por sus siglas en inglés, Public Use File), es un tipo de publicación del archivo de microdatos, que está disponible gratuitamente para cualquier usuario, por ejemplo, en el sitio web del INE. (Benschop and Welch 2021), pág. 10 Barajado (En inglés, shuffling) Método que consiste en enmascarar una variable considerada confidencial mediante la generación de una distribución condicional. (Benschop and Welch 2021), pág. 74 Base de datos Una colección lógica de información que está interrelacionada y que se gestiona y almacena como una unidad, por ejemplo, en el mismo archivo informático. (OECD s.f.) Celdas confidenciales Las celdas de una tabla que no son publicables debido al riesgo de divulgación estadística se denominan celdas confidenciales. (OECD s.f.) Clave Combinación o patrón de variables clave o cuasi – identificadores. También, es usado el término llave. (Benschop and Welch 2021), pág. 9 Codificación superior o inferior Corresponde a la agrupación de una variable continua en una categoría en los extremos de los valores posibles que agrupa todos los valores mayores o menores a un número (por ejemplo: valores mayores o iguales a 5 quedarán en la categoría “5 o más” mientras que el resto conserva su valor). Adaptado de (Benschop and Welch 2021), pág. 52 Confidencialidad de los datos Es una propiedad de los datos, generalmente como resultado de medidas legislativas, que previenen su divulgación no autorizada. (OECD s.f.) Control de Divulgación Estadística (SDC) Proceso que busca tratar y alterar los datos para que puedan publicarse o difundirse sin revelar la información confidencial que contiene, mientras que, al mismo tiempo, limitan la pérdida de información debido al anonimato de los datos. En el GSBPM, estos métodos están relacionados con la etapa de difusión y generalmente se basan en restringir la cantidad o modificar los datos publicados. (Australian Bureau of Statistics 2021) Convenio Contrato, convención o acuerdo que se desarrolla en función de un asunto específico destinado a crear, transferir, modificar o extinguir una obligación. - Es un acuerdo de voluntades entre dos o más organismos públicos con personalidad jurídica, sobre cualquier cuestión pendiente de resolver. - Son instrumentos jurídicos, suscritos por dos o más organismos de la Administración del Estado, que tienen por finalidad, comprometer la colaboración mutua entre ellos, dentro de las facultades que la ley les confiere para satisfacer necesidades actuales o futuras y que requieren de su formalización, mediante actos administrativos, para producir efectos jurídicos. Tipos de convenios: 1. Marco: establece las bases para el intercambio de información, mediante convenios específicos. 2. Específico: consiste en la materialización de un convenio marco, y tiene por objeto señalar específicamente las obligaciones de cada parte, detallando los compromisos que adquiere cada institución. Fiscalía INE Datos personales Son datos de carácter personal o datos personales, “los relativos a cualquier información concerniente a personas naturales, identificadas o identificables”. [Ley N° 19628 1999] Datos originales Datos a los que no se les aplica algún método de anonimización. También se denominan “datos brutos” o “datos no tratados”. (Benschop and Welch 2021), pág. 11 Divulgación Se produce cuando una persona u organización reconoce o aprende algo que no sabía sobre otra persona u organización a través de los datos divulgados. Ver también Divulgación de identidad, Divulgación de atributos y Divulgación inferencial. (Benschop and Welch 2021), pág. 9 Divulgación de atributos La divulgación de atributos ocurre cuando un usuario puede determinar nuevas características de un individuo u organización con base en la información disponible en los datos publicados. A este usuario se le denominará intruso, ver intruso. (Benschop and Welch 2021), pág. 8 Divulgación de identidad La divulgación de identidad ocurre cuando un intruso asocia a un individuo (o grupo) u organización conocida, con un registro de datos publicado. (Benschop and Welch 2021), pág. 9 Divulgación inferencial La divulgación inferencial ocurre si un intruso puede determinar, a partir de los datos publicados, el valor de alguna característica de un individuo u organización con mayor precisión que lo pretendido. (Benschop and Welch 2021), pág. 9 Encuesta Investigación sobre las características de una población particular, que utiliza procedimientos estandarizados para recopilar información de la población de estudio (incluidos censos, encuestas de muestra, la recopilación de datos de registros administrativos y actividades estadísticas derivadas) para estimar sus características mediante el uso sistemático de la metodología estadística. (Instituto Nacional de Estadísticas 2022) Escenario de divulgación Describe la información potencialmente disponible para un tercero (por ejemplo: datos del censo, padrones electorales, registro de población, datos recopilados por empresas privadas o incluso datos de encuestas publicadas por el INE), para identificar a los encuestados y las formas en que dicha información se puede combinar con los microdatos establecidos para ser publicados y utilizados para la re-identificación de registros en el conjunto de datos. (Benschop and Welch 2021), págs. 25-26 Estructura jerárquica Datos que se componen de colecciones de registros que están interconectados a través de enlaces, por ejemplo, individuos que pertenecen a grupos/hogares o empleados que pertenecen a empresas. (Benschop and Welch 2021), pág. 9 Identificador Variable/información (o grupo de variables) que puede utilizarse para establecer la identidad de un individuo u organización. Los identificadores pueden conducir a una identificación directa o indirecta. (Benschop and Welch 2021), pág. 9 Identificadores directos Son variables que identifican inequívocamente unidades estadísticas, como, RUT, ROL, número de seguro social, o nombres y direcciones de empresas o personas. Los identificadores directos deben eliminarse como primer paso del proceso de anonimización. (Benschop and Welch 2021), pág. 9 Identificadores indirectos Son variables que, si bien no identifican inequívocamente unidades estadísticas, en combinación se pueden vincular a información externa para re-identificar a los informantes en el conjunto de datos publicado. También se les denomina “cuasi-identificadores” o “variables clave”. (Benschop and Welch 2021), pág. 9 Informante Empresas, autoridades, personas individuales, etc., de quienes se recopilan datos e información asociada para su uso en la compilación de estadísticas. Adaptado de (OECD s.f.) Intervalo Un conjunto de números entre dos cotas designadas que pueden o no estar incluidos (abiertos, semiabiertos o cerrados). Los corchetes (por ejemplo, [0, 1]) denotan un intervalo cerrado, que incluye los puntos finales 0 y 1. Los paréntesis, por ejemplo, (0, 1) denotan un intervalo abierto, que no incluye los puntos finales. Adaptado de (Benschop and Welch 2021), pág. 9 Intruso Usuario que hace mal uso de los datos publicados al tratar de identificar y divulgar información sobre un individuo u organización, utilizando un conjunto de características conocidas por el usuario. (Benschop and Welch 2021), pág. 9 K-anonimato La medida de riesgo -anonimato se basa en el principio de que, en un conjunto de datos seguro, el número de individuos que comparten la misma combinación de valores (claves) de identificadores indirectos categóricos debe ser superior a un umbral especificado . Es una medida de riesgo basada en los microdatos que se liberarán, ya que solo tiene en consideración la muestra. (Benschop and Welch 2021), pág. 28 Metadatos Son datos que entregan la información necesaria para el uso e interpretación adecuada de las estadísticas por parte de las personas usuarias. Los metadatos describen los datos producidos por medio de la documentación de contenidos relacionados, por ejemplo, con la metodología; el trabajo de campo; el procesamiento; análisis y la calidad; entre otros, de una operación estadística particular. Contexto: Generalmente se hace una distinción entre metadatos estructurales y de referencia.​ Los metadatos estructurales se utilizan para identificar y describir formalmente: nombres de dimensiones, diccionarios de variables, descripciones técnicas de conjuntos de datos, ubicaciones de conjuntos de datos, palabras clave para buscar datos, etc​ Los metadatos de referencia (a veces llamados metadatos explicativos) describen los contenidos y la calidad de los resultados estadísticos. Incluye documentación descriptiva sobre el contexto de la información producida, como, por ejemplo, las metodologías para la recolección y análisis de datos, así como características de la calidad y difusión de la operación. (Instituto Nacional de Estadísticas 2022) Métodos determinísticos Métodos que siguen cierto algoritmo y producen los mismos resultados si se aplican repetidamente a los mismos datos con el mismo conjunto de parámetros. (Benschop and Welch 2021), pág. 8 Métodos no perturbativos Métodos que reducen los detalles en los datos o suprimen ciertos valores (enmascaramiento) sin distorsionar la estructura de datos. (Benschop and Welch 2021), pág. 9 Métodos perturbativos Métodos que alteran los valores para limitar el riesgo de divulgación al crear incertidumbre en torno a los valores verdaderos, al tiempo que conservan la mayor cantidad de contenido y estructura posible, por ejemplo, microagregación y adición de ruido. (Benschop and Welch 2021), pág. 9 Métodos probabilísticos Métodos que dependen de un mecanismo de probabilidad o un mecanismo de generación de números aleatorios. Cada vez que se utiliza un método probabilístico se genera un resultado diferente. (Benschop and Welch 2021), pág. 9 Microagregación Método que se basa en la sustitución de valores para una determinada variable con un valor común para un grupo de registros. La agrupación de registros se basa en una medida de proximidad de variables de interés. Los grupos de registros también se utilizan para calcular el valor de reemplazo. (Benschop and Welch 2021), pág. 9 Microdatos Corresponde a los datos sobre las características asociadas a las unidades estadísticas que se encuentran consolidadas en una base de datos. Son observaciones no agregadas o mediciones de las características de la o las unidades estadísticas, siendo la forma primaria en la que se almacenan los datos y que a partir de esta se derivan los resultados. El conjunto de microdatos es uno de los resultados y/o producto de la recolección de datos y del procesamiento de los datos. (Instituto Nacional de Estadísticas 2022) Muestra única Un registro de la muestra con un conjunto particular de características que no se repite en otras observaciones, de modo que el individuo u organización se puede distinguir de otras unidades de la muestra en función de ese conjunto de características. (Benschop and Welch 2021), pág. 10 Operación estadística Aplicación de un conjunto interrelacionado de procesos, que comprende la detección de necesidades, el diseño, construcción, recolección de datos, procesamiento, análisis, difusión y evaluación, lo cual conduce a la obtención de resultados estadísticos sobre un tema de estudio. Contexto: cuando se hace referencia al concepto se deben tener las siguientes consideraciones. • El concepto de operación estadística permite identificar e individualizar un proceso estadístico sobre un tema o ámbito particular; por ejemplo, el Índice de Precios al Consumidor, la Encuesta Nacional de Empleo o el Censo de Población y Viviendas, corresponden a operaciones específicas que se realizan implementando un proceso compuesto por subprocesos, tareas y actividades. • Las operaciones estadísticas que realizan las oficinas estadísticas o unidades del sistema estadístico pueden ser clasificadas y agrupadas por medio de inventarios o catastros permitiendo la coordinación y planificación estadística, los cuales constituyen la base para la formulación de los Planes Nacionales de Recopilación Estadística (PNRE). (Instituto Nacional de Estadísticas 2022) Pérdida de información Se refiere a la reducción del contenido de información en los datos liberados en relación con el contenido de información en los datos sin procesar. A menudo se mide con el uso de medidas analíticas comunes, como regresiones e indicadores. Ver también Utilidad de los datos. (Benschop and Welch 2021), pág. 9 Población única Un registro en la población con un conjunto particular de características que no se repite en la población, de modo que el individuo u organización puede distinguirse de otras unidades de la población en función de ese conjunto de características. (Benschop and Welch 2021), pág. 10 Post Randomization Method (PRAM) Método en el que los puntajes de una variable categórica se alteran de acuerdo con ciertas probabilidades. Por lo tanto, es una clasificación errónea intencional con probabilidades de clasificación errónea conocidas (Benschop and Welch 2021), pág. 10 Privacidad Es un concepto que se aplica a las unidades, mientras que la confidencialidad se aplica a los datos. El concepto se define de la siguiente manera: “Es el estatus otorgado a los datos que ha sido acordado entre la persona u organización que proporciona los datos y la organización que los recibe y que describe el grado de protección que se brindará”. (OECD s.f.) Producto estadístico Resultados físicos o digitales de una operación estadística, en general corresponden a publicaciones de información mediante la presentación de datos y metadatos, que buscan satisfacer las necesidades de la comunidad usuaria. (Instituto Nacional de Estadísticas 2022) Protección de datos Se refiere al conjunto de leyes, políticas y procedimientos motivados por la privacidad que tienen como objetivo minimizar la intrusión en la privacidad de los informantes causada por la recopilación, el almacenamiento y la difusión de datos personales. (OECD s.f.) Recodificación Método en el que se agrupan categorías o valores existentes y se reemplazan con nuevos valores, por ejemplo, las categorías “protestante” y “católico” se reemplazan por “cristiano”. La recodificación reduce los detalles en los datos y, para las variables continuas, conduce a una transformación de continua a categórica, por ejemplo, creando bandas de ingresos. (Benschop and Welch 2021), pág. 10 Registro Un conjunto de datos derivados de un objeto/unidad de estudio, por ejemplo, un individuo (en datos a nivel individual), un hogar (en datos a nivel de hogar) o una empresa (en datos de la empresa). Los registros también se denominan “observaciones”. (Benschop and Welch 2021), pág. 10 Registro administrativo Conjunto de datos recopilados y utilizados para fines administrativos por una entidad pública o privada sobre un tipo de hecho, evento, acción, objeto, sujeto, obtenidos sistemáticamente con base en un formato específico ya sea impreso, digital u otro y dentro del marco de sus atribuciones. Contexto: a modo de ejemplo, se consideran registros administrativos las bases de datos con identificadores únicos asociados a números de identificación personal, números de identificación tributaria u otros, los datos geográficos que permitan identificar o ubicar espacialmente los datos, así como los listados de unidades y transacciones administrados por los integrantes del SEN, así como entidades privadas de interés para las oficinas estadísticas. (Instituto Nacional de Estadísticas 2022) Regresión Proceso estadístico para medir la relación entre el valor medio de una variable y los valores correspondientes de otras variables. (Benschop and Welch 2021), pág. 10 Riesgo de divulgación Se refiere a la probabilidad de que ocurra efectivamente una divulgación de la información confidencial de un informante, o una divulgación exacta con un alto nivel de confianza. Adaptado de (Benschop and Welch 2021), pág. 9 Riesgo global Es una medida sobre todo el conjunto de datos que agrega los riesgos individuales como la proporción esperada de individuos en una muestra que pueden ser correctamente re-identificados por un intruso. Hay que utilizar con cuidado esta medida, ya que puede esconder altos riesgos individuales con un riesgo global aceptable. (Benschop and Welch 2021), pág. 40 Riesgo individual Es la probabilidad de una correcta re-identificación de individuos en los datos divulgados. Adaptado de (Benschop and Welch 2021), pág. 28 Riesgo jerárquico Es la probabilidad de una correcta re-identificación de unidades tomando en cuenta la estructura jerárquica de los datos. La estructura jerárquica de un conjunto de datos puede estar dado por ser miembros de un hogar, trabajadores de una empresa o alumnos de un colegio, entre otros ejemplos, el riesgo entonces tomará en cuenta que si se identifica algún miembro de este hogar, empresa o colegio puede que se identifique al resto de sus miembros. Adaptado de (Benschop and Welch 2021), pág. 41 sdcMicro Un paquete basado en R creado por Templ, M., Kowarik, A. y Meindl, B. con herramientas para la anonimización de microdatos, es decir, para la creación de archivos de uso público y científico con cierto estándar de anonimato en las observaciones. (Benschop and Welch 2021), pág. 11 Supresión de datos La supresión de datos implica no divulgar información que se considera insegura porque no se aplican las reglas de confidencialidad. A veces esto se hace reemplazando valores que significan atributos individuales con valores faltantes (por ejemplo, pasando del nivel de ingresos de un hogar a un “missing” o “sin dato” para proteger la identidad del hogar). En el contexto de esta guía, generalmente para lograr el nivel deseado de k – anonimato. (Benschop and Welch 2021), pág. 11 Tabulados Expresión gráfica que sintetiza un valor o estimación producto del cruce entre dos o más variables. [Instituto Nacional de Estadísticas 2020] pág. 60 Técnicas de control de divulgación estadística Se pueden definir como el conjunto de métodos para reducir el riesgo de divulgar información sobre personas, empresas u otras organizaciones. Dichos métodos solo están relacionados con el paso de difusión y generalmente se basan en restringir la cantidad o modificar los datos publicados. (OECD s.f.) Umbral de riesgo Nivel, valor, margen o punto establecido a partir del cual se produce la identificación de unidades. Si no es seguro, se deberán tomar medidas adicionales para reducir el riesgo de identificación. (Benschop and Welch 2021), pág. 11 Unidad de observación Unidad identificable sobre la que se obtiene información (o son informados), registran y compilan datos estadísticos. (Instituto Nacional de Estadísticas 2022) Usuario final El usuario del archivo de microdatos liberado después de la anonimización. Adaptado de (Benschop and Welch 2021), pág. 9 Utilidad de los datos Describe el valor de una publicación de datos determinada como recurso analítico. Esto comprende la integridad analítica de los datos y su validez analítica. Los métodos de control de divulgación suelen tener un efecto adverso en la utilidad de los datos. Idealmente, el objetivo de cualquier régimen de control de divulgación debería ser maximizar la utilidad de los datos al tiempo que se minimiza el riesgo de divulgación. En la práctica, las decisiones de control de divulgación son una compensación entre la utilidad y el riesgo de divulgación. (OECD s.f.) Valor atípico Un valor inusual que se informa correctamente pero que no es típico del resto de la población. Los valores atípicos (outliers, en inglés) también pueden ser observaciones con una combinación inusual de valores para variables, como la viuda de 20 años. En su propia edad, 20 y viuda no son valores inusuales, pero su combinación puede serlo. (Benschop and Welch 2021), pág. 10 Variable Cualquier característica, número o cantidad que se puede medir o contar para cada unidad de observación. (Benschop and Welch 2021), pág. 11 Variable categórica Una variable discreta que toma valores sobre un conjunto finito, por ejemplo, sexo representado por los números 1 o 0 para hombre y mujer. También llamado factor en R. (Benschop and Welch 2021), pág. 8 Variable continua Una variable que puede tomar valores sobre un conjunto denso. Ejemplos son los ingresos, la altura del cuerpo y el tamaño de la parcela. Adaptado de (Benschop and Welch 2021), pág. 8 Variables de no identificación Son variables que no pueden utilizarse para la re-identificación de los informantes o fuentes. Esto podría deberse a que estas variables no están contenidas en ningún otro archivo de datos u otra fuente externa. Estas variables son importantes en el procedimiento del control a la divulgación, ya que pueden contener variables sensibles. (Benschop and Welch 2021), pág. 24 Variable factor Son una forma de clasificar variables categóricas en factores, que pueden ser ordenadas o no. (Benschop and Welch 2021), pág. 9 Variable semicontinua (discreta) Es una variable que toma valores contenidos en un conjunto discreto. Un ejemplo es la edad medida en años, que podría tomar valores en el conjunto {0, 1, . . ., 100}. La naturaleza finita de los valores para estas variables significa que pueden tratarse como variables categóricas a los efectos de SDC. Adaptado de (Benschop and Welch 2021), pág. 24 Variable sensible Variable contenida en un registro de datos, además de las variables clave, que pertenecen al dominio privado de los informantes que no quisieran que se divulgaran. Algunos datos son claramente sensibles, como la posesión de antecedentes penales o la condición médica, pero hay otros casos en los que la distinción depende de las circunstancias, por ejemplo, los ingresos de una persona pueden considerarse como una variable sensible en algunos países. La determinación de variables sensibles a menudo está sujeta a preocupaciones legales y éticas. (OECD s.f.) Referencias "],["tipos-de-liberación-de-datos.html", "Capítulo 4 Tipos de liberación de datos 4.1 Condiciones para la liberación de datos bajo versión PUF", " Capítulo 4 Tipos de liberación de datos Esta sección expone sobre la liberación de microdatos, cuyos lineamientos se extrajeron de la guía elaborada por el Banco Mundial (Benschop and Welch 2021), que a su vez recoge el trabajo conjunto realizado por el Banco Mundial y sus socios en la Red Internacional de Encuestas de Hogares IHSN1 (Dupriez and Boyko 2010). El balance entre riesgo y utilidad en el proceso SDC depende en gran medida de quiénes son los usuarios y bajo qué condiciones se difunde o libera un archivo de microdatos. En general, se practican tres tipos de métodos de liberación de datos para diferentes grupos objetivo, a saber: archivo de uso público (PUF), archivo de uso científico (SUF) y enclave de datos. En la Tabla 4.1 se resumen los tipos de liberación y su aplicabilidad en el INE, dado el marco legal vigente en Chile. Como se podrá observar, el tipo PUF es el único tipo de liberación de microdatos que es aplicable para el INE dado el marco legal vigente en Chile. Tabla 4.1: Resumen de tipos de liberación de microdatos Tipo Descripción Aplicabilidad con el marco legal vigente Archivo de Uso Público (PUF) Los datos están disponibles directamente para cualquier persona interesada, por ejemplo, en el sitio web del INE. Estos datos se hacen fácilmente accesibles debido a que los riesgos de identificar a las unidades individuales se consideran mínimos. En el contexto INE, el PUF se puede entregar a nivel de microdatos mediante las siguientes formas: i. Base de datos publicadas (BP) que se dispone en la página web del INE y en la página web de la institución demandante, según corresponda. ii. Base de datos a solicitar por transparencia (BST) que se entrega directamente al usuario responsable de la solicitud. Aplicable. Archivo de Uso Científico (SUF) La difusión está restringida a los usuarios que han recibido autorización para acceder a ellos después de enviar una solicitud documentada y firmar un acuerdo que rige el uso de los datos. Si bien los archivos con licencia general también se anonimizan para garantizar que el riesgo de identificar a las unidades (personas, hogares o establecimientos) se minimice cuando se usan de forma aislada, aún pueden (potencialmente) contener datos identificables si se vinculan con otros archivos de datos. Este tipo de liberación de datos también es conocido como archivo con licencia, microdatos bajo contrato o archivo de investigación. No aplicable. Enclave de datos o centro de datos de investigación controlado Algunos archivos pueden ofrecerse a los usuarios bajo condiciones estrictas en un enclave de datos. Esta es una instalación (puede ser una instalación al interior del INE) equipada con computadoras que no están conectadas a Internet o una red externa y desde las cuales no se puede descargar información a través de puertos USB, CD – DVD u otras unidades. Los enclaves de datos contienen datos que son particularmente sensibles o permiten la identificación directa o fácil de los informantes. No aplicable. 4.1 Condiciones para la liberación de datos bajo versión PUF En general, los datos que se consideran públicos están abiertos a cualquier persona con acceso al sitio web del INE. Sin embargo, es una buena práctica incluir declaraciones de principios que definan los usos adecuados y las precauciones que se adoptarán utilizando los datos. Si bien estos pueden no ser legalmente vinculantes, sirven para sensibilizar al usuario. Prohibiciones como intentos de vincular los datos a otras fuentes puede ser parte de la “declaración de uso”, requerida para el uso de datos. La difusión de archivos de microdatos implica necesariamente la aplicación de reglas o principios. A continuación, se listan principios básicos o “declaraciones de uso” aplicables a una liberación PUF: Los datos y otros materiales proporcionados por el INE no serán redistribuidos o vendidos a otras personas, instituciones u organizaciones sin el acuerdo por escrito del INE. Los datos se usarán solo para fines de investigación estadística y científica. Serán empleados únicamente para reportar información agregada, incluido el modelado, y no para investigar individuos u organizaciones específicos. No se intentará volver a identificar a los informantes, y no se usará la identidad de ninguna persona o establecimiento descubierto inadvertidamente. Cualquier descubrimiento de este tipo se informará inmediatamente al INE. No se intentará crear enlaces entre conjuntos de datos proporcionados por el INE o entre datos del INE y otros conjuntos de datos que podrían identificar individuos u organizaciones. Libros, artículos, documentos de conferencias, tesis, disertaciones, informes u otras publicaciones que empleen datos obtenidos del INE citará la fuente, de acuerdo con el requisito de cita provisto con el conjunto de datos, en caso de no haber sido proporcionado, se debe citar de acuerdo a la norma APA más actualizada. Se enviará al INE una copia electrónica de todas las publicaciones basadas en los datos descargados. El recolector original de los datos, el INE y las agencias de financiamiento relevantes no tienen responsabilidad por el uso o interpretación de los datos o inferencias basadas en ellos. Nota: Los puntos 3 y 6 de la lista requieren que los usuarios reciban una manera fácil de comunicarse con el INE. Es una buena práctica proporcionar un número de contacto, una dirección de correo electrónico y, posiblemente, un sistema de “suministro de comentarios” en línea. Referencias "],["proceso-sdc-una-introducción.html", "Capítulo 5 Proceso SDC: Una introducción 5.1 Necesidad por control de divulgación estadística (proceso SDC) 5.2 Balance riesgo-utilidad en el proceso SDC", " Capítulo 5 Proceso SDC: Una introducción 5.1 Necesidad por control de divulgación estadística (proceso SDC) La protección de la confidencialidad ha sido una preocupación de las Oficinas Nacionales de Estadísticas (ONE), lo que ha sido foco de atención recientemente, esto debido a que en las últimas décadas se ha experimentado un avance tecnológico importante, junto con el desarrollo de técnicas de re-identificación, por ejemplo, basado en machine learning. Por lo tanto, proteger los datos personales de los informantes y resguardar la vida personal se hace un imperativo (Yazdani 2015). Por esta razón, hoy en día, resolver la tensión entre la protección de la información personal y el suministro de datos es realmente un desafío que deben asumir las ONE. En esta situación, tres motivaciones empujan a las ONE a preservar la confidencialidad. El primer motivo para mantener la confidencialidad proviene del cumplimiento del marco normativo entre los cuales se establecen las funciones de la ONE. Existe una obligación legal y ética de los productores para garantizar que los datos proporcionados por los informantes se utilicen únicamente con fines estadísticos. La ONE debe respetar la confianza de los informantes, cuidar su privacidad y mantenerlos alejados de cualquier daño que pueda surgir de la información que han proporcionado. La ONE debe velar por resguardar el cumplimiento del marco normativo y las normas éticas. El segundo motivo subyace en el deseo de la ONE de obtener la cooperación de los informantes y obtener datos más precisos. Los informantes que confían que su información permanecerá confidencial tienen más probabilidades de participar en la encuesta y reportar con precisión su información privada. Cualquier duda sobre la confidencialidad puede reducir la disposición de los posibles informantes a cooperar en una encuesta y puede afectar la calidad de las respuestas (Yazdani 2015). El último motivo es la obligación impuesta a la ONE por la legislación vigente, así como por compromisos internacionales. La fuerza de la sociedad sobre los gobiernos ha llevado al establecimiento de entornos legales para salvaguardar la privacidad y la ONE está mandada a respetar estas restricciones legales (Duncan, Elliot, and Salzar-González 2011). Además, como lo aprobó por unanimidad la Asamblea General de las Naciones Unidas en enero de 2014, el principio 6 de los Principios Fundamentales de las Estadísticas Oficiales postula que “Los datos individuales que reúnan los organismos de estadística para la compilación estadística, se refieran a personas naturales o jurídicas, deben ser estrictamente confidenciales y utilizarse exclusivamente para fines estadísticos”. Los motivos señalados anteriormente son de naturaleza moral, ética y legal. El proceso SDC busca tratar y procesar los datos individuales para que cumplan el marco normativo y así, puedan publicarse o difundirse respetando el secreto estadístico, pero al mismo tiempo, controlar la pérdida de información debido al tratamiento de los datos. El objetivo de anonimizar los microdatos es transformar los conjuntos de datos para lograr un “nivel aceptable” de riesgo de divulgación. El nivel de aceptabilidad del riesgo de divulgación y la necesidad de anonimización generalmente quedan a discreción del productor de datos y guiado por la legislación. Estos se formulan en las políticas y programas de difusión de los proveedores de datos y se basan en consideraciones que incluyen “[. . .] los costos y la experiencia involucrados; cuestiones de calidad de los datos, posible uso indebido y malentendidos de los datos por parte de los usuarios; asuntos legales y éticos; y mantener la confianza y el apoyo de los encuestados”(Benschop, Machingauta, and Welch 2021, 33). 5.2 Balance riesgo-utilidad en el proceso SDC Por otra parte, el proceso SDC se caracteriza por el balance entre el riesgo de divulgación y la utilidad de los datos para los usuarios finales. La escala riesgo-utilidad se extiende entre dos extremos: No se difunden datos (riesgo cero de divulgación) y, por lo tanto, los usuarios no obtienen ninguna utilidad de los datos, Los datos se difunden sin ningún tratamiento y, por lo tanto, con el máximo riesgo de divulgación, pero con la máxima utilidad para el usuario (es decir, sin pérdida de información). El objetivo de un proceso SDC bien implementado es encontrar el punto óptimo en el que la utilidad para los usuarios finales se maximice a un nivel de riesgo aceptable. En el balance entre Riesgo y Utilidad que se muestra en la Figura 5.1, por un extremo, el triángulo corresponde a los datos sin procesar, los que no tienen pérdida de información, pero generalmente tienen un riesgo de divulgación más alto que el nivel aceptable. El otro extremo es el cuadrado, que corresponde a la no publicación de datos. En ese caso, no hay riesgo de divulgación, pero tampoco hay utilidad de los datos para los usuarios. Los puntos intermedios corresponden a diferentes opciones de métodos SDC y/o parámetros aplicados a diferentes variables. El proceso SDC busca métodos y parámetros, que son aplicados de una manera que produce una reducción del riesgo de forma muchas veces satisfactoria, minimizándose generalmente la pérdida de información. Figura 5.1: Balance Riesgo-Utilidad en un conjunto de datos. Imagen extraída de (Benschop, Machingauta, and Welch 2021, 15). El proceso SDC no puede lograr la eliminación total del riesgo, pero puede reducir el riesgo a un nivel aceptable. Cualquier aplicación de métodos SDC suprimirá o alterará los valores en los datos y, como tal, disminuirá la utilidad (es decir, dará como resultado una pérdida de información) en comparación con los datos originales. Un hilo común que se enfatizará a lo largo de esta guía será que el proceso SDC debe priorizar el objetivo de proteger a los informantes y, al mismo tiempo, tener en cuenta a los usuarios de datos para limitar la pérdida de información. En general, cuanto menor es el riesgo de divulgación, mayor es la pérdida de información y menor es la utilidad de los datos para los usuarios finales. En la práctica, la elección de métodos SDC es un proceso iterativo: después de aplicar los métodos, el riesgo de divulgación y la utilidad de datos se vuelven a medir y se comparan con los resultados de otros métodos SDC y parámetros aplicados. Si el resultado es satisfactorio, los datos pueden ser liberados. Como se verá más adelante, a menudo el primer intento no será el óptimo. El riesgo puede no ser reducido lo suficiente o la pérdida de información puede ser demasiado alta y el proceso debe repetirse con diferentes métodos o parámetros hasta que se encuentre una solución satisfactoria. El riesgo de divulgación, la utilidad de los datos y la pérdida de información en el contexto de proceso SDC y cómo medirlos se analizan en capítulos posteriores de esta guía. Nuevamente, debe enfatizarse que el nivel de SDC y los métodos aplicados dependen en gran medida de todo el marco de publicación de datos. Por ejemplo, una consideración clave es a quién y bajo qué condiciones se liberarán los datos (ver sección Tipos de liberación de datos). Si los datos se van a difundir como datos de uso público, entonces el nivel de SDC aplicado solo tendrá que ser mayor que en los casos en que los datos se difundan bajo condiciones de licencia a usuarios confiables, después de un examen cuidadoso 2 . Se discutirá cómo se podría lograr esto más adelante en la guía. Esto ha dispuesto que entidades internacionales desarrollen diferentes técnicas de anonimización, que se ajustan a diferentes tipos de datos, consiguiendo de mejor manera resguardar la calidad de ellos. El INE, igualmente deberá tener en cuenta este balance al publicar sus datos, velando porque se ponga a disposición de la ciudadanía información de la mayor calidad posible, cumpliendo el marco normativo relativo a la protección de datos, manteniendo así la confianza de los informantes. Referencias "],["introducción-a-sdcmicro.html", "Capítulo 6 Introducción a sdcMicro 6.1 Introducción 6.2 Instalación de R, sdcMicro y otros paquetes 6.3 Leer funciones en R 6.4 Valores faltantes 6.5 Clases en R 6.6 Objetos de la clase sdcMicroObj 6.7 Estructura del hogar 6.8 Tiempo de cómputo 6.9 Errores comunes", " Capítulo 6 Introducción a sdcMicro 6.1 Introducción El paquete R sdcMicro Templ, Kowarik, and Meindl (2015) sirve para evaluar y anonimizar conjuntos de microdatos confidenciales, facilita el manejo de métodos SDC mediante una implementación de clase S4 orientada a objetos. Incluye todos los métodos populares de perturbación y riesgo de divulgación. El paquete realiza un nuevo cálculo automático de recuentos de frecuencia, medidas de riesgo individuales y globales, pérdida de información y estadísticas de utilidad de datos después de cada paso de anonimización. Todos los métodos están altamente optimizados en términos de costos computacionales para poder trabajar con grandes conjuntos de datos. Los profesionales también pueden utilizar fácilmente las funciones de generación de informes que resumen el proceso de anonimización. Describimos el paquete y demostramos su funcionalidad con un complejo conjunto de datos de prueba procedente de encuestas de hogares, que ha sido distribuido por la Red Internacional de Encuestas de Hogares. Para más información ver https://cran.r-project.org/web/packages/sdcMicro/sdcMicro.pdf 6.2 Instalación de R, sdcMicro y otros paquetes Esta guía se basa en el paquete de software sdcMicro, que es un paquete adicional para el lenguaje de programación estadístico R. Tanto R como sdcMicro, así como otros paquetes de R, están disponibles gratuitamente en el sitio web de CRAN (Comprehensive R Archive Network) para Linux, Mac y Windows (http://cran.r-project.org ). Este sitio web también ofrece descripciones de paquetes. Además de la versión estándar de R, existe una interfaz de usuario más fácil de usar para R: RStudio. RStudio también está disponible gratuitamente para Linux, Mac y Windows (http://www.rstudio.com ). El paquete sdcMicro tiene dependencia de otros paquetes R que deben instalarse en su computadora antes de usar sdcMicro. Se instalarán automáticamente al instalar sdcMicro. Para algunas funcionalidades, usamos otros paquetes (como foreign para leer datos y algunos paquetes gráficos). Si es así, esto se indica en la sección correspondiente de esta guía. R, RStudio, el paquete sdcMicro y sus dependencias y otros paquetes tienen actualizaciones periódicas. Se recomienda encarecidamente comprobar periódicamente si hay actualizaciones: esto requiere instalar una nueva versión para una actualización de R; con el comando update.packages() o usando las opciones de menú en R o RStudio se pueden actualizar los paquetes instalados. Al iniciar R o RStudio, es necesario especificar cada vez qué paquetes se están utilizando cargándolos. Esta carga de paquetes se puede realizar con la función library() o require(). Ambas opciones se ilustran en el Bloque 6.1. Bloque 6.1 Cargando paquetes requeridos library(sdcMicro) # cargando paquete sdcMicro require(sdcMicro) # cargando paquete sdcMicro Todos los paquetes y funciones están documentados. La forma más fácil de acceder a la documentación de una función específica es usar la ayuda integrada, que generalmente brinda una descripción general de los parámetros de las funciones, así como algunos ejemplos. La ayuda de una función específica se puede llamar con un signo de interrogación seguido del nombre de la función sin ningún argumento. El Bloque 6.2 muestra cómo llamar al archivo de ayuda para la función microaggregation() del paquete sdcMicro 3. La página de descarga de cada paquete en el sitio web de CRAN también proporciona un manual de referencia con una descripción completa de las funciones del paquete. Bloque 6.2 Visualización de ayuda para funciones ?microaggregation # ayuda para la función microagregación Cuando se encuentran problemas o errores en el paquete sdcMicro, se pueden publicar comentarios o sugerencias para los desarrolladores de sdcMicro en su GitHub (https://github.com/sdcTools/sdcMicro/issues). 6.3 Leer funciones en R El primer paso en el proceso SDC cuando se usa sdcMicro es leer los datos en R y crear un marco de datos4 R es compatible con la mayoría de los formatos de datos estadísticos y proporciona funciones de lectura para la mayoría de los tipos de datos. Para esas funciones de lectura, a veces es necesario instalar paquetes adicionales y sus dependencias en R. En la Tabla 6.1 se proporciona una descripción general de los formatos de datos, las funciones y los paquetes que contienen estas funciones . Estas funciones también están disponibles como escritura (por ejemplo, write_dta()) para guardar los datos anónimos en el formato requerido 5. Tabla 6.1: Paquetes y funciones para lectura de datos en R Tipo/software Extensión Paquete Función SPSS .sav haven read_sav() STATA (v.5-14) .dta haven read_dta() SAS .sas7bdat haven read_sas() Excel .csv utils (paquete base) read_csv() Excel .xls/.xlsx readxl read_xlsx() La mayoría de estas funciones tienen opciones que especifican cómo manejar los valores faltantes y las variables con niveles de factor y etiquetas de valor. El Bloque 6.3, el Bloque 6.4 y el Bloque 6.5 proporcionan código de ejemplo para leer un archivo STATA (.dta), un archivo de valores separados por ; (.csv) y un archivo SPSS (.sav), respectivamente. Bloque 6.3 Lectura en un archivo STATA setwd(&quot;../Capacitación/GitHub&quot;) # directorio de trabajo fname = &quot;data.dta&quot; # nombre del archivo library(haven) # carga el paquete requerido para la función de lectura/escritura # para archivos STATA file &lt;- read_dta(fname) # lee los datos en el marco de datos tbl llamado file Bloque 6.4 Lectura en un archivo csv setwd(&quot;../Capacitación/GitHub&quot;) # directorio # de # trabajo fname = &quot;data.csv&quot; # nombre del archivo file &lt;- read.csv(fname, header = TRUE, sep = &quot;;&quot;, dec = &quot;.&quot;) # lee los datos hacia un dataframe llamado file, # la primera línea contiene los nombres de las variables, # campos son separados con comas, posiciones decimales se indican con ‘;’ Bloque 6.5 Lectura en un archivo SPSS setwd(&quot;../Capacitación/GitHub&quot;) # directorio # de # trabajo fname = &quot;data.sav&quot; # nombre del archivo library(haven) # carga paquete requerido para la función lectura/escritura # para archivos SPSS file &lt;- read_sav(fname) # lee los datos hacia un dataframe llamado file El tamaño máximo de datos en R está técnicamente restringido. El tamaño máximo depende de la versión R (32 o 64 bits) y del sistema operativo. Algunos métodos SDC requieren largos tiempos de cálculo para grandes conjuntos de datos (consulte la Sección Tiempo de cómputo). 6.4 Valores faltantes La forma estándar en que los valores faltantes se representan en R es mediante el símbolo NA, que es diferente a los valores imposibles, como la división por cero o el logaritmo de un número negativo, que se representan con el símbolo NaN. El valor NA se usa tanto para variables numéricas como categóricas6. Los valores suprimidos por la rutina localSuppression() también se reemplazan por el símbolo NA. Algunos conjuntos de datos y software estadístico pueden usar diferentes valores para los valores faltantes, como ‘999’ o cadenas. Es posible incluir argumentos en las funciones de lectura para especificar cómo se deben tratar los valores faltantes en el conjunto de datos y recodificar automáticamente los valores faltantes a NA. Por ejemplo, la función read.table() tiene el argumento na.strings, que reemplaza las cadenas especificadas con valores NA. Los valores faltantes también se pueden recodificar después de leer los datos en R. Esto puede ser necesario si hay varios códigos de valores perdidos diferentes en los datos, códigos de valores perdidos diferentes para diferentes variables o la función de lectura para el tipo de datos no permite especificar los códigos de valores perdidos. Al preparar los datos, es importante volver a codificar cualquier valor faltante que no esté codificado como NA a NA en R antes de iniciar el proceso de anonimización para garantizar la medición correcta del riesgo (por ejemplo, k-anonimato), así como para asegurar que muchos de los métodos se aplican correctamente a los datos. El Bloque 6.6 muestra cómo recodificar el valor ‘99’ a NA para la variable “TOILET”. Bloque 6.6 Recodificación de valores perdidos a NA file[file[,&#39;TOILET&#39;] == 99,&#39;TOILET&#39;] &lt;- NA # Recodificar el código de valor faltante 99 a NA para la variable TOILET 6.5 Clases en R Todos los objetos en R son de una clase específica, como un número entero, un carácter, una matriz, un factor o un marco de datos. La clase de un objeto es un atributo que hereda de la clase base, haciéndolo miembro e instancia de esta clase. Para averiguar la clase de un objeto, se puede utilizar la función class(). Las funciones en R pueden requerir objetos o argumentos de ciertas clases o funciones que pueden tener una funcionalidad diferente según la clase del argumento. Algunos ejemplos son las funciones de escritura que requieren marcos de datos y la mayoría de las funciones en el paquete sdcMicro que requieren marcos de datos u objetos sdcMicro. La funcionalidad de las funciones en el paquete sdcMicro difiere para marcos de datos y objetos sdcMicro. Es fácil cambiar el atributo de clase de un objeto con funciones que comienzan con “as.”, seguido del nombre de la clase (por ejemplo, as.factor(), as.matrix(), as.data.frame()). El Bloque 6.7 muestra cómo verificar la clase de un objeto y cambiar la clase a “data.frame”. Antes de cambiar el atributo de clase del objeto “file”, estaba en la clase “matrix”. Una clase importante definida y utilizada en el paquete sdcMicro es la clase denominada sdcMicroObj. Esta clase se describe en la siguiente sección. Bloque 6.7 Cambiando la clase de un objeto en R # Averiguar la clase del objeto &#39;file&#39; class(file) &quot;matrix&quot; # Cambiar la clase al marco de datos (data frame) file &lt;- as.data.frame(file) # Comprobando la clase del resultado (file) &quot;data.frame&quot; 6.6 Objetos de la clase sdcMicroObj El paquete sdcMicro se basa en objetos 7 de la clase sdcMicroObj, una clase especialmente definida para el paquete sdcMicro. Cada componente de esta clase tiene una estructura determinada con elementos que contienen información sobre el proceso de anonimización (consulte la Tabla 6.2 para obtener una descripción de todos los elementos o propiedades (slots, en inglés)). Antes de evaluar el riesgo y la utilidad y aplicar métodos SDC, se recomienda crear un objeto de clase sdcMicro. Todos los ejemplos de esta guía se basan en estos objetos. La función utilizada para crear un objeto sdcMicro es createSdcObj(). La mayoría de las funciones en el paquete sdcMicro, como microaggregation() o localSuppression(), usan automáticamente la información requerida (por ejemplo, identificadores indirectos, pesos de muestra) del objeto sdcMicro si se aplica a un objeto de clase sdcMicro. Los argumentos de la función createSdcObj() permiten especificar el archivo de datos original y categorizar las variables en este archivo de datos antes del inicio del proceso de anonimización. En el Bloque 6.8, mostramos todos los argumentos de la función createSdcObj(), y primero definimos vectores con los nombres de las diferentes variables. Esta práctica brinda una mejor visión general y luego permite cambios rápidos en las opciones de variables si es necesario. Elegimos los identificadores indirectos categóricos (keyVars); las variables vinculadas a los identificadores indirectos categóricos que necesitan el mismo patrón de supresión (ghostVars, consulte la sección Supresión local); los identificadores indirectos numéricos (numVars); las variables seleccionadas para aplicar PRAM (pramVars); una variable con pesos muestrales (weightVar); el identificador de agrupación (hhId, por ejemplo, un identificador de hogar, consulte la sección Riesgo jerárquico (o del hogar)); una variable que especifica los estratos (strataVar) y las variables sensibles especificadas para el cálculo de l-diversity (sensibleVar, consulte la sección l-diversity). La mayoría de los métodos SDC en el paquete sdcMicro se aplican automáticamente dentro de los estratos, si se especifica el argumento ‘strataVar’. Los ejemplos son la supresión local y PRAM. No se deben especificar todas las variables, por ejemplo, si no hay una estructura jerárquica (hogar), se puede omitir el argumento ‘hhId’. Los nombres de las variables corresponden a los nombres de las variables en el marco de datos que contiene los microdatos a anonimizar. La selección de variables es importante para las medidas de riesgo que se calculan automáticamente. Además, varios métodos se aplican por defecto a todas las variables de un tipo, por ejemplo, microagregación a todas las variables clave 8. Después de seleccionar estas variables, podemos crear el objeto sdcMicro. Para obtener un resumen del objeto, es suficiente escribir el nombre del objeto. Bloque 6.8 Seleccionando variables y creando un objeto de clase sdcMicroObj para el proceso SDC en R # Seleccionar variables para crear objeto sdcMicro # Selección de variables categóricas selectedKeyVars &lt;- c(&#39;URBRUR&#39;, &#39;REGION&#39;, &#39;HHSIZE&#39;) # Variables clave continuas selectedNumVar &lt;- c(&#39;TANHHEXP&#39;, &#39;INCTOTGROSSHH&#39;) # PRAM variables selectedPramVars &lt;- c(&#39;ROOF&#39;, &#39;TOILET&#39;, &#39;WATER&#39;, &#39;ELECTCON&#39;, &#39;FUELCOOK&#39;, &#39;OWNMOTORCYCLE&#39;, &#39;CAR&#39;, &#39;TV&#39;, &#39;LIVESTOCK&#39;) # Peso del hogar selectedWeightVar &lt;- c(&#39;WGTPOP&#39;) # Creando el objeto sdcMicro con las variables asignadas sdcInitial &lt;- createSdcObj(dat = file, keyVars = selectedKeyVars, numVar = selectedNumVar, weightVar = selectedWeightVar, pramVars = selectedPramVars) # Resumen del objeto sdcInitial ## --------------------------------------------------------------------------- La Tabla 6.2 presenta los nombres de los elementos y sus respectivos contenidos. Los nombres de los elementos se pueden listar usando la función slotNames(), que se ilustra en el Bloque 6.9. Algunos espacios se llenan solo después de aplicar ciertos métodos, por ejemplo, evaluar una medida de riesgo específica. Se puede acceder a ciertos elementos de los objetos mediante funciones de acceso (por ejemplo, extractManipData para extraer los datos anónimos) o funciones de impresión (por ejemplo, print()) con los argumentos apropiados. También se puede acceder directamente al contenido de un espacio con el operador ‘@’ y el nombre del espacio. Esto se ilustra para el elemento o atributo de riesgo en el Bloque 6.9. Esta funcionalidad puede ser práctica para guardar resultados intermedios y comparar los resultados de diferentes métodos. Además, para cambios manuales en los datos durante el proceso SDC, como cambiar códigos de valores faltantes o recodificación manual, es útil el acceso directo de los datos en los elementos o propiedades con los datos manipulados (es decir, nombres de elemento que comienzan con ‘manip’). Dentro de cada elemento generalmente hay varios elementos. Sus nombres se pueden mostrar con la función names() y se puede acceder a ellos con el operador ‘$’. Esto se muestra para el elemento con el riesgo individual en el elemento de riesgo. Bloque 6.9 Visualización de nombres de elementos o propiedades y acceso a elementos o propiedades de un objeto S4 # Lista de todos los slots de objeto sdcMicro slotNames(sdcInitial) # Accediendo al slot de riesgos sdcInitial@risk # Lista de nombres dentro del slot de riesgo names(sdcInitial@risk) ## [1] &quot;global&quot; &quot;individual&quot; &quot;numeric&quot; # Dos formas de acceder al riesgo individual dentro del slot de riesgo sdcInitial@risk$individual get.sdcMicroObj(sdcInitial, &quot;risk&quot;)$individual Tabla 6.2: Nombres de elementos o propiedades y descripción de los elementos o propiedades del objeto sdcMicro Nombre de elemento Contenido origData datos originales como se especifica en el argumento dat de la función createSdcObj(). keyVars índices de columnas en origData con variables clave categóricas especificadas. pramVars índices de columnas en origData con variables PRAM especificadas. numVars índices de columnas en origData con variables clave numéricas especificadas. ghostVars índices de columnas en origData con ghostVars especificados. weightVar índices de columnas en origData con variable de peso especificada. hhId índices de columnas en origData con variable de clúster especificada. strataVar índices de columnas en origData con variable de estratos especificada. sensibleVar índices de columnas en origData con variables sensibles especificadas para l-diversity. manipKeyVars variables clave categóricas manipuladas después de aplicar métodos SDC (ver elemento keyVars). manipPramVars variables PRAM manipuladas después de aplicar PRAM (ver elemento pramVars). manipNumVar variables clave numéricas manipuladas después de aplicar métodos SDC (ver elemento numVars). manipGhostVars variables fantasma manipuladas (ver elemento ghostVars). manipStrataVar variables de estratos manipulados (ver elemento strataVar). originalRisk medidas de riesgo globales e individuales antes de la anonimización. risk medidas de riesgo global e individual después de la aplicación de métodos SDC. utility medidas de utilidad (il1 y eigen). pram detalles sobre PRAM después de aplicar PRAM. localSuppression número de supresión por variable después de la supresión local. options opciones especificadas. additionalResults resultados adicionales. set lista de elemento actualmente en uso (para uso interno). prev información para deshacer un paso con la función undo(). deletedVars variables eliminadas (identificadores directos). Hay dos opciones para guardar los resultados después de aplicar los métodos SDC: Sobrescribir el objeto sdcMicro existente, o creando un nuevo objeto sdcMicro. El objeto original no se modificará y se puede utilizar para comparar resultados. Esto es especialmente útil para comparar varios métodos y seleccionar la mejor opción. En ambos casos, el resultado de cualquier función debe reasignarse a un objeto con el operador ‘&lt;-’. Ambos métodos se ilustran en el Bloque 6.10. Bloque 6.10 Guardado de resultados de la aplicación de métodos SDC # Aplicar supresión local y reasignar los resultados al mismo objeto sdcMicro sdcInitial &lt;- localSuppression(sdcInitial) # Aplicar supresión local y asignar los resultados a un nuevo objeto sdcMicro sdc1 &lt;- localSuppression(sdcInitial) Si los resultados se reasignan al mismo objeto sdcMicro, es posible deshacer el último paso del proceso SDC. Esto es útil al cambiar los parámetros. Sin embargo, los resultados del último paso se pierden después de deshacer ese paso. La función undolast() se puede usar para retroceder solo un paso, no varios. El resultado también debe ser reasignado al mismo objeto. Esto se ilustra en el Bloque 6.11. Bloque 6.11 Deshacer último paso en proceso SDC # Deshacer el último paso en el proceso SDC sdcInitial &lt;- undolast(sdcInitial) 6.7 Estructura del hogar Si los datos tienen una estructura jerárquica y algunas variables se miden en el nivel jerárquico más alto y otras en el nivel más bajo, el proceso SDC debe adaptarse en consecuencia (véanse también la sección Riesgo jerárquico (o del hogar)). Un ejemplo común en los datos de encuestas sociales son los conjuntos de datos con una estructura de hogar. Las variables que se miden a nivel del hogar son, por ejemplo, los ingresos del hogar, el tipo de vivienda y la región. Las variables medidas a nivel individual son, por ejemplo, la edad, el nivel educativo y el estado civil. Algunas variables se miden a nivel individual, no obstante, son las mismas para todos los miembros del hogar en casi todos los hogares. Estas variables deben ser tratadas como medidas a nivel de hogar desde la perspectiva del SDC. Un ejemplo es la variable religión para algunos países. El proceso SDC debe dividirse en dos etapas en los casos en que los datos tengan una estructura de hogar. Primero, las variables en el nivel superior (hogar) deben anonimizarse; posteriormente, las variables de nivel superior tratadas deben fusionarse con las variables individuales y anonimizarse conjuntamente. En esta sección, explicamos cómo extraer variables del hogar de un archivo y fusionarlas con las variables de niveles individuales después del tratamiento en R. Ilustramos este proceso con un ejemplo de variables a nivel individual y del hogar. Estos pasos se ilustran en el Bloque 6.12. Requerimos una identificación individual y una identificación familiar en el conjunto de datos; si faltan, deben generarse. La identificación individual debe ser única para cada individuo en el conjunto de datos y la identificación del hogar debe ser única para todos los hogares. El primer paso es extraer las variables del hogar y guardarlas en un nuevo marco de datos. Especificamos las variables que se miden a nivel del hogar en el vector de cadena “HHVars” y restamos solo estas variables del conjunto de datos. Este marco de datos tendrá para cada hogar el mismo número de entradas que miembros del hogar (por ejemplo, si un hogar tiene cuatro miembros, este hogar aparecerá cuatro veces en el archivo). A continuación, aplicamos la función unique() para seleccionar solo un registro por hogar. Este argumento de la función unique() es la identificación del hogar, que es la misma para todos los miembros del hogar, Bloque 6.12 Crear un archivo a nivel de hogar con registros únicos (eliminar duplicados) 9 # Crear subconjunto de archivo con solo variables medidas a nivel de hogar HHVars &lt;- c(&#39;IDH&#39;, selectedKeyVars, selectedPramVars, selectedNumVar, selectedWeightVar) fileHH &lt;- file[,HHVars] # Elimine las filas duplicadas en función de la identificación del hogar / # solo cada hogar una vez en el fileHH fileHH &lt;- unique(fileHH, by = c(&#39;HID&#39;)) # Dimensiones del fileHH (número de hogares) dim(fileHH) Después de anonimizar las variables del hogar con base en el marco de datos “fileHH”, recombinamos las variables del hogar anonimizadas con las variables originales, que se miden a nivel individual. Podemos extraer las variables de nivel individual del conjunto de datos original usando “INDVars”, un vector de cadena con los nombres de las variables de nivel individual. Para extraer los datos anonimizados del objeto sdcMicro, podemos usar la función extractManipData() del paquete sdcMicro. A continuación, fusionamos los datos usando la función merge(). El argumento ‘by’ en la función merge() especifica la variable utilizada para la combinación; en este caso, la identificación del hogar, que tiene el mismo nombre de variable en ambos conjuntos de datos. Todas las demás variables deben tener nombres diferentes en ambos conjuntos de datos. Estos pasos se ilustran en Bloque 6.13. Bloque 6.13 Fusión de variables anonimizadas a nivel de hogar con variables a nivel individual # Crea objeto sdcMicro inicial para variables de nivel de hogar sdcHH &lt;- createSdcObj(dat = fileHH, keyVars = selectedKeyVars, pramVars = selectedPramVars, weightVar = selectedWeightVar, numVars = selectedNumVar) numHH &lt;- length(fileHH[,1]) # número de hogares # Extrae variables de nivel de hogar manipuladas del objeto SDC HHmanip &lt;- extractManipData(sdcHH) # Selecciona variables (nivel individual) selectedKeyVarsIND = c(&#39;GENDER&#39;, &#39;REL&#39;, &#39;MARITAL&#39;,&#39;AGEYRS&#39;, &#39;EDUCY&#39;, &#39;INDUSTRY1&#39;) # lista de variables clave seleccionadas # Peso de la muestra (WGTHH, pesos individuales) selectedWeightVarIND = c(&#39;WGTHH&#39;) # ID hogar selectedHouseholdID = c(&#39;IDH&#39;) # Todas las variables individuales INDVars &lt;- c(selectedKeyVarsIND) # Recombinando los datos HH anonimizados y las variables a nivel individual indVars &lt;- c(&quot;IDH&quot;, &quot;IDP&quot;, selectedKeyVarsIND, &quot;WGTHH&quot;) # IDH y todas las variantes no HH fileInd &lt;- file[indVars] # subset de file sin HHVars fileCombined &lt;- merge(HHmanip, fileInd, by.x = c(&#39;IDH&#39;)) fileCombined &lt;- fileCombined[order(fileCombined[,&#39;IDH&#39;], fileCombined[,&#39;IDP&#39;]),] dim(fileCombined) # Objeto SDC con solo las variables a nivel IND sdcCombined &lt;- createSdcObj(dat = fileCombined, keyVars = c(selectedKeyVarsIND), weightVar = selectedWeightVarIND, hhId = selectedHouseholdID) # Objeto SDC con ambos niveles de variables, a HH y IND sdcCombinedAll &lt;- createSdcObj(dat = fileCombined, keyVars = c(selectedKeyVarsIND, selectedKeyVars ), weightVar = selectedWeightVarIND, hhId = selectedHouseholdID) sdcCombinedAll El archivo fileCombined se utiliza para el proceso SDC con todo el conjunto de datos. En el estudio de casos de la sección Caso de estudio se ilustra cómo tratar los datos con la estructura del hogar. El tamaño de un hogar también puede ser un identificador indirecto, incluso si el tamaño del hogar no está incluido en el conjunto de datos como variable. Con el fin de evaluar el riesgo de divulgación, podría ser necesario crear dicha variable mediante un recuento de los miembros de cada hogar. El Bloque 6.14 muestra cómo generar la variable de tamaño de hogar, con valores para cada individuo en función de la identificación del hogar (IDH). Se muestran dos casos: 1) el archivo ordenado por IDH y 2) el archivo no ordenado. Bloque 6.14 Generando la variable tamaño del hogar # Ordenado por IDH file$hhsize &lt;- rep(unname(table(file$IDH)), unname(table(file$IDH))) # Desordenado file$hhsize &lt;- rep(diff(c(1, 1 + which(diff(file$IDH) != 0), length(file$IDH) + 1)), diff(c(1, 1 + which(diff(file$IDH) != 0), length(file$IDH) + 1))) En algunos casos, el orden de las personas dentro de los hogares puede proporcionar información que podría conducir a la reidentificación. Un ejemplo es la información sobre la relación con el jefe de hogar. En muchos países, el primer miembro del hogar es el cabeza de familia, el segundo es la pareja del cabeza de familia y los siguientes son los hijos. Por lo tanto, el número de línea dentro del hogar podría correlacionarse bien con una variable que contiene información sobre la relación con el jefe de hogar. Una forma de evitar esta divulgación involuntaria de información es cambiar el orden de los individuos dentro de cada hogar al azar. El Bloque 6.15 ilustra una manera de hacer esto en R. Bloque 6.15 Cambiando el orden de los individuos dentro de los hogares # Cargando datos anonimizados dataAnon&lt;-readRDS(&quot;dataAnon.RDS&quot;) # Lista de tamaños de hogar por hogar hhsize &lt;- diff(c(1, 1 + which(diff(dataAnon$IDH) != 0), length(dataAnon$IDH) + 1)) # Números de línea asignados al azar dentro de cada hogar set.seed(123) dataAnon$INDID &lt;- unlist(lapply(hhsize, function(n){sample(1:n, n, replace = FALSE, prob = rep(1/n, n))})) # Ordene el archivo por IDH y INDID aleatorio (número de línea) dataAnon &lt;- dataAnon[order(dataAnon$IDH, dataAnon$INDID),] 6.8 Tiempo de cómputo Algunos métodos SDC pueden tardar mucho tiempo en evaluarse en términos de cómputo. Por ejemplo, la supresión local con la función localSuppression() del paquete sdcMicro en R puede tardar días en ejecutarse en grandes conjuntos de datos de más de 30.000 personas que tienen muchos identificadores indirectos categóricos. El uso de la función groupVars(), por ejemplo, no es computacionalmente intensivo, pero aún puede llevar mucho tiempo si el conjunto de datos es grande y las medidas de riesgo deben volver a calcularse. Nuestra experiencia revela que el tiempo de cómputo es una función de los siguientes factores: el método SDC aplicado; tamaño de los datos, es decir, número de observaciones, número de variables y número de categorías o niveles de factores de cada variable categórica; complejidad de los datos (por ejemplo, el número de diferentes combinaciones de valores de identificadores indirectos en los datos); así como las especificaciones de la computadora (procesador, la memoria RAM y los medios de almacenamiento). El uso de la paralelización puede mejorar el rendimiento incluso en una sola computadora con un procesador con múltiples núcleos. R no utiliza múltiples núcleos a menos que se le indique que lo haga. La paralelización permite que los trabajos/escenarios 10 en los conjuntos de datos puedan procesarse simultáneamente a través de la asignación eficiente de tareas a diferentes procesadores. Sin paralelización, dependiendo del servidor/computadora, solo se usa un núcleo cuando se ejecutan los trabajos secuencialmente. Ejecutar el programa de anonimización sin paralelización conduce a un tiempo de ejecución significativamente mayor. Sin embargo, tenga en cuenta que la paralelización en sí misma también provoca una sobrecarga. Por lo tanto, una suma de los tiempos que lleva ejecutar cada tarea en paralelo no equivale necesariamente al tiempo que puede llevar ejecutarlas secuencialmente. Sin embargo, el hecho de que la RAM se comparta podría reducir ligeramente las ganancias de la paralelización 11. 6.9 Errores comunes En esta sección, presentamos algunos errores comunes y sus causas, que pueden encontrarse al usar el paquete sdcMicro en R para la anonimización de microdatos: La clase de una determinada variable no es aceptada por la función, por ejemplo, una variable categórica de clase numérica debe recodificarse primero a la clase requerida (por ejemplo, factor o data.frame). En la sección Clases en R se muestra cómo hacerlo. Después de realizar cambios manualmente en las variables, el riesgo no cambió, ya que no se actualiza automáticamente y debe volver a calcularse manualmente mediante la función calcRisks(). Referencias "],["medición-de-riesgos.html", "Capítulo 7 Medición de riesgos 7.1 Tipos de divulgación 7.2 Clasificación de variables 7.3 Escenarios de divulgación 7.4 Niveles de riesgo 7.5 Riesgo individual 7.6 Medidas de riesgo para variables continuas 7.7 Riesgo global 7.8 Riesgo jerárquico (o del hogar) 7.9 Referencias", " Capítulo 7 Medición de riesgos 7.1 Tipos de divulgación Medir el riesgo de divulgación es una parte importante del proceso SDC: las medidas de riesgo se utilizan para juzgar si un archivo de datos es lo suficientemente seguro para su liberación. Antes de medir el riesgo de divulgación, debemos definir qué tipo de divulgación es relevante para los datos disponibles, a saber: divulgación de identidad, divulgación de atributos y divulgación inferencial (ver Lambert (1993) y Anco Hundepool et al. (2012)). Divulgación de identidad, que ocurre si el intruso asocia a un individuo conocido con un registro de datos publicado. Por ejemplo, el intruso vincula un registro de datos publicado con información externa o identifica a un informante con valores de datos extremos. En este caso, un intruso puede explotar un pequeño subconjunto de variables para realizar la vinculación, y una vez que la vinculación es exitosa, el intruso tiene acceso a toda la demás información en los datos publicados relacionados con el informante específico. Divulgación de atributos, que ocurre si el intruso puede determinar algunas características nuevas de un individuo en función de la información disponible en los datos publicados. La divulgación de atributos ocurre si se vuelve a identificar correctamente a un informante y el conjunto de datos incluye variables que contienen información que el intruso desconocía previamente. La divulgación de atributos también puede ocurrir sin divulgación de identidad. Por ejemplo, si un hospital publica datos que muestran que todas las pacientes de 56 a 60 años que tienen cáncer, un intruso conoce la condición médica de cualquier paciente de 56 a 60 años en el conjunto de datos sin tener que identificar a la persona específica. Divulgación inferencial, que ocurre si el intruso es capaz de determinar el valor de alguna característica de un individuo con mayor precisión con los datos liberados de lo que hubiera sido posible de otro modo. Por ejemplo, con un modelo de regresión altamente predictivo, un intruso puede inferir la información confidencial de ingresos de un informante utilizando atributos registrados en los datos, lo que lleva a una divulgación inferencial. Los métodos SDC para microdatos están destinados a evitar la divulgación de identidades y atributos. La divulgación inferencial generalmente no se aborda en SDC en el entorno de microdatos, ya que los microdatos se liberan precisamente para que los investigadores puedan hacer inferencias estadísticas y comprender las relaciones entre las variables. En ese sentido, la inferencia no puede compararse con la divulgación. Además, las inferencias están diseñadas para predecir el comportamiento agregado, no individual y, por lo tanto, suelen ser malos predictores de valores de datos individuales. 7.2 Clasificación de variables A los efectos del proceso SDC, utilizamos las clasificaciones de variables descritas en los siguientes párrafos (consulte la Figura 7.1 para obtener una descripción general). La clasificación inicial de variables en variables de identificación y no identificación depende de la forma en que los intrusos pueden utilizar las variables para la reidentificación: Variables de identificación: contienen información que puede conducir a la identificación de los informantes y se pueden clasificar en: Los identificadores directos, que revelan de manera directa e inequívoca la identidad del informante. Algunos ejemplos son nombres, números de pasaporte, números de identificación social y direcciones. Los identificadores directos deben eliminarse del conjunto de datos antes de su publicación. La eliminación de identificadores directos es un proceso sencillo y siempre es el primer paso para producir un conjunto de microdatos seguro para su publicación. Sin embargo, la eliminación de identificadores directos a menudo no es suficiente. Los identificadores indirectos (cuasi-identificadores o variables clave) contienen información que, cuando se combina con otros identificadores indirectos en el conjunto de datos, puede conducir a la reidentificación de los informantes. Este es especialmente el caso cuando se pueden usar para hacer coincidir la información con otra información o datos externos. Ejemplos de identificadores indirectos son la raza, la fecha de nacimiento, el sexo y el código postal, que pueden combinarse o vincularse fácilmente con información externa disponible públicamente y hacer posible la identificación. Las combinaciones de valores de varios identificadores indirectos se denominan claves. Los valores de los identificadores indirectos por sí mismos a menudo no conducen a la identificación (por ejemplo, hombre/mujer), pero una combinación de varios valores de identificador indirecto puede hacer que un registro sea único (por ejemplo, hombre, 18 años, casado) y, por lo tanto, identificable. En general, no es aconsejable eliminar simplemente los identificadores indirectos de los datos para resolver el problema. En muchos casos, serán variables importantes para cualquier análisis sensato. En la práctica, cualquier variable en el conjunto de datos podría potencialmente usarse como un identificador indirecto. SDC aborda esto mediante la identificación de variables como identificadores indirectos y anonimizándolas mientras mantiene la información en el conjunto de datos para su publicación. Las variables de no identificación son variables que no se pueden utilizar para volver a identificar a los informantes. Esto podría deberse a que estas variables no están contenidas en ningún otro archivo de datos u otras fuentes externas y no son observables por un intruso. No obstante, las variables de no identificación son importantes en el proceso SDC, ya que pueden contener información confidencial/sensible, que puede resultar perjudicial si se produce una divulgación como resultado de la divulgación de la identidad basada en variables de identificación. Estas clasificaciones de variables dependen parcialmente de la disponibilidad de conjuntos de datos externos que pueden contener información que, cuando se combina con los datos actuales, podría conducir a la divulgación. La identificación y clasificación de variables como identificadores indirectos depende, entre otros, de la disponibilidad de información en conjuntos de datos externos. Un paso importante en el proceso SDC es definir una lista de posibles escenarios de divulgación en función de cómo los identificadores indirectos podrían combinarse entre sí y la información en conjuntos de datos externos, y luego tratar los datos para evitar la divulgación. Analizamos los escenarios de divulgación con más detalle en la sección Escenarios de divulgación. Para el proceso SDC, también es útil clasificar aún más los identificadores indirectos en variables categóricas, continuas y semicontinuas o discretas. Esta clasificación es importante para determinar los métodos SDC apropiados para esa variable, así como la validez de las medidas de riesgo. Las variables categóricas toman valores sobre un conjunto finito, y cualquier operación aritmética que las utilice generalmente no tiene sentido o no está permitida. Ejemplos de variables categóricas son género, región y nivel educativo. Las variables continuas pueden tomar un número infinito de valores en un conjunto denso. Algunos ejemplos son los ingresos, la altura del cuerpo y el tamaño del terreno. Las variables continuas se pueden transformar en variables categóricas mediante la construcción de intervalos (como bandas de ingresos)12. Las variables semicontinuas o discretas son variables continuas que toman valores limitados a un conjunto finito. Un ejemplo es la edad medida en años, que podría tomar valores en el conjunto {0, 1,…, 100}. La naturaleza finita de los valores de estas variables significa que pueden tratarse como variables categóricas a los efectos de SDC 13. Además de estas clasificaciones de variables, el proceso SDC clasifica aún más las variables según su sensibilidad o confidencialidad. Tanto las variables identificadoras indirectas como las de no identificación pueden clasificarse como sensibles (o confidenciales) o no sensibles (o no confidenciales). Esta distinción no es importante para los identificadores directos, ya que los identificadores directos se eliminan de los datos publicados. Las variables sensibles contienen información confidencial que no debe liberarse sin un tratamiento adecuado, utilizando los métodos de SDC para reducir el riesgo de divulgación. Algunos ejemplos son los ingresos, la religión, la afiliación política y las variables relativas a la salud. Que una variable sea sensible depende del contexto y del país: una determinada variable puede considerarse sensible en un país y no sensible en otro. Las variables no sensibles contienen información no confidencial sobre el informante, como el lugar de residencia o el área de residencia rural/urbana. Sin embargo, la clasificación de una variable como no sensible no significa que no deba ser considerada en el proceso de SDC. Las variables no sensibles aún pueden servir como identificadores indirectos cuando se combinan con otras variables u otros datos externos. Figura 7.1: Clasificación de las variables. 7.3 Escenarios de divulgación La evaluación del riesgo de divulgación se lleva a cabo con referencia a las fuentes de datos disponibles en el entorno donde se liberará el conjunto de datos. En este contexto, el riesgo de divulgación es la posibilidad de volver a identificar correctamente a una unidad en el archivo de microdatos publicado 14 comparando sus datos con un archivo externo basado en un conjunto de identificadores indirectos. La evaluación de riesgos se realiza mediante la identificación de los llamados escenarios de divulgación o intrusión. Un escenario de divulgación describe la información potencialmente disponible para el intruso (por ejemplo, datos del censo, padrones electorales, registros de población o datos recopilados por empresas privadas) para identificar a los informantes y las formas en que dicha información puede combinarse con el conjunto de microdatos que se liberará y utilizará para reidentificación de registros en el conjunto de datos. Normalmente, estos conjuntos de datos externos incluyen identificadores directos. En ese caso, la reidentificación de los registros en el conjunto de datos publicado conduce a la divulgación de la identidad y, posiblemente, de los atributos. El principal resultado de la evaluación de los escenarios de divulgación es la identificación de un conjunto de identificadores indirectos (es decir, variables clave) que deben tratarse durante el proceso SDC (ver Elliot et al. (2010)). Un ejemplo de un escenario de divulgación podría ser el reconocimiento espontáneo de un informante por parte de un investigador. Por ejemplo, mientras revisa los datos, el investigador reconoce a una persona con una combinación inusual de las variables edad y estado civil. Por supuesto, esto solo puede suceder si la persona es bien conocida o es conocida por el investigador. Otro ejemplo de un escenario de divulgación para un archivo disponible públicamente sería si las variables en los datos pudieran vincularse a un registro electoral disponible públicamente. Un intruso podría hacer coincidir todo el conjunto de datos con las personas del registro. Sin embargo, esto puede ser difícil y requerir experiencia especializada, o software, y se deben cumplir otras condiciones. Los ejemplos son que el momento en el que se recopilaron los conjuntos de datos debe coincidir aproximadamente y el contenido de las variables debe ser (casi) idéntico. Si no se cumplen estas condiciones, la coincidencia exacta es mucho menos probable. La evaluación del riesgo de divulgación se basa en los identificadores indirectos, que se identifican en el análisis de escenarios de riesgo de divulgación. El riesgo de divulgación depende directamente de la inclusión o exclusión de variables en el conjunto de identificadores indirectos elegidos. Por lo tanto, este paso en el proceso SDC (hacer la elección de los identificadores indirectos) debe abordarse con gran reflexión y cuidado. Veremos más adelante, cuando discutamos los pasos en el proceso de SDC con más detalle, que el primer paso para cualquier oficina de estadística es realizar un ejercicio en el que se compila un inventario de todos los conjuntos de datos disponibles en el país. Se consideran tanto los conjuntos de datos publicados por la oficina nacional de estadística (como el INE) como por otras fuentes y se analiza su disponibilidad para los intrusos, así como las variables incluidas en estos conjuntos de datos. 7.4 Niveles de riesgo Con microdatos de encuestas y censos, a menudo tenemos que preocuparnos por la divulgación a nivel individual o de unidad, es decir, identificar a los informantes individuales. Los informantes individuales suelen ser personas físicas, pero también pueden ser unidades, como empresas, escuelas, centros de salud, etc. Los archivos de microdatos suelen tener una estructura jerárquica en la que las unidades individuales pertenecen a grupos, por ejemplo, las personas pertenecen a hogares. La estructura jerárquica más común en los microdatos es la estructura del hogar en los datos de las encuestas de hogares. Por lo tanto, en esta guía, a veces llamamos al riesgo de divulgación de datos con una estructura jerárquica “riesgo hogar”. Sin embargo, los conceptos se aplican por igual a los datos del establecimiento y otros datos con estructuras jerárquicas, como los datos de la escuela con los alumnos y profesores o los datos de la empresa con los empleados. Veremos que es importante tener en cuenta esta estructura jerárquica al medir el riesgo de divulgación. Para los datos jerárquicos, la información recopilada en el nivel jerárquico superior (por ejemplo, nivel del hogar) sería la misma para todos los individuos del grupo que pertenecen a ese nivel jerárquico superior (por ejemplo, el hogar) [Los supuestos para esta medida de riesgo son estrictos y el riesgo se estima en muchos casos mayor que el riesgo real. Entre otras suposiciones, se supone que todos los individuos de la muestra también están incluidos en el archivo externo utilizado por el intruso para compararlos. Si no es así, el riesgo es mucho menor; si el individuo en el archivo liberado no está incluido en el archivo externo, la probabilidad de una coincidencia correcta es cero. Otras suposiciones son que los archivos no contienen errores y que ambos conjuntos de datos se recopilaron simultáneamente, es decir, contienen la misma información. Estos supuestos a menudo no se cumplen en general, pero son necesarios para el cálculo de una medida. Un ejemplo de una violación de las últimas suposiciones podría ocurrir si los conjuntos de datos se recopilan en diferentes puntos en el tiempo y los registros han cambiado. Esto podría suceder cuando las personas se mudan o cambian de trabajo y hace imposible la coincidencia correcta. Los supuestos son conservadores y asumen el mayor riesgo de divulgación.]. Algunos ejemplos típicos de variables que tendrían los mismos valores para todos los miembros de una misma unidad jerárquica superior son, en el caso de los hogares, las relativas a la vivienda y los ingresos del hogar. Estas variables difieren de una encuesta a otra y de un país a otro 15. Esta estructura jerárquica crea un mayor nivel de riesgo de divulgación por dos razones: si se reidentifica a una persona del hogar, la estructura del hogar permite la reidentificación de los demás miembros del hogar en el mismo hogar, los valores de las variables para otros miembros del hogar que son comunes para todos los miembros del hogar pueden usarse para volver a identificar a otro individuo del mismo hogar. Esto se analiza con más detalle en la sección Riesgo jerárquico (o del hogar). A continuación, primero analizamos las medidas de riesgo utilizadas para evaluar el riesgo de divulgación en ausencia de una estructura jerárquica. Esto incluye medidas de riesgo que buscan agregar el riesgo individual para todos los individuos en el archivo de microdatos; el objetivo es cuantificar una medida de riesgo de divulgación global para el archivo. Luego discutimos cómo cambian las medidas de riesgo cuando se tiene en cuenta la estructura jerárquica de los datos. También discutiremos cómo las medidas de riesgo difieren para los identificadores indirectos categóricos y continuos. Para las variables categóricas, utilizaremos el concepto de unicidad de combinaciones de valores de identificadores indirectos (las llamadas “claves”) que se utilizan para identificar a las personas en riesgo. El concepto de unicidad, sin embargo, no es útil para variables continuas, ya que es probable que todos o muchos individuos tengan valores únicos para esa variable, por definición de una variable continua. Las medidas de riesgo para variables categóricas son generalmente medidas a priori, es decir, pueden evaluarse antes de aplicar métodos de anonimización ya que se basan en el principio de unicidad. Las medidas de riesgo para variables continuas son medidas a posteriori; se basan en la comparación de los microdatos antes y después de la anonimización y son, por ejemplo, basadas en la proximidad de observaciones entre conjuntos de datos originales y tratados (anonimizados). Los archivos que se limitan solo a identificadores indirectos categóricos o continuos son los más fáciles para medir el riesgo. Veremos en secciones posteriores que, en los casos en que ambos tipos de variables están presentes, la recodificación de variables continuas en categorías es un enfoque para simplificar el proceso SDC, pero también veremos que desde una perspectiva de utilidad esto puede no ser deseable. Un ejemplo podría ser el uso de quintiles de ingresos en lugar de las variables de ingresos reales. Veremos que medir el riesgo de divulgación con base en las variables categóricas y continuas por separado generalmente no es un enfoque válido. Las medidas de riesgo discutidas en la siguiente sección se basan en varios supuestos. En general, estas medidas se basan en suposiciones bastante restrictivas y, a menudo, conducirán a estimaciones de riesgo conservadoras. Estas medidas de riesgo conservadoras pueden exagerar el riesgo ya que suponen el peor de los casos. Sin embargo, se deben cumplir dos suposiciones para que las medidas de riesgo sean válidas y significativas; los microdatos deben ser una muestra de una población más grande (no censo) y las ponderaciones de la muestra deben estar disponibles. 7.5 Riesgo individual 7.5.1 Identificadores indirectos categóricos y recuentos de frecuencia El enfoque principal de la medición del riesgo para los identificadores indirectos categóricos es la divulgación de la identidad. La medición del riesgo de divulgación se basa en la evaluación de la probabilidad de reidentificación correcta de las personas en los datos publicados. Utilizamos medidas basadas en los microdatos reales que se publicarán. En general, cuanto más rara sea la combinación de valores de los identificadores indirectos (es decir, clave) de una observación en la muestra, mayor será el riesgo de revelación de identidad. Un intruso que intente hacer coincidir a una persona que tiene una clave relativamente rara dentro de los datos de muestra con un conjunto de datos externo en el que existe la misma clave tendrá una mayor probabilidad de encontrar una coincidencia correcta que cuando un número mayor de personas comparten la misma clave. Esto se puede ilustrar con el siguiente ejemplo que se ilustra en la Tabla 7.1. La Tabla 7.1 muestra los valores de 10 informantes para los identificadores indirectos “área”, “género”, “nivel educacional” y “situación laboral”. En los datos, encontramos siete combinaciones únicas de valores de identificadores indirectos (es decir, patrones o claves) de los cuatro identificadores indirectos. Ejemplos de claves son {‘urbano’, ‘femenino’, ‘secundaria incompleta’, ‘ocupado’} y {‘urbano’, ‘femenino’, ‘primaria incompleta’, ‘no FL’}. Sea \\(f_{k}\\) la frecuencia de muestreo de la k-ésima clave, es decir, el número de individuos de la muestra con valores de los identificadores indirectos que coinciden con la clave k. Este sería 2 para la clave {urbano, femenino, secundaria incompleta, ocupado}, ya que esta clave es compartida por los individuos 1 y 2 y 1 para la clave {‘urbano’, ‘femenino’, ‘primaria incompleta’, ‘no FL’}, que es exclusivo del individuo 3. Por definición, \\(f_{k}\\) es el mismo para cada registro que comparte una clave particular. Tabla 7.1: Conjunto de datos de ejemplo que muestra frecuencias de muestra, frecuencias de población y riesgo de divulgación individual Id Área Género Nivel educacional Situación laboral Peso (\\(w_{i}\\)) \\(f_{k}\\) \\(F_{k}\\) Riesgo (\\(r_{k}\\)) 1 Urbano Femenino Secundaria incompleta Ocupado 180 2 360 0.0054 2 Urbano Femenino Secundaria incompleta Ocupado 180 2 360 0.0054 3 Urbano Femenino Primaria incompleta No FL 215 1 215 0.0251 4 Urbano Masculino Secundaria completa Ocupado 76 2 152 0.0126 5 Rural Femenino Secundaria completa Desocupado 186 1 186 0.0282 6 Urbano Masculino Secundaria completa Ocupado 76 2 152 0.0126 7 Urbano Femenino Primaria completa No FL 180 1 180 0.029 8 Urbano Masculino Post secundaria Desocupado 215 1 215 0.0251 9 Urbano Femenino Secundaria incompleta No FL 186 2 262 0.0074 10 Urbano Femenino Secundaria incompleta No FL 76 2 262 0.0074 Fuente: Adaptación de (Benschop, Machingauta, and Welch 2021, 28) Cuanto menos personas con las que una persona comparte su combinación de identificadores indirectos, más probable es que la persona coincida correctamente en otro conjunto de datos que contenga estos identificadores indirectos. Incluso cuando los identificadores directos se eliminan del conjunto de datos, esa persona tiene un mayor riesgo de divulgación que otras, suponiendo que sus pesos de muestra sean los mismos. La Tabla 7.1 reporta las frecuencias de muestreo \\(f_{k}\\) de las llaves para todos los individuos. Las personas con las mismas claves tienen la misma frecuencia de muestreo. Si \\(f_{k}=1\\), este individuo tiene una combinación única de valores de identificadores indirectos y se denomina “muestra única”. El conjunto de datos de la Tabla 7.1 contiene cuatro muestras únicas. Las medidas de riesgo se basan en esta frecuencia de muestreo. En el Bloque 7.1, mostramos cómo usar el paquete sdcMicro para crear una lista de frecuencias de muestra \\(f_{k}\\) para cada registro en un conjunto de datos. Esto se hace usando la función sdcMicro freq(). Un valor de 2 para una observación significa que en la muestra hay un individuo más con exactamente la misma combinación de valores para los identificadores indirectos seleccionados. En el Bloque 7.1, la función freq() se aplica a “sdcInitial”, que es un objeto sdcMicro. Los objetos se usan cuando se hace SDC con sdcMicro. La función freq() muestra la frecuencia de muestreo de las claves construidas sobre un conjunto definido de identificadores indirectos. El Bloque 7.1 corresponde a los datos de la Tabla 7.1. Bloque 7.1 Cálculo \\(f_{k}\\) usando sdcMicro setwd(&quot;..\\Capacitación\\GitHub&quot;) # directorio de trabajo library(sdcMicro) # carga paquete sdcMicro # Set up conjunto de datos data &lt;- as.data.frame(cbind(as.factor(c(&#39;Urbano&#39;, &#39;Urbano&#39;, &#39;Urbano&#39;, &#39;Urbano&#39;, &#39;Rural&#39;, &#39;Urbano&#39;, &#39;Urbano&#39;, &#39;Urbano&#39;, &#39;Urbano&#39;, &#39;Urbano&#39;)), as.factor(c(&#39;Femenino&#39;, &#39;Femenino&#39;, &#39;Femenino&#39;, &#39;Masculino&#39;,&#39;Femenino&#39;, &#39;Masculino&#39;, &#39;Femenino&#39;, &#39;Masculino&#39;, &#39;Femenino&#39;, &#39;Femenino&#39;)), as.factor(c(&#39;Sec in&#39;, &#39;Sec in&#39;, &#39;Prim in&#39;, &#39;Sec com&#39;, &#39;Sec com&#39;, &#39;Sec com&#39;, &#39;Prim com&#39;, &#39;Post-sec&#39;, &#39;Sec in&#39;, &#39;Sec in&#39;)), as.factor(c(&#39;Ocu&#39;, &#39;Ocu&#39;, &#39;No-FL&#39;, &#39;Ocu&#39;, &#39;Desocu&#39;, &#39;Ocu&#39;, &#39;No-FL&#39;, &#39;Desocu&#39;, &#39;No-FL&#39;,&#39;No-FL&#39;)), as.factor(c(&#39;Sí&#39;, &#39;Sí&#39;, &#39;Sí&#39;, &#39;Sí&#39;, &#39;Sí&#39;, &#39;No&#39;, &#39;No&#39;, &#39;Sí&#39;, &#39;No&#39;, &#39;Sí&#39;)), c(180, 180, 215, 76, 186, 76, 180, 215, 186, 76) )) # Especificar nombres de variables names(data) &lt;- c(&#39;Área&#39;, &#39;Género&#39;, &#39;Educ&#39;, &#39;SitLab&#39;, &#39;Salud&#39;, &#39;Pesos&#39;) # Set up objeto sdcMicro con especificación de identificadores indirectos y pesos sdcInitial &lt;- createSdcObj(dat = data, keyVars = c(&#39;Área&#39;, &#39;Género&#39;, &#39;Educ&#39;, &#39;SitLab&#39;), weightVar = &#39;Pesos&#39;) data$fk&lt;-freq(sdcInitial, type = &#39;fk&#39;) Para datos de muestra, es más interesante mirar \\(F_{k}\\), la frecuencia de población de una combinación de identificadores indirectos (clave) k, que es el número de individuos de la población con la clave que corresponde a la clave k. Se desconoce la frecuencia poblacional si los microdatos son una muestra y no un censo. Bajo ciertas suposiciones, el valor esperado de las frecuencias de la población se puede calcular utilizando el peso del diseño de la muestra \\(w_{i}\\)(en una muestra simple, esta es la inversa de la probabilidad de inclusión) para cada individuo i. \\[F_{k}=\\sum_{i|individuo\\,i\\, correspondiente\\, a\\, la\\, clave\\, k} w_{i}\\] \\(F_{k}\\) es la suma de los pesos muestrales de todos los registros con la misma clave k. Por lo tanto, como \\(f_{k}\\), \\(F_{k}\\) es el mismo para cada registro con clave k. El riesgo de una reidentificación correcta es la probabilidad de que la clave coincida con el individuo correcto de la población. Dado que cada individuo en la muestra con clave k corresponde a \\(F_{k}\\) individuos en la población, la probabilidad de reidentificación correcta es \\(1/F_{k}\\). Esta es la probabilidad de reidentificación en el peor de los casos y puede interpretarse como riesgo de divulgación. Los individuos con la misma clave tienen las mismas frecuencias, es decir, la frecuencia de la clave. Si \\(F_{k}=1\\), la clave k es tanto una muestra como una población única y el riesgo de divulgación sería 1. Las características únicas de la población son un factor importante a considerar al evaluar el riesgo y merecen especial atención. Además, \\(f_{k}\\), la frecuencia de muestreo de la clave k (es decir, el número de individuos en la muestra con la combinación de identificadores indirectos correspondientes a la combinación especificada en la clave k) y \\(F_{k}\\), la frecuencia de población estimada de k, se puede visualizar en sdcMicro. El Bloque 7.2 ilustra cómo devolver listas de longitud n de frecuencias para todos los individuos. Las frecuencias se muestran para cada individuo y no para cada clave. Bloque 7.2 Cálculo de frecuencias muestrales y poblacionales usando sdcMicro # frecuencia muestral de individuos data$fk&lt;-freq(sdcInitial, type = &#39;fk&#39;) # frecuencia poblacional de individuos data$FK&lt;-freq(sdcInitial, type = &#39;Fk&#39;) En la práctica, este enfoque conduce a estimaciones de riesgo conservadoras, ya que no tiene en cuenta adecuadamente los métodos de muestreo. En este caso, las estimaciones del riesgo de reidentificación pueden ser demasiado altas. Si se utiliza este riesgo sobreestimado, los datos pueden estar sobreprotegidos (es decir, la pérdida de información será mayor que la necesaria) al aplicar las medidas de SDC. La medida del riesgo \\(r_{k}\\) es como \\(f_{k}\\) y \\(F_{k}\\), el mismo para todos los individuos que comparten el mismo patrón de valores de identificadores indirectos y se denomina riesgo individual. Los valores \\(r_{k}\\) también puede interpretarse como la probabilidad de divulgación de los individuos o como la probabilidad de una coincidencia exitosa con individuos elegidos al azar de un archivo de datos externo con los mismos valores de los identificadores indirectos. Esta medida de riesgo se basa en ciertos supuestos 16, que son estrictos y pueden conducir a una medida de riesgo relativamente conservadora. En sdcMicro, la medida de riesgo \\(r_{k}\\) se calcula automáticamente al crear un objeto sdcMicro y se guarda en el slot de “riesgo” 17. El Bloque 7.3 muestra cómo recuperar las medidas de riesgo usando sdcMicro para nuestro ejemplo. Las medidas de riesgo también se presentan en la Tabla 7.1. Bloque 7.3 Slot de riesgo individual en el objeto sdcMicro sdcInitial@risk$individual Los principales factores que influyen en el riesgo individual son las frecuencias de muestreo \\(f_{k}\\) y los pesos de diseño de muestreo \\(w_{i}\\). Si un individuo tiene un riesgo relativamente alto de divulgación, en nuestro ejemplo serían los individuos 3, 5, 7 y 8 en la Tabla 7.1 y el Bloque 7.3, la probabilidad de que un posible intruso relacione correctamente a estos individuos con un archivo de datos externo es relativamente alta. En nuestro ejemplo, la razón del alto riesgo es el hecho de que estos individuos son muestras únicas (es decir, \\(f_{k}=1\\)). Este riesgo es el riesgo del peor de los casos y no implica que la persona sea reidentificada con certeza con esta probabilidad. Por ejemplo, si un individuo incluido en los microdatos no está incluido en el archivo de datos externo, la probabilidad de una coincidencia correcta es cero. No obstante, la medida del riesgo calculada a partir de las frecuencias será positiva como medida de evaluación. 7.5.2 k-anonimato La medida del riesgo k- anonimato se basa en el principio de que, en un conjunto de datos seguro, el número de personas que comparten la misma combinación de valores (claves) de identificadores indirectos categóricos debe ser superior a un umbral especificado k. El k-anonimato es una medida de riesgo basada en los microdatos a publicar, ya que solo tiene en cuenta la muestra. Un individuo viola el k-anonimato si la frecuencia de muestreo \\(f_{k}\\) para la llave k es menor que el umbral especificado k. Por ejemplo, si un individuo tiene la misma combinación de identificadores indirectos que otros dos individuos en la muestra, estos individuos satisfacen el 3-anonimato pero violan el 4-anonimato. En el conjunto de datos de la Tabla 7.1, seis personas satisfacen el 2-anonimato y cuatro violan el 2-anonimato. Los individuos que violan el 2-anonimato son muestras únicas. La medida de riesgo es el número de observaciones que violan el k-anonimato para un cierto valor de k, que es \\[ \\sum_{i} I(f_{k}&lt;k), \\] donde \\(I\\) es la función indicadora e \\(i\\) se refiere al i-ésimo registro. Esto es simplemente un recuento del número de personas con una frecuencia de muestreo de su clave inferior a k. El recuento es mayor para los k más grandes, ya que si un registro satisface k-anonimato, también satisface (k+1)- anonimato. La medida del riesgo k-anonimato no considera los pesos de la muestra, pero es importante considerar los pesos de la muestra al determinar el nivel requerido de k-anonimato. Si los pesos de la muestra son grandes, un individuo en el conjunto de datos representa a más individuos en la población objetivo, la probabilidad de una coincidencia correcta es menor y, por lo tanto, el umbral requerido puede ser más bajo. Los pesos de muestra grandes van de la mano con conjuntos de datos más pequeños. En un conjunto de datos más pequeño, la probabilidad de encontrar otro registro con la misma clave es menor que en un conjunto de datos más grande. Esta probabilidad está relacionada con el número de registros en la población con una clave particular a través de los pesos muestrales. En sdcMicro podemos mostrar el número de observaciones que violan un determinado umbral de k-anonimato. En el Bloque 7.4, usamos sdcMicro para calcular la cantidad de infractores para los umbrales \\(k=2\\) y \\(k=3\\). Se da tanto el número absoluto de infractores como el número relativo como porcentaje del número de individuos en la muestra. En el ejemplo, cuatro observaciones violan el 2-anonimato y las 10 observaciones violan el 3-anonimato. Bloque 7.4 Uso de la función print() para mostrar observaciones que violan k-anonimato print(sdcInitial, &#39;kAnon&#39;) Para otros niveles de k-anonimato, es posible calcular el número de personas infractoras utilizando los recuentos de frecuencia de muestreo en el objeto sdcMicro. El número de infractores es el número de personas con recuentos de frecuencia de muestreo inferiores al umbral especificado k. En el Bloque 7.5, mostramos un ejemplo de cómo calcular cualquier umbral para k usando las medidas de riesgo ya almacenadas disponibles después de configurar un objeto sdcMicro en R. k se puede reemplazar con cualquier umbral requerido. La elección del umbral requerido que deben cumplir todas las personas en el archivo de microdatos depende de muchos factores y se analiza más adelante en la sección Supresión local sobre la supresión local. En muchas instituciones, los umbrales típicamente requeridos para k-anonimato son 3 y 5. Bloque 7.5 Violaciones de k-anonimato para distintos valores de k k=10 sum(sdcInitial@risk$individual[,2] &lt; k) Es importante tener en cuenta que los valores faltantes (NAs en R 18 ) se tratan como si fueran cualquier otro valor. Dos personas con claves {‘Masculino’, NA, ‘Ocupado’} y {‘Masculino’, ‘Secundaria completa’, ‘Ocupado’} comparten la misma clave y, de manera similar, {‘Masculino’, NA, ‘Ocupado’} y {‘Masculino’, ‘Secundaria incompleta’, ‘Ocupado’} también comparten la misma clave. Por lo tanto, el valor que falta en la primera clave se interpreta primero como ‘Secundaria completa’ y luego como ‘Secundaria incompleta’. Esto se ilustra en la Tabla 7.2. Tabla 7.2: Conjunto de datos de ejemplo para ilustrar el efecto de los valores faltantes en el k-anonimato Id Género Nivel educacional Situación laboral \\(f_{k}\\) 1 Masculino Secundaria completa Ocupado 2 2 Masculino Secundaria incompleta Ocupado 2 3 Masculino NA Ocupado 3 Fuente: Adaptación de (Benschop, Machingauta, and Welch 2021, 32) Si un conjunto de datos satisface k-anonimato, un intruso siempre encontrará al menos k individuos con la misma combinación de identificadores indirectos. El k-anonimato suele ser un requisito necesario para la anonimización de un conjunto de datos antes de su publicación, pero no es necesariamente un requisito suficiente. La medida de k-anonimato solo se basa en recuentos de frecuencia y no tiene en cuenta (las diferencias en) los pesos de las muestras. Con frecuencia el k-anonimato se logra aplicando primero la recodificación y luego la supresión local y, en algunos casos, mediante la microagregación, antes de utilizar otras medidas de riesgo y métodos de divulgación para reducir aún más el riesgo de divulgación. Estos métodos se analizan en la sección Métodos SDC. 7.5.3 l-diversity El k-anonimato ha sido criticado por no ser lo suficientemente restrictivo. La información confidencial puede divulgarse incluso si los datos satisfacen el k-anonimato. Esto puede ocurrir en los casos en que los datos contienen variables categóricas confidenciales (de no identificación) que tienen el mismo valor para todas las personas que comparten la misma clave. Ejemplos de tales variables sensibles son aquellas que contienen información sobre el estado de salud de un individuo. La Tabla 7.3 ilustra este problema utilizando los mismos datos que se utilizaron anteriormente, pero agregando una variable sensible, “salud”. Los dos primeros individuos cumplen 2-anonimato para los identificadores indirectos “área”, “género”, “nivel educacional” y “situación laboral”. Esto significa que un intruso encontrará al menos dos personas al hacer coincidir el conjunto de microdatos publicado en función de esos cuatro identificadores indirectos. Sin embargo, si el intruso sabe que alguien pertenece a la muestra y tiene la clave {‘Urbano’, ‘Femenino’, ‘Secundaria incompleta’ y ‘Ocupado’}, con certeza se revela el estado de salud (‘sí’), porque para ambos las observaciones con esta clave tienen el mismo valor. Esta información se revela así sin la necesidad de coincidir exactamente con el individuo. Este no es el caso de los individuos con clave {‘Urbano’, ‘Masculino’, ‘Secundaria completa’, ‘Ocupado’}. El concepto de l-diversity (distinto) aborda esta deficiencia del k-anonimato. Un conjunto de datos satisface l-diversity si para cada clave k hay por lo menos l diferentes valores para cada una de las variables sensibles. En el ejemplo, los primeros dos individuos satisfacen solo 1-diversity, los individuos 4 y 6 satisfacen 2-diversity. El nivel requerido de l-diversity depende del número de valores posibles que puede tomar la variable sensible. Si la variable sensible es una variable binaria, el nivel más alto de l-diversity que se puede conseguir es 2. Una muestra única siempre solo satisfará 1-diversity. Para computar l-diversity para variables sensibles en sdcMicro, se puede usar la función ldiversity(). Esto se ilustra en el Bloque 7.6. Como argumentos, especificamos los nombres de las variables sensibles 19 en el archivo, así como una constante para l-diversity 20 y el código de valores faltantes en los datos. La salida se guarda en el slot de “riesgo” del objeto sdcMicro. El resultado muestra el mínimo, máximo, media y cuantiles de las l-puntuaciones de diversidad para todos los individuos de la muestra. El resultado del Bloque 7.6 reproduce los resultados según los datos de la Tabla 7.3. Tabla 7.3: Ilustración de l-diversity Id Área Género Nivel educacional Situación laboral Salud \\(f_{k}\\) \\(F_{k}\\) l-diversity 1 Urbano Femenino Secundaria incompleta Ocupado Enfermo 2 360 1 2 Urbano Femenino Secundaria incompleta Ocupado Enfermo 2 360 1 3 Urbano Femenino Primaria incompleta No FL Enfermo 1 215 1 4 Urbano Masculino Secundaria completa Ocupado Enfermo 2 152 2 5 Rural Femenino Secundaria completa Desocupado Enfermo 1 186 1 6 Urbano Masculino Secundaria completa Ocupado Sano 2 152 2 7 Urbano Femenino Primaria completa No FL Sano 1 180 1 8 Urbano Masculino Post secundaria Desocupado Enfermo 1 215 1 9 Urbano Femenino Secundaria incompleta No FL Sano 2 262 2 10 Urbano Femenino Secundaria incompleta No FL Enfermo 2 262 2 Fuente: Adaptación de (Benschop, Machingauta, and Welch 2021, 33) Bloque 7.6 Función para l-diversity en sdcMicro # Calculando l-diversity sdcInitial &lt;- ldiversity(obj = sdcInitial, ldiv_index = c(&quot;Salud&quot;), l_recurs_c = 2, missing = NA) # Resultado para l-diversity sdcInitial@risk$ldiversity # l-diversity score para cada registro sdcInitial@risk$ldiversity[,&#39;Salud_Distinct_Ldiversity&#39;] l-diversity es útil si los datos contienen variables sensibles categóricas que no son identificadores indirectos en sí mismos. No es posible seleccionar identificadores indirectos para calcular la l-diversity. La l-diversity debe calcularse para cada variable sensible por separado. 7.6 Medidas de riesgo para variables continuas El principio de rareza o unicidad de combinaciones de identificadores indirectos (claves) no es útil para variables continuas, porque es probable que todos o muchos individuos tengan claves únicas. Por lo tanto, se explotan otros enfoques para medir el riesgo de divulgación de las variables continuas. Estos métodos se basan en la unicidad de los valores en la vecindad de los valores originales. La unicidad se define de diferentes formas: en términos absolutos (medida de intervalo) o en términos relativos (vinculación de registros). La mayoría de las medidas son medidas a posteriori: se evalúan después de anonimizar los datos sin procesar, comparar los datos tratados con los datos sin procesar y evaluar para cada individuo la distancia entre los valores en los datos sin procesar y los tratados. Esto significa que estos métodos no son útiles para identificar personas en riesgo dentro de los datos sin procesar, sino que muestra la distancia/diferencia entre el conjunto de datos antes y después de la anonimización y, por lo tanto, puede interpretarse como una evaluación del método de anonimización. Por esa razón, se asemejan a las medidas de pérdida de información discutidas en la sección Medición de la utilidad y la pérdida de información. Finalmente, las medidas de riesgo para identificadores indirectos continuos también se basan en la detección de valores atípicos. Los valores atípicos juegan un papel importante en la reidentificación de estos registros. 7.6.1 Vinculación de registros (o coincidencia de registros) Vinculación de registros (o Record linkage, en inglés) es un método a posteriori que evalúa el número de vínculos correctos al vincular los valores perturbados con los valores originales. El algoritmo de vinculación se basa en la distancia entre el original y los valores perturbados (es decir, vinculación de registros basada en la distancia). Los valores perturbados se emparejan con el individuo más cercano. Es importante señalar que este método no brinda información sobre el riesgo inicial, sino que es una medida para evaluar el algoritmo de perturbación (es decir, está diseñado para indicar el nivel de incertidumbre introducido en la variable al contar la cantidad de registros que podría coincidir correctamente). Los algoritmos de vinculación de registros difieren con respecto a qué medida de distancia se utiliza. Cuando una variable tiene una escala muy diferente a la de otras variables continuas en el conjunto de datos, se recomienda volver a escalar las variables antes de usar la vinculación de registros. Escalas muy diferentes pueden dar lugar a resultados no deseados al medir la distancia multivariada entre registros en función de varias variables continuas. Dado que estos métodos se basan tanto en datos sin procesar como en datos tratados, los ejemplos de sus aplicaciones requieren la introducción de métodos SDC y, por lo tanto, se posponen a los estudios de casos en la sección Caso de estudio. Además de la vinculación de registros basada en la distancia, otro método de vinculación es la vinculación de registros probabilísticos. La literatura muestra, sin embargo, que los resultados de la vinculación de registros basados en la distancia son mejores que los resultados de la vinculación de registros probabilísticos. Las personas en los datos tratados que están vinculadas a las personas correctas en los datos sin procesar se consideran en riesgo de divulgación. 7.6.2 Medida de intervalo La aplicación exitosa de un método SDC debería dar como resultado valores perturbados que no se consideran demasiado cercanos a sus valores iniciales; si el valor es relativamente cercano, la reidentificación puede ser relativamente fácil. En la aplicación de medidas de intervalo, se crean intervalos alrededor de cada valor perturbado y luego se determina si el valor original de esa observación perturbada está contenido en este intervalo. Los valores que están dentro del intervalo alrededor del valor inicial después de la perturbación se consideran demasiado cercanos al valor inicial y, por lo tanto, no son seguros y necesitan más perturbaciones. Los valores que están fuera de los intervalos se consideran seguros. El tamaño de los intervalos se basa en la desviación estándar de las observaciones y un parámetro de escala. Este método está implementado en la función dRisk() en sdcMicro. El Bloque 7.7 muestra cómo imprimir o mostrar el valor de riesgo calculado por sdcMicro comparando las variables de ingresos antes y después de la anonimización. “sdcObj” es un objeto sdcMicro y “compExp“ es un vector que contiene los nombres de las variables de ingresos. El tamaño de los intervalos es k veces la desviación estándar, donde k es un parámetro en la función dRisk(). El más largo k, cuanto más grandes son los intervalos y, por lo tanto, mayor es el número de observaciones dentro del intervalo construidas alrededor de sus valores originales y mayor es la medida de riesgo. El resultado 1 indica que todas (100 por ciento) las observaciones están fuera del intervalo de 0,1 veces la desviación estándar alrededor de los valores originales. Bloque 7.7 Ilustración de medida de intervalo dRisk(obj = sdcObj@origData[,compExp], xm = sdcObj@manipNumVars[,compExp], k = 0.1) [1] 1 Para la mayoría de los valores, este es un enfoque satisfactorio. Sin embargo, no es una medida suficiente para valores atípicos. Después de la perturbación, los valores atípicos seguirán siendo valores atípicos y se pueden volver a identificar fácilmente, incluso si están lo suficientemente lejos de sus valores iniciales. Por lo tanto, los valores atípicos deben tratarse con precaución. 7.6.3 Detección de valores atípicos Los valores atípicos son importantes para medir el riesgo de reidentificación en microdatos continuos. Los datos continuos suelen estar sesgados, especialmente a la derecha. Esto significa que hay algunos valores atípicos con valores muy altos en relación con las otras observaciones de la misma variable. Algunos ejemplos son los ingresos en los datos de los hogares, donde solo unas pocas personas/hogares pueden tener ingresos muy altos, o los datos de facturación de empresas que son mucho más grandes que otras empresas de la muestra. En casos como estos, incluso si estos valores se perturban, aún puede ser fácil identificar estos valores atípicos, ya que seguirán siendo los valores más grandes incluso después de la perturbación (la perturbación habrá creado incertidumbre en cuanto al valor exacto, pero debido a que el valor comenzó mucho más lejos de otras observaciones, aún puede ser fácil vincularlo con el individuo de altos ingresos o la empresa muy grande). Los ejemplos serían el único médico en un área geográfica con altos ingresos o una sola gran empresa en un tipo de industria. Por lo tanto, la identificación de valores atípicos en datos continuos es un paso importante cuando se identifican personas con alto riesgo. En la práctica, identificar los valores de una variable continua que son mayores que un valor predeterminado p%-percentil podría ayudar a identificar valores atípicos y, por lo tanto, unidades con mayor riesgo de identificación. El valor de p depende de la asimetría de los datos. Podemos calcular el p%-percentil de una variable continua en R y mostrar los individuos que tienen ingresos superiores a este percentil. El Bloque 7.8 proporciona una ilustración del percentil 90. Bloque 7.8 Cómputo del percentil 90 % de la variable INCWAGE setwd(&quot;../Capacitación/GitHub&quot;) # directorio de trabajo fname = &quot;data.dta&quot; # nombre del archivo library(haven) # carga el paquete requerido para la función de lectura/escritura # para archivos STATA file &lt;- read_dta(fname) # Cómputo de 90 % percentil para variable INCWAGE perc90 &lt;- quantile(file[,&#39;INCWAGE&#39;], 0.90, na.rm = TRUE) # Muestra ID de observaciones con valores para INCWAGE mayores al 90 % percentil file[(file[, &#39;INCWAGE&#39;] &gt;= perc90), &#39;IDP&#39;] Un segundo enfoque para la detección de valores atípicos es una medida a posteriori que compara los datos tratados y sin procesar. Se construye un intervalo alrededor de los valores perturbados como se describe en la sección anterior. Si los valores originales caen dentro del intervalo alrededor de los valores perturbados, los valores perturbados se consideran inseguros ya que están demasiado cerca de los valores originales. Existen diferentes formas de construir dichos intervalos, como intervalos basados en rangos e intervalos basados en desviación estándar. Templ and Meindl (2008) proponen una alternativa robusta para estos intervalos. Construyen los intervalos en función de la distancia robusta de Mahalanobis (RMD, por su sigla en inglés) al cuadrado de los valores individuales. El RMD escala los intervalos de manera que los valores atípicos obtienen intervalos más grandes y, por lo tanto, deben tener una perturbación mayor para que se consideren seguros que los valores que no son atípicos. Este método se implementa en sdcMicro en la función dRiskRMD(), que es una extensión de la función dRisk(). 7.7 Riesgo global Para construir una medida de riesgo agregado a nivel global para el conjunto de datos completo, podemos agregar las medidas de riesgo a nivel individual de varias maneras. Las medidas de riesgo global deben usarse con precaución: detrás de un riesgo global aceptable pueden esconderse algunos registros de muy alto riesgo que se compensan con muchos registros de bajo riesgo. 7.7.1 Media de las medidas de riesgo individuales Una forma sencilla de agregar las medidas de riesgo individuales es tomar la media de todos los individuos de la muestra, que es igual a sumar todas las claves de la muestra si se multiplica por las frecuencias de muestra de estas claves y se divide por el tamaño de la muestra, \\(n\\): \\[R_{1}=\\frac{1}{n}\\sum_{i} r_{k}=\\frac{1}{n}\\sum_{k}f_{k}r_{k},\\] donde \\(r_{k}\\) es el riesgo individual de clave \\(k\\) que el i-ésimo registro comparte (ver la sección Identificadores indirectos categóricos y recuentos de frecuencia). Esta medida se informa como riesgo global en sdcMicro, se almacena en el slot de “riesgo” y se puede imprimir como se muestra en el Bloque 7.9. Indica que la probabilidad de reidentificación promedio es 0,01582 o 0,1582%. Bloque 7.9 Cómputo de la medida de riesgo global # Riesgo global (probabilidad promedio de re-identificación) sdcInitial@risk$global$risk El riesgo global en los datos de ejemplo de la Tabla 7.1 es 0,01582, que es la proporción esperada de todos los individuos de la muestra que un intruso podría volver a identificar. Otra forma de expresar el riesgo global es el número de reidentificaciones esperadas, \\(n*R_{1}\\), que es en el ejemplo 10 * 0,01582. El número esperado de reidentificaciones también se guarda en el objeto sdcMicro. El Bloque 7.10 muestra cómo imprimir esto. Bloque 7.10 Cómputo del número esperado de reidentificaciones # # Riesgo global(Número esperado de re-identificaciones) sdcInitial@risk$global$risk_ER 7.7.2 Recuento de personas con riesgos superiores a un cierto umbral Todos los individuos pertenecientes a la misma clave tienen el mismo riesgo individual, \\(r_{k}\\). Otra forma de expresar el riesgo total en la muestra es el número total de observaciones que superan un determinado umbral de riesgo individual. La fijación del umbral puede ser absoluta (por ejemplo, todas aquellas personas que tengan un riesgo de divulgación superior a 0,05 o 5%) o relativa (por ejemplo, todas aquellas personas con riesgos superiores al cuartil superior del riesgo individual). El Bloque 7.11 muestra cómo utilizando R, se contaría el número de observaciones con un riesgo de reidentificación individual superior al 5%. En el ejemplo, ninguna persona tiene un riesgo de divulgación superior a 0,05. Bloque 7.11 Número de personas con riesgo individual superior al umbral 0,05 sum(sdcInitial@risk$individual[,1] &gt; 0.05) Estos cálculos se pueden usar para tratar los datos de las personas cuyos valores de riesgo están por encima de un umbral predeterminado. Más adelante veremos que hay métodos en sdcMicro, como localSupp(), que se pueden usar para suprimir valores de ciertas variables clave para aquellas personas con riesgo por encima de un umbral específico. Esto se explica con más detalle en la sección Supresión local. 7.8 Riesgo jerárquico (o del hogar) En muchas encuestas sociales, los datos tienen una estructura jerárquica donde un individuo pertenece a una entidad de nivel superior (ver la sección Niveles de riesgo). Ejemplos típicos son los hogares en las encuestas sociales o los alumnos en las escuelas. La reidentificación de un miembro del hogar también puede conducir a la reidentificación de los otros miembros del hogar. Por tanto, es fácil ver que, si tenemos en cuenta la estructura del hogar, el riesgo de reidentificación es el riesgo de que al menos uno de los miembros del hogar sea reidentificado. \\[r^h=P(A_{1}\\bigcup A_{2}\\bigcup \\dots \\bigcup A_{J})=1-\\prod_{j=1}^J 1-P(A_{j}), \\] donde \\(A_{j}\\) es el evento que el j-ésimo miembro del hogar sea identificado y \\(P(A_{j})=r_{k}\\) es el riesgo de divulgación individual del j-ésimo miembro. Por ejemplo, si un hogar tiene tres miembros con riesgos de divulgación individuales en función de sus respectivas claves 0,02, 0,03 y 0,03, respectivamente, el riesgo del hogar es \\[1-((1-0,02)(1-0,03)(1-0,03))=0,078\\] El riesgo jerárquico o del hogar no puede ser menor que el riesgo individual, y el riesgo del hogar es siempre el mismo para todos los miembros del hogar. El riesgo del hogar debe utilizarse en los casos en que los datos contengan una estructura jerárquica, es decir, cuando la estructura del hogar esté presente en los datos. Usando sdcMicro, si se especifica un identificador de hogar (en el argumento hhId en la función createSdcObj()) al crear un objeto sdcMicro, el riesgo del hogar se calculará automáticamente. El Bloque 7.12 muestra cómo imprimir estas medidas de riesgo. Bloque 7.12 Cómputo del riesgo del hogar y número esperado de reidentificaciones # Riesgo del hogar sdcInitial@risk$global$hier_risk # Riesgo del hogar (Número esperado de reidentificaciones) sdcInitial@risk$global$hier_risk_ER El tamaño de un hogar es un identificador importante en sí mismo, especialmente para hogares grandes. Sin embargo, la supresión de la variable del tamaño real (por ejemplo, el número de miembros del hogar) no es suficiente para eliminar esta información del conjunto de datos, ya que un simple recuento de los miembros del hogar para un hogar en particular permitirá reconstruir esta variable siempre que un ID del hogar esté en los datos, lo que permite asignar individuos a los hogares. Señalamos esto para la atención del lector ya que es importante. 7.9 Referencias Referencias "],["métodos-sdc.html", "Capítulo 8 Métodos SDC 8.1 Clasificación de los métodos SDC 8.2 Métodos no perturbativos 8.3 Métodos perturbativos 8.4 Anonimización del identificador indirecto de tamaño del hogar 8.5 Resumen de métodos SDC", " Capítulo 8 Métodos SDC Esta sección describe los métodos SDC más utilizados. Todos los métodos se pueden implementar en R utilizando el paquete sdcMicro. Discutimos qué método es más adecuado para cada tipo de datos, tanto en términos de características como del tipo de dato. Además, se discuten opciones como los parámetros específicos de cada método, así como sus impactos. Las conclusiones pretenden ser orientativas, pero deben utilizarse con precaución, ya que cada operación estadística genera datos con características diferentes y las recomendaciones del documento no siempre serán las más adecuadas para sus datos en particular. Para determinar qué métodos de anonimización son adecuados para variables y/o conjuntos de datos específicos, comenzamos presentando algunas clasificaciones de los métodos SDC. 8.1 Clasificación de los métodos SDC Los métodos SDC pueden clasificarse en no perturbativos y perturbativos (A. Hundepool et al. 2012). Los métodos no perturbativos reducen el detalle de los datos mediante la generalización o la supresión de ciertos valores (enmascaramiento) sin distorsionar la estructura de los datos. Los métodos perturbativos no suprimen los valores del conjunto de datos, sino que alteran los valores para limitar el riesgo de divulgación creando incertidumbre en torno a los valores reales. Tanto los métodos no perturbativos como los perturbativos pueden utilizarse para variables categóricas y continuas. También distinguimos entre métodos probabilísticos y deterministas SDC. Los métodos probabilísticos dependen de un mecanismo de probabilidad o de un mecanismo de generación de números aleatorios. Cada vez que se utiliza un método probabilístico, se genera un resultado diferente. Para estos métodos se suele recomendar que se establezca una semilla (con la función set.seed()) para el generador de números aleatorios si se quiere producir resultados replicables. Los métodos deterministas siguen un algoritmo determinado y producen los mismos resultados si se aplican repetidamente a los mismos datos con el mismo conjunto de parámetros. Los métodos SDC para microdatos pretenden evitar la revelación de identidad y de atributos. Para cada tipo de control de la divulgación se utilizan diferentes métodos SDC. Métodos como la recodificación y la supresión local se aplican a los identificadores indirectos para evitar la divulgación de identidad, mientras que la codificación superior de un identificador indirecto (por ejemplo, los ingresos) o la perturbación de una variable sensible evitan la divulgación de atributos. Discutiremos los métodos SDC que se implementan en el paquete sdcMicro o que pueden implementarse fácilmente en R. Estos son los métodos más comúnmente aplicados en la literatura y utilizados en la mayoría de las agencias con experiencia en el uso de estos métodos. La Tabla 8.1 ofrece una visión general de los métodos de SDC discutidos en esta guía, su clasificación, los tipos de datos a los que son aplicables y los nombres de sus funciones en el paquete sdcMicro. Tabla 8.1: Métodos SDC y funciones correspondientes en sdcMicro Método Clasificación del método SDC Tipo de datos Función en sdcMicro Recodificación Global no perturbativo, determinista continuo y categórico globalRecode , groupVars Codificación Superior e Inferior no perturbativo, determinista continuo y categórico topBotCoding Supresión Local no perturbativo, determinista categórico localSuppression,localSupp PRAM perturbativo, probabilístico categórico pram Micro agregación perturbativo, probabilístico continuo microaggregation Adición de Ruido perturbativo, probabilístico continuo addNoise Shuffling perturbativo, probabilístico continuo shuffle Rank swapping perturbativo, probabilístico continuo rankSwap 8.2 Métodos no perturbativos 8.2.1 Recodificación La recodificación es un método determinista utilizado para disminuir el número de categorías o valores distintos de una variable. Se realiza combinando o agrupando categorías para las variables categóricas o construyendo intervalos para las variables continuas. La recodificación se aplica a todas las observaciones de una determinada variable y no solo a las que corren el riesgo de ser reveladas. Existen dos tipos generales de recodificación: la recodificación global y la codificación superior e inferior. 8.2.1.1 Recodificación global La recodificación global combina varias categorías de una variable categórica o construye intervalos para variables continuas. Esto reduce el número de categorías disponibles en los datos y, potencialmente, el riesgo de divulgación, especialmente para las categorías con pocas observaciones, pero también, y esto es importante, reduce el nivel de detalle de la información disponible para el analista. Para ilustrar la recodificación, utilizamos el siguiente ejemplo. Supongamos que tenemos cinco regiones en nuestro conjunto de datos. Algunas regiones son muy pequeñas y, cuando se combinan con otras variables clave del conjunto de datos, producen un alto riesgo de reidentificación para algunos individuos de esas regiones. Una forma de reducir el riesgo sería combinar algunas de las regiones al recodificarlas. Podríamos, por ejemplo, hacer tres grupos de los cinco, llamarlos “Norte”, “Centro” y “Sur” y en consecuencia reetiquetar los valores. De este modo, el número de categorías de la región variable se reduce de cinco a tres. Nota: Cualquier agrupación debe ser una agrupación pertinente para los objetivos analíticos de la operación estadística y no una unión aleatoria de categorías. Algunos ejemplos serían agrupar las comunas en provincias, las regiones en macrozonas o las categorías detalladas de agua limpia. Agrupar todas las regiones pequeñas sin proximidad geográfica no es necesariamente la mejor opción desde el punto de vista de los servicios públicos. La Tabla 8.2 lo ilustra con un conjunto de datos de ejemplo muy simplificado. Antes de la recodificación, tres individuos tienen claves distintas, mientras que después de la recodificación (agrupando la “Región 1” y la “Región 2” en el “Norte”, la “Región 3” en el “Centro” y la “Región 4” y la “Región 5” en el “Sur”), el número de claves distintas se reduce a cuatro y la frecuencia de cada clave es de al menos dos, basándose en los tres identificadores indirectos seleccionados. Los recuentos de la frecuencia de las claves \\(fk\\) se muestran en la última columna de la Tabla 8.2. Un intruso encontraría al menos dos individuos para cada clave y no podría distinguir más entre los individuos 1 - 3, los individuos 4 y 6, los individuos 5 y 7 y los individuos 8 - 10, basándose en las variables clave seleccionadas. Tabla 8.2: Ilustración del efecto de la recodificación en los recuentos de frecuencia de las variables clave Antes de recodificar Después de recodificar Individuo Región Sexo Religión \\(f_k\\) Región Sexo Religión \\(f_k\\) 1 Región 1 Mujer Católica 1 Norte Mujer Católica 3 2 Región 2 Mujer Católica 2 Norte Mujer Católica 3 3 Región 2 Mujer Católica 2 Norte Mujer Católica 3 4 Región 3 Mujer Protestante 2 Centro Mujer Protestante 2 5 Región 3 Hombre Protestante 1 Centro Hombre Protestante 2 6 Región 3 Mujer Protestante 2 Centro Mujer Protestante 2 7 Región 3 Hombre Protestante 2 Centro Hombre Protestante 2 8 Región 4 Hombre Musulmán 2 Sur Hombre Musulmán 3 9 Región 4 Hombre Musulmán 2 Sur Hombre Musulmán 3 10 Región 5 Hombre Musulmán 1 Sur Hombre Musulmán 3 La recodificación suele ser el primer paso de un proceso de anonimización. Puede utilizarse para reducir el número de combinaciones únicas de valores de las variables clave. Por lo general, esto aumenta los recuentos de frecuencia de la mayoría de las claves y reduce el riesgo de divulgación. La reducción del número de combinaciones posibles se ilustra en la Tabla 8.3 con los identificadores indirectos “región”, “estado civil” y “edad”. La Tabla 8.3 muestra el número de categorías de cada variable y el número de combinaciones teóricamente posibles, que es el producto del número de categorías de cada identificador indirecto, antes y después de la recodificación. La “edad” se interpreta como una variable semicontinua y se trata como una variable categórica. El número de combinaciones posibles y, por tanto, el riesgo de reidentificación se reducen en gran medida con la recodificación. Hay que tener en cuenta que el número de combinaciones posibles es un número teórico; en la práctica, pueden incluirse combinaciones muy improbables, como edad = 3 y estado civil = viudo, y el número real de combinaciones en un conjunto de datos puede ser inferior. Tabla 8.3: Ilustración del efecto de la recodificación en el número de combinaciones teóricamente posibles de un conjunto de datos Número de categorías Región Estado civil Edad Posibles combinaciones antes de la recodificación 20 8 100 16.000 después de la recodificación 6 6 15 540 Los principales parámetros para la recodificación global son el tamaño de los nuevos grupos, así como la definición de los valores que se agrupan en las nuevas categorías. Nota: Hay que tener cuidado de elegir las nuevas categorías, deberían generarse en función del uso de los datos por parte de los usuarios finales y de minimizar la pérdida de información como resultado de la recodificación. Podemos observarlo mediante tres ejemplos: Variable de edad: Las categorías de edad deben elegirse de forma que sigan permitiendo a los usuarios de los datos realizar cálculos relevantes para el tema que se está estudiando. Por ejemplo, si es necesario calcular indicadores para niños de edades comprendidas entre los 6 y los 11 años y entre los 12 y los 17 años, además, es necesario agrupar la edad para reducir el riesgo, hay que tener cuidado de crear intervalos de edad que sigan permitiendo realizar los cálculos. Una agrupación satisfactoria podría ser, por ejemplo, 0 - 5, 6 - 11, 12 - 17, etc., mientras que una agrupación 0 - 10, 11 - 15, 16 - 18 destruiría la utilidad de los datos para estos usuarios. Aunque es una práctica habitual crear intervalos (grupos) de igual anchura (tamaño), también es posible (si los usuarios de los datos lo requieren) recodificar solo una parte de las variables y dejar algunos valores como estaban originalmente. Esto podría hacerse, por ejemplo, recodificando todas las edades superiores a 20 años, pero dejando las inferiores a 20 años tal y como están. Si los métodos SDC distintos de la recodificación se van a utilizar más tarde o en un paso siguiente, hay que tener cuidado al aplicar la recodificación solo a una parte de la distribución, ya que esto podría aumentar la pérdida de información debida a los otros métodos, ya que la agrupación no protege las variables no agrupadas. La recodificación parcial seguida de métodos de supresión como la supresión local puede, por ejemplo, conducir a un número de supresiones mayor del deseado o necesario en caso de que la recodificación se realice para todo el rango de valores (ver la siguiente sección de Supresión local). En el ejemplo anterior, el número de supresiones de los valores inferiores a 20 será probablemente mayor que para los valores del rango recodificado. El número desproporcionadamente alto de supresiones en este rango de valores que no se recodifican puede conducir a una mayor pérdida de utilidad para estos grupos. Variables geográficas: Si los datos originales especifican información de nivel administrativo en detalle, por ejemplo, hasta el nivel de comuna, entonces potencialmente esos niveles inferiores podrían ser recodificados o agregados en niveles administrativos superiores, por ejemplo, la provincia, para reducir el riesgo. Al hacerlo, hay que tener en cuenta lo siguiente: La agrupación de comunas en niveles abstractos que se cruzan con diferentes provincias haría que el análisis de datos a nivel comunal o provincial fuera un reto. Se debe tener cuidado de entender lo que el usuario requiere y la intención del estudio. Si un componente clave de la encuesta es realizar un análisis a nivel comunal, la agregación a nivel provincial podría perjudicar la utilidad de los datos para el usuario. La recodificación debería aplicarse si el nivel de detalle de los datos no es necesario para la mayoría de los usuarios de los datos y para evitar un gran número de supresiones cuando se utilicen posteriormente otros métodos SDC. Si los usuarios necesitan información a un nivel más detallado, otros métodos, como los Métodos perturbativos, podrían ofrecer una solución mejor que la recodificación. Instalaciones sanitarias: Un ejemplo de una situación en la que un alto nivel de detalle podría no ser necesario y la recodificación podría hacer muy poco daño a la utilidad es el caso de una variable detallada de instalaciones sanitarias en el hogar que enumera las respuestas para 20 tipos de inodoros. Es posible que los investigadores solo necesiten distinguir entre instalaciones de inodoros mejoradas y no mejoradas y que no necesiten la clasificación exacta de hasta 20 tipos. La información detallada de los tipos de inodoros puede utilizarse para volver a identificar a los hogares, mientras que la recodificación en dos categorías -instalaciones mejoradas y no mejoradas- reduce el riesgo de reidentificación y, en este contexto, apenas reduce la utilidad de los datos. Este enfoque puede aplicarse a cualquier variable con muchas categorías en las que los usuarios de los datos no estén interesados en los detalles, sino en algunas categorías agregadas. La recodificación aborda la agregación para los usuarios de los datos y al mismo tiempo protege los microdatos. Es importante hacer un balance de las agregaciones utilizadas por los usuarios. La recodificación debe aplicarse solo si la eliminación de la información detallada de los datos no perjudica a la mayoría de las personas usuarias. Si los usuarios necesitan información a un nivel más detallado, entonces la recodificación no es apropiada y otros métodos, como los perturbativos, podrían funcionar mejor. En sdcMicro existen diferentes opciones de recodificación global. En los siguientes párrafos, damos ejemplos de recodificación global con las funciones groupAndRename() y globalRecode(). La función groupAndRename() se utiliza generalmente para las variables categóricas y la función globalRecode() para las variables continuas. Por último, discutimos el uso del redondeo para reducir el detalle en las variables continuas. 8.2.1.1.1 Recodificación de una variable categórica mediante la función sdcMicro groupAndRename() Supongamos que se ha creado un objeto de la clase sdcMicro, que se llama sdcInitial (véase el apartado Objetos de la clase sdcMicroObj cómo crear objetos de la clase sdcMicro). En el Bloque 8.1, la variable “sizeRes” tiene cuatro categorías diferentes: “capital”, “ciudad grande”, “ciudad pequeña”, “pueblo” y “campo”). Las tres primeras se recodifican o reagrupan como “urbano” y la categoría “campo” pasa a llamarse “rural”. En los argumentos de la función, especificamos las categorías que se van a agrupar (anterior) y los nombres de las categorías después de la recodificación (posterior). Es importante que los vectores “anterior” y “posterior” tengan la misma longitud. Por lo tanto, tenemos que repetir “urbano” tres veces en el vector (posterior) para que coincida con los tres valores diferentes que se recodifican en “urbano”. Nota: La función groupAndRename() solo funciona en variables tipo factor. Nos referimos a la sección Clases en R sobre cómo cambiar la clase de una variable. Cargar librerías. require(dplyr) require(foreign) require(sdcMicro) Cargaremos la base en formato de dta (stata). #directorio de trabajo #getwd() fname &lt;- &quot;data/data.dta&quot; file &lt;- read.dta(fname, convert.factors = TRUE) Ajustaremos las variables a factores. # Crear variables área y etnia para evaluar recodificación area_names &lt;- c(&quot;capital, large city&quot;, &quot;small city&quot;, &quot;town&quot;, &quot;countryside&quot;) area &lt;- sample(area_names[1:3], nrow(file[file$URBRUR==1,]), replace=TRUE, prob=c(0.60,0.27, 0.13)) file &lt;- file %&gt;% mutate(sizeRes = ifelse(URBRUR==1, area, area_names[4])) %&gt;% relocate(sizeRes, .after = URBRUR) %&gt;% mutate(sizeRes = factor(sizeRes, levels = area_names)) etnia_names &lt;- c(&quot;mapuche&quot;,&quot;diaguita&quot;,&quot;atacameno&quot;,&quot;otra&quot;,&quot;No aplica&quot;) etnia &lt;- sample(etnia_names, nrow(file), replace=TRUE, prob=c(0.2,0.1,0.1,0.1, 0.95)) file &lt;- file %&gt;% mutate(etnia = etnia) %&gt;% mutate(etnia = factor(etnia, levels = etnia_names)) selectedKeyVarsHH = c(&quot;sizeRes&quot;,&quot;AGEYRS&quot;, &quot;GENDER&quot;, &quot;REGION&quot;, &quot;etnia&quot;,&quot;RELIG&quot;) #, #selectedKeyVarsHH = c(&quot;URBRUR&quot;, &quot;REGION&quot;, &quot;HHSIZE&quot;, &quot;OWNAGLAND&quot;, &quot;RELIG&quot;) file$URBRUR &lt;- as.factor(file$URBRUR) file$REGION &lt;- as.factor(file$REGION) file$OWNHOUSE &lt;- as.factor(file$OWNHOUSE) file$OWNAGLAND &lt;- as.factor(file$OWNAGLAND) file$RELIG &lt;- as.factor(file$RELIG) numVarsHH &lt;- c(&quot;LANDSIZEHA&quot;, &quot;TANHHEXP&quot;, &quot;TFOODEXP&quot;, &quot;TALCHEXP&quot;, &quot;TCLTHEXP&quot;, &quot;THOUSEXP&quot;, &quot;TFURNEXP&quot;, &quot;THLTHEXP&quot;, &quot;TTRANSEXP&quot;, &quot;TCOMMEXP&quot;, &quot;TRECEXP&quot;, &quot;TEDUEXP&quot;, &quot;TRESTHOTEXP&quot;, &quot;TMISCEXP&quot;, &quot;INCTOTGROSSHH&quot;, &quot;INCRMT&quot;, &quot;INCWAGE&quot;, &quot;INCFARMBSN&quot;, &quot;INCNFARMBSN&quot;, &quot;INCRENT&quot;, &quot;INCFIN&quot;, &quot;INCPENSN&quot;, &quot;INCOTHER&quot;) pramVarsHH &lt;- c(&quot;ROOF&quot;, &quot;TOILET&quot;, &quot;WATER&quot;, &quot;ELECTCON&quot;, &quot;FUELCOOK&quot;, &quot;OWNMOTORCYCLE&quot;, &quot;CAR&quot;, &quot;TV&quot;, &quot;LIVESTOCK&quot;) weightVarHH &lt;- c(&quot;WGTPOP&quot;) # Ajuste strata file$strata_region &lt;- file$REGION strata_var &lt;- c(&quot;strata_region&quot;) # Ajuste para transformar factores file[,c(pramVarsHH)] &lt;- lapply(file[,c(pramVarsHH)], as.factor) HHVars &lt;- c(&quot;IDH&quot;, selectedKeyVarsHH, pramVarsHH, numVarsHH, weightVarHH, strata_var) #agrega strata fileHH &lt;- file fileHH &lt;- fileHH[which(!duplicated(fileHH$IDH)),] sdcHH &lt;- createSdcObj(dat=fileHH, keyVars=selectedKeyVarsHH, pramVars=pramVarsHH, weightVar=weightVarHH, numVars = numVarsHH, strataVar = &quot;strata_region&quot;) sdcInitial &lt;- sdcHH sdc_respaldo &lt;- sdcHH Bloque 8.1 Uso de la función sdcMicro groupAndRename() para recodificar una variable categórica # Frequencias de sizeRes antes de recodificar table(sdcInitial@manipKeyVars$sizeRes) ## ## capital, large city small city town countryside ## 792 348 176 684 # Recodificar urbano sdcInitial &lt;- groupAndRename(sdcInitial, var = &quot;sizeRes&quot;, before = c(&quot;capital, large city&quot;, &quot;small city&quot;, &quot;town&quot;), after = c(&quot;urban&quot;, &quot;urban&quot;, &quot;urban&quot;)) # Recodificar rural sdcInitial &lt;- groupAndRename(obj = sdcInitial, var = c(&quot;sizeRes&quot;), before = c(&quot;countryside&quot;), after = c(&quot;rural&quot;)) # Frequencias de sizeRes después de recodificar table(sdcInitial@manipKeyVars$sizeRes) ## ## urban rural ## 1316 684 La 8.1 ilustra el efecto de la recodificación de la variable “sizeRes” y muestra respectivamente los recuentos de frecuencia antes y después de la recodificación. Vemos que el número de categorías se ha reducido de 4 a 2 y las categorías pequeñas (“small city” y “town”) han desaparecido. Figura 8.1: Efecto de la recodificación y recuentos de frecuencia antes y después de la recodificación 8.2.1.1.2 Recodificación de una variable continua mediante la función sdcMicro: globalRecode() La recodificación global de las variables numéricas (continuas) puede lograrse en sdcMicro utilizando la función globalRecode(), que permite especificar un vector con los puntos de quiebre entre los intervalos. La recodificación de una variable continua la convierte en una variable categórica. Además, se puede especificar un vector de etiquetas para las nuevas categorías. Por defecto, las etiquetas son los intervalos, por ejemplo, “(0, 10]”. El Bloque 8.2 muestra cómo recodificar la variable edad en intervalos de 10 años para valores de edad entre 0 y 100. Nota: A los valores que quedan fuera de los intervalos especificados se les asigna un valor perdido NA Por lo tanto, los intervalos deben cubrir todo el rango de valores de la variable. Bloque 8.2 Uso de la función sdcMicro globalRecode() para recodificar una variable continua (edad) sdcInitial &lt;- globalRecode(sdcInitial, column = c(&quot;AGEYRS&quot;), breaks = 10 * c(0:10)) # Frecuencias de edad después de recodificar table(sdcInitial@manipKeyVars$AGEYRS) ## ## (0,10] (10,20] (20,30] (30,40] (40,50] (50,60] (60,70] (70,80] (80,90] (90,100] ## 0 44 389 578 428 266 173 92 27 3 # Guardo objeto de edad en tramos para volver a utilizar en localSupresion sdcInitial_edad &lt;- sdcInitial Figura 8.2: Variable de edad antes y después de la recodificación En lugar de crear intervalos de igual anchura, también podemos crear intervalos de anchura desigual. Esto se ilustra en el Bloque 8.3, donde utilizamos los grupos de edad 1-5, 6-11, 12-17, 18-21, 22-25, 26-49, 50-64 y 65+. En este ejemplo, es un paso útil, ya que incluso después de recodificar en intervalos de 10 años, las categorías con valores de edad altos tienen frecuencias bajas. Elegimos los intervalos respetando los valores relevantes de la edad escolar y de la edad laboral (por ejemplo, la edad de jubilación es de 65 años en este ejemplo) de forma que los datos puedan seguir utilizándose para la investigación común sobre educación y empleo. La 8.3 muestra el efecto de la recodificación de la variable “edad”. Bloque 8.3 Uso de globalRecode() para crear intervalos de ancho desigual sdcInitial &lt;- undolast(sdcInitial) sdcInitial &lt;- globalRecode(sdcInitial, column = c(&quot;AGEYRS&quot;), breaks = c(0, 5, 11, 17, 21, 25, 49, 65, 100)) # Frecuencias de edad después de recodificar table(sdcInitial@manipKeyVars$AGEYRS) ## ## (0,5] (5,11] (11,17] (17,21] (21,25] (25,49] (49,65] (65,100] ## 0 0 6 52 122 1213 398 209 Figura 8.3: Variable de edad antes y después de la recodificación Precaución sobre el uso de la función globalRecode() en sdcMicro: En la implementación actual de sdcMicro, los intervalos se definen como abiertos a la izquierda. En términos matemáticos, esto significa que, en nuestro ejemplo, la edad 0 está excluida de los intervalos especificados. En notación de intervalos, esto se denota como (0, 5] (como en las etiquetas del eje x en la 8.2 y la 8.3 para la variable recodificada). El intervalo (0, 5] se interpreta como de 0 a 5 y no incluye el 0, pero sí el 5. R recodifica los valores que no están contenidos en ninguno de los intervalos como perdidos (NA). Esta implementación establecería en nuestro ejemplo todos los valores de edad 0 (niños menores de 1 año) como perdidos y podría significar potencialmente una gran pérdida de datos. La función globalRecode() solo permite construir intervalos que queden abiertos. Este puede no ser un resultado deseable y la pérdida de las edades cero de los datos es claramente problemática para un conjunto de datos del mundo real. Para construir intervalos abiertos a la derecha, por ejemplo, en nuestro ejemplo, para los intervalos de edad [0,14), [15, 65), [66, 100), presentamos dos alternativas de recodificación global: Una solución para las variables semicontinuas21 y el valor 9999,5 se clasificaría erróneamente como perteneciente al intervalo [10000, 19999].] que permitiría utilizar globalRecode() sería restar un pequeño número a los intervalos límite, permitiendo así crear los intervalos deseados. En el siguiente ejemplo, restar 0,1 a cada intervalo obliga a globalRecode() a incluir el 0 en el intervalo inferior y permitir las pausas donde las queramos. Establecemos el límite superior del intervalo para que sea mayor que el valor máximo de la variable “edad”. Podemos utilizar la opción etiquetas para definir etiquetas claras para las nuevas categorías. Esto se ilustra en el Bloque 8.4. Bloque 8.4 Construcción de intervalos abiertos a la derecha para variables semicontinuas utilizando la función incorporada de sdcMicro, globalRecode() sdcInitial &lt;- undolast(sdcInitial) sdcInitial &lt;- globalRecode(sdcInitial, column = c(&quot;AGEYRS&quot;), breaks = c(-0.1, 14.9, 64.9, 99.9), labels = c(&#39;[0,15)&#39;, &#39;[15,65)&#39;, &#39;[65,100)&#39;)) Figura 8.4: Variable de edad antes y después de la recodificación También es posible utilizar código en R para recodificar manualmente las variables sin utilizar las funciones sdcMicro. Cuando se utilizan las funciones sdcMicro, el cambio en el riesgo después de la recodificación se recalcula automáticamente, pero si se recodifica manualmente no lo hace. En este caso, hay que dar un paso más y recalcular el riesgo después de cambiar manualmente las variables en el objeto sdcMicro. Este enfoque también es válido para las variables continuas y se ilustra en el Bloque 8.5. Bloque 8.5 Construcción de intervalos para variables semicontinuas y continuas mediante recodificación manual en R sdcInitial &lt;- undolast(sdcInitial) # Grupo edad 0-14 sdcInitial@manipKeyVars$AGEYRS[sdcInitial@manipKeyVars$AGEYRS &gt;= 0 &amp; sdcInitial@manipKeyVars$AGEYRS &lt; 15] &lt;- 0 # Grupo edad 15-64 sdcInitial@manipKeyVars$AGEYRS[sdcInitial@manipKeyVars$AGEYRS &gt;= 15 &amp; sdcInitial@manipKeyVars$AGEYRS &lt; 65] &lt;- 1 # Grupo edad 65-100 sdcInitial@manipKeyVars$AGEYRS[sdcInitial@manipKeyVars$AGEYRS &gt;= 65 &amp; sdcInitial@manipKeyVars$AGEYRS &lt;= 100] &lt;- 2 # Añadir etiquetas para los nuevos valores sdcInitial@manipKeyVars$AGEYRS &lt;-ordered(sdcInitial@manipKeyVars$AGEYRS, levels = c(0,1,2), labels = c(&quot;0-14&quot;, &quot;15-64&quot;, &quot;65-100&quot;)) # Recalcular el riesgo tras una transformación manual sdcInitial &lt;- calcRisks(sdcInitial) 8.2.1.2 Codificación superior e inferior La codificación superior e inferior es similar a la recodificación global, pero en lugar de recodificar todos los valores, solo se recodifican los valores superiores y/o inferiores de la distribución o las categorías. Esto solo puede aplicarse a las variables categóricas ordinales y a las variables semi-continuas, ya que los valores tienen que estar al menos ordenados. La codificación superior e inferior es especialmente útil si el grueso de los valores se encuentra en el centro de la distribución y las categorías periféricas tienen pocas observaciones (valores atípicos). Los ejemplos son la edad y los ingresos; para estas variables, a menudo habrá solo unas pocas observaciones por encima de ciertos umbrales, normalmente en las colas de la distribución. Cuanto menor sea el número de observaciones dentro de una categoría, mayor será el riesgo de identificación. Una solución podría ser agrupar los valores de las colas de la distribución en una categoría. Esto reduce el riesgo para esas observaciones y, lo que es más importante, lo hace sin reducir la utilidad de los datos para las demás observaciones de la distribución. Decidir dónde aplicar el umbral y qué observaciones deben agruparse requiere: Revisar la distribución global de la variable para identificar en qué punto las frecuencias caen por debajo del número deseado de observaciones e identificar los valores atípicos en la distribución. 8.5 muestra la distribución de la variable edad y sugiere 65 (línea vertical roja) para el código superior de edad. Tener en cuenta el uso previsto de los datos y el propósito para el que se realizó la encuesta. Por ejemplo, si los datos se utilizan normalmente para medir la participación en la fuerza laboral de las personas de 15 a 64 años, la codificación superior e inferior no debe interferir con las categorías de 15 a 64 años. De lo contrario, el analista se encontraría con la imposibilidad de crear las medidas deseadas para las que estaban destinados los datos. En el ejemplo, consideramos esto y codificamos todas las edades superiores a 64 años. Figura 8.5: Utilización de la distribución de frecuencias de la variable edad para determinar el umbral de la codificación superior La codificación superior e inferior se puede hacer fácilmente con la función topBotCoding() en sdcMicro. La codificación superior y la inferior no pueden hacerse simultáneamente en sdcMicro. El Bloque 8.6 ilustra cómo recodificar valores de edad superior a 64 y valores de edad inferior a 5; 65 y 5 reemplazan los valores respectivamente. Para construir varias categorías de codificación superior o inferior, por ejemplo, edad de 65 a 80 años y superior a 80 años, se puede utilizar la función groupAndRename() en sdcMicro o la recodificación manual como se describe en la subsección anterior. Bloque 8.6 Codificación superior y codificación inferior en sdcMicro utilizando la función topBotCoding() sdcInitial &lt;- sdc_respaldo # leo nuevamente la Tabla # Top coding en edad 65 sdcInitial &lt;- topBotCoding(obj = sdcInitial, value = 65, replacement = 65, kind = &quot;top&quot;, column = &quot;AGEYRS&quot;) # Bottom coding en edad 5 sdcInitial &lt;- topBotCoding(obj = sdcInitial, value = 5, replacement = 5, kind = &quot;bottom&quot;, column = &quot;AGEYRS&quot;) #table(sdcInitial@manipKeyVars$AGEYRS) Figura 8.6: Distribución de frecuencias de la variable edad con codificación superior 8.2.1.3 Redondeo El redondeo es similar a la agrupación, pero se utiliza para las variables continuas. El redondeo es útil para evitar la coincidencia exacta con fuentes de datos externas. Además, puede utilizarse para reducir el nivel de detalle de los datos. Algunos ejemplos son la eliminación de las cifras decimales o el redondeo a la unidad más cercana. sdcInitial &lt;- sdc_respaldo # leo nuevamente la Tabla table(sdcInitial@manipKeyVars$AGEYRS) ## ## 12 14 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 ## 1 3 2 7 15 16 14 28 31 24 39 45 41 52 50 65 48 77 60 55 78 56 56 48 45 55 33 50 45 41 52 51 ## 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 ## 32 39 39 46 36 38 26 19 22 22 22 28 29 24 16 22 13 10 25 13 10 17 21 26 13 9 10 3 11 5 5 15 ## 79 80 81 82 83 84 85 86 87 88 90 91 ## 7 14 5 1 4 6 4 3 1 2 1 3 # Se redondea a la decena más cercana sdcInitial@manipKeyVars$AGEYRS &lt;- round(sdcInitial@manipKeyVars$AGEYRS,-1) table(sdcInitial@manipKeyVars$AGEYRS) ## ## 10 20 30 40 50 60 70 80 90 ## 4 176 493 559 326 233 122 77 10 En la siguiente sección se analiza el método de supresión local. La recodificación suele utilizarse antes de la supresión local para reducir el número de supresiones necesarias. Lectura recomendada de recodificación: - Hundepool, Anco, Josep Domingo-Ferrer, Luisa Franconi, Sarah Giessing, Rainer Lenz, Jane Naylor, Eric Schulte Nordholt, Giovanni Seri, and Peter Paul de Wolf. 2006. Handbook on Statistical Disclosure Control. ESSNet SDC. http://neon.vb.cbs.nl/casc/handbook.htm. - Hundepool, Anco, Josep Domingo-Ferrer, Luisa Franconi, Sarah Giessing, Eric Schulte Nordholt, Keith Spicer, and Peter Paul de Wolf. 2012. Statistical Disclosure Control. Chichester: John Wiley &amp; Sons Ltd. doi:10.1002/9781118348239. - Templ, Matthias, Bernhard Meindl, Alexander Kowarik, and Shuang Chen. 2014. Statistical Disclosure Control (SDCMicro). http://www.ihsn.org/home/software/disclosure-control-toolbox. (accessed June 9, 2018). - De Waal, A.G., and Willenborg, L.C.R.J. 1999. Information loss through global recoding and local suppression. Netherlands Official Statistics, 14:17-20, 1999. Special issue on SDC 8.2.2 Supresión local En las encuestas es frecuente encontrar valores para ciertas variables o combinaciones de identificadores indirectos que son compartidos por muy pocos individuos. Cuando esto ocurre, el riesgo de reidentificación para esos encuestados es mayor que para el resto de los encuestados (véase la sección k-anonimato). A menudo se utiliza la supresión local tras reducir el número de claves en los datos al recodificar las variables adecuadas. La recodificación reduce el número de supresiones necesarias, así como el tiempo de cálculo para la supresión. La supresión de valores significa que los valores de una variable se sustituyen por un valor ausente NA en R). En la sección k-anonimato se analiza cómo influyen los valores perdidos en los recuentos de frecuencia y en el \\(k\\)-anonimato. Es importante tener en cuenta que no se suprimen todos los valores de todos los individuos de una determinada variable, lo que ocurriría al eliminar un identificador directo, como el “nombre”; solo se suprimen determinados valores de una variable concreta y de un encuestado o conjunto de encuestados concreto. Esto se ilustra en el siguiente ejemplo y en la Tabla 8.4. La Tabla 8.4 presenta un conjunto de datos con siete encuestados y tres identificadores indirectos. La combinación {“mujer”, “rural”, “superior”} para las variables “sexo”, “región” y “educación” es una combinación poco segura, ya que es única en la muestra. Al suprimir el valor “mujer” o “superior”, el encuestado ya no puede distinguirse de los demás encuestados, ya que ese encuestado comparte la misma combinación de variables clave con al menos otros tres encuestados. Solo se suprime el valor de la combinación insegura del único encuestado en riesgo, no los valores de la misma variable de los demás encuestados. La libertad de elegir qué valor se suprime puede utilizarse para minimizar el número total de supresiones y, por tanto, la pérdida de información. Además, si una variable es muy importante para el usuario, podemos elegir no suprimir los valores de esta variable, a menos que sea estrictamente necesario. En el ejemplo, podemos elegir entre suprimir el valor “mujer” o “mayor” para conseguir un archivo de datos seguro; elegimos suprimir “mayor”. Esta elección debe hacerse teniendo en cuenta las necesidades de los usuarios de los datos. En este ejemplo, consideramos que “sexo” es más importante que “educación”. Tabla 8.4: Ilustración de la supresión local - datos antes y después de la supresión Datos originales Después de supresión local ID Sexo Zona Educación Sexo Zona Educación 1 mujer rural superior mujer rural NA / perdido 2 hombre rural superior hombre rural superior 3 hombre rural superior hombre rural superior 4 hombre rural superior hombre rural superior 5 mujer rural media mujer rural media 6 mujer rural media mujer rural media 7 mujer rural media mujer rural media Dado que las variables continuas tienen un elevado número de valores únicos (por ejemplo, los ingresos en dólares o la edad en años), el \\(k\\)-anonimato y la supresión local no son adecuadas para las variables continuas o las variables con un número muy elevado de categorías. Una posible solución en esos casos podría ser recodificar primero para producir menos categorías (por ejemplo, recodificar la edad en intervalos de 10 años o los ingresos en quintiles). No obstante, tenga siempre presente el efecto que tendrá cualquier recodificación en la utilidad de los datos. El paquete sdcMicro incluye dos funciones para la supresión local: localSuppression() y localSupp(). La función localSuppression() es la más utilizada y permite el uso de la supresión en identificadores indirectos especificados para lograr un cierto nivel de \\(k\\)-anonimato para estos identificadores indirectos. El algoritmo utilizado busca minimizar el número total de supresiones mientras se alcanza el umbral de \\(k\\)-anonimato requerido. Por defecto, el algoritmo tiene más probabilidades de suprimir valores de variables con muchas categorías o valores diferentes, y menos de suprimir variables con menos categorías. Por ejemplo, es más probable que se supriman los valores de una variable geográfica, con 12 áreas diferentes, que los valores de la variable “sexo”, que suele tener solo dos categorías. Si las variables con muchos valores diferentes son importantes para la utilidad de los datos y no se desea la supresión para ellas, es posible clasificar las variables por importancia en la función localSuppression() y así especificar el orden en el que el algoritmo tratará de suprimir los valores dentro de los identificadores indirectos para lograr el \\(k\\)-anonimato. El algoritmo trata de aplicar menos supresiones a las variables de gran importancia que a las de menor importancia. Sin embargo, las supresiones en las variables con alta importancia pueden ser inevitables para lograr el nivel requerido de \\(k\\)-anonimato. En el Bloque 8.7, se aplica la supresión local para alcanzar el umbral de \\(k\\)-anonimato de 5 en los identificadores indirectos “sexo”, “región”, “religión”, “edad” y “etnia”22. Sin clasificar la importancia de las variables, el valor de la variable “edad” es más probable que se suprima, ya que es la variable con más categorías. La variable “edad” tiene 10 categorías después de la recodificación. La variable “sexo” es la menos probable que se suprima, ya que solo tiene dos valores diferentes: “hombre” y “mujer”. Las demás variables tienen 4 categorías (“tamañoRes”), 2 (“región”) y 8 (“etnia”). Después de aplicar la función localSuppression(), mostramos el número de supresiones por variable con la función incorporada print() con la opción ‘ls’ para la salida de supresión local. Como se esperaba, la variable “edad” es la que tiene más supresiones (80). De hecho, solo la variable “etnia” de las demás variables también necesitó supresiones (8) para alcanzar el umbral de \\(k\\)-anonimato de 5. La variable “etnia” es la segunda variable con mayor número de supresiones. Posteriormente, deshacemos y rehacemos la supresión local en los mismos datos y reducimos el número de supresiones en “edad” especificando el vector de importancia con alta importancia (poca supresión) en el identificador indirecto “edad”. También,asignamos importancia a la variable “sexo”. Esto se hace especificando un vector de importancia. Los valores del vector de importancia pueden ir de 1 a k, el número de identificadores indirectos. En nuestro ejemplo, k es igual a 5. Las variables con valores más bajos en los vectores de importancia tienen una importancia alta y, cuando es posible, reciben menos supresiones que las variables con valores más altos. Para asignar una importancia alta a las variables “edad” y “sexo”, especificamos el vector de importancia como c(5, 1, 1, 4, 4, 5), con el orden según el orden de las variables especificadas en el objeto sdcMicro. El efecto es claro: no hay supresiones en las variables “edad” y “sexo”. En cambio, las demás variables, especialmente “tamañoRes” y “etnia”, recibieron muchas más supresiones. El número total de valores suprimidos ha aumentado de 88 a 166. Nota: Un menor número de supresiones en una variable aumenta el número de supresiones necesarias en otras variables (véase el Bloque 8.7). Por lo general, el número total de valores suprimidos necesarios para alcanzar el nivel requerido de \\(k\\)-anonimato aumenta cuando se especifica un vector de importancia, ya que el vector de importancia impide utilizar el patrón de supresión óptimo. El vector de importancia debe especificarse solo en los casos en que las variables con muchas categorías desempeñen un papel importante en la utilidad de los datos para los usuarios de los mismos23. Bloque 8.7 Aplicación de la supresión local con y sin vector de importancia # Se comienza con la edad recodificada en tramos de 10 años sdcInitial &lt;- sdcInitial_edad #sdcInitial &lt;- sdc_respaldo # leo nuevamente la Tabla #sdcInitial &lt;- undolast(sdcInitial) # supresión local sin vector de importancia sdcInitial &lt;- localSuppression(sdcInitial, k = 2) print(sdcInitial, type=&quot;ls&quot;) ## Local suppression (applied per strata given by variable(s) strata_region) ## KeyVar | Suppressions (#) | Suppressions (%) ## sizeRes | 1 | 0.050 ## AGEYRS | 280 | 14.000 ## GENDER | 0 | 0.000 ## REGION | 0 | 0.000 ## etnia | 17 | 0.850 ## RELIG | 25 | 1.250 ## ---------------------------------------------------------------------- # Deshacer las supresiones sdcInitial &lt;- undolast(sdcInitial) # Supresión local con vector de importancia para evitar supresiones # en las variables primera (sexo) y cuarta (edad) sdcInitial &lt;- localSuppression(sdcInitial, importance = c(5, 1, 1, 4, 4, 5), k = 2) # c(5, 1, 1, 5, 5), k = 5) print(sdcInitial, type=&quot;ls&quot;) ## Local suppression (applied per strata given by variable(s) strata_region) ## KeyVar | Suppressions (#) | Suppressions (%) ## sizeRes | 138 | 6.900 ## AGEYRS | 16 | 0.800 ## GENDER | 1 | 0.050 ## REGION | 0 | 0.000 ## etnia | 108 | 5.400 ## RELIG | 60 | 3.000 ## ---------------------------------------------------------------------- La 8.7 demuestra el efecto del umbral de \\(k\\)-anonimato requerido y el vector de importancia en la utilidad de los datos utilizando varios indicadores relacionados con el mercado laboral de un conjunto de datos24 antes y después de la anonimización. La 8.7 muestra los cambios relativos como porcentaje del valor inicial después de volver a calcular los indicadores con los datos a los que se aplicó la supresión local. Los indicadores son la proporción de mujeres y hombres activos y el número de mujeres y hombres en edad de trabajar. Los valores calculados a partir de los datos brutos son, respectivamente, 68%, 12%, 8.943 y 9.702. La línea vertical en 0 es el punto de referencia de la ausencia de cambios. Los números indican el umbral de \\(k\\)-anonimato requerido (3 o 5) y los colores indican el vector de importancia: el rojo (sin símbolo) es ningún vector de importancia, el azul (con símbolo \\(\\color {blue}{\\text{*}}\\)) es de alta importancia en la variable con la información sobre la situación laboral y el verde oscuro (con símbolo \\(\\color {darkgreen}{\\text{+}}\\)) es de alta importancia en la variable de edad. Un umbral de \\(k\\)-anonimato más alto conlleva una mayor pérdida de información (es decir, mayores desviaciones de los valores originales de los indicadores, los 5 están más alejados del punto de referencia de ningún cambio que los correspondientes 3) causada por la supresión local. Reducir el número de supresiones en la variable de situación laboral especificando un vector de importancia no mejora los indicadores. En cambio, reducir el número de supresiones en la edad reduce en gran medida la pérdida de información. Dado que los grupos de edad específicos tienen una gran influencia en el cálculo de estos indicadores (los casos raros se encuentran en los extremos y se suprimirán), los índices de supresión elevados sobre la edad distorsionan los indicadores. En general, es útil comparar las medidas de utilidad (véase la sección Medición de la utilidad y la pérdida de información) para especificar el vector de importancia, ya que los efectos pueden ser imprevisibles. Figura 8.7: Cambios en los indicadores del mercado laboral tras la anonimización de los datos de I2D2 El umbral de \\(k\\)-anonimato que debe fijarse depende de varios factores, que son, entre otros: Los requisitos legales para un archivo de datos seguro. Otros métodos que se aplicarán a los datos. El número de supresiones y la consiguiente pérdida de información resultante de umbrales más altos. El tipo de variable. Las ponderaciones y el tamaño de la muestra. El tipo de publicación (véase la sección Tipos de liberación de datos). Los niveles aplicados habitualmente para el umbral de \\(k\\)-anonimato son 3 y 5. La Tabla 8.5 ilustra la influencia del vector de importancia y el umbral de \\(k\\)-anonimato en el tiempo de ejecución, el riesgo global tras la supresión y el número total de supresiones necesarias para alcanzar este umbral de \\(k\\)-anonimato. El conjunto de datos contiene unos 63.000 individuos. Cuanto mayor sea el umbral de \\(k\\)-anonimato, más supresiones serán necesarias y menor será el riesgo tras la supresión local (número esperado de reidentificaciones). En este ejemplo concreto, el tiempo de cálculo es menor para los umbrales más altos. Esto se debe al mayor número de supresiones necesarias, lo que reduce la dificultad de la búsqueda de un patrón de supresión óptimo. La variable edad se recodifica en intervalos de cinco años y tiene 20 categorías de edad. Esta es la variable con el mayor número de categorías. Dar prioridad a la supresión de otras variables conduce a un mayor número total de supresiones y a un mayor tiempo de cálculo. Tabla 8.5: Efecto de los vectores de importancia y umbrales de \\(k\\)-anonimato en el tiempo de ejecución y número total de supresiones Umbral k-anonimato Vector de importancia Número total de supresiones Umbral k-anonimato Vector de importancia Número total de supresiones 3 ninguno (por defecto) 6,676 5,387 293.0 11.8 3 situación laboral 7,254 5,512 356.5 13.1 3 variable de edad 8,175 60 224.6 4.5 5 ninguno (por defecto) 9,971 7,894 164.6 8.5 5 situación laboral 11,668 8,469 217.0 10.2 5 variable de edad 13,368 58 123.1 3.8 En los casos en que hay un gran número de identificadores indirectos y las variables tienen muchas categorías, el número de combinaciones posibles aumenta rápidamente (véase k-anonimato). Si el número de variables y categorías es muy grande, el tiempo de cálculo del algoritmo localSuppression() puede ser muy largo (véase la sección Tiempo de cómputo sobre el tiempo de cálculo). Además, es posible que el algoritmo no llegue a una solución, o que llegue a una solución que no cumpla el nivel de \\(k\\)-anonimato especificado. Por lo tanto, se recomienda reducir el número de identificadores indirectos y/o categorías antes de aplicar la supresión local. Esto puede hacerse recodificando las variables o seleccionando algunas variables para otros métodos (perturbativos), como el PRAM. De este modo se garantiza que el número de supresiones sea limitado y, por tanto, la pérdida de datos se limite solo a los valores que suponen un mayor riesgo. En algunos conjuntos de datos, puede resultar difícil reducir el número de identificadores indirectos e incluso después de reducir el número de categorías mediante recodificación, el algoritmo de supresión local tarda mucho tiempo en calcular las supresiones necesarias. Una solución en estos casos puede ser el llamado “enfoque all-m” (véase (Wolf 2015)). El enfoque all-m consiste en aplicar el algoritmo de supresión local descrito anteriormente a todos los posibles subconjuntos de tamaño m del conjunto total de identificadores indirectos. La ventaja de este enfoque es que los problemas parciales son más fáciles de resolver y el tiempo de cálculo será menor. Hay que tener cuidado, ya que este método no conduce necesariamente al \\(k\\)-anonimato en el conjunto completo de identificadores indirectos. Hay dos posibilidades para alcanzar el mismo nivel de protección 1) elegir un umbral más alto para k o 2) volver a aplicar el algoritmo de supresión local en el conjunto completo de k después de utilizar el método all-m para alcanzar el umbral requerido. En el segundo caso, el enfoque all-m conduce a un menor tiempo de cálculo a costa de un mayor número total de supresiones. Nota: El nivel requerido no se alcanza automáticamente en todo el conjunto de identificadores indirectos si se utiliza el enfoque all-m. Por lo tanto, es importante evaluar cuidadosamente las medidas de riesgo después de utilizar el enfoque all-m. En sdcMicro el enfoque all-m se implementa en el argumento ‘combs’ de la función localSuppression(). El valor de m se especifica en el argumento ‘combs’ y también puede tomar varios valores. Los subconjuntos de diferentes tamaños se utilizan secuencialmente en el algoritmo de supresión local. Por ejemplo, si ‘combs’ se establece como c(3,9), primero se consideran todos los subconjuntos de tamaño 3 y posteriormente todos los subconjuntos de tamaño 9. Establecer el último valor del argumento combs en el número total de variables clave garantiza la consecución del \\(k\\)-anonimato para el conjunto de datos completo. También es posible especificar diferentes valores de k para cada tamaño de subconjunto en el argumento k. Si quisiéramos lograr el anonimato de 5 en los subconjuntos de tamaño 3 y posteriormente el anonimato de 3 en los subconjuntos de tamaño 9, estableceríamos el argumento k como c(5,3). El Bloque 8.8 ilustra el uso del enfoque all-m en sdcMicro. Bloque 8.8 El enfoque all-m en sdcMicro sdcInitial &lt;- undolast(sdcInitial) # Aplicar k-anonimato con umbral 5 a todos los subconjuntos de dos variables clave y # posteriormente al conjunto de datos completo sdcInitial &lt;- localSuppression(sdcInitial, k = 5, combs = c(2, 5)) print(sdcInitial, type=&quot;ls&quot;) ## Local suppression (applied per strata given by variable(s) strata_region) ## KeyVar | Suppressions (#) | Suppressions (%) ## sizeRes | 0 | 0.000 ## AGEYRS | 510 | 25.500 ## GENDER | 0 | 0.000 ## REGION | 0 | 0.000 ## etnia | 82 | 4.100 ## RELIG | 52 | 2.600 ## ---------------------------------------------------------------------- sdcInitial &lt;- undolast(sdcInitial) # Aplicar k-anonimato con umbral 5 a todos los subconjuntos de tres variables clave y # posteriormente con el umbral 2 al conjunto de datos completo sdcInitial &lt;- localSuppression(sdcInitial, k = c(3, 5), combs = c(5, 2)) print(sdcInitial, type=&quot;ls&quot;) ## Local suppression (applied per strata given by variable(s) strata_region) ## KeyVar | Suppressions (#) | Suppressions (%) ## sizeRes | 0 | 0.000 ## AGEYRS | 409 | 20.450 ## GENDER | 0 | 0.000 ## REGION | 0 | 0.000 ## etnia | 34 | 1.700 ## RELIG | 52 | 2.600 ## ---------------------------------------------------------------------- La Tabla 8.6 presenta los resultados de utilizar el enfoque all-m de un conjunto de datos de prueba con 9 variables clave y 4.000 registros. La Tabla muestra los argumentos k y “combs” de la función localSuppression(), el número de violaciones de \\(k\\)-anonimato para diferentes niveles de k, así como el número total de supresiones. Observamos que las diferentes combinaciones no siempre conducen al nivel de \\(k\\)-anonimato requerido. Por ejemplo, cuando se establece k=3, y “combs” 3 y 7, todavía hay 15 registros en el conjunto de datos (con un total de 9 identificadores indirectos) que violan el anonimato 3 después de la supresión local. Debido al menor tamaño de la muestra, las ganancias en tiempo de ejecución no son todavía evidentes en este ejemplo, ya que la ejecución del algoritmo varias veces consume tiempo. Un conjunto de datos más grande se beneficiaría más del enfoque all-m, ya que el algoritmo tardaría más tiempo. Tabla 8.6: Efecto del enfoque all-m en el \\(k\\)-anonimato Argumentos Número de incumplimientos para diferentes niveles de \\(k\\)-anonimato en el conjunto completo Número total de supresiones Tiempo de ejecución (segundos) k combs k = 2 k = 3 k = 5 . . Antes supresión de la local 2,464 3,324 3,877 0 0.00 3 . 0 0 1,766 2,264 17.08 5 . 0 0 0 3,318 10.57 3 3 2,226 3,202 3,819 3,873 13.39 3 3,7 15 108 1,831 6,164 46.84 3 3,9 0 0 1,794 5,982 31.38 3 5,9 0 0 1,734 6,144 62.30 5 3 2,047 3,043 3,769 3,966 12.88 5 3,7 0 6 86 7,112 46.57 5 3,9 0 0 0 7,049 24.13 5 5,9 0 0 0 7,129 54.76 5,3 3,7 11 108 1,859 6,140 45.60 5,3 3,9 0 0 1,766 2,264 30.07 5,3 5,9 0 0 0 3,318 51.25 A menudo el conjunto de datos contiene variables relacionadas con las variables clave utilizadas para la supresión local. Ejemplos de ello son las variables rural/urbano a las regiones en caso de que las regiones sean completamente rurales o urbanas o las variables que solo se responden para categorías específicas (por ejemplo, el sector para los que trabajan, las variables relacionadas con la escolaridad para ciertos rangos de edad). En esos casos, las variables rural/urbana o sector podrían no ser identificadores indirectos en sí mismas, pero podrían permitir al intruso reconstruir valores suprimidos en los identificadores indirectos región o situación laboral. Por ejemplo, si la región 1 es completamente urbana y todas las demás regiones son solo semiurbanas o rurales, una supresión en la variable región para un registro de la región 1 puede reconstruirse simplemente mediante la variable rural/urbana. Por lo tanto, es útil suprimir los valores correspondientes a las supresiones en esas variables vinculadas. El Bloque 8.9 ilustra cómo suprimir los valores de la variable “urbrur” correspondientes a las supresiones en la variable región. Todos los valores de “urbrur” que corresponden a un valor suprimido NA en la variable “region” se suprimen (se ponen a NA). Bloque 8.9 Suprimir manualmente los valores de las variables vinculadas. # Suprimir los valores de urbrur en el archivo si la región está suprimida file[is.na(sdcInitial@manipKeyVars$region) &amp; !is.na(sdcInitial@origData$region),&#39;sizRes&#39;] &lt;- NA Como alternativa, las variables vinculadas pueden especificarse al crear el objeto sdcMicro. Las variables vinculadas se denominan variables “fantasma”. Cualquier supresión en la variable clave conducirá a una supresión en las variables vinculadas a esa variable clave. El Bloque 8.10 muestra cómo especificar la vinculación entre “región” y “urbrur” con variables fantasma. Bloque 8.10 Suprimir valores en variables enlazadas especificando variables fantasma # Las variables fantasma (vinculadas) se especifican como una lista de vínculos ghostVars &lt;- list() # Cada enlace es una lista, con la variable clave en el primer elemento y # la(s) variable(s) vinculada(s) en el segundo elemento ghostVars[[1]] &lt;- list() ghostVars[[1]][[1]] &lt;- &quot;REGION&quot; ghostVars[[1]][[2]] &lt;- c(&quot;URBRUR&quot;) # Crear sdcMicroObj sdcInitial &lt;- createSdcObj(dat=fileHH, keyVars=selectedKeyVarsHH, pramVars=pramVarsHH, weightVar=weightVarHH, numVars = numVarsHH, ghostVars = ghostVars) # Las variables fantasma manipuladas se encuentran en manipGhostVars head(sdcInitial@manipGhostVars,10) ## URBRUR ## 1 2 ## 8 1 ## 12 2 ## 20 1 ## 31 2 ## 38 1 ## 42 1 ## 44 1 ## 46 2 ## 47 1 La alternativa más sencilla para la función localSuppression() en sdcMicro es la función localSupp(). La función localSupp() puede utilizarse para suprimir los valores de ciertas variables clave de los individuos con riesgos superiores a un determinado umbral. En este caso, se suprimirán todos los valores de la variable especificada para los encuestados con un riesgo superior al umbral especificado. La medida de riesgo utilizada es el riesgo individual (véase la sección Riesgo individual. Esto es útil si una variable tiene valores sensibles que no deben publicarse para los individuos con alto riesgo de reidentificación. Lo que se considera alta probabilidad de reidentificación depende de los requisitos legales. En el siguiente ejemplo, los valores de la variable “educación” se suprimen para todos los individuos cuyo riesgo individual es superior a 0,08, lo que se ilustra en el Bloque 8.11. Para obtener una visión general de los valores de riesgo individuales, puede ser útil observar las estadísticas resumidas de los valores de riesgo individuales, así como el número de supresiones. Bloque 8.11 Aplicación de la función integrada sdcMicro localSupp() # Estadísticas resumidas summary(sdcInitial@risk$individual[,1]) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 3.371e-05 7.124e-04 3.004e-03 4.893e-03 6.236e-03 8.541e-02 # Número de individuos con riesgo individual superior al 0,1 sum(sdcInitial@risk$individual[,1] &gt; 0.08) ## [1] 2 # supresión local sdcInitial &lt;- localSupp(sdcInitial, threshold = 0.08, keyVar = &quot;etnia&quot;) print(sdcInitial, type=&quot;ls&quot;) ## Local suppression: ## KeyVar | Suppressions (#) | Suppressions (%) ## sizeRes | 0 | 0.000 ## AGEYRS | 0 | 0.000 ## GENDER | 0 | 0.000 ## REGION | 0 | 0.000 ## etnia | 2 | 0.100 ## RELIG | 0 | 0.000 ## ---------------------------------------------------------------------- 8.3 Métodos perturbativos Los métodos perturbativos no suprimen los valores del conjunto de datos, sino que perturban (alteran) los valores para limitar el riesgo de divulgación creando incertidumbre en torno a los valores reales. Un intruso no sabe si una coincidencia entre los microdatos y un archivo externo es correcta o no. La mayoría de los métodos perturbativos se basan en el principio del enmascaramiento matricial, es decir, el conjunto de datos alterado \\(Z\\) se calcula como \\[Z = AXB + C\\] donde \\(X\\) son los datos originales, \\(A\\) es una matriz utilizada para transformar los registros, \\(B\\) es una matriz para transformar las variables y \\(C\\) es una matriz con ruido aditivo. Nota: Las medidas de riesgo basadas en el recuento de frecuencias de las claves dejan de ser válidas tras aplicar los métodos perturbativos. Esto puede verse en la Tabla 8.7, que muestra los mismos datos antes y después de intercambiar algunos valores. Los valores intercambiados aparecen en cursiva. Tanto antes como después de perturbar los datos, todas las observaciones violan el \\(k\\)-anonimato en el nivel 3 (es decir, cada clave no aparece más de dos veces en el conjunto de datos). No obstante, el riesgo de reidentificación correcta de los registros se reduce y, por tanto, es posible que no se revele la información contenida en otras variables (sensibles). Con cierta probabilidad, una coincidencia de los microdatos con un archivo de datos externo será errónea. Por ejemplo, un intruso encontraría un individuo con la combinación {“hombre”, “urbano”, “superior”}, que es una muestra única. Sin embargo, esta coincidencia no es correcta, ya que el conjunto de datos original no contenía ningún individuo con estas características y, por tanto, el individuo coincidente no puede ser una coincidencia correcta. El intruso no puede saber con certeza si la información revelada de otras variables para ese registro es correcta. Tabla 8.7: Efecto del enfoque all-m en el \\(k\\)-anonimato Variable Datos originales Después de perturbar los datos ID Sexo Zona Educación Sexo Zona Educación 1 mujer rural superior mujer rural superior 2 mujer rural superior mujer rural media 3 hombre rural media hombre rural media 4 hombre rural media mujer rural media 5 mujer urbana media hombre urbana superior 6 mujer urbana media mujer urbana media Una de las ventajas de los métodos perturbativos es que se reduce la pérdida de información, ya que no se suprimirán valores, dependiendo del nivel de perturbación. Una desventaja es que los usuarios de los datos pueden tener la impresión de que los datos no se han anonimizado antes de su publicación y estarán menos dispuestos a participar en futuras encuestas. Por lo tanto, es necesario elaborar informes tanto para uso interno como externo (véase Etapa 6.4.5: Generar reportes y liberar datos). Una alternativa a los métodos perturbativos es la generación de archivos de datos sintéticos con las mismas características que los archivos de datos originales. Los archivos de datos sintéticos no se discuten en estas directrices. Aquí abordamos cinco métodos perturbativos: El método de post aleatorización (PRAM), la microagregación, la adición de ruido, el shuffling y el rank swapping. 8.3.1 PRAM (Método de Post-Aleatorización) PRAM es un método perturbativo para datos categóricos. Este método reclasifica los valores de una o más variables, de manera que los intrusos que intentan reidentificar a los individuos en los datos lo hacen, sin embargo, con probabilidad positiva, la reidentificación realizada es con el individuo equivocado. Esto significa que el intruso puede ser capaz de hacer coincidir varios individuos entre los archivos externos y los archivos de datos liberados, pero no puede estar seguro de que estas coincidencias correspondan al individuo correcto. PRAM se define mediante la matriz de transición \\(P\\), que especifica las probabilidades de transición, es decir, la probabilidad de que un valor de una determinada variable permanezca inalterado o se cambie a cualquiera de los otros \\(k-1\\) valores. \\(k\\) es el número de categorías o niveles del factor dentro de la variable que se va a PRAM. Por ejemplo, si la variable región tiene 10 regiones diferentes, \\(k\\) es igual a 10. En el caso de PRAM para una sola variable, la matriz de transición es de tamaño \\(k∗k\\). Ilustramos el PRAM con un ejemplo de la variable “región”, que tiene tres valores diferentes: “capital”, “rural1” y “rural2”. La matriz de transición para aplicar PRAM a esta variable es de tamaño 3*3: \\[\\begin{split} P = \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ 0.05 &amp; 0.8 &amp; 0.15 \\\\ 0.05 &amp; 0.15 &amp; 0.8 \\\\ \\end{bmatrix} \\end{split}\\] Los valores de la diagonal son las probabilidades de que un valor de la categoría correspondiente no se modifique. El valor 1 en la posición (1,1) de la matriz significa que todos los valores “capital” permanecen “capital”; esto podría ser una decisión útil, ya que la mayoría de los individuos viven en la capital y no necesitan protección. El valor 0,8 en la posición (2,2) significa que un individuo con valor “rural1” se quedará con probabilidad 0,8 “rural1”. Los valores 0,05 y 0,15 en la segunda fila de la matriz indican que el valor “rural1” se cambiará a “capital” o “rural2” con una probabilidad de 0,05 y 0,15, respectivamente. Si en el fichero inicial teníamos 5.000 individuos con valor “capital” y respectivamente 500 y 400 con valores “rural1” y “rural2”, esperamos después de aplicar PRAM tener 5.045 individuos con capital, 460 con rural1 y 395 con rural2 [9]. La recodificación se realiza de forma independiente para cada individuo. Vemos que la tabulación de la variable “región” arroja resultados diferentes antes y después de PRAM, que se muestran en la Tabla 8.8. La desviación de la expectativa se debe a que PRAM es un método probabilístico, es decir, los resultados dependen de un mecanismo de generación de probabilidades; en consecuencia, los resultados pueden diferir cada vez que aplicamos PRAM a las mismas variables de un conjunto de datos. Nota:El número de valores modificados es mayor de lo que podría pensarse al inspeccionar las tabulaciones de la Tabla 8.8. No todos los 5.000 individuos con valor “capital” después de PRAM tenían este valor antes de PRAM y los 457 individuos en rural1 después de PRAM no están todos incluidos en los 500 individuos antes de PRAM. El número de cambios es mayor que las diferencias en la tabulación (véase la matriz de transición). Dado que la matriz de transición es conocida por los usuarios finales, hay varias formas de corregir el análisis estadístico de los datos por las distorsiones introducidas por el PRAM. Tabla 8.8: Tabulación de la variable “región” antes y después del PRAM Valor Tabulación antes de PRAM Tabulación después de PRAM rural1 500 457 rural2 400 391 Una forma de garantizar la consistencia entre las tabulaciones antes y después de PRAM es elegir la matriz de transición de forma que, en la expectativa, las tabulaciones antes y después de aplicar PRAM sean las mismas para todas las variables. [10] Este método se llama PRAM invariante y se implementa en sdcMicro en la función pram(). El método pram() determina la matriz de transición que satisface los requisitos de PRAM invariante. El PRAM invariante no garantiza que las tabulaciones cruzadas de las variables (a diferencia de las tabulaciones univariantes) permanezcan iguales. # Ejecutamos nuevamente las variables clave selectedKeyVarsHH &lt;- c(&quot;URBRUR&quot;, &quot;REGION&quot;, &quot;HHSIZE&quot;, &quot;OWNAGLAND&quot;, &quot;RELIG&quot;) HHVars &lt;- c(&quot;IDH&quot;, selectedKeyVarsHH, pramVarsHH, numVarsHH, weightVarHH, strata_var) #agrega strata fileHH &lt;- file fileHH &lt;- fileHH[which(!duplicated(fileHH$IDH)),] sdcHH &lt;- createSdcObj(dat=fileHH, keyVars=selectedKeyVarsHH, pramVars=pramVarsHH, weightVar=weightVarHH, numVars = numVarsHH, strataVar = &quot;strata_region&quot;) sdcInitial &lt;- sdcHH sdc_respaldo &lt;- sdcHH En el Bloque 8.12, damos un ejemplo de PRAM invariante utilizando sdcMicro25. PRAM es un método probabilístico y los resultados pueden diferir cada vez que aplicamos PRAM a las mismas variables de un conjunto de datos. Para superar esto y hacer que los resultados sean reproducibles, es una buena práctica establecer una semilla para el generador de números aleatorios en R, de modo que se generen los mismos números aleatorios cada vez26. También, se muestra el número de registros modificados por variable. 8.3.1.1 Bloque 8.12 Producción de resultados reproducibles de PRAM utilizando set.seed() # establecer la semilla para la generación de números aleatorios set.seed(123) sdcInitial_edit &lt;- pram(obj = sdcInitial) sdcInitial_edit@pram$summary ## variable nrChanges percChanges ## 1 ROOF 81 4.05 ## 2 TOILET 247 12.35 ## 3 WATER 177 8.85 ## 4 ELECTCON 7 0.35 ## 5 FUELCOOK 160 8.00 ## 6 OWNMOTORCYCLE 62 3.10 ## 7 CAR 19 0.95 ## 8 TV 106 5.30 ## 9 LIVESTOCK 23 1.15 La Tabla 8.9 muestra la tabulación de la variable después de aplicar el PRAM invariante. Podemos ver que las desviaciones de las tabulaciones iniciales, que tienen expectativa 0, son menores que la matriz de transición que no cumple la propiedad de invariancia. Las desviaciones restantes se deben a la aleatoriedad. Tabla 8.9: Tabulación de la variable “región” antes y después del PRAM (invariante) Valor Tabulación antes de PRAM Tabulación después de PRAM Tabulación después del PRAM invariante capital 5,000 5,052 4,998 rural1 500 457 499 rural2 400 391 403 La Tabla 8.10 presenta las tabulaciones cruzadas con la variable sexo. Antes de aplicar PRAM invariante, la proporción de hombres en la ciudad es mucho mayor que la de mujeres (alrededor del 60%). Esta propiedad no se mantiene después de PRAM invariante (los porcentajes de hombres y mujeres en la ciudad son aproximadamente iguales), aunque se mantienen las tabulaciones univariantes. Una solución es aplicar PRAM por separado para los hombres y las mujeres de este ejemplo27. Esto puede hacerse especificando el argumento de los estratos en la función pram() de sdcMicro (véase más adelante). Tabla 8.10: Tabulación cruzada de la variable “región” y la variable “sexo” antes y después del PRAM invariante Tabulación antes de PRAM Tabulación después del PRAM invariante Valor hombre mujer hombre mujer capital 3,056 1,944 2,623 2,375 rural1 157 343 225 274 rural2 113 287 187 216 La función pram() en sdcMicro tiene varias opciones relacionadas a estratificación (strata_variables), entradas diagonales mínimas para utilizar una matriz de transición P personalizada (pd) y la cantidad de perturbación para el método Pram invariante, entregada mediante un vector numérico de longitud 1 (que se reciclará si es necesario) o un vector de la misma longitud que el número de variables. Nota: Si no se establece ninguna opción y el método PRAM se aplica a un objeto sdcMicro, todas las variables PRAM seleccionadas en el objeto sdcMicro se utilizan automáticamente para PRAM y esta se aplica dentro de los estratos seleccionados (véase la sección Objetos de la clase sdcMicroObj sobre los objetos sdcMicro para más detalles). 8.3.1.2 Bloque 8.13 Selección de variables para aplicar PRAM set.seed(123) # establecer la semilla para la generación de números aleatorios # Aplicar PRAM solo a la variable TOILET sdcInitial &lt;- pram(obj = sdcInitial, variables = c (&quot;TOILET&quot;)) sdcInitial@pram$summary ## variable nrChanges percChanges ## 1 TOILET 106 5.3 Los resultados de PRAM difieren si se aplican simultáneamente a varias variables o posteriormente a cada variable por separado. No es posible especificar toda la matriz de transición en sdcMicro, pero podemos establecer valores mínimos (entre 0 y 1) para las entradas diagonales. Las entradas diagonales especifican la probabilidad de que un determinado valor permanezca igual después de aplicar PRAM. Si fijamos el valor mínimo en 1, no habrá cambios en esta categoría. Por defecto, este valor es 0,8, que se aplica a todas las categorías. También es posible especificar un vector con valor para cada elemento diagonal de la transformación matriz/categoría. En el Bloque 8.14 los valores de la primera región tienen menos probabilidades de cambiar que los valores de las otras regiones. Nota: El método PRAM invariante requiere que la matriz de transición tenga un valor propio unitario. Por lo tanto, no se pueden utilizar todos los conjuntos de restricciones (por ejemplo, el valor mínimo 1 en cualquiera de las categorías). 8.3.1.3 Bloque 8.14 Especificación de los valores mínimos de la diagonal de la matriz de transición PRAM sdcInitial &lt;- sdc_respaldo # reasignar sdcInitial &lt;- pram(obj = sdcInitial, variables = c(&quot;TOILET&quot;), pd = c(0.9)) #un valor por variable sdcInitial@pram$summary ## variable nrChanges percChanges ## 1 TOILET 133 6.65 En el método PRAM invariante, también podemos especificar la cantidad de perturbaciones especificando el parámetro alfa. Esta elección se refleja en la matriz de transición. Por defecto, el valor de alfa es 0,5. Cuanto mayor sea alfa, mayores serán las perturbaciones. Un valor de alfa igual a cero no produce cambios. El valor máximo de alfa es 1. PRAM es especialmente útil cuando un conjunto de datos contiene muchas variables y la aplicación de otros métodos de anonimización, como la recodificación y la supresión local, conduciría a una pérdida significativa de información. Las comprobaciones del riesgo y la utilidad son importantes después de PRAM. Para hacer inferencia estadística sobre las variables a las que se aplicó PRAM, el investigador necesita conocer el método PRAM, así como la matriz de transición. Sin embargo, la matriz de transición, junto con la semilla de números aleatorios, puede conducir a la divulgación mediante la reconstrucción de los valores no perturbados. Por lo tanto, se recomienda publicar la matriz de transición, pero nunca la semilla aleatoria. Una desventaja del uso de PRAM es que se pueden generar combinaciones muy improbables, como la de una persona de 63 años que va a la escuela. Por lo tanto, es necesario auditar las variables PRAM para evitar que tales combinaciones se produzcan en el archivo de datos publicado. En principio, la matriz de transición puede diseñarse de forma que ciertas transiciones no sean posibles (probabilidad 0). Por ejemplo, para los que van a la escuela, la edad debe oscilar entre los 6 y los 18 años y solo se permiten esos cambios. En sdcMicro la matriz de transición no puede especificarse exactamente. Una alternativa útil es construir estratos y aplicar PRAM dentro de los estratos. De este modo, los cambios entre variables solo se aplicarán dentro de los estratos. El Bloque 8.15 ilustra esto aplicando PRAM a la variable “toilet” dentro de los estratos generados por la “region”. Esto evita que se produzcan cambios en la variable “toilet”, donde se intercambian los tipos de inodoros de una determinada región con los de otras regiones. Por ejemplo, en la región de la capital no se utilizan ciertos tipos de inodoros no mejorados y, por lo tanto, estas combinaciones no deberían producirse después de aplicar PRAM. Los valores solo se cambian con los que están disponibles en el mismo estrato. Los estratos pueden estar formados por cualquier variable categórica, por ejemplo, sexo, grupos de edad, nivel de educación. 8.3.1.4 Bloque 8.15 Minimizar las combinaciones improbables aplicando el PRAM por estratos sdcInitial &lt;- sdc_respaldo # reasignar #Aplicar PRAM dentro de los estratos formados por la variable educ sdcInitial &lt;- pram(obj = sdcInitial, variables = c(&quot;TOILET&quot;), strata_variables = c(&quot;REGION&quot;)) sdcInitial@pram$summary ## variable nrChanges percChanges ## 1 TOILET 158 7.9 Lectura recomendada de PRAM: - Gouweleeuw, J. M, P Kooiman, L.C.R.J Willenborg, and P.P de Wolf. “Post Randomization for Statistical Disclosure Control: Theory and Implementation.” Journal of Official Statistics 14, no. 4 (1998a): 463-478. Available at http://www.jos.nu/articles/abstract.asp?article=144463 - Gouweleeuw, J. M, P Kooiman, L.C.R.J Willenborg, and Peter Paul de Wolf. “The Post Randomization Method for Protecting Microdata.” Qüestiió, Quaderns d’Estadística i Investigació Operativa 22, no. 1 (1998b): 145-156. Available at http://www.raco.cat/index.php/Questiio/issue/view/2250 - Marés, Jordi, and Vicenç Torra. 2010.”PRAM Optimization Using an Evolutionary Algorithm.” In Privacy in Statistical Databases, by Josep Domingo-Ferrer and Emmanouil Magkos, 97-106. Corfú, Greece: Springer. - Warner, S.L. “Randomized Response: A Survey Technique for Eliminating Evasive Answer Bias.” Journal of American Statistical Association 57 (1965): 622-627. 8.3.2 Microagregación La microagregación es más adecuada para las variables continuas, pero puede extenderse en algunos casos a las variables categóricas28. Es más útil cuando se han predeterminado reglas de confidencialidad (por ejemplo, se ha establecido un determinado umbral de \\(k\\)-anonimato) que permiten la divulgación de datos solo si las combinaciones de variables son compartidas por más de un número umbral predeterminado de encuestados (\\(k\\)). El primer paso en la microagregación es la formación de pequeños grupos de individuos que sean homogéneos con respecto a los valores de las variables seleccionadas, como grupos con ingresos o edad similares. Posteriormente, los valores de las variables seleccionadas de todos los miembros del grupo se sustituyen por un valor común, por ejemplo, la media de ese grupo. Los métodos de microagregación difieren en cuanto a (i) cómo se define la homogeneidad de los grupos, (ii) los algoritmos utilizados para encontrar grupos homogéneos y (iii) la determinación de los valores de sustitución. En la práctica, la microagregación funciona mejor cuando los valores de las variables de los grupos son más homogéneos. En ese caso, la pérdida de información debida a la sustitución de valores por valores comunes para el grupo será menor que en los casos en que los grupos son menos homogéneos. En el caso univariante, y también para las variables categóricas ordinales, la formación de grupos homogéneos es sencilla: los grupos se forman ordenando primero los valores de la variable y luego creando \\(g\\) grupos de tamaño \\(n_i\\) para todos los grupos \\(i\\) en \\(1, ..., g\\). Esto maximiza la homogeneidad dentro del grupo, que se mide por la suma al cuadrado de los residuos dentro de los grupos (\\(SSE\\)) \\[ SSE = \\sum_{i = 1}^{g}{\\sum_{j = 1}^{n_{i}}{\\left( x_{ij} - {\\overline{x}}_{i} \\right)^{T}\\left( x_{ij} - {\\overline{x}}_{i} \\right)}} \\] Cuanto menor sea \\(SSE\\), mayor será la homogeneidad dentro del grupo. El tamaño de los grupos puede variar entre ellos, pero a menudo se utilizan grupos de igual tamaño para simplificar la búsqueda29. La función microaggregation() de sdcMicro puede utilizarse para la microagregación univariante. El argumento “aggr” especifica el tamaño del grupo. La formación de grupos es más fácil si todos los grupos -excepto quizá el último grupo de los restantes- tienen el mismo tamaño. Este es el caso en la implementación en sdcMicro, ya que no es posible tener grupos de diferentes tamaños. El Bloque 8.16 muestra cómo utilizar la función microaggregation() en sdcMicro30. El tamaño de grupo por defecto es 3, pero el usuario puede especificar cualquier tamaño de grupo deseado. La elección del tamaño del grupo depende de la homogeneidad dentro de los grupos y del nivel de protección requerido. En general, cuanto más grande sea el grupo, mayor será la protección. Una desventaja de los grupos de igual tamaño es que los datos pueden ser inadecuados para ello. Por ejemplo, si dos individuos tienen un ingreso bajo (por ejemplo, 832 y 966) y cuatro individuos tienen un ingreso alto (por ejemplo, 3.313, 3.211, 2.987, 3.088), la media de dos grupos de tamaño tres (por ejemplo, (832 + 966 + 2.987) / 3 = 1.595 y (3.088 + 3.211 + 3.313) / 3 = 3.204) no representaría ni el ingreso bajo ni el alto. 8.3.2.1 Bloque 8.16 Aplicación de la microagregación con la función sdcMicro microaggregation() sdcInitial &lt;- sdc_respaldo # reasignar sdcInitial &lt;- microaggregation(obj = sdcInitial, variables = &quot;INCTOTGROSSHH&quot;, aggr = 3, method = &quot;mdav&quot;, measure = &quot;mean&quot;) Por defecto, la función de microagregación sustituye los valores por la media del grupo. Un enfoque alternativo y más robusto es reemplazar los valores del grupo con la mediana. Esto puede especificarse en el argumento “measure” de la función microaggregation(). En los casos en que se elige la mediana, un individuo de cada grupo mantiene el mismo valor si los grupos tienen tamaños impares. En los casos en los que hay un alto grado de heterogeneidad dentro de los grupos (suele ser el caso de los grupos más grandes), se prefiere la mediana para preservar la información de los datos. Un ejemplo es el ingreso, donde un valor atípico puede dar lugar a múltiples valores atípicos cuando se utiliza la microagregación. Esto se ilustra en la Tabla 8.11. Si elegimos la media como reemplazo de todos los valores, que se agrupan con el valor atípico (6,045 en el grupo 2), a estos registros se les asignarán valores alejados de sus valores originales. Si elegimos la mediana, los ingresos de los individuos 1 y 2 no se ven alterados, pero ningún valor es un valor atípico. Por supuesto, esto puede plantear problemas en sí mismo. En el caso de que la microagregación se aplique a variables categóricas, se utiliza la mediana (el valor en el grupo que más se repite) para calcular el valor de reemplazo de aquel grupo. Nota: Si la microagregación altera los valores atípicos, esto puede tener un impacto significativo en el cálculo de algunas medidas sensibles a los valores atípicos, como el índice GINI. Tabla 8.11: Ilustración del efecto de la elección de la media frente a la mediana para la microagregación cuando se trata de valores atípicos ID Grupo Ingresos Microagregación (media) Microagregación (mediana) 1 1 2,300 2,245 2,300 2 2 2,434 3,608 2,434 3 1 2,123 2,245 2,300 4 1 2,312 2,245 2,300 5 2 6,045 3,608 2,434 6 2 2,345 3,608 2,434 En el caso de múltiples variables candidatas a la microagregación, una posibilidad es aplicar la microagregación univariante a cada una de las variables por separado. La ventaja de la microagregación univariante es la mínima pérdida de información, ya que los cambios en las variables son limitados. Sin embargo, la literatura muestra que el riesgo de divulgación puede ser muy alto si la microagregación univariante se aplica a varias variables por separado y no se aplican técnicas adicionales de anonimización (Josep Domingo-Ferrer et al. 2002). Para superar este inconveniente, una alternativa a la microagregación univariante es la microagregación multivariante. La microagregación multivariada se utiliza ampliamente en las estadísticas oficiales (Benschop, Machingauta, and Welch 2019). El primer paso de la agregación multivariante es la creación de grupos homogéneos basados en varias variables. Los grupos se forman a partir de las distancias multivariadas entre los individuos. Posteriormente, los valores de todas las variables para todos los miembros del grupo se sustituyen por los mismos valores. La Tabla 8.12 lo ilustra con tres variables. Vemos que la agrupación por ingresos, gastos y patrimonio conduce a una agrupación diferente, como en el caso de la Tabla 8.11, en la que los grupos se formaron basándose solo en los ingresos. Tabla 8.12: Ilustración de la microagregación multivariante Antes de microagregación Después de microagregación ID Grupo Ingreso Gasto Patrimonio Ingreso Gasto Patrimonio 1 1 2,300 1,714 5.3 2,285.7 1,846.3 6.3 2 1 2,434 1,947 7.4 2,285.7 1,846.3 6.3 3 1 2,123 1,878 6.3 2,285.7 1,846.3 6.3 4 2 2,312 1,950 8.0 3,567.3 2,814.0 8.3 5 2 6,045 4,569 9.2 3,567.3 2,814.0 8.3 6 2 2,345 1,923 7.8 3,567.3 2,814.0 8.3 Existen varios métodos de microagregación multivariante que difieren en cuanto al algoritmo utilizado para crear grupos de individuos. Además, existe un trade-off entre la velocidad del algoritmo y la homogeneidad dentro del grupo, que está directamente relacionada con la pérdida de información. En el caso de los grandes conjuntos de datos, esto es especialmente difícil. En este artículo se analiza con más detalle el algoritmo de distancia máxima al vector medio (MDAV). El algoritmo MDAV fue introducido por primera vez por (Josep Domingo-Ferrer and Torra 2005) y representa una buena opción con respecto a la compensación entre el tiempo de cálculo y la homogeneidad del grupo, calculada por el \\(SSE\\) dentro del grupo. El algoritmo MDAV está implementado en sdcMicro. El algoritmo calcula un registro medio o centroide \\(C\\), que contiene los valores medios de todas las variables incluidas. Seleccionamos un individuo \\(A\\) con la mayor distancia euclidiana al cuadrado respecto a \\(C\\), y construimos un grupo de \\(k\\) registros alrededor de \\(A\\). El grupo de \\(k\\) registros está formado por \\(A\\) y los \\(k-1\\) registros más cercanos a \\(A\\) medidos por la distancia euclidiana. A continuación, seleccionamos otro individuo \\(B\\), con la mayor distancia euclidiana al cuadrado desde el individuo \\(A\\). Con los registros restantes, construimos un grupo de \\(k\\) registros alrededor de \\(B\\). De la misma manera, seleccionamos un individuo \\(D\\) con la mayor distancia desde \\(B\\) y, con los registros restantes, construimos un nuevo grupo de \\(k\\) registros alrededor de \\(D\\). El proceso se repite hasta que nos queden menos de \\(2∗k\\) registros. El algoritmo MDAV crea grupos de igual tamaño con la excepción, quizá, de un último grupo con los remanentes. El conjunto de datos microagregados se calcula sustituyendo cada registro del conjunto de datos original por los valores medios del grupo al que pertenece. Sin embargo, los tamaños de grupo iguales pueden no ser ideales para los datos caracterizados por tener una alta variabilidad. En sdcMicro la microagregación multivariante también se implementa en la función microaggregation(). El Bloque 8.17 muestra cómo elegir el algoritmo MDAV en sdcMicro. 8.3.2.2 Bloque 8.17 Microagregación multivariada con el algoritmo de distancia máxima al vector medio (MDAV) en sdcMicro sdcInitial &lt;- createSdcObj(dat=fileHH, keyVars=selectedKeyVarsHH, pramVars=pramVarsHH, weightVar=weightVarHH, numVars = numVarsHH) # reasignar sin strata var sdcInitial &lt;- microaggregation(obj = sdcInitial, variables = c(&quot;INCTOTGROSSHH&quot;, &quot;TANHHEXP&quot;), method = &quot;mdav&quot;) #sdc_respaldo@origData %&gt;% view() También es posible agrupar las variables solo dentro de los estratos. Esto reduce el tiempo de cálculo y añade una capa adicional de protección a los datos, debido a la mayor incertidumbre producida 31. En sdcMicro esto puede lograrse especificando las variables de estrato, como se muestra en el Bloque 8.18. 8.3.2.3 Bloque 8.18 Especificación de variables de estrato para la microagregación sdcInitial &lt;- sdc_respaldo # reasignar con variable de estrato incluida sdcInitial &lt;- microaggregation(obj = sdcInitial, variables = c(&quot;INCTOTGROSSHH&quot;, &quot;TANHHEXP&quot;), method = &quot;mdav&quot;)# # No corre el estrato en opción: strata_variables = c(&quot;strata_region&quot;) Además del método MDAV, hay algunos otros métodos de agrupación implementados en sdcMicro (Matthias Templ Bernhard Meindl and Kowarik 2014). La Tabla 8.13 ofrece un resumen de estos métodos. Mientras que el método “MDAV” utiliza la distancia euclidiana, el método “rmd” utiliza la distancia de Mahalanobis. Una alternativa a estos métodos es la clasificación de los encuestados basada en el primer componente principal (CP), que es la proyección de todas las variables en un espacio unidimensional que maximiza la varianza de esta proyección. El rendimiento de este método depende de la parte de la varianza total de los datos que explica el primer CP. El método “rmd” es más intensivo desde el punto de vista computacional debido al cálculo de las distancias de Mahalanobis, pero proporciona mejores resultados con respecto a la homogeneidad de los grupos. Se recomienda para conjuntos de datos más pequeños (Matthias Templ Bernhard Meindl and Kowarik 2014). Tabla 8.13: Métodos de agrupación para la microagregación que son implementados en sdcMicro Método / opción en sdcMicro Descripción mdav la agrupación se basa en medidas de distancia clásicas (euclidianas) rmd la agrupación se basa en medidas de distancia multivariante robusta (Mahalanobis) pca la agrupación se basa en el análisis de componentes principales, mientras que los datos se clasifican según el primer componente principal clustpppca la agrupación se basa en el clustering y en el análisis de componentes principales (robusto) para cada cluster influence la agrupación se basa en el clustering y la agregación se realiza dentro de los clusters En el caso de que se utilicen múltiples variables para la microagregación, se recomienda examinar primero la matriz de covarianza o de correlación de estas variables. Si no todas las variables están bien correlacionadas, pero dos o más conjuntos de variables muestran una alta correlación, se producirá una menor pérdida de información al aplicar la microagregación por separado a estos conjuntos de variables. En general, si las variables están muy correlacionadas, se producirá una menor pérdida de información al aplicar la microagregación multivariante. La ventaja de sustituir los valores por la media de los grupos en lugar de otros valores de sustitución tiene la ventaja de que se conservan las medias globales de las variables. Lectura recomendada de microagregación: - Domingo-Ferrer, Josep, and Josep Maria Mateo-Sanz. 2002.”Practical data-oriented microaggregation for statistical disclosure control.” IEEE Transactions on Knowledge and Data Engineering 14 (2002): 189-201. - Hansen, Stephen Lee, and Sumitra Mukherjee. 2003. “A polynomial algorithm for univariate optimal.” IEEE Transactions on Knowledge and Data Engineering 15 (2003): 1043-1044. - Hundepool, Anco, Josep Domingo-Ferrer, Luisa Franconi, Sarah Giessing, Rainer Lenz, Jane Naylor, Eric Schulte Nordholt, Giovanni Seri, and Peter Paul de Wolf. 2006. Handbook on Statistical Disclosure Control. ESSNet SDC. http://neon.vb.cbs.nl/casc/handbook.htm - Hundepool, Anco, Josep Domingo-Ferrer, Luisa Franconi, Sarah Giessing, Eric Schulte Nordholt, Keith Spicer, and Peter Paul de Wolf. 2012. Statistical Disclosure Control. Chichester: John Wiley &amp; Sons Ltd. doi:10.1002/9781118348239. - Templ, Matthias, Bernhard Meindl, Alexander Kowarik, and Shuang Chen. 2014, August. “International Household Survey Network (IHSN).” http://www.ihsn.org/home/software/disclosure-control-toolbox. (accessed July 9, 2018). 8.3.3 Adición de ruido La adición de ruido o enmascaramiento, consiste en añadir o restar valores (pequeños) a los valores originales de una variable, y es lo más adecuado para proteger las variables continuas (véase (Brand 2002) para una visión general). La adición de ruido puede impedir la coincidencia exacta de las variables continuas. Las ventajas de la adición de ruido son que el ruido es típicamente continuo con media cero, y la coincidencia exacta con archivos externos no será posible. Sin embargo, dependiendo de la magnitud del ruido añadido, la comparación aproximada de intervalos puede ser posible. Cuando se utiliza la adición de ruido para proteger los datos, es importante tener en cuenta el tipo de datos, el uso previsto de los mismos y las propiedades de los datos antes y después de la adición de ruido, es decir, la distribución -en particular la media-, la covarianza y la correlación entre los conjuntos de datos perturbados y los originales. Dependiendo de los datos, también puede ser útil comprobar que los valores perturbados están dentro de un rango de valores con sentido. La 8.9 ilustra los cambios en la distribución de los datos con niveles crecientes de ruido. En el caso de los datos que tienen valores atípicos, es importante señalar que cuando la distribución de los datos perturbados es similar a la distribución de los datos originales (por ejemplo, con niveles de ruido bajos), la adición de ruido no protegerá los valores atípicos. Después de la adición de ruido, estos valores atípicos generalmente pueden seguir detectándose como tales y, por tanto, identificarse fácilmente. Un ejemplo es un único valor de ingreso muy elevado en una determinada región. Después de perturbar este valor de ingreso, el valor seguirá siendo reconocido como el ingreso más alto de esa región y, por tanto, puede utilizarse para la reidentificación. Esto se ilustra en la 8.8, donde se representan 10 observaciones originales (círculos abiertos) y las observaciones anonimizadas (triángulos rojos). La décima observación es un valor atípico. Los valores de las nueve primeras observaciones están suficientemente protegidos por la adición de ruido: su magnitud y orden han cambiado y se puede evitar con éxito la coincidencia exacta o por intervalos. El valor atípico no está suficientemente protegido, ya que, tras la adición de ruido, el valor atípico puede seguir identificándose fácilmente. El hecho de que el valor absoluto haya cambiado no es una protección suficiente. Por otro lado, con niveles de ruido elevados, la protección es mayor incluso para los valores atípicos, pero la estructura de los datos no se conserva y la pérdida de información es grande, lo que no es una situación ideal. Una forma de sortear el problema de los valores atípicos es añadir ruido de mayor magnitud a los valores atípicos que a los demás valores. Figura 8.8: Ilustración del efecto de la adición de ruido a los valores atípicos Existen varios algoritmos de adición de ruido. La versión más simple de la adición de ruido es el ruido aditivo no correlacionado normalmente distribuido, donde \\(x_j\\), los valores originales de la variable \\(j\\) son reemplazados por \\[z_{j} = x_{j} + \\varepsilon_{j},\\] donde \\(\\varepsilon_{j} \\sim N(0, \\sigma_{\\varepsilon_{j}}^{2})\\) y \\(\\sigma_{\\varepsilon_{j}} = \\alpha * \\sigma_{j}\\) con \\(\\sigma_{j}\\) la desviación estándar de los datos originales. De este modo, se conservan la media y las covarianzas, pero no las varianzas ni el coeficiente de correlación. Si el nivel de ruido añadido \\(\\alpha\\), se da a conocer al usuario, se pueden estimar muchos estadísticos de forma coherente a partir de los datos perturbados. El ruido añadido es proporcional a la varianza de la variable original. La magnitud del ruido añadido se especifica mediante el parámetro α, que especifica esta proporción. La desviación estándar de los datos perturbados es \\(1 + \\alpha\\) veces la desviación estándar de los datos perturbados. La decisión sobre la magnitud del ruido añadido debe estar informada por la situación legal relativa a la privacidad de los datos, la sensibilidad de los datos y los niveles aceptables de riesgo de divulgación y pérdida de información. En general, el nivel de ruido es una función de la varianza de las variables originales, el nivel de protección necesario y el rango de valores deseado tras la anonimización32. Un valor \\(\\alpha\\) demasiado pequeño dará lugar a una protección insuficiente, mientras que un valor \\(\\alpha\\) demasiado alto hará que los datos sean inútiles para los usuarios. En sdcMicro la adición de ruido se implementa en la función addNoise(). El algoritmo y el parámetro pueden especificarse como argumentos en la función addNoise(). La adición de ruido simple se implementa en la función addNoise() con el valor “additive” para el argumento “method”. El Bloque 8.19 muestra cómo utilizar sdcMicro para añadir ruido no correlacionado a las variables de gasto, donde la desviación estándar del ruido añadido es igual a la mitad de la desviación estándar de las variables originales33. El ruido se añade a todas las variables seleccionadas. 8.3.3.1 Bloque 8.19 Adición de ruido no correlacionado sdcInitial &lt;- addNoise(obj = sdcInitial, variables = c(&quot;TFOODEXP&quot;, &quot;TALCHEXP&quot;, &quot;TCLTHEXP&quot;, &quot;THOUSEXP&quot;, &quot;TFURNEXP&quot;, &quot;THLTHEXP&quot;, &quot;TTRANSEXP&quot;, &quot;TCOMMEXP&quot;, &quot;TRECEXP&quot;, &quot;TEDUEXP&quot;, &quot;TRESTHOTEXP&quot;, &quot;TMISCEXP&quot;), noise = 0.5, method = &quot;additive&quot;) La 8.9 muestra la distribución de frecuencias de una variable numérica continua y la distribución antes y después de la adición de ruido con diferentes niveles de ruido (0.1, 0.5, 1, 2 y 5). El primer gráfico muestra la distribución de los valores originales. Los histogramas muestran claramente que el ruido de grandes magnitudes (valores altos de alfa) conduce a una distribución de los datos alejada de los valores originales. La distribución de los datos pasa a ser una distribución normal cuando la magnitud del ruido crece respectivamente a la varianza de los datos. La media de los datos se conserva, pero, al aumentar el nivel de ruido, la varianza de los datos perturbados crece. Tras añadir un ruido de magnitud 5, la distribución de los datos originales queda completamente alterada. Figura 8.9: Distribución de frecuencias de una variable continua antes y después de la adición de ruido La 8.10 muestra el rango de valores de una variable antes de añadir ruido (sin ruido) y después de añadir varios niveles de ruido (α de 0,1 a 1,5 con incrementos de 0,1). En la figura se representan el valor mínimo, los percentiles 20, 30 y 40, la mediana, los percentiles 60, 70, 80 y 90 y el valor máximo. La mediana (percentil 50) se indica con el símbolo rojo “\\(\\color {red}{\\text{+}}\\)”. De las 8.9 y 8.10 se desprende que el rango de valores se amplía tras la adición de ruido, y que la mediana se mantiene aproximadamente en el mismo nivel, al igual que la media por construcción. Cuanto mayor sea la magnitud del ruido añadido, mayor será el rango de valores. En los casos en que la variable debe permanecer en un determinado rango de valores (por ejemplo, solo valores positivos, entre 0 y 100), esto puede ser una desventaja de la adición de ruido. Por ejemplo, las variables de gasto suelen tener valores no negativos, pero la adición de ruido a estas variables puede generar valores negativos, que son difíciles de interpretar. Una forma de evitar este problema es poner a cero los valores negativos. Sin embargo, este truncamiento de los valores por debajo de un determinado umbral distorsionará la distribución (matriz de media y varianza) de los datos perturbados. Esto significa que las características que se preservaron con la adición de ruido, como la conservación de la media y la matriz de covarianza, se pierden y el usuario, incluso con el conocimiento de la magnitud del ruido, ya no puede utilizar los datos para una estimación coherente. Otra forma de evitar los valores negativos es la aplicación de ruido multiplicativo en lugar de aditivo. En ese caso, las variables se multiplican por un factor aleatorio con esperanza 1 y varianza positiva. Esto también dará lugar a mayores perturbaciones (en valor absoluto) de los valores atípicos. Si la varianza del ruido añadido es pequeña, no habrá factores negativos o serán pocos y, por tanto, habrá menos cambios de signo que en el caso del enmascaramiento por ruido aditivo. El enmascaramiento de ruido multiplicativo no está implementado en sdcMicro, pero puede implementarse con relativa facilidad en R base generando un vector de números aleatorios y multiplicando los datos con este vector. Para más información sobre el enmascaramiento de ruido multiplicativo y las propiedades de los datos después del enmascaramiento, nos remitimos a (Kim and Winkler 2003). Figura 8.10: Niveles de ruido y el impacto en el rango de valores (percentiles) Si se seleccionan dos o más variables para la adición de ruido, se prefiere la adición de ruido correlacionado para preservar la estructura de correlación en los datos. En este caso, la matriz de covarianza del ruido \\(\\Sigma_{\\varepsilon}\\) es proporcional a la matriz de covarianza de los datos originales \\(\\Sigma_{X}\\): \\[\\Sigma_{\\varepsilon} = \\alpha \\Sigma_{X}\\] En la función addNoise() del paquete sdcMicro, se puede utilizar la adición de ruido correlacionado especificando los métodos “correlated” o “correlated2”. El método “correlated” asume que las variables se distribuyen aproximadamente de forma normal. El método “correlated2” es una versión del método “correlated”, que es robusto contra el supuesto de normalidad. El Bloque 8.20 muestra cómo utilizar el método “correlated2”. La normalidad de las variables puede investigarse en R, con, por ejemplo, un test Jarque-Bera o Shapiro-Wilk34. 8.3.3.2 Bloque 8.20 Adición de ruido correlacionado sdcInitial &lt;- addNoise(obj = sdcInitial, variables = c(&quot;TFOODEXP&quot;, &quot;TALCHEXP&quot;, &quot;TCLTHEXP&quot;, &quot;THOUSEXP&quot;, &quot;TFURNEXP&quot;, &quot;THLTHEXP&quot;, &quot;TTRANSEXP&quot;, &quot;TCOMMEXP&quot;, &quot;TRECEXP&quot;, &quot;TEDUEXP&quot;, &quot;TRESTHOTEXP&quot;, &quot;TMISCEXP&quot;), noise = 0.5, method = &quot;correlated2&quot;) En muchos casos, solo hay que proteger los valores atípicos, o hay que protegerlos más. El método “outdect” añade ruido solo a los valores atípicos, lo que se ilustra en el Bloque 8.21. Los valores atípicos se identifican con métodos univariantes y multivariantes robustos basados en una distancia de Mahalanobis robusta calculada por el estimador MCD (A. K. Matthias Templ Bernhard Meindl and Chen 2014). Sin embargo, la adición de ruido no es el método más adecuado para la protección de los valores atípicos. 8.3.3.3 Bloque 8.21 Adición de ruido para los valores atípicos mediante el método “outdect” sdcInitial &lt;- addNoise(obj = sdcInitial, variables = c(&quot;TFOODEXP&quot;, &quot;TALCHEXP&quot;, &quot;TCLTHEXP&quot;, &quot;THOUSEXP&quot;, &quot;TFURNEXP&quot;, &quot;THLTHEXP&quot;, &quot;TTRANSEXP&quot;, &quot;TCOMMEXP&quot;, &quot;TRECEXP&quot;, &quot;TEDUEXP&quot;, &quot;TRESTHOTEXP&quot;, &quot;TMISCEXP&quot;), noise = 0.5, method = &quot;outdect&quot;) Si la adición de ruido se aplica a variables que son una proporción de un agregado, esta estructura puede verse seriamente alterada por la adición de ruido. Los ejemplos son los datos de ingresos y gastos con muchas categorías de ingresos y gastos. Las categorías suman el total de ingresos o el total de gastos. En los datos originales, los agregados coinciden con la suma de los componentes. Sin embargo, después de añadir ruido a sus componentes (por ejemplo, diferentes categorías de gasto), sus nuevos agregados ya no coincidirán necesariamente con la suma de las categorías. Una forma de mantener esta estructura es añadir ruido solo a los agregados y liberar los componentes como relación de los agregados perturbados. El Bloque 8.22 ilustra esto añadiendo ruido al total de los gastos. Posteriormente, se utilizan los cocientes de las categorías de gasto iniciales para cada individuo para reconstruir los valores perturbados de cada categoría de gasto. 8.3.3.4 Bloque 8.22 Adición de ruido a agregados y sus componentes # añadir ruido a los totales (ingresos / gastos) sdcInital &lt;- addNoise(noise = 0.5, obj = sdcInitial, variables=c(&quot;TANHHEXP&quot;, &quot;INCTOTGROSSHH&quot;), method=&quot;additive&quot;) # multiplicar los totales anonimizados por los ratios para obtener los componentes anonimizados compExp &lt;- c(&quot;TFOODEXP&quot;, &quot;TALCHEXP&quot;, &quot;TCLTHEXP&quot;, &quot;THOUSEXP&quot;, &quot;TFURNEXP&quot;, &quot;THLTHEXP&quot;, &quot;TTRANSEXP&quot;, &quot;TCOMMEXP&quot;, &quot;TRECEXP&quot;, &quot;TEDUEXP&quot;, &quot;TRESTHOTEXP&quot;, &quot;TMISCEXP&quot;) sdcInital@manipNumVars[,compExp] &lt;- sdcInital @manipNumVars[,&quot;TANHHEXP&quot;] * sdcInital @origData[,compExp]/ sdcInital@origData[,&quot;TANHHEXP&quot;] # recalcular los riesgos después de cambiar manualmente los valores en el objeto sdcMicro calcRisks(sdcInital) ## The input dataset consists of 2000 rows and 40 variables. ## --&gt; Categorical key variables: URBRUR, REGION, HHSIZE, OWNAGLAND, RELIG ## --&gt; Numerical key variables: LANDSIZEHA, TANHHEXP, TFOODEXP, TALCHEXP, TCLTHEXP, THOUSEXP, TFURNEXP, THLTHEXP, TTRANSEXP, TCOMMEXP, TRECEXP, TEDUEXP, TRESTHOTEXP, TMISCEXP, INCTOTGROSSHH, INCRMT, INCWAGE, INCFARMBSN, INCNFARMBSN, INCRENT, INCFIN, INCPENSN, INCOTHER ## --&gt; Weight variable: WGTPOP ## --&gt; Strata variable(s): strata_region ## ---------------------------------------------------------------------- ## Information on categorical key variables: ## ## Reported is the number, mean size and size of the smallest category &gt;0 for recoded variables. ## In parenthesis, the same statistics are shown for the unmodified data. ## Note: NA (missings) are counted as seperate categories! ## Key Variable Number of categories Mean size Size of smallest (&gt;0) ## URBRUR 2 (2) 1000.000 (1000.000) 684 (684) ## REGION 6 (6) 333.333 (333.333) 260 (260) ## HHSIZE 23 (23) 86.957 (86.957) 1 (1) ## OWNAGLAND 4 (4) 531.667 (531.667) 332 (332) ## RELIG 7 (7) 166.667 (166.667) 7 (7) ## ---------------------------------------------------------------------- ## Infos on 2/3-Anonymity: ## ## Number of observations violating ## - 2-anonymity: 115 (5.750%) ## - 3-anonymity: 239 (11.950%) ## - 5-anonymity: 497 (24.850%) ## ## ---------------------------------------------------------------------- ## Numerical key variables: LANDSIZEHA, TANHHEXP, TFOODEXP, TALCHEXP, TCLTHEXP, THOUSEXP, TFURNEXP, THLTHEXP, TTRANSEXP, TCOMMEXP, TRECEXP, TEDUEXP, TRESTHOTEXP, TMISCEXP, INCTOTGROSSHH, INCRMT, INCWAGE, INCFARMBSN, INCNFARMBSN, INCRENT, INCFIN, INCPENSN, INCOTHER ## ## Disclosure risk is currently between [0.00%; 65.50%] ## ## Current Information Loss: ## - IL1: 5502068.37 ## - Difference of Eigenvalues: -3410140045704050.500% ## ---------------------------------------------------------------------- Lectura recomendada de adición de ruido: - Brand, Ruth. 2002. “Microdata Protection through Noise Addition.” In Inference -Control in Statistical Databases - From Theory to Practice, edited byJosep Domingo-Ferrer. Lecture Notes in Computer Science Series 2316, 97-116. Berlin Heidelberg: Springer. http://link.springer.com/chapter/10.1007%2F3-540-47804-3_8 - Kim, Jay J, and William W Winkler. 2003. “Multiplicative Noise for Masking Continuous Data.” Research Report Series (Statistical Research Division. US Bureau of the Census). https://www.census.gov/srd/papers/pdf/rrs2003-01.pdf - Torra, Vicenç, and Isaac Cano. 2011. “Edit Constraints on Microaggregation and Additive Noise.” In Privacy and Security Issues in Data Mining and Machine Learning, edited by C. Dimitrakakis, A. Gkoulalas-Divanis, A. Mitrokotsa, V. S. Verykios, Y. Saygin. Lecture Notes in Computer Science Volume 6549, 1-14. Berlin Heidelberg: Springer. http://link.springer.com/book/10.1007/978-3-642-19896-0 - Mivule, K. 2013. “Utilizing Noise Addition for Data Privacy, An Overview.” Proceedings of the International Conference on Information and Knowledge Engineering (IKE 2012), (pp.65-71).Las Vegas, USA. http://arxiv.org/ftp/arxiv/papers/1309/1309.3958.pdf 8.3.4 Rank swapping (Intercambio de rangos) Rank swapping se basa en intercambiar los valores de una determinada variable entre los registros. Rank swapping es un tipo de intercambio de datos, que se define para las variables ordinales y continuas. Para Rank swapping, los valores de la variable se ordenan primero. El número posible de valores con los que se puede intercambiar una variable está limitado por los valores que se encuentran alrededor del valor original al ordenar los valores del conjunto de datos. El tamaño de este vecindario puede especificarse, por ejemplo, como un porcentaje del número total de observaciones. Esto también significa que un valor puede ser intercambiado con valores iguales o muy similares. Esto es especialmente cierto si la vecindad es pequeña o si solo hay unos pocos valores diferentes en la variable (variable ordinal). Un ejemplo es la variable “educación” si tiene pocas categorías: (“ninguna”, “primaria”, “secundaria”, “terciaria”). En estos casos, Rank swapping no es un método adecuado al encontrarse con pocas categorías y limitarse por los valores que se encuentran alrededor, para que fuese adecuado, tendría que contar con un número mayor de categorías a intercambiar. Si Rank swapping se aplica a varias variables en simultáneo, la estructura de correlación entre las variables se mantiene. Por lo tanto, es importante comprobar si la estructura de correlación en los datos es plausible. Rank swapping se implementa en la función rankSwap() de sdcMicro. Las variables que deben intercambiarse deben especificarse en el argumento “variables”. Por defecto, los valores por debajo del percentil 5 y por encima del percentil 95 se codifican por arriba y por abajo y se sustituyen por su valor medio (véase la sección Codificación superior e inferior). Especificando las opciones “TopPercent” y “BottomPercent” podemos elegir estos percentiles. El argumento “p” define el tamaño de la vecindad como porcentaje del tamaño de la muestra. Si el valor “p” es 0.05, el vecindario tendrá un tamaño de \\(0.05 * n\\), donde \\(n\\) es el tamaño de la muestra. Dado que Rank swapping es un método probabilístico, es decir, el intercambio depende de un mecanismo generador de números aleatorios, se recomienda especificar una semilla para el generador de números aleatorios antes de utilizar Rank swapping y así garantizar la reproducibilidad de los resultados. La semilla también puede especificarse como argumento de la función rankSwap(). El Bloque 8.23 muestra cómo aplicar Rank swapping con sdcMicro. Si las variables contienen valores perdidos (NA en R), la función rankSwap() los recodificará automáticamente con el valor especificado en el argumento “missing”. Este valor no debe estar en el rango de valores de ninguna de las variables. Después de utilizar la función rankSwap(), estos valores deberían recodificarse como NA. Esto se muestra en el Bloque 8.23. 8.3.4.1 Bloque 8.23 Rank swapping usando sdcMicro # establecer la semilla para el generador de números aleatorios set.seed(12345) # comprobar la estructura de correlación entre las variables cor(file$THOUSEXP, file$TFOODEXP) ## [1] 0.3811335 # aplicar rank swapping rankSwap(sdcInitial, variables = c(&quot;THOUSEXP&quot;, &quot;TFOODEXP&quot;), missing = NA) ## setting parameter R0 = 0.95 as no inputs have been specified. ## The input dataset consists of 2000 rows and 40 variables. ## --&gt; Categorical key variables: URBRUR, REGION, HHSIZE, OWNAGLAND, RELIG ## --&gt; Numerical key variables: LANDSIZEHA, TANHHEXP, TFOODEXP, TALCHEXP, TCLTHEXP, THOUSEXP, TFURNEXP, THLTHEXP, TTRANSEXP, TCOMMEXP, TRECEXP, TEDUEXP, TRESTHOTEXP, TMISCEXP, INCTOTGROSSHH, INCRMT, INCWAGE, INCFARMBSN, INCNFARMBSN, INCRENT, INCFIN, INCPENSN, INCOTHER ## --&gt; Weight variable: WGTPOP ## --&gt; Strata variable(s): strata_region ## ---------------------------------------------------------------------- ## Information on categorical key variables: ## ## Reported is the number, mean size and size of the smallest category &gt;0 for recoded variables. ## In parenthesis, the same statistics are shown for the unmodified data. ## Note: NA (missings) are counted as seperate categories! ## Key Variable Number of categories Mean size Size of smallest (&gt;0) ## URBRUR 2 (2) 1000.000 (1000.000) 684 (684) ## REGION 6 (6) 333.333 (333.333) 260 (260) ## HHSIZE 23 (23) 86.957 (86.957) 1 (1) ## OWNAGLAND 4 (4) 531.667 (531.667) 332 (332) ## RELIG 7 (7) 166.667 (166.667) 7 (7) ## ---------------------------------------------------------------------- ## Infos on 2/3-Anonymity: ## ## Number of observations violating ## - 2-anonymity: 115 (5.750%) ## - 3-anonymity: 239 (11.950%) ## - 5-anonymity: 497 (24.850%) ## ## ---------------------------------------------------------------------- ## Numerical key variables: LANDSIZEHA, TANHHEXP, TFOODEXP, TALCHEXP, TCLTHEXP, THOUSEXP, TFURNEXP, THLTHEXP, TTRANSEXP, TCOMMEXP, TRECEXP, TEDUEXP, TRESTHOTEXP, TMISCEXP, INCTOTGROSSHH, INCRMT, INCWAGE, INCFARMBSN, INCNFARMBSN, INCRENT, INCFIN, INCPENSN, INCOTHER ## ## Disclosure risk is currently between [0.00%; 0.00%] ## ## Current Information Loss: ## - IL1: 5545918.62 ## - Difference of Eigenvalues: -5560974891348373.000% ## ---------------------------------------------------------------------- Se ha comprobado que Rank swapping da buenos resultados con respecto al equilibrio entre la pérdida de información y la protección de los datos (Josep Domingo-Ferrer and Torra 2001). Rank swapping no es útil para variables con pocos valores diferentes o muchos valores perdidos, ya que el intercambio en ese caso no dará lugar a valores alterados. Además, si el intruso sabe a quién pertenece el valor más alto o más bajo de una variable específica (por ejemplo, los ingresos), el nivel de esta variable se revelará después de Rank swapping, porque los valores en sí no se alteran y los valores originales se revelan todos. Esto puede resolverse codificando por arriba y por abajo los valores más bajos y/o más altos. Lectura recomendada de adición de Rank Swapping: - Dalenius T. and Reiss S.P. 1978. Data-swapping: a technique for disclosure control (extended abstract). In Proc. ASA Section on Survey Research Methods. American Statistical Association, Washington DC, 191–194. - Domingo-Ferrer J. and Torra V. 2001. “A Quantitative Comparison of Disclosure Control Methods for Microdata.” In Confidentiality, Disclosure and Data Access: Theory and Practical Applications for Statistical Agencies, edited by P. Doyle, J.I. Lane, J.J.M. Theeuwes, and L. Zayatz, 111–134. Amsterdam, North-Holland. - Hundepool A., Van de Wetering A., Ramaswamy R., Franconi F., Polettini S., Capobianchi A., De Wolf P.-P., Domingo-Ferrer J., Torra V., Brand R. and Giessing S. 2007. μ-Argus User’s Manual version 4.1. 8.3.5 Shuffling (Barajado) El shuffling introducido por (Muralidhar and Sarathy 2006) es similar al swapping, pero utiliza un modelo de regresión subyacente con las variables para determinar cuáles se intercambian. El shuffling puede utilizarse para variables continuas y es un método determinista. El shuffling mantiene las distribuciones marginales en los datos barajados. Sin embargo, shuffling requiere una clasificación completa de los datos, que puede ser muy intensiva desde el punto de vista computacional para grandes conjuntos de datos con múltiples variables. El método se explica en detalle en (Muralidhar and Sarathy 2006). La idea es clasificar a los individuos en función de sus variables originales. A continuación, se ajusta un modelo de regresión con las variables a proteger como regresores y un conjunto de variables que predicen bien esta variable (es decir, con las que están correlacionadas) como regresores. Este modelo de regresión se utiliza para generar \\(n\\) valores sintéticos (predichos) para cada variable que hay que proteger. Estos valores generados también se ranquean y cada valor original se sustituye por otro valor original con el rango que corresponde al ranking del valor generado. Esto significa que todos los valores originales estarán en los datos. La Tabla 8.14 presenta un ejemplo simplificado del método shuffling. En este ejemplo no se especifican los regresores. Tabla 8.14: Métodos de agrupación para la microagregación que son implementados en sdcMicro ID Ingreso (orig.) Rango (orig.) Ingreso (pred.) Rango (pred.) Valores barajados 1 2,300 2 2,466.56 4 2,345 2 2,434 6 2,583.58 7 2,543 3 2,123 1 2,594.17 8 2,643 4 2,312 3 2,530.97 6 2,434 5 6,045 10 5,964.04 10 6,045 6 2,345 4 2,513.45 5 2,365 7 2,543 7 2,116.16 1 2,123 8 2,854 9 2,624.32 9 2,854 9 2,365 5 2,203.45 2 2,300 10 2,643 8 2,358.29 3 2,312 Se recomienda el uso del método “ds” (el método por defecto de shuffling en sdcMicro) (Matthias Templ Bernhard Meindl and Kowarik 2014). En el argumento “form” debe especificarse una función con regresores para las variables a proteger. Al menos dos regresores deben especificarse y estos deben tener poder predictivo para las variables a predecir. Esto puede comprobarse con medidas de bondad de ajuste como el \\(R^2\\) de la regresión. El \\(R^2\\) solo capta las relaciones lineales, pero estas son también las únicas relaciones que capta el modelo de regresión lineal utilizado para el shuffling. A continuación, se presenta un ejemplo para barajar las variables de gasto, que se predicen mediante el gasto total de los hogares y el tamaño de estos. 8.3.5.1 Bloque 8.24 Shuffling usando una ecuación de regresión especificada # Evaluar el R-cuadrado (bondad de ajuste) del modelo de regresión summary(lm(file, form = TFOODEXP + TALCHEXP + TCLTHEXP + THOUSEXP + TFURNEXP + THLTHEXP + TTRANSEXP + TCOMMEXP + TRECEXP + TEDUEXP + TRESTHOTEXP + TMISCEXP ~ TANHHEXP + HHSIZE)) ## ## Call: ## lm(formula = TFOODEXP + TALCHEXP + TCLTHEXP + THOUSEXP + TFURNEXP + ## THLTHEXP + TTRANSEXP + TCOMMEXP + TRECEXP + TEDUEXP + TRESTHOTEXP + ## TMISCEXP ~ TANHHEXP + HHSIZE, data = file) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.92e-10 -5.00e-12 -4.00e-12 -3.00e-12 3.90e-08 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.853e-10 8.003e-12 3.565e+01 &lt;2e-16 *** ## TANHHEXP 1.000e+00 1.075e-16 9.300e+15 &lt;2e-16 *** ## HHSIZE 3.366e-13 1.087e-12 3.100e-01 0.757 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 3.794e-10 on 10571 degrees of freedom ## Multiple R-squared: 1, Adjusted R-squared: 1 ## F-statistic: 4.975e+31 on 2 and 10571 DF, p-value: &lt; 2.2e-16 # Shuffling utilizando la ecuación de regresión especificada sdcInitial &lt;- shuffle(sdcInitial, method=&quot;ds&quot;, form = TFOODEXP + TALCHEXP + TCLTHEXP + THOUSEXP + TFURNEXP + THLTHEXP + TTRANSEXP + TCOMMEXP + TRECEXP + TEDUEXP + TRESTHOTEXP + TMISCEXP ~ TANHHEXP + HHSIZE) Lectura recomendada de shuffling: - K. Muralidhar and R. Sarathy. 2006.”Data shuffling - A new masking approach for numerical data,” Management Science, 52, 658-670. 8.3.6 Comparación de PRAM, Rank swapping y Shuffling PRAM, Rank swapping y Shuffling son métodos perturbativos, es decir, cambian los valores de los registros individuales y se utilizan principalmente para las variables continuas. Tras el rank swapping y shuffling, todos los valores originales están contenidos en el conjunto de datos tratado, pero pueden asignarse a otros registros. Esto implica que las tabulaciones univariantes no se modifican. Esto también se mantiene en la expectativa de PRAM, si se elige una matriz de transición que tenga la propiedad invariante. La elección de un método se basa en la estructura a preservar en los datos. En los casos en los que el modelo de regresión se ajusta a los datos, el shuffling funcionaría muy bien, ya que debería haber suficientes regresores (continuos) disponibles. El rank swapping funciona bien si hay suficientes categorías en las variables. Se prefiere PRAM si el método de perturbación debe aplicarse solo a una o pocas variables; la ventaja es la posibilidad de especificar restricciones en la matriz de transición y aplicar PRAM solo dentro de los estratos, que pueden ser definidos por el usuario. 8.4 Anonimización del identificador indirecto de tamaño del hogar El tamaño de un hogar es un identificador importante, especialmente para los hogares grandes35. Sin embargo, la supresión de la variable de tamaño real, si está disponible (por ejemplo, el número de miembros del hogar), no basta para eliminar esta información del conjunto de datos, ya que un simple recuento de los miembros del hogar para un hogar concreto permitirá reconstruir esta variable siempre que haya un identificador del hogar en los datos. En cualquier caso, los hogares de un tamaño muy grande o con una clave única o especial (es decir, una combinación de valores de identificadores indirectos) deben comprobarse manualmente. Una forma de tratarlos es eliminar estos hogares del conjunto de datos antes de su publicación. Otra posibilidad es dividir los hogares, pero hay que tener cuidado de suprimir o cambiar los valores de estos hogares para evitar que un intruso entienda inmediatamente que estos hogares han sido divididos y los reconstruya combinando los dos hogares con los mismos valores. 8.5 Resumen de métodos SDC Tabla 8.15: Métodos de agrupación para la microagregación que son implementados en sdcMicro Métodos Técnicas Ventajas Desventajas Tipo de datos Perturbativos PRAM Aplicar a subgrupos del conjunto de datos. Probabilidad positiva de un match con un individuo erróneo. Seleccionar la matriz de transición y probabilidad. Útil con muchas variables y/o alta pérdida de información. Modificación de datos originales, se intercambian características. Mayor complejidad y posibilidad de error (seleccionar estratos). Aparenta que no hay anonimización. En el caso de las encuestas por muestreo, cada observación puede tener un peso muestral diferente, por lo que, después de la generalización, no se garantiza la coherencia. Categórico Perturbativos Microagregación Sencilla de comprender y aplicar. Versión univariada implica baja pérdida de información. Versión multivariada permite disminuir bastante el riesgo. Todos los valores originales están contenidos en la data tratada (distribuciones univariadas no cambian). Evita la introducción de inconsistencias que requieran edición. Trade-off entre pérdida de información y disminución de riesgo según si se aplica de forma univariado o multivariada. Continuo Perturbativos Adición de ruido Puede añadir ruido de forma univariada o bivariada. Sencilla de comprender y aplicar. Puede mantener niveles altos riesgos, no permite medir los riesgos post-aplicación. Variable de número enteros puede pasar a tener decimales (por ejemplo, 3,5 hijos). Puede incrementar rango de valores de variable. Necesaria edición posterior a la anonimización. Continuo Perturbativos Shuffling (Barajado) Todos los valores originales están contenidos en la data tratada (distribuciones univariadas no cambian). Permite mantener relaciones multivariadas. Requiere una clasificación completa de los datos, que puede ser computacionalmente muy intensiva para grandes conjuntos de datos con varias variables. Necesita regresión lineal (deben cumplirse supuestos y la recta ajustar bien) La técnica requiere al menos dos variables cuantitativas en la fórmula de la función. Continuo Perturbativos Rank swapping (Intercambio de rangos) Todos los valores originales están contenidos en la data tratada (distribuciones univariadas no cambian). Sencilla de comprender y aplicar. Permite mantener relaciones multivariadas. Baja pérdida de información. Reduce rango de valores mínimos y máximos. Puede mantener niveles altos de riesgos. Continuo No perturbativos Supresión local Quitar datos atípicos. Seleccionar datos a eliminar según importancia. No es útil para variables continuas ni con alto número de categorías. Con alto número de variables o categorías puede no lograr solución. Limitación de algoritmo en librería sdcMicro. Observaciones con variables suprimidas quedan con valor perdido. Categórico No perturbativos Recodificación Global Se disminuye información, pero manteniendo estructura y relaciones. Pérdida de información continua al categorizar para estimación de modelos. Cambia nivel de medición de variables continuas a ordinales o categóricas. Continuo y categórico No perturbativos Codificación superior e inferior Se pierde menos información que con recodificación global, permite agrupar solo las colas de la distribución. Menor nivel de anonimización, se requiere evaluar trade-off entre ambos métodos. Continuo y categórico Referencias "],["medición-de-la-utilidad-y-la-pérdida-de-información.html", "Capítulo 9 Medición de la utilidad y la pérdida de información 9.1 Medidas generales de utilidad para variables continuas y categóricas 9.2 Evaluación de la utilidad de los datos con la ayuda de visualizaciones de datos (en R)", " Capítulo 9 Medición de la utilidad y la pérdida de información Hoy en día, resolver la tensión entre la protección de la información personal y el suministro de datos es realmente un desafío que deben asumir las ONE. En esta situación, tres motivaciones empujan a las ONE a preservar la confidencialidad. SDC es un intercambio entre el riesgo de divulgación versus la pérdida de utilidad de los datos (siempre buscando minimizar este último), al tiempo que reduce el riesgo de divulgación a un nivel aceptable. La utilidad de los datos en este contexto significa la utilidad de los datos anonimizados para los análisis estadísticos de los usuarios finales, así como la validez de estos análisis cuando se realizan con datos anonimizados. El riesgo de divulgación y su medición se definirán más adelante en Medición de riesgos. Para lograr este equilibrio entre minimizar el riesgo de divulgación y maximizar la utilidad de los datos para los usuarios finales, es necesario medir la utilidad de los datos después de la anonimización y compararla con la utilidad de los datos originales. En esta sección se busca describir las medidas que se pueden usar para comparar la utilidad de los datos antes y después de la anonimización, así como también cuantificar la pérdida de información. La pérdida de información es inversa a la utilidad de los datos: cuanto mayor sea la utilidad de los datos después de la anonimización, menor será la pérdida de información. Nota 1. Si los microdatos a anonimizar se basan en una muestra, los datos incurrirán en un error de muestreo. También pueden estar presentes otros errores en los datos, como un error de falta de respuesta. 2. Los métodos discutidos aquí solo miden la pérdida de información causada por el proceso de anonimización en relación con los datos de la muestra original y no intentan medir el error causado por otras fuentes. La pérdida de información se evalúa con respecto a las necesidades y usos de los usuarios finales de los microdatos. Sin embargo, los diferentes usuarios de los datos anonimizados pueden tener usos muy diversos para los datos publicados y es posible que no sea posible recopilar una lista exhaustiva de los distintos usos. Es así que nos enfocaremos en la publicación de un conjunto de datos para evitar la divulgación no intencional. La publicación de múltiples conjuntos de datos anónimos para diferentes propósitos puede dar lugar a una divulgación no intencionada.36 El proceso SDC se caracteriza por el balance entre el riesgo de divulgación y la utilidad de los datos para los usuarios finales. La escala riesgo-utilidad se extiende entre dos extremos: No se difunden datos (riesgo cero de divulgación) y, por lo tanto, los usuarios no obtienen ninguna utilidad de los datos. Los datos se difunden sin ningún tratamiento y, por lo tanto, con el máximo riesgo de divulgación, pero con la máxima utilidad para el usuario (es decir, sin pérdida de información). El objetivo de un proceso SDC bien implementado es encontrar el punto óptimo en el que la utilidad para los usuarios finales se maximice a un nivel de riesgo aceptable. En el balance entre Riesgo y Utilidad que se muestra en la Figura @ref(fig:fig1_sec05), por un extremo, el triángulo corresponde a los datos sin procesar, los que no tienen pérdida de información, pero generalmente tienen un riesgo de divulgación más alto que el nivel aceptable. El otro extremo es el cuadrado, que corresponde a la no publicación de datos. En ese caso, no hay riesgo de divulgación, pero tampoco hay utilidad de los datos para los usuarios. Los puntos intermedios corresponden a diferentes opciones de métodos SDC y/o parámetros aplicados a diferentes variables. El proceso SDC busca métodos y parámetros, que son aplicados de una manera que produce una reducción del riesgo de forma muchas veces satisfactoria, minimizándose generalmente la pérdida de información. (#fig:fig1_sec05)Balance riesgo-utilidad en un conjunto de datos. Fuente: Imagen extraída de (Benschop and Welch 2021), pág.78. En las siguientes secciones, primero proponemos medidas generales de utilidad independientes del uso de datos, y luego presentamos un ejemplo de una medida específica útil para medir la pérdida de información con respecto a usos de datos específicos. Finalmente, mostramos cómo visualizar cambios en los datos causados por la anonimización y discutimos la selección de medidas de utilidad para un conjunto de datos en particular. 9.1 Medidas generales de utilidad para variables continuas y categóricas Las medidas generales de pérdida de información se pueden dividir en aquellas que comparan los valores reales de los datos sin procesar y los anonimizado, y aquellas que comparan las estadísticas de ambos conjuntos de datos. Todas las medidas son a posteriori, ya que miden la utilidad después de la anonimización y requieren tanto los datos originales como los anonimizados. Las medidas de utilidad son diferentes para variables categóricas y para las variables continuas. 9.1.1 Variables categóricas 9.1.1.1 Número de valores faltantes Una medida informativa es comparar el número de valores faltantes en los datos. Los valores faltantes a menudo se producen después de la supresión y a mayor cantidad de aplicación de supresiones será mayor el grado de pérdida de información. Después de usar la función de supresión local en un objeto sdcMicro , la cantidad de supresiones para cada variable clave categórica se puede recuperar con la función print(), como se muestra en el Bloque 9.137. El argumento ‘ls’ en la función print() es la supresión local. La salida muestra el número absoluto y relativo de supresiones. Bloque 9.1 Uso de la función print() para recuperar el número total de supresiones para cada variable clave categórica sdcInitial &lt;- localSuppression(sdcInitial, k = 5, importance = NULL) print(sdcInitial, &#39;ls&#39;) ## Local Suppression: ## KeyVar | Suppressions (#) | Suppressions (%) ## URBRUR | 0 | 0.000 ## REGION | 81 | 4.050 ## RELIG | 0 | 0.000 ## MARITAL | 0 | 0.000 ## -------------------------------------------------------------- Es posible contar y comparar el número de valores faltantes en los datos originales y los datos tratados. Esto puede ser útil para ver el aumento proporcional en el número de valores faltantes. Los valores faltantes también pueden tener otras fuentes, como la no respuesta. En el Bloque 9.2 se muestran los valores faltantes para cada una de las variables clave categóricas en un objeto sdcMicro. Aquí se utiliza el supuesto que todos los valores faltantes están codificados como NA. Si los valores perdidos no están codificados como NA, sino otro valor, se debe utilizar el código de valores perdidos alternativo. Los resultados concuerdan con el número de valores faltantes introducidos por la supresión local en el ejemplo anterior, pero también muestran que la variable “RELIG” tiene 1000 valores faltantes en los datos originales. Bloque 9.2 Número de valores faltantes para cada variable clave categórica en un objeto sdcMicro # Almacene los nombres de todas las variables clave categóricas en un vector namesKeyVars &lt;- names(sdcInitial@manipKeyVars) # Elaborar una matriz para almacenar el número de valores faltantes (NA) antes y después de la anonimización NAcount &lt;- matrix(NA, nrow = 2, ncol = length(namesKeyVars)) colnames(NAcount) &lt;- c(paste0(&#39;NA&#39;, namesKeyVars)) # column names rownames(NAcount) &lt;- c(&#39;initial&#39;, &#39;treated&#39;) # row names # Recuento de NA en todas las variables clave (NOTA: solo se cuentan las codificadas como NA) for(i in 1:length(namesKeyVars)) { NAcount[1, i] &lt;- sum(is.na(sdcInitial@origData[,namesKeyVars[i]])) NAcount[2, i] &lt;- sum(is.na(sdcInitial@manipKeyVars[,i])) } # Mostrar resultados NAcount ## NAURBRUR NAREGION NARELIG NAMARITAL ## inicial 0 0 1000 51 ## tratado 0 81 1000 51 9.1.1.2 Número de registros cambiados Otra estadística útil es el número de registros modificados por variable. Estos se pueden contabilizar de forma similar a los valores perdidos e incluyen supresiones (es decir, cambios en los valores perdidos/NA en R ). El número de registros cambiados es un buen indicador del impacto de los métodos de anonimización en los datos. A continuación en el Bloque 9.3 se muestra cómo calcular la cantidad de registros modificados para las variables PRAMmed. Bloque 9.3 Cálculo del número de registros modificados por variable # Almacene los nombres de todas las variables del pram en un vector namesPramVars &lt;- names(sdcInitial@manipPramVars) # Marco para guardar la cantidad de registros modificados recChanged &lt;- rep(0, length(namesPramVars)) names(recChanged) &lt;- c(paste0(&#39;RC&#39;, namesPramVars)) # Cuenta del número de registros cambiados for(j in 1:length(namesPramVars)) # para todas las variables clave { comp &lt;- sdcInitial@origData[namesPramVars[j]] != sdcInitial@manipPramVars[namesPramVars[j]] temp1 &lt;- sum(comp, na.rm = TRUE) # cambio en todas las variables sin NA temp2 &lt;- sum(is.na(comp)) # contabiliza los NA en el vector temp3 &lt;- sum(is.na(sdcInitial@origData[namesPramVars[j]]) + is.na(sdcInitial@manipPramVars[namesPramVars[j]])==2) # ambos NA, sin cambios, contabilizados en temp2 recChanged[j] &lt;- temp1 + temp2 - temp3 } # Mostrar resultados recChanged ## RCWATER RCROOF RCTOILET ## 125 86 180 9.1.1.3 Comparación de tablas de contingencia Una forma útil de medir la pérdida de información en variables categóricas es comparar tabulaciones univariadas y, lo que es más interesante, tablas de contingencia (también tabulaciones cruzadas o tablas de doble entrada) entre pares de variables. Para mantener la validez analítica de un conjunto de datos, las tablas de contingencia deben permanecer aproximadamente iguales. La función table() produce tablas de contingencia de una o más variables. El Bloque 9.4 a continuación crea una tabla de contingencia de las variables “REGION” y “URBRUR”. Observamos pequeñas diferencias entre las tablas antes y después de la anonimización. Bloque 9.4 Comparación de tablas de contingencia de variables categóricas # Tabla de contingencia (tabulación cruzada) de las variables region y urban/rural table(sdcInitial@origData[, c(&#39;REGION&#39;, &#39;URBRUR&#39;)]) # antes de la anonimización ## URBRUR ## REGION 1 2 ## 1 235 89 ## 2 261 73 ## 3 295 76 ## 4 304 71 ## 5 121 139 ## 6 100 236 table(sdcInitial@manipKeyVars[, c(&#39;REGION&#39;, &#39;URBRUR&#39;)]) # después de la anonimización ## URBRUR ## REGION 1 2 ## 1 235 89 ## 2 261 73 ## 3 295 76 ## 4 304 71 ## 5 105 130 ## 6 79 201 (J. Domingo-Ferrer and Torra 2001)proponen una medida de pérdida de información basada en tablas de contingencia, que cuantifica la distancia entre las tablas de contingencia en los datos originales y los tratados. Alternativamente, se pueden usar visualizaciones de la tabla de contingencia con gráficos de mosaico para comparar el impacto de los métodos de anonimización en las tabulaciones y tablas de contingencia (consulte la Gráficos de mosaico). 9.1.2 Variables continuas 9.1.2.1 Estadísticas: media, covarianza, correlación Las estadísticas que caracterizan el conjunto de datos no deben cambiar después de la anonimización, como lo son la media, varianza, covarianza y la correlación entre las variables más importantes en el conjunto de datos. (J. Domingo-Ferrer and Torra 2001) da una visión general de las estadísticas que se pueden considerar. Para evaluar la pérdida de información causada por la anonimización, se deben comparar las estadísticas apropiadas para las variables continuas antes y después de la anonimización. Para evaluar la pérdida de utilidad se cuentan con varias formas de cálculo, por ejemplo, comparando medias y (co-)varianzas en los datos o comparando las distribuciones (multivariadas) de los datos. Especialmente los cambios en las correlaciones brindan información valiosa sobre la validez de los datos para las regresiones. Las funciones del paquete base R o cualquier otro paquete estadístico se pueden usar para hacer esto. Los siguientes son algunos ejemplos en R. Para calcular la media de cada variable numérica usamos la función colMeans(). Para ignorar los valores perdidos, es necesario utilizar la opción na.rm = TRUE. “numVars” es un vector con los nombres de las variables numéricas. El Bloque 9.5 muestra cómo calcular las medias de todas las variables numéricas. Los datos no tratados se extraen de la ranura ‘origData’ del objeto sdcMicro y los datos anonimizados del slot ‘manipNumVars’, que contiene las variables numéricas manipuladas. Observamos pequeños cambios en cada una de las tres variables. Bloque 9.5 Comparando las medias de variables continuas # datos no tratados colMeans(sdcInitial@origData[, numVars], na.rm = TRUE) ## INC INCRMT INCWAGE ## 479.7710 961.0295 1158.1330 # datos anonimizados colMeans(sdcInitial@manipNumVars[, numVars], na.rm = TRUE) ## INC INCRMT INCWAGE ## 489.6030 993.8512 1168.7561 De la misma manera, se pueden calcular las matrices de correlación y covarianza de las variables numéricas en el objeto sdcMicro a partir de los datos no tratados y anonimizados. Esto se muestra en el Bloque 9.6. Observamos que la varianza de cada variable (los elementos diagonales en la matriz de covarianza) ha aumentado por la anonimización. Estas funciones también permiten calcular intervalos de confianza en el caso de muestras. Las medias y las covarianzas de los subconjuntos de los datos tampoco deberían diferir. Un ejemplo es la media de ingresos por género, por grupo de edad o por región. Este tipo de características de los datos son importantes para el análisis. Bloque 9.6 Comparación de estructuras de covarianza y matrices de correlación de variables numéricas # datos no tratados cov(sdcInitial@origData[, numVars]) ## INC INCRMT INCWAGE ## INC 1645926.1 586975.6 2378901 ## INCRMT 586975.6 6984502.3 1664257 ## INCWAGE 2378900.7 1664257.4 16169878 cor(sdcInitial@origData[, numVars]) ## INC INCRMT INCWAGE ## INC 1.0000000 0.1731200 0.4611241 ## INCRMT 0.1731200 1.0000000 0.1566028 ## INCWAGE 0.4611241 0.1566028 1.0000000 # datos anonimizados cov(sdcInitial@manipNumVars[, numVars]) ## INC INCRMT INCWAGE ## INC 2063013.1 649937.5 2382447 ## INCRMT 649937.5 8566169.1 1778985 ## INCWAGE 2382447.4 1778985.1 19925870 cor(sdcInitial@manipNumVars[, numVars]) ## INC INCRMT INCWAGE ## INC 1.0000000 0.1546063 0.3715897 ## INCRMT 0.1546063 1.0000000 0.1361665 ## INCWAGE 0.3715897 0.1361665 1.0000000 (J. Domingo-Ferrer and Torra 2001) propone varias medidas para la diferencia entre las matrices de covarianza y las de correlación. Estas medidas se basan en el error cuadrático medio, el error absoluto medio o la variación media de las celdas individuales. Nos referimos a (J. Domingo-Ferrer and Torra 2001) para obtener una descripción completa de estas medidas. 9.1.2.2 Medida de pérdida de información IL1s Alternativamente, también podemos comparar los datos reales y cuantificar la distancia entre el conjunto de datos original \\(X\\) y el conjunto de datos tratado \\(Z\\). Aquí \\(X\\) y \\(Z\\) contienen sólo variables continuas. (Yancey, Winkler, and Creecy 2002) introduce la medida de distancia IL1s, que es la suma de las distancias absolutas entre las observaciones correspondientes en los conjuntos de datos sin procesar y anónimos, que están estandarizados por la desviación estándar de las variables en los datos originales. Para las variables continuas en el conjunto de datos, la medida IL1s se define como: \\[IL1s=\\frac{1}{pn}\\sum_{j=1}^{p} \\sum_{i=1}^{n} \\frac{|xij−zij|} {\\sqrt2S_1} \\] Donde \\(p\\) es el número de variables continuas; \\(n\\) es el número de registros en el conjunto de datos; \\(xij\\) y \\(zij\\), son los valores antes y después de la anonimización de la variable \\(j\\) e \\(i\\); Sj es la desviación estándar de la variable \\(j\\) en los datos originales (Yancey, Winkler, and Creecy 2002). Cuando se usa sdcMicro, la medida de utilidad de datos IL1s se pueden calcular para todos los cuasi-identificadores numéricos con la función dUtility(), que se ilustra en el Bloque 9.7 a continuación. En caso de ser necesario, también se puede calcular la medida en subconjuntos del conjunto completo de cuasi-identificadores numéricos. La función se llama dUtility(), pero devuelve una medida de pérdida de información. El resultado se guarda en la ranura de utilidad del objeto sdcMicro . El Bloque 9.7 a continuación ilustra cómo llamar al resultado. Bloque 9.7 Uso de dUtility() para calcular la medida de utilidad de datos de IL1 en sdcMicro # Evaluación de la medida IL1s para las variables en sdcMicro object sdcInitial sdcInitial &lt;- dUtility(sdcInitial) # Mostrar los resultados de IL1s sdcInitial@utility$il1 ## [1] 0.2203791 # IL1s para un subconjunto numérico cuasi-identificadores subset &lt;- c(&#39;INCRMT&#39;, &#39;INCWAGE&#39;, &#39;INCFARMBSN&#39;) dUtility(obj = sdcInitial@origData[,subset], xm = sdcInitial@manipNumVars[,subset], method = &#39;IL1&#39;) ## [1] 0.5641103 La medida es útil para comparar diferentes métodos. Cuanto menor sea el valor de la medida, más cerca estarán los valores de los valores originales y mayor será la utilidad. Nota Esta medida está relacionada con las medidas de riesgo basadas en distancia e intervalos (ver la sección Medidas de riesgo para variables continuas) Cuanto mayor sea la distancia entre los valores originales y anonimizados, menor será la utilidad de los datos. Sin embargo, una mayor distancia también reduce el riesgo de re-identificación. 9.1.2.3 Valores propios Otra forma de evaluar la pérdida de información es comparar los valores propios robustos de los datos antes y después de la anonimización. El Bloque 9.8 ilustra cómo usar este enfoque con sdcMicro . Aquí “contVars” es un vector con los nombres de las variables continuas que nos interesan. “obj” es el argumento que especifica los datos no tratados y “xm” es el argumento que especifica los datos anonimizados. La salida de la función es la diferencia en valores propios. Por lo tanto, el valor mínimo es 0. Nuevamente, el uso principal es comparar diferentes métodos. Cuanto mayor sea el valor, mayores serán los cambios en los datos y la pérdida de información. Bloque 9.8 Uso de dUtility() para calcular valores propios en sdcMicro # Comparación de valores para variables continuas dUtility(obj = sdcInitial@origData[,contVars], xm = sdcInitial@manipNumVars[,contVars], method = &#39;eigen&#39;) ## [1] 2.482948 # Comparación de valores propios robustos de variables continuas* dUtility(obj = sdcInitial@origData[,contVars], xm = sdcInitial@manipNumVars[,contVars], method = &#39;robeigen&#39;) ## [1] -4.297621e+14 9.1.3 Medidas de utilidad basadas en las necesidades del usuario final No se pueden catalogar todas las necesidades y usos de un determinado conjunto de datos. Sin embargo, algunos tipos de datos tienen usos similares o características importantes, que pueden evaluarse antes y después de la anonimización. Los ejemplos de “indicadores de evaluación comparativa” (Templ et al. 2014) son diferentes para cada conjunto de datos. Los ejemplos incluyen medidas de pobreza para conjuntos de datos de ingresos y tasas de asistencia escolar. A menudo, las ideas para seleccionar dichos indicadores provienen de los informes que publican los usuarios de datos basados en microdatos publicados anteriormente. Como guía es necesario comparar los indicadores calculados sobre los datos no tratados y los datos después de la anonimización con diferentes métodos. Si las diferencias entre los indicadores no son demasiado grandes, el conjunto de datos anonimizados puede publicarse. Se debe tener en cuenta que los indicadores calculados sobre muestras son estimaciones con cierta varianza e intervalo de confianza. Por lo tanto, para datos de muestra, es informativo comparar la superposición de los intervalos de confianza y/o evaluar si la estimación puntual calculada después de la anonimización está contenida dentro del intervalo de confianza de la estimación original. Ejemplos de indicadores de referencia y sus intervalos de confianza y cómo calcularlos en R se incluyen en los estudios de casos de estas directrices. Aquí damos el ejemplo del coeficiente GINI. El coeficiente de GINI es una medida de dispersión estadística, que a menudo se utiliza para medir la desigualdad de ingresos. Una forma de medir la pérdida de información en los datos de ingresos es comparar la distribución de ingresos, lo que se puede hacer fácilmente comparando los coeficientes de GINI. Varios paquetes de R tienen funciones para calcular el coeficiente GINI. Elegimos el paquete laeken, que calcula el coeficiente GINI como el área entre la línea de 45 grados y la curva de Lorenz. Para usar la función gini(), primero tenemos que instalar y cargar la paquete laeken. Para calcular el coeficiente de GINI para la variable, usamos los pesos de muestra en los datos. Esto se muestra en Bloque 9.9. El coeficiente de GINI de los datos de la muestra es una variable aleatoria. Por lo tanto, es útil construir un intervalo de confianza alrededor del coeficiente para evaluar la importancia de cualquier cambio en el coeficiente después de la anonimización. La función gini() calcula un intervalo de confianza de 1-alfa para el coeficiente de GINI mediante el uso de bootstrap. Bloque 9.9 Cálculo del coeficiente de GINI a partir de la variable de ingresos para determinar la desigualdad de ingresos # Coeficiente de Gini antes de la anonimización gini(inc = sdcInitial@origData[selInc,&#39;INC&#39;], weights = curW[selInc], na.rm = TRUE)$value # antes ## [1] 34.05928 # Coeficiente de Gini después de la anonimización gini(inc = sdcInitial@manipNumVars[selInc,&#39;INC&#39;], weights = curW[selInc], na.rm = TRUE)$value # después ## [1] 67.13218 9.1.4 Regresión Además de comparar matrices de covarianza y correlación, las regresiones son una herramienta útil para evaluar si la estructura de los datos se mantiene después de la anonimización. Al comparar los parámetros de regresión, también es posible comparar relaciones entre variables no continuas (por ejemplo, al introducir variables ficticias o regresión con variables ordinales). Si se sabe con qué propósito y en qué campo se usan los datos, se pueden usar regresiones para comparar el cambio en los coeficientes y los intervalos de confianza. Un ejemplo de la regresión para evaluar la utilidad de los datos en los datos de ingresos es la ecuación de Mincer. La ecuación de Mincer explica los ingresos en función de la educación y la experiencia mientras controla otras variables. La ecuación de Mincer se utiliza a menudo para evaluar la brecha salarial de género y la desigualdad salarial de género mediante la inclusión de una variable ficticia de género. Aquí mostramos cómo evaluar el impacto de los métodos de anonimización en el coeficiente de género. Realizamos una regresión del ingreso logarítmico en una constante, una variable ficticia de género, años de educación, años de experiencia, años de experiencia al cuadrado y otros factores que influyen en el salario. \\[ln(wage)=β_0+β_1gender+β_2education+β_3experience+β_3experience^2+βX\\] El parámetro de interés aquí es \\(β_1\\), el efecto del género en el logaritmo del salario. \\(X\\) es una matriz con varios otros factores que influyen en el salario y \\(β\\) los coeficientes de estos factores. El Bloque 9.10 ilustra cómo ejecutar una regresión de Mincer en \\(R\\) usando la función \\(ln()\\) y la evaluación de los coeficientes y los intervalos de confianza alrededor de los coeficientes. Realizamos la regresión como se especifica para los empleados asalariados con un salario positivo en los grupos de edad de 15 a 65 años. Bloque 9.10 Estimación de la ecuación de Mincer (regresión) para evaluar la utilidad de los datos antes y después de la anonimización # Variables de la ecuación de Mincer antes de la anonimización Mlwage &lt;- log(sdcMincer@origData$wage) # salario de registro # TRUE if &#39;paid employee&#39;, else FALSE or NA Mempstat &lt;- sdcMincer@origData$empstat==&#39;Paid employee&#39; Mage &lt;- sdcMincer@origData$age # edad en años Meducy &lt;- sdcMincer@origData$educy # educación en años Mexp &lt;- sdcMincer@origData$exp # experiencia en años Mexp2 &lt;- Mexp^2 # experiencia al cuadrado Mgender &lt;- sdcMincer@origData$gender # variable ficticia de género Mwgt &lt;- sdcMincer@origData$wgt # variable de género para la regresión MfileB &lt;- as.data.frame(cbind(Mlwage, Mempstat, Mage, Meducy, Mexp, Mexp2, Mgender, Mwgt)) # Variables de la ecuación de Mincer después de la anonimización Mlwage &lt;- log(sdcMincer@manipNumVars$wage) # salario de registro Mempstat &lt;- sdcMincer@manipKeyVars$empstat==&#39;Paid employee&#39; # TRUE if &#39;paid employee&#39;, else FALSE or NA Mage &lt;- sdcMincer@manipKeyVars$age # edad en años Meducy &lt;- sdcMincer@manipKeyVars$educy # educación en años Mexp &lt;- sdcMincer@manipKeyVars$exp # experiencia en años Mexp2 &lt;- Mexp^2 # experiencia al cuadrado Mgender &lt;- sdcMincer@manipKeyVars$gender # variable ficticia de género Mwgt &lt;- sdcMincer@origData$wgt # variable de género para la regresión MfileA &lt;- as.data.frame(cbind(Mlwage, Mempstat, Mage, Meducy, Mexp, Mexp2, Mgender, Mwgt)) # Fórmula de regresión Mformula &lt;- &#39;Mlwage ~ Meducy + Mexp + Mexp2 + Mgender&#39; # Regresión con la ecuación de Mincer mincer1565B &lt;- lm(Mformula, data = subset(MfileB, MfileB$Mage &gt;= 15 &amp; MfileB$Mage &lt;= 65 &amp; MfileB$Mempstat==TRUE &amp; MfileB$Mlwage != -Inf), na.action = na.exclude, weights = Mwgt) # antes mincer1565A &lt;- lm(Mformula, data = subset(MfileA, MfileA$Mage &gt;= 15 &amp; MfileA$Mage &lt;= 65 &amp; MfileA$Mempstat==TRUE &amp; MfileA$Mlwage != -Inf), na.action = na.exclude, weights = Mwgt) # después # los objetos mincer1565B y mincer1565A con los resultados # regresión antes y después de la anonimización mincer1565B$coefficients # antes ## (Intercept) Meducy Mexp Mexp2 Mgender ## 3.9532064886 0.0212367075 0.0255962570 -0.0005682651 -0.4931289413 mincer1565A$coefficients # después ## (Intercept) Meducy Mexp Mexp2 Mgender ## 4.0526250282 0.0141090329 0.0326711056 -0.0007605492 -0.5393641862 # Intervalos de confianza al 95% confint(obj = mincer1565B, level = 0.95) # antes ## 2.5 % 97.5 % ## (Intercept) 3.435759991 4.4706529860 ## Meducy -0.018860497 0.0613339120 ## Mexp 0.004602597 0.0465899167 ## Mexp2 -0.000971303 -0.0001652273 ## Mgender -0.658085143 -0.3281727396 confint(obj = mincer1565A, level = 0.95) # después ## 2.5 % 97.5 % ## (Intercept) 3.46800378 4.6372462758 ## Meducy -0.03305743 0.0612754964 ## Mexp 0.01024867 0.0550935366 ## Mexp2 -0.00119162 -0.0003294784 ## Mgender -0.71564602 -0.3630823543 Si las nuevas estimaciones caen dentro del intervalo de confianza original y los intervalos de confianza nuevos y originales se superponen en gran medida, los datos pueden considerarse válidos para este tipo de regresión después de la anonimización. La Figura @ref(fig:fig2__sec05) muestra las estimaciones puntuales y los intervalos de confianza para el coeficiente de género en este intercambio para un conjunto de datos de ingresos de muestra y varios métodos y parámetros de SDC. El punto rojo y la barra de confianza (en la parte superior) corresponden a las estimaciones de los datos no tratados, mientras que las otras barras de confianza corresponden a los métodos SDC con diferentes parámetros. La anonimización reduce el número de re-identificaciones esperadas en los datos (eje izquierdo) y las estimaciones puntuales y los intervalos de confianza varían mucho para los diferentes métodos SDC. Elegiríamos un método que reduzca el número esperado de identificaciones, sin cambiar el coeficiente de género y con una gran superposición del intervalo de confianza con el intervalo de confianza estimado a partir de los datos originales. (#fig:fig2_sec05)Efecto de la anonimización en las estimaciones puntuales e intervalo de confianza del coeficiente de género en la ecuación de Mincer. Fuente: Imagen extraída de (Benschop and Welch 2021), pág.90. 9.2 Evaluación de la utilidad de los datos con la ayuda de visualizaciones de datos (en R) El uso de gráficos y otras técnicas de visualización, actúan como una buena forma de evaluar cuánto han cambiado los datos después de la anonimización ayudando a seleccionar las técnicas de anonimización adecuadas para los datos. Las visualizaciones pueden ser una herramienta útil para evaluar el impacto en la utilidad de los datos de los métodos de anonimización ya que facilitan la elección entre los métodos de anonimización. El lenguaje de programación R proporciona varias funciones y paquetes que pueden ayudar a visualizar los resultados de la anonimización. Esta sección enumera algunas de estas funciones y paquetes y proporciona ejemplos de código para ilustrar cómo implementarlos. Se mostrarán las siguientes formas: histogramas y gráficos de densidad diagrama de caja gráfico en mosaico Para hacer visualizaciones apropiadas, necesitamos usar los datos sin procesar y los datos anonimizados. Cuando se utiliza un objeto sdcMicro para el proceso de anonimización, los datos sin procesar se almacenan en la ranura “origData” del objeto y las variables anonimizadas están en las ranuras “manipKeyVars”, “manipPramVars”, “manipNumVars” y “manipStrataVar”. Consulte la sección Objetos de la clase sdcMicroObj para obtener más información sobre los objetos sdcMicro , los slots y cómo acceder a ellos. 9.2.0.1 Histogramas y gráficos de densidad Son útiles para realizar comparaciones rápidas de la distribución de variables antes y después de la anonimización. La ventaja de los histogramas es que los resultados son exactos. Sin embargo, la visualización depende de los anchos de las barras y el inicio de la primera barra. Los histogramas se pueden utilizar para variables continuas y semicontinuas. Los gráficos de densidad muestran la densidad del kernel de los datos; por lo tanto, la gráfica depende del kernel que se elija y si los datos se ajustan bien al kernel. Sin embargo, los gráficos de densidad son una buena herramienta para ilustrar el cambio de valores y rangos de valores de variables continuas. Los histogramas se pueden trazar con la función hist() y las densidades del kernel con las funciones plot() y density() en R . El Bloque 9.11 muestra ejemplos de cómo utilizar estas funciones para ilustrar los cambios en la variable “INC”, una variable de ingresos. La función hist() necesita como argumento los puntos de ruptura del histograma. Los resultados se muestran en la Figura @ref(fig:fig3_sec05) y la Figura @ref(fig:fig4_sec05). Los histogramas y los gráficos de densidad dan una indicación clara de cómo han cambiado los valores: la variabilidad de los datos ha aumentado y la forma de la distribución ha cambiado. Bloque 9.11 Trazado de histogramas y densidades kernel # Histograma # gráfico de histograma antes de la anonimización hist(sdcInitial@origData$INC, breaks = (0:180)*1e2, main = &quot;Histogram income - original data&quot;) # gráfico de histograma después de la anonimización (adición de ruido) hist(sdcInitial@manipNumVars$INC, breaks = (-20:190)*1e2, main = &quot;Histogram income - anonymized data&quot;) # gráfico de densidades # trazo de la curva de densidad original plot(density(sdcInitial@origData$INC), xlim = c(0, 8000), ylim = c(0, 0.006), main = &quot;Density income&quot;, xlab = &quot;income&quot;) par (new = TRUE) # trazo de la curva de densidad después de la anonimización (adición de ruido) plot(density(sdcInitial@manipNumVars$INC), xlim = c(0, 8000), ylim = c(0, 0.006), main = &quot;Density income&quot;, xlab = &quot;income&quot;) (#fig:fig3_sec05)Histogramas de ingresos antes y después de la anonimización. Fuente: Imagen extraída de (Benschop and Welch 2021), pág.88. (#fig:fig4_sec05)Gráficas de densidad de ingresos antes y después de la anonimización. Fuente: Imagen extraída de (Benschop and Welch 2021), pág.89. 9.2.0.2 Diagramas de caja Los diagramas de caja brindan una descripción general rápida de los cambios en la dispersión y los valores atípicos de las variables continuas antes y después de la anonimización. El Bloque 9.12 a continuación muestra cómo generar diagramas de caja en R con la función boxplot(). resultado de la figura @ref(fig:fig5_sec05) muestra un ejemplo de una variable de gasto después de agregar ruido. El diagrama de caja muestra claramente que la variabilidad en la variable gasto aumentó como resultado de los métodos de anonimización aplicados. Bloque 9.12 Creación de diagramas de caja para variables continuas boxplot(sdcObj@origData$TOTFOOD, sdcObj@manipNumVars$TOTFOOD, xaxt = &#39;n&#39;, ylab = &quot;Expenditure&quot;) axis(1, at = c(1,2), labels = c(&#39;before&#39;, &#39;after&#39;)) (#fig:fig5_sec05)Ejemplo de diagramas de caja de una variable de gasto antes y después de la anonimización. Fuente: Imagen extraída de (Benschop and Welch 2021), pág.89. 9.2.0.3 Gráficos de mosaico Los gráficos de mosaico univariados y multivariados son útiles para mostrar cambios en las tabulaciones de variables categóricas, especialmente cuando se comparan varios “escenarios” uno al lado del otro. Un escenario aquí se refiere a la elección de métodos de anonimización y sus parámetros. Con gráficos de mosaico podemos, por ejemplo, ver rápidamente el efecto de diferentes niveles de k-anonimato o diferencias en los vectores de importancia en el algoritmo de supresión local (ver la Sección Supresión local. Ilustramos los cambios en las tabulaciones con un ejemplo de la variable “WATER” antes y después de aplicar PRAM. Podemos usar gráficos de mosaico para ver rápidamente los cambios de cada categoría. El Bloque 9.13 muestra el código en R . La función mosaicplot() está disponible en el paquete base de R. Para graficar una tabulación, primero se debe hacer la tabulación con la función table(). Para mostrar las etiquetas en mosaicplot(), cambiamos la clase de las variables a ‘factor’. Al observar el gráfico de mosaico en la Figura @ref(fig:fig6_sec05), vemos que la PRAM invariante prácticamente no tiene influencia en la distribución univariante. Bloque 9.13 Creando mosaicos univariados # Recopilación de datos de la variable WATER antes y después de la anonimización # asignación de etiquetas al gráfico dataWater &lt;- t(cbind(table(factor(sdcHH@origData$WATER, levels = c(1, 2, 3, 4, 5, 6, 7, 8, 9), labels = c(&quot;Pipe (own tap)&quot;, &quot;Public standpipe&quot;, &quot;Borehole&quot;, &quot;Wells (protected)&quot;, &quot;Wells (unprotected)&quot;, &quot;Surface water&quot;, &quot;Rain water&quot;, &quot;Vendor/truck&quot;, &quot;Other&quot;))), table(factor(sdcHH@manipPramVars$WATER, levels = c(1,2, 3, 4, 5, 6, 7, 8, 9), labels = c(&quot;Pipe (own tap)&quot;, &quot;Public standpipe&quot;, &quot;Borehole&quot;, &quot;Wells (protected)&quot;, &quot;Wells (unprotected)&quot;, &quot;Surface water&quot;, &quot;Rain water&quot;, &quot;Vendor/truck&quot;,&quot;Other&quot;))))) rownames(dataWater) &lt;- c(&quot;before&quot;, &quot;after&quot;) # gráfico de mosaico mosaicplot(dataWater, main = &quot;&quot;, color = 2:10, las = 2) (#fig:fig6_sec05)Gráfico de mosaico para ilustrar los cambios en la variable WATER. Fuente: Imagen extraída de (Benschop and Welch 2021), pág.90. Usamos las variables “gender” y “relationship status” para ilustrar el uso de gráficos de mosaico para la ilustración de cambios en las tabulaciones univariadas introducidas por varios conjuntos de métodos de anonimización. La Tabla 9.1 proporciona los métodos aplicados en cada escenario. El escenario 0, el escenario base, muestra las categorías originales de las variables de género y estado civil, mientras que los escenarios 1 a 6 muestran cambios en las categorías después de aplicar diferentes técnicas de anonimización. La tabla muestra una descripción de los métodos de anonimización utilizados en cada escenario. En total, visualizamos el impacto de seis conjuntos diferentes de métodos de anonimización. Podemos usar gráficos de mosaico para ver rápidamente qué conjunto de métodos tiene qué impacto en las variables de gender y relationship status, que se pueden usar para seleccionar el mejor escenario. Mirando los gráficos de mosaico en la Figura @ref(fig:fig7_sec05), vemos que los escenarios 2, 5 y 6 dan los cambios más pequeños para la variable de gender y los escenarios 3 y 4 para la variable de relationship status. Tabla 9.1: Descripción de métodos de anonimización por escenario Escenario Descripción de los métodos de anonimización aplicados 0 (base) Datos originales sin tratamiento 1 Recodificar age (intervalos de cinco años), más la supresión local (requerido k = 3, alta importancia en las variables de water, toilet y literacy) 2 Recodificar age (intervalos de cinco años), más supresión local (requerido k = 5, sin vector de importancia) 3 Recodificar la age (intervalos de cinco años), más la supresión local (requerido k = 3, alta importancia en toilet), al mismo tiempo que se recodifican las variables region, urban, education level y ocupation 4 Recodificar age (pasos de cinco años), más supresión local (requerido k = 5, alta importancia en water, toilet, y education level), al mismo tiempo que se recodifican variables de region, urban, education level y ocupation 5 Recodificar age (intervalos de cinco años), más supresión local (requerido k = 3, sin vector de importancia), microagregación (wealth index), al mismo tiempo que se recodifican variables de region, urban, education level y ocupation 6 Recodificar age (intervalos de cinco años) más supresión local (requerido k=3, sin vector de importancia), literacy PRAM, al mismo tiempo que se recodifican variables de region, urban, education level y ocupation (#fig:fig7_sec05)Comparación de variables de gender y relationship status tratadas versus no tratadas con gráficos de mosaico. Fuente: Imagen extraída de (Benschop and Welch 2021), pág.91 PRAM preserva las distribuciones univariadas. Por lo tanto, en este caso es más interesante observar los gráficos de mosaico multivariado. Los diagramas de mosaico también son una herramienta poderosa para mostrar cambios en tabulaciones cruzadas/tablas de contingencia. El Bloque 9.14 a continuación muestra cómo generar gráficos de mosaico para dos variables. Para comparar los cambios, necesitamos comparar dos gráficos diferentes. La Figura @ref(fig:fig8_sec05) y la Figura @ref(fig:fig9_sec05) ilustran que la PRAM no conserva las tablas de doble entrada en este caso. Bloque 9.14 Creando mosaicos multivariados # Antes de la anonimización: tabla de contingencia y gráfico de mosaico ROOFTOILETbefore &lt;- t(table(factor(sdcHH@origData$ROOF, levels = c(1,2, 3, 4, 5, 9), labels = c(&quot;Concrete/cement/ \\n brick/stone&quot;, &quot;Wood&quot;, &quot;Bamboo/thatch&quot;, &quot;Tiles/shingles&quot;, &quot;Tin/metal sheets&quot;, &quot;Other&quot;)), factor(sdcHH@origData$TOILET, levels = c(1,2, 3, 4, 9), labels = c(&quot;Flush \\n toilet&quot;, &quot;Improved \\n pit \\n latrine&quot;, &quot;Pit \\n latrine&quot;, &quot;No \\n facility&quot;, &quot;Other&quot;)))) mosaicplot(ROOFTOILETbefore, main = &quot;&quot;, las = 2, color = 2:6) # Después de la anonimización: tabla de contingencia y gráfico de mosaico ROOFTOILETafter &lt;- t(table(factor(sdcHH@manipPramVars$ROOF, levels = c(1,2, 3, 4, 5, 9), labels = c(&quot;Concrete/cement/ \\n brick/stone&quot;, &quot;Wood&quot;, &quot;Bamboo/thatch&quot;, &quot;Tiles/shingles&quot;, &quot;Tin/metal sheets&quot;, &quot;Other&quot;)), factor(sdcHH@manipPramVars$TOILET, levels = c(1,2, 3, 4, 9), labels = c(&quot;Flush \\n toilet&quot;, &quot;Improved \\\\n pit \\n latrine&quot;, &quot;Pit \\n latrine&quot;, &quot;No \\n facility&quot;, &quot;Other&quot;)))) mosaicplot(ROOFTOILETafter, main = &quot;&quot;, las = 2, color = 2:6) (#fig:fig8_sec05)Gráfico de mosaico de las variables ROOF e TOILET antes de la anonimización. Fuente: Imagen extraída de (Benschop and Welch 2021),pág. 92. (#fig:fig9_sec05)Gráfico de mosaico de las variables ROOF e TOILET después de la anonimización. Fuente: Imagen extraída de (Benschop and Welch 2021), pág.93. 9.2.1 Elección de la medida de utilidad Además de los requisitos de los usuarios sobre los datos, las medidas de utilidad deben elegirse de acuerdo con los tipos de variables y los métodos de anonimización empleados. Las medidas de utilidad empleadas pueden ser una combinación de medidas generales y específicas del usuario. Como se discutió anteriormente, se deben usar diferentes medidas de utilidad para datos continuos y categóricos. Además, algunas medidas de utilidad no son informativas después de que se hayan aplicado ciertos métodos de anonimización. Por ejemplo, después de aplicar métodos perturbativos que intercambian valores de datos, la comparación directa de valores no es útil porque dará la impresión de altos niveles de pérdida de información. En tales casos, es más informativo observar las medias, las covarianzas y los indicadores de evaluación comparativa que se pueden calcular a partir de los datos. Es más, es importante no solo centrarse en las características de las variables una por una, sino también en las interacciones entre las variables. Esto se puede hacer mediante tabulaciones cruzadas y regresiones. En general, al anonimizar datos muestreados, es recomendable calcular intervalos de confianza alrededor de las estimaciones para interpretar la magnitud de los cambios. Nota: Para material de lectura recomendado sobre la medición de la utilidad y la pérdida de información ver (De Waal and Willenborg 1999), (J. Domingo-Ferrer and Torra 2001) y (J. Domingo-Ferrer and Torra 2001). Referencias "],["proceso-control-a-la-divulgación-estadística-sdc-ine-2021.html", "Capítulo 10 Proceso Control a la Divulgación Estadística (SDC) INE 2021 10.1 Introducción 10.2 Etapa 6.4.1: Definiciones previas al proceso de anonimización 10.3 Etapa 6.4.2: Preparación y exploración de datos 10.4 Etapa 6.4.3: Medición y evaluación de riesgos de divulgación 10.5 Etapa 6.4.4.1: Selección y aplicación de métodos SDC 10.6 Etapa 6.4.4.2: Evaluación de proceso SDC 10.7 Etapa 6.4.5: Generar reportes y liberar datos", " Capítulo 10 Proceso Control a la Divulgación Estadística (SDC) INE 2021 10.1 Introducción Esta sección presenta el proceso SDC en una representación paso a paso y se puede utilizar como guía para el proceso SDC real, de acuerdo con los lineamientos INE 2021 (ver (Instituto Nacional de Estadísticas 2021b)). Sin embargo, debe tenerse en cuenta que, a menudo, es necesario saltar de un paso a otro y volver a los pasos anteriores durante el proceso SDC real, ya que no es necesariamente un proceso lineal paso a paso. Esta guía reúne las diferentes partes del proceso SDC como se discutió en las secciones anteriores y los enlaces a estas secciones. El estudio de caso en la siguiente sección sigue estos pasos. La Figura 10.2 al final de esta sección presenta todo el proceso de forma esquemática. 10.2 Etapa 6.4.1: Definiciones previas al proceso de anonimización El propósito de esta etapa es establecer los requerimientos necesarios para iniciar el subproceso de control a la divulgación, que incluye la revisión de insumos, revisión de las necesidades de los usuarios y características estadísticas prioritarias, y la determinación de la necesidad de protección de confidencialidad. Esto último, está estrechamente relacionado con la interpretación de las leyes y normas sobre este tema en Chile. Los procedimientos descritos para esta etapa aplican para todas las operaciones estadísticas y productos relacionados cuyo levantamiento de información y/o publicación sea realizado por el INE (muestras, censos, procesos de múltiples fuentes y registros estadísticos) que darán a conocer información al público general u otros usuarios. En esta etapa se debe revisar que no existan restricciones legales que impidan la publicación de los microdatos. Por otra parte, si el conjunto de datos no posee variables sensibles o variables de identificación (directa o indirecta), se pasa a la Etapa 6.4.5: Generar reportes y liberar datos. 10.2.1 Definiciones previas Organización del proceso y equipo de trabajo: El trabajo del proceso SDC y los roles del equipo a cargo se deben organizar considerando las siguientes dos fases: diagnóstico e implementación. La fase de diagnóstico corresponde a la evaluación de riesgo de intrusión con los datos no tratados (originales o brutos), y permite juzgar si el conjunto de datos es lo suficientemente seguro para su publicación, mientras que la fase de implementación se refiere a la aplicación de métodos SDC y su evaluación, a fin de producir un conjunto de datos seguro para su publicación. Revisión de insumos o productos estadísticos necesarios que permiten la ejecución del proceso: Se debe revisar que los insumos o productos estadísticos provenientes de los siguientes procesos en el mapa de procesos INE, segmento negocios38: 2. “Diseño y planificación”, 5. “Procesamiento” y 6.3 “Interpretar y explicar los resultados”; necesarios para la ejecución de este subproceso, se encuentren completos y actualizados. Esto incluye la revisión de convenios, fichas metodológicas, manuales de usuarios, bases de datos, diccionario de variables, paquetes estadísticos, infraestructura y seguridad, entre otros. 10.2.2 Determinación de la necesidad de protección de la confidencialidad Antes de iniciar el proceso SDC para un conjunto de microdatos, se debe determinar la necesidad de protección de la confidencialidad. Esto está estrechamente relacionado con la interpretación de las leyes y reglamentos sobre este tema en Chile. Un primer paso es determinar las unidades estadísticas en el conjunto de datos: si se trata de individuos, hogares o entidades legales, como empresas, es probable que sea necesario controlar la divulgación. También hay ejemplos de microdatos para los que no hay necesidad de control de divulgación. Los ejemplos podrían ser datos con observaciones climáticas y meteorológicas o datos con viviendas como unidades estadísticas. Sin embargo, aunque las unidades estadísticas primarias no sean personas físicas o jurídicas, los datos pueden contener información confidencial sobre personas físicas o jurídicas. Por ejemplo, un conjunto de datos con viviendas como unidades estadísticas primarias también puede contener información sobre las personas que viven en estas viviendas y sus ingresos o un conjunto de datos sobre hospitalizaciones puede incluir información sobre los pacientes hospitalizados. En estos casos, es probable que todavía sea necesaria la protección de la confidencialidad. Una opción para resolver esto es eliminar la información sobre las personas físicas y jurídicas en los conjuntos de datos para su publicación. Un conjunto de datos también puede contener más de un tipo de unidad estadística. El ejemplo estándar aquí es un conjunto de datos que contiene información sobre individuos y hogares. Otro ejemplo son los datos con empleados en empresas. Todos los tipos de unidades estadísticas presentes en el conjunto de datos deben ser considerados para la necesidad de SDC. Esto es especialmente importante en caso de que los datos tengan una estructura jerárquica, como individuos en hogares o empleados en empresas. Además, se debe evaluar si las variables contenidas en el conjunto de datos son de identificación, confidenciales o sensibles. Qué variables son sensibles o confidenciales depende nuevamente de la legislación aplicable y puede diferir sustancialmente de un país a otro. En caso de que el conjunto de datos incluya variables sensibles o confidenciales, es probable que se requiera SDC. El conjunto de variables sensibles y variables de identificación junto con las unidades estadísticas en el conjunto de datos determinan la necesidad de control de divulgación estadística. Por otra parte, se debe realizar una revisión normativa que pueda afectar o impedir la publicación de la información sujeta a anonimizar, esto incluye: identificar las restricciones actuales de publicación de la información, identificar acuerdos y restricciones de las particularidades establecidas en los convenios del INE con fuentes externas. Si no existen variables sensibles o variables de identificación en el conjunto de datos, o restricciones desde el marco legal normativo, la decisión es pasar a la Etapa 6.4.5: Generar reportes y liberar datos, según las características establecidas en la metodología de la operación estadística o convenio institucional, según corresponda a lo establecido en el proceso 2. “Diseño y planificación”. Por el contrario, en caso de que el conjunto de datos contenga variables sensibles o variables de identificación, y no haya restricciones desde el marco legal normativo, la decisión es llevar a cabo un proceso SDC. 10.2.3 Definición de las características de las bases de datos a preservar En este paso, analizamos los principales usos de los datos por parte de los usuarios finales del archivo de microdatos publicado. Los datos deben ser útiles para el tipo de análisis estadístico para el que se recopilaron y para el que se utilizan principalmente. Los usos y requisitos de los usuarios de datos serán diferentes para los diferentes tipos de publicación. Ponerse en contacto directamente con los usuarios de datos o buscar estudios y artículos científicos que utilicen datos similares puede resultar útil a la hora de recopilar esta información y realizar esta evaluación. Además, es importante comprender qué nivel de precisión necesitan los usuarios de datos y qué tipos de categorías se utilizan. Por ejemplo, en el caso de la recodificación global de la edad en años, uno podría recodificar la edad en grupos de 10 años, por ejemplo, \\(0 – 9, 10 – 19, 20 – 29, ...\\). Sin embargo, muchos indicadores relacionados con el mercado laboral usan categorías que abarcan el rango 15 – 65. Por lo tanto, construir categorías que coincidan con las categorías utilizadas para los indicadores hace que los datos sean mucho más útiles y, al mismo tiempo, reduce el riesgo de divulgación de manera similar. Este conocimiento es importante para la selección de medidas de utilidad apropiadas, que a su vez se utilizan para seleccionar los métodos SDC apropiados. La anonimización siempre conducirá a la pérdida de información y un archivo PUF tendrá una utilidad reducida. Las estadísticas calculadas a partir del archivo de microdatos anonimizados y publicados deberían producir resultados analíticos que concuerdan o casi concuerdan con las estadísticas publicadas previamente a partir de los datos originales. Si, por ejemplo, se calculó el promedio de ingresos de los hogares chilenos previamente a partir de estos datos y se publicó, el conjunto de datos anónimos publicado debería producir un resultado muy similar al resultado publicado oficialmente. Como mínimo, el resultado debe estar dentro de la región de confianza del resultado publicado. Puede darse el caso de que no todas las estadísticas publicadas puedan generarse a partir de los datos publicados. Si este es el caso, se debe elegir en qué indicadores y estadísticas enfocarse, e informar a los usuarios sobre cuáles se han seleccionado y por qué. Además, es importante definir porcentajes de variación permitidos por variable y niveles de desagregación geográfica o temática para las características estadísticas, a fin de medir la utilidad que compara los datos originales y los datos anonimizados, teniendo en cuenta la necesidad del usuario final para su análisis. Algunos ejemplos de características estadísticas a preservar son las siguientes: Propiedades globales de las variables, como promedios. Mantener cifras por nivel de desagregación geográfica o temática, como, por ejemplo, mantener para la variable grupos étnicos en los totales de cada categoría a nivel regional. Mantener correlaciones entre variables. Mantener tendencias de las variables a través del tiempo, por ejemplo, si los ingresos promedio de los hogares chilenos ha presentado un comportamiento decreciente en el primer trimestre de 2021, al publicar la base de datos anonimizada el equipo de trabajo desea garantizar que esta tendencia se conserve. Como se discutió en la Sección Medición de la utilidad y la pérdida de información, es necesario calcular medidas generales de utilidad que comparen los datos sin procesar y anonimizados, teniendo en cuenta la necesidad del usuario final para su análisis. En algunos casos, las medidas de utilidad pueden arrojar resultados contradictorios, por ejemplo, un determinado método SDC podría generar una menor pérdida de información para las cifras de la fuerza laboral pero una mayor pérdida de información para los índices relacionados con la educación. En tales casos, es posible que sea necesario clasificar los usos de los datos en orden de importancia y se debe documentar claramente para el usuario que la priorización de ciertas métricas sobre otras significa hará que algunas métricas ya no sean válidas. Esto puede ser necesario, ya que no es posible liberar varios archivos para diferentes usuarios. Este problema se presenta especialmente en estudios polivalentes. Para obtener más detalles sobre las medidas de utilidad, consulte la Sección Medición de la utilidad y la pérdida de información. 10.3 Etapa 6.4.2: Preparación y exploración de datos Después de evaluar la necesidad de un control de divulgación estadística, debemos preparar los datos y, si hay varios, combinar y considerar todos los archivos de datos relacionados. Luego exploramos las características y la estructura de los datos, que son importantes para los usuarios de los datos. La compilación de un inventario de estas características es importante para evaluar la utilidad de los datos después de la anonimización y producir un conjunto de datos anonimizados, que es útil para los usuarios finales. El primer paso en la preparación de datos es clasificar las variables como confidenciales o no confidenciales y eliminar identificadores directos como nombres completos, números de pasaporte, direcciones, números de teléfono y coordenadas GPS. En el caso de datos de encuestas, una inspección del cuestionario de la encuesta es útil para clasificar las variables. Además, es necesario seleccionar las variables que contienen información relevante para los usuarios finales y deben incluirse en el conjunto de datos para su publicación. En este punto, también puede ser útil eliminar variables que no sean identificadores directos del conjunto de microdatos que se publicará. Un ejemplo puede ser una variable con muchos valores faltantes, por ejemplo, una variable registrada solo para un grupo selecto de personas elegibles para un módulo de encuesta en particular y valores faltantes para el resto. Tales variables pueden causar un alto nivel de riesgo de divulgación y agregar poca información para los usuarios finales. Ejemplos son variables relacionadas con la educación (grado actual), donde un valor faltante indica que la persona no está actualmente en la escuela, o variables relacionadas con el parto, donde un valor faltante indica que la persona no ha dado a luz en el período de referencia. Los valores faltantes en sí mismos pueden ser reveladores, especialmente si indican que la variable no es aplicable. A menudo, las variables a las que les faltan la mayoría de los valores ya se eliminan en esta etapa. Otras variables que podrían eliminarse en esta etapa son aquellas demasiado sensibles para anonimizarlas y difundirlas o aquellas que no son importantes para los usuarios de datos y que podrían aumentar el riesgo de divulgación. Las relaciones pueden existir entre las variables en un conjunto de datos por una variedad de razones. Por ejemplo, las variables pueden ser mutuamente excluyentes en los casos en que se utilizan varias variables binarias para cada categoría. Un individuo que no está en la fuerza laboral tendrá un valor faltante para el sector en el que esta persona está empleada (o, más precisamente, no aplicable). Las relaciones también pueden existir si algunas variables son proporciones, sumas u otras funciones matemáticas de otras variables. Algunos ejemplos son la variable tamaño del hogar (como un recuento de personas por hogar) o el gasto agregado (como la suma de todos los componentes del gasto). Un cierto valor en una variable también puede reducir el número de valores posibles o válidos para otra variable; por ejemplo, la edad de una persona que asiste a la educación primaria o el sexo de una persona que ha dado a luz. Estas relaciones son importantes por dos razones: 1) pueden ser utilizadas por intrusos para reconstruir valores anonimizados. Por ejemplo, si se suprime la edad pero otra variable indica que está en la escuela, aún es posible inferir un rango de edad probable para ese individuo. Otro ejemplo es si se demuestra que un individuo está activo en el Sector B de la economía. Incluso si se suprime la condición laboral de este individuo, se puede inferir que esta persona está empleada. 2) las relaciones en los datos originales deben mantenerse en el conjunto de datos anonimizados y deben evitarse las inconsistencias (por ejemplo, los métodos SDC no deben crear niños en edad escolar de 58 años o niños casados de 3 años), o el conjunto de datos será inválido para el análisis. Otro ejemplo es el caso de los gastos por categoría, donde es importante que la suma de las categorías sume el total. Una forma de garantizar esto es anonimizar los totales y luego recalcular las subcategorías de acuerdo con las acciones originales de los totales anónimos. También es útil en esta etapa consolidar variables que brinden la misma información cuando sea posible, para reducir el número de variables, reducir la probabilidad de inconsistencias y minimizar las variables que un intruso puede usar para reconstruir los datos. Esto es especialmente cierto si los microdatos provienen de un cuestionario elaborado y cada variable representa una (sub) pregunta que conduce a un conjunto de datos con cientos de variables. Como ejemplo, tomamos una encuesta con varias variables de fuerza laboral que indican si una persona está en la fuerza laboral, empleada o desempleada, y si está empleada, en qué sector. Los datos de la Tabla 10.1 ilustra este ejemplo. Es posible que cada tipo de sector tenga su propia variable binaria. En ese caso, este conjunto de variables se puede resumir en dos variables: una variable que indica si una persona está en la fuerza laboral y otra que indica la situación laboral, así como el sector respectivo si una persona está empleada. Estas dos variables contienen toda la información contenida en las cinco variables anteriores y facilitan el proceso de anonimización. Si los usuarios de datos están acostumbrados a un determinado formato de publicación en el que la norma ha sido incluir las cinco variables, entonces es posible volver a transformar las variables después del proceso de anonimización en lugar de complicar el proceso de anonimización tratando de tratar más variables de las necesarias. Tabla 10.1: Ilustración de la combinación de variables sin pérdida de información para el proceso SDC. FL-Orig Empleado-Orig Sector-A Sector-B Sector-C FL-Nueva Empleado-Nueva Sí Sí NA Sí NA Sí B No No NA NA NA No No Sí Sí Sí NA NA Sí A Sí Sí NA Sí NA Sí B Sí Sí NA NA Sí Sí C Sí No NA NA NA Sí No Nota sobre los pasos siguientes: Los siguientes pasos, Etapa 6.4.3: Medición y evaluación de riesgos de divulgación, Etapa 6.4.4.1: Selección y aplicación de métodos SDC y Etapa 6.4.4.2: Evaluación de proceso SDC, deben repetirse si los datos tienen identificadores indirectos que se encuentran en diferentes niveles jerárquicos, por ejemplo, individuo y hogar. En ese caso, las variables del nivel jerárquico superior deben anonimizarse primero y luego fusionarse con las variables no tratadas del nivel inferior. Posteriormente, el conjunto de datos combinado debe anonimizarse. Este enfoque garantiza la consistencia en los datos tratados. Si descuidamos este procedimiento, los valores de las variables medidas en el nivel jerárquico superior podrían recibir un tratamiento diferente para las observaciones de la misma unidad. Por ejemplo, la variable “región” es la misma para todos los miembros del hogar. Si se suprimiera el valor ‘Valparaíso’ para dos miembros pero no para los tres restantes, esto daría lugar a una divulgación no intencionada; con la identificación del hogar, la variable región sería fácil de reconstruir para los dos valores suprimidos. Las secciones Riesgo jerárquico (o del hogar) y Estructura del hogar brindan más detalles sobre cómo tratar los datos con la estructura del hogar en R y sdcMicro . 10.4 Etapa 6.4.3: Medición y evaluación de riesgos de divulgación El propósito de esta etapa es calcular medidas de riesgo sobre los datos originales o brutos y, en base a estas medidas, juzgar si un archivo de microdatos es lo suficientemente seguro para su publicación. Los procedimientos descritos para esta etapa aplican para todas las operaciones estadísticas y productos relacionados cuyo levantamiento de información y/o publicación sea realizado por el INE (encuestas, censos, procesos de múltiples fuentes y registros administrativos) que darán a conocer información al público general u otros usuarios. En esta etapa solo se calculan las medidas de riesgo sobre los datos originales, que permiten decidir si el archivo de microdatos es lo suficientemente seguro para su publicación, o si requiere la aplicación de métodos SDC (ver Etapa 6.4.4.1: Selección y aplicación de métodos SDC). La decisión sobre qué hacer con las unidades riesgosas (una vez aplicados los métodos SDC) se aborda en la Etapa 6.4.4.2: Evaluación de proceso SDC. 10.4.1 Definición de escenarios de divulgación y selección de identificadores indirectos (cuasi-identificadores o variables clave) Después de determinar el tipo de publicación de los datos, se deben examinar las posibilidades de cómo un individuo en los microdatos podría (de manera realista) ser identificado por un intruso bajo ese tipo de publicación. Para el lanzamiento de PUF, el enfoque está en el uso de conjuntos de datos externos de varias fuentes. Estas posibilidades se describen en escenarios de divulgación o intrusión, que especifican a qué datos podría tener acceso un intruso y cómo se pueden utilizar estos datos auxiliares para la divulgación de identidad. Esto conduce a la especificación de identificadores indirectos, que son un conjunto de variables que están disponibles tanto en el conjunto de datos que se publicará como en conjuntos de datos auxiliares y necesitan protección. Esto es especialmente cierto para los lanzamientos de PUF. Los escenarios de divulgación también pueden ayudar a definir el nivel requerido de anonimización. La redacción de escenarios de divulgación requiere el apoyo de especialistas en la materia, suponiendo que el especialista en la materia no sea la misma persona que realiza la anonimización. Los conjuntos de datos auxiliares pueden contener información sobre la identidad de las personas y permitir la divulgación de la identidad. Ejemplos de estos archivos de datos auxiliares son los registros de población y los padrones electorales, registros de Servicio de Impuestos Internos, encuestas publicadas por el INE y datos censales, así como los datos recopilados por empresas especializadas, entre otras. De entre los diferentes escenarios de divulgación que pueden ser considerados, uno debe ser priorizado. La definición de este escenario puede responder a los siguientes criterios: Considerar escenarios realistas (probables). Las variables o conjuntos de datos pueden no coincidir perfectamente (por ejemplo, diferentes definiciones, variables más o menos detalladas, diferentes períodos de tiempo, etc.). Los registros externos podrían no estar lo suficientemente actualizados y, por lo tanto, un matching exacto con la base de datos a anonimizar, puede ser poco probable. Algunos criterios para priorizar la selección de los escenarios son: Probabilidad de datos disponibles para el intruso con más variables y categorías, y probabilidad de matching exitoso, considerando combinación de variables con mayor frecuencia. ** Notas **: - Pueden ser especificados tanto identificadores indirectos categóricos como cuantitativos. - Considerar como mínimo un identificador indirecto, pero sin número máximo. - Considerar en la definición de los escenarios, variables que den cuenta de la desagregación geográfica. Por ejemplo, región, provincia, comuna. - Considerar el escenario de reconocimiento espontáneo. Bajo este escenario, se debe verificar combinaciones raras o patrones inusuales en las variables. Ejemplos de variables que pueden conducir a reconocimiento espontáneo son: número de integrantes del hogar, área de un terreno, número de trabajadores de una empresa, ingresos y gastos, enfermedades, profesiones u oficios de baja prevalencia en el área geográfica circunscrita, entre otras. - Si el número de identificadores indirectos es alto, se recomienda reducir el conjunto de identificadores indirectos, eliminando algunas variables del conjunto de datos para su publicación. Sin embargo, esta decisión debe estar fundada bajo los siguientes criterios: 1) La variable no posee alto valor analítico y se puede prescindir de ella, o 2) La variable tiene una alta contribución al riesgo de divulgación. Si esta variable no se puede tratar adecuadamente mediante los métodos SDC (es decir, aún se mantienen altos niveles de riesgo), se debe quitar del conjunto de datos. 10.4.2 Medición y evaluación de riesgos El siguiente paso es evaluar el riesgo de divulgación de los datos no tratados (sin procesar). Aquí es importante distinguir entre datos muestrales y datos censales. En el caso de los datos del censo, es posible calcular directamente las medidas de riesgo cuando se supone que el conjunto de datos cubre a toda la población. Si se trabaja con una muestra, o una muestra del censo (que es el caso más común cuando se liberan datos de muestra), podemos usar los modelos discutidos en la Sección Medición de riesgos para estimar el riesgo en la población. Las principales entradas para la medición del riesgo son el conjunto de identificadores indirectos determinados a partir de los escenarios de divulgación en la sección anterior y los umbrales para los cálculos de riesgo (por ejemplo, el nivel de k-anonimato o el umbral por el cual un individuo se considera en riesgo). Si los datos tienen una estructura jerárquica (por ejemplo, una estructura de hogar), el riesgo debe medirse teniendo en cuenta esta estructura como se describe en la Sección Riesgo jerárquico (o del hogar). Cada una de las diferentes medidas de riesgo descritas en la Sección Medición de riesgos tiene ventajas y desventajas. En general, el k-anonimato, el riesgo individual y el riesgo global se utilizan para producir una idea del riesgo de divulgación. Estos valores pueden ser inicialmente muy altos, pero a menudo pueden reducirse muy fácilmente después de una recodificación simple pero apropiada (consulte la Etapa 6.4.4.1: Selección y aplicación de métodos SDC). Los umbrales son los establecidos por la institución de acuerdo con el tipo de operación estadística. Recuerde siempre, sin embargo, que al usar una muestra, las medidas de riesgo basadas en los modelos presentados en la literatura ofrecen el peor escenario de riesgo y, por lo tanto, podrían ser una exageración de los riesgos reales para algunos casos (consulte la Sección Riesgo individual). 10.5 Etapa 6.4.4.1: Selección y aplicación de métodos SDC La selección de los métodos SDC depende de la necesidad de protección de datos (medida por el riesgo de divulgación), la estructura de los datos y el tipo de variables. La influencia de los diferentes métodos sobre las características de los datos importantes para los usuarios o la utilidad de los datos también debe tenerse en cuenta al seleccionar los métodos SDC. En la práctica, la elección de los métodos SDC es parcialmente un proceso de prueba y error: después de aplicar un método elegido, el riesgo de divulgación y la utilidad de los datos se miden y comparan con otras opciones de métodos y parámetros. La elección de los métodos está sujeta a la legislación, por un lado, y a un compromiso entre utilidad y riesgo, por el otro. La clasificación de métodos que se presenta en la Tabla 10.2 ofrece una buena visión general para elegir los métodos apropiados. Los métodos deben elegirse según el tipo de variable, continua o categórica, los requisitos de los usuarios y el tipo de liberación. Para una descripción más completa de estos métodos, consulte la Sección Métodos SDC. Tabla 10.2: Métodos SDC y funciones correspondientes en sdcMicro Método Clasificación Tipo de datos Función en sdcMicro Recodificación global No perturbativo, determinístico Continuo y categórico globalRecode,groupVars Codificación superior e inferior No perturbativo, determinístico Continuo y categórico topBotCoding Supresión local No perturbativo, determinístico Categórico localSuppression,localSupp PRAM Perturbativo, probabilístico Categórico pram Microagregación Perturbativo, probabilístico Continuo microaggregation Adición de ruido Perturbativo, probabilístico Continuo addNoise Barajado Perturbativo, probabilístico Continuo shuffle Intercambio de rango Perturbativo, probabilístico Continuo rankSwap En general, para la anonimización de variables categóricas, es útil restringir el número de supresiones aplicando primero una recodificación global y/o eliminando variables del conjunto de microdatos. Cuando el número requerido de supresiones para lograr el nivel de riesgo requerido es suficientemente bajo, las pocas unidades en riesgo pueden ser tratadas mediante supresión. Estos son generalmente valores atípicos. Cabe señalar que posiblemente no todas las variables se puedan publicar y algunas se deban eliminar del conjunto de datos (consulte la Etapa 6.4.2: Preparación y exploración de datos). La recodificación y el uso mínimo de la supresión garantizan que las cifras ya publicadas de los datos sin procesar se puedan reproducir suficientemente bien a partir de los datos anonimizados. Si se aplica la supresión sin una recodificación suficiente, el número de supresiones puede ser muy alto y la estructura de los datos puede cambiar significativamente. Esto se debe a que la supresión afecta principalmente a las combinaciones que son raras en los datos. Si los resultados de la recodificación y la supresión no logran el resultado requerido, especialmente en los casos en que el número de identificadores indirectos seleccionados es alto, una alternativa es usar métodos perturbativos. Estos se pueden utilizar sin una recodificación previa de las variables. Estos métodos, sin embargo, preservan la estructura de datos solo parcialmente. El método preferido depende de los requisitos de los usuarios. Nos referimos a la Sección Métodos SDC y especialmente a la Sección Métodos perturbativos para una discusión de los métodos perturbativos implementados en sdcMicro. Finalmente, la selección de los métodos SDC depende de los datos utilizados, ya que los mismos métodos producen diferentes resultados en diferentes conjuntos de datos. Por lo tanto, la comparación de resultados con respecto al riesgo y la utilidad (ver Etapa 6.4.4.2: Evaluación de proceso SDC) es clave para la elección realizada. La mayoría de los métodos se implementan en el paquete sdcMicro. Sin embargo, a veces es útil emplear soluciones a medida. En la sección Métodos SDC se presentan algunos ejemplos. 10.6 Etapa 6.4.4.2: Evaluación de proceso SDC El propósito de esta etapa es verificar si la base de datos anonimizada cumple con las condiciones para presentarse como versión final. Estas son: el nivel de riesgo definido en la Etapa 6.4.3: Medición y evaluación de riesgos de divulgación y la utilidad esperada definida en la Etapa 6.4.1: Definiciones previas al proceso de anonimización. Su alcance considera la reevaluación del riesgo y la medición de la utilidad, comparar con mediciones de los datos originales y decidir si la base cumple o no con los criterios establecidos. 10.6.1 Vuelva a medir el riesgo En este paso, reevaluamos el riesgo de divulgación con las medidas de riesgo elegidas en la Etapa 6.4.3: Medición y evaluación de riesgos de divulgación después de aplicar los métodos SDC. Además de estas medidas de riesgo, también es importante observar a las unidades con alto riesgo y/o características especiales, combinaciones de valores o valores atípicos en los datos. Si el riesgo no está en un nivel aceptable, la Etapa 6.4.3: Medición y evaluación de riesgos de divulgación y Etapa 6.4.4.1: Selección y aplicación de métodos SDC deben repetirse con diferentes métodos y/o parámetros. Medidas de riesgo basadas en conteos de frecuencia (k-anonimato, riesgo individual, riesgo global y riesgo del hogar) no se pueden utilizar después de aplicar métodos perturbativos ya que sus estimaciones de riesgo no son válidas. Estos métodos se basan en introducir incertidumbre en el conjunto de datos y no en aumentar las frecuencias de las claves en los datos y, por lo tanto, sobreestimarán el riesgo. 10.6.2 Mida la utilidad En este paso, volvemos a medir las medidas de utilidad definidas en la Etapa 6.4.1: Definiciones previas al proceso de anonimización y las comparamos con los resultados de los datos sin procesar. Además, aquí es útil construir intervalos de confianza alrededor de las estimaciones puntuales y comparar estos intervalos de confianza. La importancia del valor absoluto de una desviación solo puede interpretarse conociendo la varianza de la estimación. Además de estas medidas de utilidad específicas, se deben evaluar las medidas de utilidad general, como se analiza en la Sección Medición de la utilidad y la pérdida de información. Esto es especialmente importante si se han aplicado métodos perturbativos. Si los datos no cumplen con los requisitos del usuario y las desviaciones son demasiado grandes, repita la Etapa 6.4.3: Medición y evaluación de riesgos de divulgación y Etapa 6.4.4.1: Selección y aplicación de métodos SDC con diferentes métodos y/o diferentes parámetros. La anonimización siempre conducirá a al menos alguna pérdida de información. 10.6.3 Evaluación de reglas de validación y consistencia Por último, se debe verificar que todas las relaciones en los datos anonimizados preserven todas las reglas de validación y consistencia propias de la operación estadística. Esto incluye: Variables que son sumas de otras variables o proporciones. Relaciones de orden, por ejemplo, la variable X debe ser siempre menor a la variable Y. Cualquier valor inusual causado por la anonimización debe ser detectado. Por ejemplo, los ingresos negativos, una persona de 14 años en la fuerza laboral o un alumno en el vigésimo grado de la escuela. Esto puede suceder después de aplicar métodos perturbativos de SDC. Se debe verificar que los indicadores publicados previamente de los datos originales o brutos son reproducibles a partir de los datos que se van a publicar. Si este no es el caso, los usuarios de datos podrían cuestionar la credibilidad del conjunto de datos anonimizados. En la Figura 10.1 se presenta el flujo que resume las actividades que componen esta etapa y que, en consecuencia, permite juzgar la efectividad de los métodos SDC aplicados y la factibilidad de liberar el conjunto de microdatos. Figura 10.1: Evaluación de proceso SDC INE 2021. 10.7 Etapa 6.4.5: Generar reportes y liberar datos El propósito de esta etapa es la generación de reportes, tanto interno como externo, que acompañan la liberación de datos. Los informes internos contienen la descripción exacta de los métodos de anonimización utilizados, los parámetros, pero también las medidas de riesgo antes y después de la anonimización. Esto permite la replicación del conjunto de datos anonimizados y es importante para las autoridades/organismos de control para garantizar que el proceso de anonimización sea suficiente para garantizar el anonimato de acuerdo con la legislación aplicable. Los informes externos informan al usuario que los datos han sido anonimizados, brindan información para un análisis válido de los datos y explican las limitaciones de los datos como resultado de la anonimización. Puede incluirse una breve descripción de los métodos utilizados. La publicación de microdatos anonimizados debe ir acompañada de los metadatos habituales de la encuesta (peso de la encuesta, estratos, metodología de la encuesta), así como información sobre los métodos de anonimización que permiten a los investigadores realizar análisis válidos (por ejemplo, cantidad de ruido agregado, matriz de transición para PRAM).Se debe tener cuidado de que esta información no se pueda utilizar para la reidentificación (por ejemplo, no se libera semilla aleatoria para PRAM). Por otra parte, los metadatos deben actualizarse para cumplir con los datos anonimizados. Las descripciones de las variables o las etiquetas de valores pueden haber cambiado como resultado del proceso de anonimización. Además, la pérdida de información debido al proceso de anonimización debe explicarse en detalle a los usuarios para que sean conscientes de los límites de la validez de los datos y sus análisis. El último paso en el proceso de SDC es la publicación real de los datos anónimos. En el contexto INE, el tipo de publicación factible es el PUF. Los cambios realizados en las variables en la Etapa 6.4.2: Preparación y exploración de datos, como la fusión de variables, se pueden deshacer para generar un conjunto de datos útil para los usuarios. Figura 10.2: Esquema general de proceso SDC INE 2021. Referencias "],["caso-de-estudio.html", "Capítulo 11 Caso de estudio 11.1 Paso Uno: Definiciones previas al proceso de anonimización 11.2 Paso Dos: Preparar y explorar datos originales 11.3 Paso Tres: Medición y evaluación del riesgo de divulgación 11.4 Paso Cuatro: Selección y aplicación de métodos SDC 11.5 Paso Cinco: Evaluar proceso SDC 11.6 Paso Seis: Generar Reportes y Liberar Datos", " Capítulo 11 Caso de estudio El objetivo del siguiente proceso de anonimización es ilustrar el proceso SDC establecido en la GUÍA PARA EL CONTROL DE DIVULGACIÓN ESTADÍSTICA EN MICRODATOS propuesta por la Mesa de Anonimización INE. Los datos utilizados corresponden a una base de datos sintética que se basa en el diseño de la 17a ENUSC 2020 (Instituto Nacional de Estadísticas de Chile 2021a). El proceso SDC aquí implementado pretender generar un archivo de datos PUF (del inglés, Public Use File), que pueda ponerse a disposición de forma pública y para cualquier usuario que lo requiera. Para ello, el proceso SDC aplicado apunta al logro de los umbrales de riesgo establecido por la GUÍA PARA EL CONTROL DE DIVULGACIÓN ESTADÍSTICA EN MICRODATOS para encuestas de hogares (Instituto Nacional de Estadísticas de Chile 2021b). Simultáneamente, el ejercicio busca mantener la utilidad de los datos, intentando minimizar la intervención de los mismos para que los usuarios puedan replicar las estadísticas priorizadas por esta encuesta. Los umbrales de riesgo establecidos son los siguientes: RIESGO GLOBAL Riesgo global inferior al 10% RIESGOS INDIVIDUALES Hasta 20% de observaciones con riesgo individual mayor al 1% Hasta 15% de observaciones con riesgo individual mayor al 5% 0% de observaciones con riesgo individual mayor al 25% K-ANONIMATO 0% de observaciones violando k = 2 Hasta 5% de observaciones violando k = 3 Hasta 10% de observaciones violando k = 5 A continuación, la guía presenta paso a paso como proceder con este conjunto de datos para lograr el cumplimiento de estos umbrales de riesgo. 11.1 Paso Uno: Definiciones previas al proceso de anonimización 11.1.1 Definición del equipo de trabajo En esta primera etapa, se define el equipo de trabajo, el cual debe estar compuesto al menos por un encargado temático, encargado de los criterios para la selección de variables claves y definición de escenarios, y un analista de anonimización, encargando de la implementación de la misma a través de un script como el aquí expuesto. 11.1.2 Insumos y/o productos necesarios para la ejecución del proceso En esta etapa se describe la metodología del producto estadístico, la revisión temática de la base de datos, su caracterización y clasificación de variables, la infraestructura con que se cuenta para el proceso, entre otros elementos que se especifican en el documento adjunto. 11.1.2.1 Archivo de Base de datos Antes de cargar los datos, declaramos el directorio de trabajo donde se ubican los archivos con que trabajaremos. Bloque 11.1 Indicar el directorio de trabajo yourdirectory&lt;-&quot;/simulacion&quot; setwd(yourdirectory) Se trabaja con la base bruta de la ENUSC, que contiene todas las variables previo a la innominación (en este caso es una base de datos sintética). Bloque 11.2 Indicar el nombre del archivo de datos fname &lt;- &quot;BD_ENUSC_SINTETICA_ETIQUETADA.sav&quot; file &lt;- haven::read_sav(fname) 11.1.2.2 Caracterización de la base de datos Primero revisamos las dimensiones del archivo, es decir, cuantos registros y variables contiene. La base contiene 47.344 registros y 73 variables. Luego, revisamos el nombre de las variables contenido en la base de datos para verificar que se ajusta a la base con que se requiere trabajar. Bloque 11.3 Inspeccionar las dimensiones del conjunto de datos y los nombres de las columnas dim(file) ## [1] 47344 73 names(file) ## [1] &quot;enc_idr&quot; &quot;rph_ID&quot; &quot;enc_id&quot; ## [4] &quot;enc_region&quot; &quot;enc_rpc&quot; &quot;enc_distrito&quot; ## [7] &quot;enc_zona&quot; &quot;enc_manzana&quot; &quot;enc_vivienda&quot; ## [10] &quot;IDC&quot; &quot;enc_letraKish&quot; &quot;enc_direccion&quot; ## [13] &quot;enc_numero&quot; &quot;enc_codfono&quot; &quot;enc_fono&quot; ## [16] &quot;enc_Nombre_ID&quot; &quot;Enc_Fono_ID&quot; &quot;Enc_Correo_ID&quot; ## [19] &quot;enc_Nombre_K&quot; &quot;enc_Edad_K&quot; &quot;Enc_Fono_K&quot; ## [22] &quot;Enc_Correo_K&quot; &quot;FECHA&quot; &quot;IH_residencia_habitual&quot; ## [25] &quot;Hora_inicio_rph&quot; &quot;rph_numeroLinea&quot; &quot;rph_nombrepila&quot; ## [28] &quot;rph_parentesco&quot; &quot;rph_dianacimiento&quot; &quot;rph_mesnacimiento&quot; ## [31] &quot;rph_agnonacimiento&quot; &quot;rph_edad&quot; &quot;rph_sexo&quot; ## [34] &quot;rph_idgen&quot; &quot;Kish&quot; &quot;rph_pertenencia_indigena&quot; ## [37] &quot;rph_nacionalidad&quot; &quot;rph_migracion&quot; &quot;rph_p9&quot; ## [40] &quot;rph_p10&quot; &quot;rph_p11&quot; &quot;rph_p12&quot; ## [43] &quot;rph_p13&quot; &quot;rph_p14&quot; &quot;Hora_termino_rph&quot; ## [46] &quot;P17&quot; &quot;P24&quot; &quot;A1_1_1&quot; ## [49] &quot;A1_1_1_N_Veces&quot; &quot;B1_1_1&quot; &quot;B1_1_1_N_Veces&quot; ## [52] &quot;C1_1_1&quot; &quot;C1_1_1_N_Veces&quot; &quot;D1_1_1&quot; ## [55] &quot;D1_1_1_N_Veces&quot; &quot;E1_1_1&quot; &quot;E1_1_1_N_Veces&quot; ## [58] &quot;F1_1_1&quot; &quot;G1_1_1&quot; &quot;G1_1_1_N_Veces&quot; ## [61] &quot;H1_1_1&quot; &quot;H1_1_1_N_Veces&quot; &quot;VA_DC&quot; ## [64] &quot;VP_DC&quot; &quot;DEN_AGREG&quot; &quot;RVA_DC&quot; ## [67] &quot;Hora_inicio_cc&quot; &quot;Hora_termino_cc&quot; &quot;Fact_Pers&quot; ## [70] &quot;Fact_Hog&quot; &quot;VarStrat&quot; &quot;Conglomerado&quot; ## [73] &quot;Fact_Ind&quot; Es importante señalar que la base de datos se compone de variables de caracterización de los hogares y las personas (módulo de Registro de Personas en el Hogar o RPH) y variables temáticas de la encuesta referidas a percepción de inseguridad y victimización. Adicionalmente, la base de datos contiene pesos muestrales, que deben ser considerados durante la anonimización. Para el nivel hogar se utiliza Fact_Hog, mientras que para el nivel persona se utiliza Fact_Ind. Además, la base de datos cuenta con variables de Conglomerado y VarStrat, que serán utilizadas para declarar el diseño complejo y evaluar la utilidad de los datos antes y después del tratamiento de los mismos. El archivo “Diccionario de Variables.xlsx” contiene la descripción de las variables contenidas en la base de datos. 11.1.2.3 Clasificación de variables Las potenciales variables clave, que podría permitir una re-identificación, se ubican en el módulo de Registro de Personas en el Hogar (RPH), ya que permiten dar cuenta de atributos de las personas y hogares, como también en la portada de la encuesta, donde se encuentran las variables de ubicación geográfica. Estas últimas coinciden en parte con la base de datos de Hoja de Ruta, no obstante esta base no se publica. 11.1.2.4 Librerías requeridas Se cargan las librerías requeridas para el proceso. En caso de que no estén instaladas, deberá instalarlas con la función install.packages() como se muestra en el siguiente ejemplo: Bloque 11.4 Ejemplo de instalación de librería #install.packages(&quot;nombre_libreria&quot;) Luego, cargamos las librerías: Bloque 11.5 Cargar librerías library(sdcMicro) # paquete sdcMicro con funciones para el proceso SDC library(survey) # para diseño complejo library(calidad) # evaluación de calidad de las estimaciones library(tidyverse) # herramientas para manipulación de datos library(openxlsx) # lectura/escritura de archivos xlsx library(stringr) # procesamiento de textos 11.1.3 Determinación de necesidades de protección de confidencialidad En esta actividad se describen el marco normativo y convenios a tener en cuenta para la anonimización, las unidades estadísticas contenidas en la base de datos, las variables sensibles contenidas en la base de datos, y el diagnóstico de necesidad de protección de confidencialidad. 11.1.3.1 Unidades estadísticas Se verifica la cantidad de viviendas y de personas registradas en la base de datos. Para ello, se mide la cantidad de valores únicos del folio de viviendas (enc_idr) y el folio de personas (rph_ID). Viviendas: 18.766 Personas: 47.344 Bloque 11.6 Contar la cantidad de folios a nivel de viviendas y personas length(unique(file$enc_idr)) ## [1] 18766 length(unique(file$rph_ID)) ## [1] 47344 De este modo, se da cuenta de la cantidad de unidades estadísticas y de la estructura jerárquica de la base de datos. 11.1.3.2 variables sensibles Se establecen como variables sensibles aquellas referidas a la tenencia de armas (P17), a elementos de seguridad en la vivienda (P24), y acerca de denuncia de delitos (DEN_AGREG). Bloque 11.7 Guardar variables sensibles en un vector de texto sensibles &lt;- c(&#39;P17&#39;, &#39;P24&#39;, &#39;DEN_AGREG&#39;) Se verifica que las variables sensibles están presentes en la base de datos. Se espera que esta función devuelva el valor TRUE. Bloque 11.8 Verificar presencia de variables sensibles all(sensibles %in% names(file)) ## [1] TRUE 11.1.3.3 Diagnóstico de necesidad de protección de confidencialidad Dado que las variables sensibles se encuentran presentes en el archivo de datos, corresponde aplicar el proceso SDC para asegurar la anonimización de los datos. 11.1.4 Propiedades estadísticas a preservar 11.1.4.1 Usos claves de los datos Se espera que los datos mantengan las siguientes propiedades: Se debe poder reproducir los indicadores principales de la encuesta con precisión, por lo que idealmente no deben modificarse, con un máximo de diferencia en la estimación no mayor a un punto porcentual (diferencia en términos absolutos, dado que las estimaciones de ENUSC son de proporción). Además, se deben mantener las variables de desagregación de tabulados de la encuesta, siendo estas sexo y región. Es decir, no deben observarse valores perdidos en estas variables. Dado que las variables temáticas no corresponden a potenciales variables clave, se descuenta la posibilidad de modificar dichas variables, asegurando mantener sus propiedades estadísticas. Por ende, el foco debe estar en mantener las relaciones entre las variables de desagregación que podrían ser modificadas como sexo y región, y las variables de los indicadores principales. Un dato frecuentemente solicitado por transparencia es la variable comuna. Si bien el diseño muestral de ENUSC no permite realizar estimaciones a ese nivel de desagregación, esta variable es de todos modos de interés para los usuarios para análisis a nivel descriptivo y referencial. En este sentido, es pertinente evaluar la posibilidad de mantener esta variable en la base de datos anonimizada. Por otro lado, la variable de edad en versiones anteriores de la ENUSC se publicaba con todos los valores de la variable (semi-continua), siendo ahora publicada como tramos etarios. Dado que usuarios del mundo académico y otros investigadores dan uso a esta variable, es también de interés analizar la posibilidad de mantenerla como semi-continua 11.1.4.2 Indicadores priorizados Los indicadores priorizados corresponden a: Victimización Agregada de Delitos Consumados Calculado en base a la variable VA_DC, por lo que la base de datos anonimizada debe permitir calcular este indicador a nivel nacional y regional (corresponde a hogares, por lo que no es desagregable por sexo). Victimización Personal de Delitos Consumados Calculado en base a la variable VP_DC, por lo que la base de datos anonimizada debe permitir calcular este indicador a nivel nacional, regional y según sexo. Finalmente, dado que la variable de edad es de interés para el análisis de cómo distintos grupos etarios se ven afectados por la delincuencia, es de interés que la relación entre la variable de edad y la variable de victimización personal se mantenga. Esto se evaluará a través de un modelo de regresión logística simple. 11.1.4.3 Medición de utilidad 11.1.4.3.1 Reproducción de estimaciones y desagregaciones Dado que las variables de sexo, región y de los indicadores principales no serán modificadas se espera que estas mantengan las propiedades estadísticas de la base de datos original o no tratada con la mayor fidelidad posible. Partiendo del supuesto de que estas variables no serán modificadas, sino que el proceso SDC se aplicará sobre otras variables (principalmente otras variables del RPH), solo podría verse alteradas las estimaciones en caso de supresión de registros. En este sentido, se espera que las estimaciones no difieran de la estimación original en más de un punto porcentual, en tanto diferencia en términos absolutos (todos los indicadores de ENUSC son de proporción). A continuación, se presentan las estimaciones de la ENUSC utilizando el paquete de calidad de las estimaciones desarrollado en el INE, ya que también se espera que se mantengan los estándares de calidad de las estimaciones. Ahora, se trabaja con un conjunto que contiene solo a los informantes que respondieron la encuesta (file_kish), descartando al resto de los integrantes del hogar. Esto es un paso necesario para poder declarar el diseño complejo de la encuesta. Se establece el diseño complejo para personas y para hogares: Bloque 11.9 Declarar el diseño complejo file_kish &lt;- file[file$Kish %in% 1,] options(survey.lonely.psu = &quot;certainty&quot;) dc_pers &lt;- svydesign(ids = ~Conglomerado, strata = ~VarStrat, data = file_kish, weights = ~Fact_Pers) dc_hog &lt;- svydesign(ids = ~Conglomerado, strata = ~VarStrat, data = file_kish, weights = ~Fact_Hog) Luego, realizamos las estimaciones desagregadas por región y sexo, guardando las tablas para posterior evaluación de la utilidad de los datos. Victimización agregada de delitos consumados, desagregado por región: Bloque 11.10 Estimar Victimización Agregada a nivel regional, con estandar de calidad INE insumos_prop &lt;- create_prop(var = &#39;VA_DC&#39;, domains = &#39;enc_region&#39;, design = dc_hog) VA_DC_REG_PRE &lt;- assess(insumos_prop) VA_DC_REG_PRE[1:6] ## enc_region stat se df n cv ## 1 1 0.5180939 0.01656239 1117 1283 0.03196793 ## 2 2 0.4986086 0.02015781 701 834 0.04042813 ## 3 3 0.5025207 0.01687235 1048 1224 0.03357544 ## 4 4 0.5096128 0.01963187 763 892 0.03852312 ## 5 5 0.5046148 0.01265927 1821 2106 0.02508700 ## 6 6 0.4937284 0.01719661 1017 1169 0.03483011 ## 7 7 0.5193102 0.01797112 920 1067 0.03460576 ## 8 8 0.5170244 0.01427234 1474 1724 0.02760477 ## 9 9 0.5070849 0.01951509 753 889 0.03848486 ## 10 10 0.5261810 0.01672262 1085 1251 0.03178111 ## 11 11 0.5240267 0.01849898 903 1066 0.03530160 ## 12 12 0.5167737 0.01889486 796 932 0.03656313 ## 13 13 0.5084057 0.02151621 604 731 0.04232094 ## 14 14 0.5096388 0.01751652 975 1135 0.03437047 ## 15 15 0.5026934 0.01590767 1191 1365 0.03164488 ## 16 16 0.4899313 0.01751388 929 1098 0.03574763 Victimización personal de delitos consumados, desagregado por sexo: Bloque 11.11 Estimar Victimización Personal según sexo, con estandar de calidad INE insumos_prop &lt;- create_prop(var = &#39;VP_DC&#39;, domains = &#39;rph_sexo&#39;, design = dc_pers ) VP_DC_SEXO_PRE &lt;- assess(insumos_prop) VP_DC_SEXO_PRE[1:6] ## rph_sexo stat se df n cv ## 1 1 0.2526373 0.005327597 6721 9439 0.02108793 ## 2 2 0.2447268 0.005269227 6590 9327 0.02153106 Victimización personal de delitos consumados, desagregado por región: Bloque 11.12 Estimar Victimización Personal a nivel regional, con estandar de calidad INE insumos_prop &lt;- create_prop(var = &#39;VP_DC&#39;, domains = &#39;enc_region&#39;, design = dc_pers) VP_DC_REG_PRE &lt;- assess(insumos_prop) VP_DC_REG_PRE[1:6] ## enc_region stat se df n cv ## 1 1 0.2568172 0.01420410 1117 1283 0.05530824 ## 2 2 0.2313854 0.01700058 701 834 0.07347300 ## 3 3 0.2379758 0.01447234 1048 1224 0.06081436 ## 4 4 0.2475154 0.01704076 763 892 0.06884725 ## 5 5 0.2422258 0.01087581 1821 2106 0.04489945 ## 6 6 0.2521763 0.01503618 1017 1169 0.05962565 ## 7 7 0.2685464 0.01612499 920 1067 0.06004546 ## 8 8 0.2611829 0.01250193 1474 1724 0.04786657 ## 9 9 0.2412502 0.01739434 753 889 0.07210085 ## 10 10 0.2361271 0.01413669 1085 1251 0.05986900 ## 11 11 0.2773473 0.01612302 903 1066 0.05813297 ## 12 12 0.2396374 0.01618739 796 932 0.06754952 ## 13 13 0.2462710 0.01884833 604 731 0.07653493 ## 14 14 0.2527983 0.01529804 975 1135 0.06051481 ## 15 15 0.2404411 0.01327941 1191 1365 0.05522937 ## 16 16 0.2431671 0.01512454 929 1098 0.06219815 Victimización personal de delitos consumados, desagregado por sexo y región: Bloque 11.13 Estimar Victimización Personal a nivel regional y según sexo, con estandar de calidad INE insumos_prop &lt;- create_prop(var = &#39;VP_DC&#39;, domains = &#39;rph_sexo+enc_region&#39;, design = dc_pers) VP_DC_REG_SEXO_PRE &lt;- assess(insumos_prop) VP_DC_REG_SEXO_PRE[1:6] ## rph_sexo enc_region stat se df n ## 1 1 1 0.2612492 0.01993875 541 660 ## 2 2 1 0.2522270 0.02020040 508 623 ## 3 1 2 0.2138315 0.02274576 317 428 ## 4 2 2 0.2493531 0.02527904 304 406 ## 5 1 3 0.2392046 0.02068420 485 600 ## 6 2 3 0.2367133 0.02041682 501 624 ## 7 1 4 0.2571475 0.02439808 340 440 ## 8 2 4 0.2388935 0.02367246 342 452 ## 9 1 5 0.2582590 0.01563089 921 1067 ## 10 2 5 0.2261775 0.01500918 889 1039 ## 11 1 6 0.2557568 0.02147664 472 582 ## 12 2 6 0.2486357 0.02088754 469 587 ## 13 1 7 0.2751938 0.02324332 429 540 ## 14 2 7 0.2616656 0.02226621 412 527 ## 15 1 8 0.2826785 0.01822327 688 829 ## 16 2 8 0.2408143 0.01715973 746 895 ## 17 1 9 0.2479841 0.02381286 359 467 ## 18 2 9 0.2333432 0.02543398 316 422 ## 19 1 10 0.2458082 0.01995371 521 639 ## 20 2 10 0.2262334 0.01988504 492 612 ## 21 1 11 0.2660547 0.02254731 422 531 ## 22 2 11 0.2894683 0.02341303 418 535 ## 23 1 12 0.2383125 0.02254203 365 475 ## 24 2 12 0.2410698 0.02307637 352 457 ## 25 1 13 0.2515748 0.02693269 252 356 ## 26 2 13 0.2411737 0.02646547 273 375 ## 27 1 14 0.2533536 0.02087620 490 598 ## 28 2 14 0.2521585 0.02282616 414 537 ## 29 1 15 0.2408291 0.01870310 565 686 ## 30 2 15 0.2400561 0.01891161 562 679 ## 31 1 16 0.2262722 0.02063687 425 541 ## 32 2 16 0.2592696 0.02167361 442 557 Se espera que la base de datos anonimizada mantenga las propiedades aquí expuestas, por lo que se almacenan en objetos para su posterior comparación con los datos tratados. Por otro lado, dado que queremos mantener la utilidad de los datos en relación con edad, se mide la relación entre la variable edad y la variable VP_DC, lo cual se debería mantener en caso que se deba recodificar la edad en tramos. 11.1.4.3.2 Relación entre variable de edad y victimización personal Se genera un modelo logit con la variable de Victimización Personal como dependiente y con la variable de edad como regresor. Se espera que los resultados aquí obtenidos sean similares con los datos tratados, lo que se evaluará al final del proceso de anonimización. Carga de datos Primero, se cargan los datos, y se filtran dejando solo al informante Kish. Bloque 11.14 Generar dataframe para modelo data &lt;- file[file$Kish %in% 1,] Dividir datos en training y testing sets Luego, se dividen los datos en sets de training y testing. Bloque 11.15 Dividir datos en training y testing sets library(caTools) set.seed(2022) ids_train &lt;- sample(data$rph_ID, nrow(data)/3*2) training&lt;- sjlabelled::remove_all_labels(data[data$rph_ID %in% ids_train,]) testing&lt;- sjlabelled::remove_all_labels(data[!data$rph_ID %in% ids_train,]) Construir modelo Luego, construimos el modelo utilizando la función glm(). Bloque 11.16 Construir modelo modelo&lt;-glm(VP_DC~rph_edad, data=training, family = &quot;binomial&quot;) summary(modelo) ## ## Call: ## glm(formula = VP_DC ~ rph_edad, family = &quot;binomial&quot;, data = training) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -0.8025 -0.7661 -0.7320 -0.6980 1.7502 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -1.3401916 0.0525124 -25.52 &lt; 2e-16 *** ## rph_edad 0.0034786 0.0007714 4.51 6.5e-06 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 13933 on 12509 degrees of freedom ## Residual deviance: 13912 on 12508 degrees of freedom ## AIC: 13916 ## ## Number of Fisher Scoring iterations: 4 Validación de modelo Luego aplicamos el test de Hosmer Lemeshow para validar el modelo. Bloque 11.17 Validación de modelo library(ResourceSelection) hoslem.test(modelo$y,fitted(modelo),g=10) # Test de Hosmer Lemeshow ## ## Hosmer and Lemeshow goodness of fit (GOF) test ## ## data: modelo$y, fitted(modelo) ## X-squared = 255.13, df = 8, p-value &lt; 2.2e-16 library(pROC) indiceC.trainig&lt;-roc(modelo$y,fitted(modelo)) # Curva ROC ## Setting levels: control = 0, case = 1 ## Setting direction: controls &lt; cases indiceC.trainig ## ## Call: ## roc.default(response = modelo$y, predictor = fitted(modelo)) ## ## Data: fitted(modelo) in 9444 controls (modelo$y 0) &lt; 3066 cases (modelo$y 1). ## Area under the curve: 0.5272 Punto de corte óptimo Se calcula el punto de corte óptimo utilizando la función coords(). Bloque 11.18 Calcular punto de corte óptimo ptocorteop.training&lt;-coords(indiceC.trainig,x=&quot;best&quot;, input=&quot;threshold&quot;, best.method=&quot;youden&quot;) ptocorteop.training ## threshold specificity sensitivity ## 1 0.270795 0.9431385 0.1457926 library(ROCR) ROC.training&lt;-performance(prediction.obj = prediction(predictions = fitted(modelo), labels = as.factor(modelo$y)), &quot;tpr&quot;, &quot;fpr&quot;) Luego, visualizamos el punto de corte óptimo utilizando la función plot(). Bloque 11.19 Visualizar punto de corte óptimo plot(ROC.training, colorize=TRUE, print.cutoffs.at=seq(0.1, by=0.1)) abline(a=0,b=1) abline(v=ptocorteop.training$threshold,col=&quot;red&quot;) Figura 11.1: Punto de corte óptimo con datos no tratados Predicciones y matriz de confusión Se realizan predicciones y se genera una matriz de confusión. Bloque 11.20 Predicciones y matriz de confusión pred.training&lt;-predict(modelo, data=training, type=&quot;response&quot;) table(ActualValue=training$VP_DC, PredictValue=pred.training&gt;ptocorteop.training$threshold) ## PredictValue ## ActualValue FALSE TRUE ## 0 8907 537 ## 1 2619 447 A continuación, se continua la evaluación del modelo con datos de prueba. Validación de modelo (con datos de prueba) Aplicamos nuevamente la validación con el test de Hosmer Lemeshow, esta vez con los datos de prueba. Bloque 11.21 Validación de modelo con datos de prueba hoslem.test(testing$VP_DC,predict(modelo,newdata=testing,type=&quot;response&quot;),g=5) # Test de Hosmer Lemeshow ## ## Hosmer and Lemeshow goodness of fit (GOF) test ## ## data: testing$VP_DC, predict(modelo, newdata = testing, type = &quot;response&quot;) ## X-squared = 60.369, df = 3, p-value = 4.903e-13 indiceC.testing=roc(testing$VP_DC,predict(modelo,newdata=testing,type=&quot;response&quot;)) # Curva ROC ## Setting levels: control = 0, case = 1 ## Setting direction: controls &lt; cases indiceC.testing ## ## Call: ## roc.default(response = testing$VP_DC, predictor = predict(modelo, newdata = testing, type = &quot;response&quot;)) ## ## Data: predict(modelo, newdata = testing, type = &quot;response&quot;) in 4666 controls (testing$VP_DC 0) &lt; 1590 cases (testing$VP_DC 1). ## Area under the curve: 0.5203 Punto de corte óptimo (con datos de prueba) Se calcula el punto de corte óptimo utilizando la función coords(). Bloque 11.22 Calcular de corte óptimo con datos de prueba ptocorteop.testing&lt;-coords(indiceC.testing,x=&quot;best&quot;,input=&quot;threshold&quot;,best.method=&quot;youden&quot;) ptocorteop.testing ## threshold specificity sensitivity ## 1 0.2633057 0.8317617 0.2440252 ROC.testing&lt;-performance(prediction(predict(modelo,newdata=testing,type=&quot;response&quot;), as.factor(testing$VP_DC)),&quot;tpr&quot;,&quot;fpr&quot;) Luego, visualizamos el punto de corte óptimo utilizando la función plot(). Bloque 11.23 Visualizar de corte óptimo con datos de prueba plot(ROC.testing, colorize=TRUE, print.cutoffs.at=seq(0.1, by=0.1)) abline(a=0,b=1) abline(v=ptocorteop.testing$threshold,col=&quot;red&quot;) Figura 11.2: Punto de corte óptimo con datos de prueba a partir de datos no tratados Predicciones y matriz de confusión (con datos de prueba) Se realizan predicciones y se genera una matriz de confusión. Bloque 11.24 Predicciones y matriz de confusión con datos de prueba pred.testing&lt;-predict(modelo, testing, type=&quot;response&quot;) table(ActualValue=testing$VP_DC, PredictValue=pred.testing&gt;ptocorteop.testing$threshold) ## PredictValue ## ActualValue FALSE TRUE ## 0 3881 785 ## 1 1202 388 Comparar área bajo la curva, umbral, sensibilidad y especificidad Finalmente, comparamos el área bajo la curva, umbral, sensibilidad y especificidad, a partir de los resultados del modelo con los datos de entrenamiento y con los datos de prueba. Bloque 11.25 Comparar área bajo la curva, umbral, sensibilidad y especificidad auc &lt;-indiceC.trainig$auc - indiceC.testing$auc corte &lt;-ptocorteop.training$threshold - ptocorteop.testing$threshold sens &lt;- ptocorteop.training$sensitivity - ptocorteop.testing$sensitivity spe &lt;- ptocorteop.training$specificity - ptocorteop.testing$specificity 11.2 Paso Dos: Preparar y explorar datos originales 11.2.1 Preparación de datos 11.2.1.1 Integración de datos La base de datos ENUSC ya se encuentra integrada y no se combina con ninguna otra base producida para este producto estadístico. 11.2.1.2 Eliminación de identificadores directos Se registra nombres de identificadores directos y otras variables internas del proyecto que no son publicadas. Bloque 11.26 Almacenar indicadores directos y otras variables excluidas en un vector de texto identificadores_directos &lt;- c(&#39;enc_id&#39;,&#39;enc_distrito&#39;, &#39;enc_zona&#39;,&#39;enc_manzana&#39;,&#39;enc_vivienda&#39;,&#39;FECHA&#39;, &#39;enc_Nombre_ID&#39;, &#39;enc_Nombre_K&#39;,&#39;enc_Edad_K&#39;, &#39;rph_dianacimiento&#39;,&#39;rph_mesnacimiento&#39;, &#39;rph_agnonacimiento&#39;, &#39;rph_nombrepila&#39;,&#39;Hora_inicio_rph&#39;, &#39;Hora_termino_rph&#39;,&#39;Hora_inicio_cc&#39;,&#39;Hora_termino_cc&#39;, &#39;IDC&#39;,&#39;enc_letraKish&#39;, &#39;enc_direccion&#39;,&#39;enc_numero&#39;,&#39;enc_codfono&#39;, &#39;enc_fono&#39;,&#39;Enc_Fono_ID&#39;,&#39;Enc_Correo_ID&#39;, &#39;Enc_Fono_K&#39;,&#39;Enc_Correo_K&#39;) all(identificadores_directos %in% names(file)) ## [1] TRUE Luego, se quitan estas variables de la base de datos. Bloque 11.27 Filtrar columnas excluidas file &lt;- file[,!names(file) %in% identificadores_directos] También, se quitan las variables de cadena con registros de observaciones, que tampoco corresponde publicar (en caso de que las hubiera). Estas corresponden a variables de texto que registran observaciones de terreno del encuestador y relatos de los delitos brindados por los informantes, información utilizada para el procesamiento de la base de datos, pero que no se consideran para su publicación. Bloque 11.28 Filtrar columnas de texto y observaciones de terreno file &lt;- file[,!str_detect(names(file),&#39;^Obs|Obs$&#39;)] 11.2.1.3 Selección de Variables En principio, todas las variables restantes son pertinentes de publicar, en la medida que se cumplan los requerimientos de anonimización de los datos. Para efectos de los análisis siguientes y para la medición del riesgo, solo se considerará el siguiente listado de variables, que se considera que pueden ser utilizadas como variables clave para la re-identificación de los informantes. Todas estas corresponden a variables de ubicación o del RPH. Variable Etiqueta enc_rpc Identificador de comuna enc_region Identificador de región IH_residencia_habitual Número de residentes habituales rph_edad Edad rph_sexo Sexo rph_idgen Identidad de Género rph_pertenencia_indigena Pertenencia a pueblos indígenas rph_nacionalidad Nacionalidad rph_p14 Razón para no buscar un empleo o iniciar una actividad por cuenta propia El resto de las variables que no son clave, pero se consideran para la publicación, se mantienen en el archivo de datos (variables temáticas sobre percepción de inseguridad y victimización). 11.2.1.4 Consolidación de variables De las variables recién descritas, la variable comuna se encuentra anidada en la variable de región, por lo que hay redundancia al mantener ambas. Dado que comuna (enc_rpc) tiene mayor nivel de información, se utilizará primero esta variable para los siguientes análisis y la medición de riesgo, incluyendo región solo en caso de que sea necesario retirar la variable de comuna. A continuación, se transforman y consolidan variables para poder aplicar adecuadamente los análisis. Primero, las variables de comparte gastos y número de grupos se excluyen del análisis, ya que son redundantes con la cantidad de residentes habituales y cantidad de hogares, siendo utilizadas solo estas últimas dos. Se fusionan categorías trans y otros, dado que son poco frecuentes. Bloque 11.29 Consolidar categorías de identidad de género y sus valores perdidos file$rph_idgen[file$rph_idgen %in% c(3,4)] &lt;- 3 file$rph_idgen[file$rph_idgen %in% c(88,99,96)] &lt;- NA Se recodifican perdidos en diversas variables clave. Bloque 11.30 Recodificar valores perdidos de pertenencia indígena file$rph_pertenencia_indigena[file$rph_pertenencia_indigena %in% c(88,99,96)] &lt;- NA file$rph_nacionalidad[file$rph_nacionalidad %in% c(88,99,96)] &lt;- NA file$rph_p14[file$rph_p14 %in% c(88,99,96)] &lt;- NA Consolidamos variable de situación ocupacional, ya que de otro modo tiene muchos valores perdidos por flujo, y apuntan a una sola clasificación con tres categorías que es lo más relevante. Bloque 11.31 Consolidar situación ocupacional # Generamos variable vacía file$rph_situacion_ocupacional &lt;- NA # Ocupados file$rph_situacion_ocupacional[file$rph_p9 %in% 1 | file$rph_p10 %in% 1] &lt;- 1 # Desocupados file$rph_situacion_ocupacional[file$rph_p12 %in% 1 &amp; file$rph_p13 %in% 1] &lt;- 2 # Inactivos file$rph_situacion_ocupacional[file$rph_p12 %in% 2 | file$rph_p13 %in% 2] &lt;- 3 # Revisamos table(file$rph_situacion_ocupacional) ## ## 1 2 3 ## 30364 2470 7498 Luego, integramos algunas categorías de inactivos con la condición de inactividad, ya que esto especifica subtipos de los inactivos que pueden ser relevantes para la re-identificación. Se agrupan las categorías que no son claves para re-identificar. Bloque 11.32 Consolidar situación ocupacional con categorías de inactivos. # Inactivo - Otros file$rph_situacion_ocupacional[file$rph_situacion_ocupacional %in% 3 &amp; (file$rph_p14 %in% c(1,2,6,7) | is.na(file$rph_p14))] &lt;- 3 # Inactivo - Estudiante file$rph_situacion_ocupacional[file$rph_situacion_ocupacional %in% 3 &amp; file$rph_p14 %in% 3] &lt;- 4 # Inactivo - Jubilado, pensionado o rentista file$rph_situacion_ocupacional[file$rph_situacion_ocupacional %in% 3 &amp; file$rph_p14 %in% 4] &lt;- 5 # Inactivo - Motivos de salud permanentes file$rph_situacion_ocupacional[file$rph_situacion_ocupacional %in% 3 &amp; file$rph_p14 %in% 5] &lt;- 6 # Revisamos table(file$rph_situacion_ocupacional) ## ## 1 2 3 4 5 6 ## 30364 2470 5358 730 718 692 Finalmente, se convierten las variables categóricas a tipo factor, quitándole el etiquetado de haven, ya que causa problemas con sdcMicro. Bloque 11.33 Convertir variables clave a factor file$enc_region &lt;- as.factor(as.numeric(file$enc_region)) file$enc_rpc &lt;- as.factor(as.numeric(file$enc_rpc)) file$rph_sexo &lt;- as.factor(as.numeric(file$rph_sexo )) file$rph_idgen &lt;- as.factor(as.numeric(file$rph_idgen)) file$rph_pertenencia_indigena &lt;- as.factor(as.numeric(file$rph_pertenencia_indigena)) file$rph_nacionalidad &lt;- as.factor(as.numeric(file$rph_nacionalidad)) file$rph_situacion_ocupacional &lt;- as.factor(as.numeric(file$rph_situacion_ocupacional)) 11.2.2 Exploración del conjunto de datos Primero, revisamos cuáles variables tenemos en la base de datos en este punto del proceso. Bloque 11.34 Revisar nuevamente variables presente en conjunto de datos names(file) ## [1] &quot;enc_idr&quot; &quot;rph_ID&quot; &quot;enc_region&quot; ## [4] &quot;enc_rpc&quot; &quot;IH_residencia_habitual&quot; &quot;rph_numeroLinea&quot; ## [7] &quot;rph_parentesco&quot; &quot;rph_edad&quot; &quot;rph_sexo&quot; ## [10] &quot;rph_idgen&quot; &quot;Kish&quot; &quot;rph_pertenencia_indigena&quot; ## [13] &quot;rph_nacionalidad&quot; &quot;rph_migracion&quot; &quot;rph_p9&quot; ## [16] &quot;rph_p10&quot; &quot;rph_p11&quot; &quot;rph_p12&quot; ## [19] &quot;rph_p13&quot; &quot;rph_p14&quot; &quot;P17&quot; ## [22] &quot;P24&quot; &quot;A1_1_1&quot; &quot;A1_1_1_N_Veces&quot; ## [25] &quot;B1_1_1&quot; &quot;B1_1_1_N_Veces&quot; &quot;C1_1_1&quot; ## [28] &quot;C1_1_1_N_Veces&quot; &quot;D1_1_1&quot; &quot;D1_1_1_N_Veces&quot; ## [31] &quot;E1_1_1&quot; &quot;E1_1_1_N_Veces&quot; &quot;F1_1_1&quot; ## [34] &quot;G1_1_1&quot; &quot;G1_1_1_N_Veces&quot; &quot;H1_1_1&quot; ## [37] &quot;H1_1_1_N_Veces&quot; &quot;VA_DC&quot; &quot;VP_DC&quot; ## [40] &quot;DEN_AGREG&quot; &quot;RVA_DC&quot; &quot;Fact_Pers&quot; ## [43] &quot;Fact_Hog&quot; &quot;VarStrat&quot; &quot;Conglomerado&quot; ## [46] &quot;Fact_Ind&quot; &quot;rph_situacion_ocupacional&quot; 11.2.2.1 Cálculo de porcentaje de valores perdidos en las variables Luego, calculamos el porcentaje de valores perdidos en las variables, considerando las celdas válidas según flujo de la encuesta (no se cuentan como valores perdidos las celdas vacías por saltos en el cuestionario). Aquellas variables que contengan más de un 50% de celdas perdidas, se excluyen del proceso de anonimización (pero sí deben incluirse en el archivo final de datos). Se observa que no hay variables clave que tengan valores perdidos. Bloque 11.35 Chequear valores perdidos any(is.na(file$enc_region)) ## [1] FALSE any(is.na(file$enc_rpc)) ## [1] FALSE any(is.na(file$IH_residencia_habitual)) ## [1] FALSE any(is.na(file$rph_sexo)) ## [1] FALSE any(is.na(file$rph_edad)) ## [1] FALSE any(is.na(file$rph_pertenencia_indigena)) ## [1] FALSE any(is.na(file$rph_nacionalidad)) ## [1] FALSE any(is.na(file$rph_situacion_ocupacional[file$rph_edad &gt; 14])) ## [1] FALSE Se concluye que todas las variables cumplen con las condiciones para incluirse en el proceso de anonimización. 11.2.2.2 Cálculo de estadísticas de resumen Por último, se revisan frecuencias para variables categóricas y estadísticos de resumen para numéricas. Esto permite visualizar que variables tienen categorías infrecuentes, lo que puede ser relevante más adelante para la toma de decisión de cuáles métodos aplicar y sobre cuáles variables. Bloque 11.36 Tablas de frecuencia de variables clave table(file$enc_region) ## ## 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ## 3223 2061 3115 2264 5269 2938 2648 4393 2241 3138 2693 2401 1842 2944 3368 2806 table(file$enc_rpc) ## ## 1101 1102 1103 1104 1105 1106 2101 2102 2103 2104 2105 2106 3101 3102 3103 3104 ## 561 601 522 500 533 506 326 355 350 358 343 329 524 564 493 461 ## 3105 3106 4101 4102 4103 4104 4105 4106 5101 5102 5103 5104 5105 5106 6101 6102 ## 514 559 393 416 342 436 351 326 889 926 890 862 812 890 495 471 ## 6103 6104 6105 6106 7101 7102 7103 7104 7105 7106 8101 8102 8103 8104 8105 8106 ## 455 507 522 488 434 470 395 463 409 477 698 720 774 700 724 777 ## 9101 9102 9103 9104 9105 9106 10101 10102 10103 10104 10105 10106 11101 11102 11103 11104 ## 402 380 337 385 344 393 539 519 495 525 492 568 340 350 380 446 ## 11105 11106 11107 12101 12102 12103 12104 12105 12106 12107 13101 13102 13103 13104 13105 13106 ## 375 432 370 322 302 382 411 340 362 282 251 273 270 234 214 293 ## 13107 14101 14102 14103 14104 14105 14106 14107 15101 15102 15103 15104 15105 15106 15107 16101 ## 307 419 447 410 373 427 444 424 443 483 511 467 544 438 482 448 ## 16102 16103 16104 16105 16106 16107 ## 362 397 351 371 431 446 table(file$rph_sexo) ## ## 1 2 ## 23694 23650 table(file$rph_idgen) ## ## 1 2 3 ## 10116 10030 20186 table(file$rph_pertenencia_indigena) ## ## 1 2 3 4 5 6 7 8 9 10 11 ## 4341 4276 4315 4368 4265 4322 4403 4317 4217 4239 4281 table(file$rph_nacionalidad) ## ## 1 2 3 4 5 6 7 8 9 ## 38923 1049 1010 1060 1025 1048 1035 1125 1069 table(file$rph_situacion_ocupacional) ## ## 1 2 3 4 5 6 ## 30364 2470 5358 730 718 692 Bloque 11.37 Estadísticos de resumen de variables clave summary(file$IH_residencia_habitual) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1.000 2.000 3.000 2.942 4.000 4.000 summary(file$rph_edad) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.00 25.00 53.00 53.06 80.00 107.00 11.3 Paso Tres: Medición y evaluación del riesgo de divulgación 11.3.1 Definición de escenarios de divulgación Las variables escogidas en su gran mayoría se encuentran contenidas también en otros productos estadísticos del INE y otras entidades públicas, ya que refieren a variables básicas de ubicación y caracterización sociodemográfica. Se destaca la coincidencia de variables de caracterización de personas de los hogares con CASEN y EPF, como ejemplos de fuentes internas. En el caso de fuentes externas, la ENPG de SENDA se considera una encuesta que contiene variables similares para hacer match. Por este motivo, se toma un único escenario conservador, en que todas estas variables son potencialmente utilizables en combinación por un intruso, siendo posibles de enlazar a otras base de datos públicas y/o privadas, habilitando una posible re-identificación de registros. En este sentido, y considerando las variables ya fusionadas/consolidadas, se mantiene el siguiente listado de variables para la medición del riesgo: Variable Etiqueta enc_rpc Identificador de comuna enc_region Identificador de región IH_residencia_habitual Número de residentes habituales rph_edad Edad rph_sexo Sexo rph_idgen Identidad de género rph_pertenencia_indigena Pertenencia a pueblos indígenas rph_nacionalidad Nacionalidad rph_situacion_ocupacional Situación ocupacional 11.3.2 Medición de riesgos de divulgación Para medir el riesgo se considerarán las medidas de riesgo global, riesgo individual, l-diversity y k-anonimato,considerando además la estructura jerárquica de la base. Por este motivo, primero se mide el riesgo a nivel de vivienda/hogar, para luego medir a nivel individual. 11.3.2.1 Medición de riesgos de divulgación a nivel vivienda/hogar En los siguientes pasos, se seleccionan las variables del nivel jerárquico superior y se genera el objeto sdcMicro en base al cual se realizan las estimaciones. Primero, se generan vectores con las variables claves y las variables numéricas en el conjunto de datos (nivel hogar). Luego, opcionalmente se pueden declarar variables para el método PRAM (en este caso se genera un vector vacío ya que no se utilizará el método PRAM). Bloque 11.38 Generar vectores con variables claves categóricas, numéricas y variables PRAM # Selección de variables para la anonimización a nivel de hogar selectedKeyVarsHH &lt;- c(&quot;enc_rpc&quot;) # variables numericas numVarsHH &lt;- c(&quot;IH_residencia_habitual&quot;) # No se declaran variables para método PRAM pramVarsHH &lt;- c() A continuación, se genera un vector con la variable de ponderación de hogares. Bloque 11.39 Asignar variables de ponderación a nivel hogar # Se indican las variables de ponderación de hogares weightVarsHH &lt;- c(&quot;Fact_Hog&quot;) Ahora, reunimos todas estas variables en un vector denominado HHVars Bloque 11.40 Generar vector con variables del nivel hogar # Luego se genera un vector con todas las variables del nivel de hogar HHVars &lt;- c(&#39;enc_idr&#39;,selectedKeyVarsHH, pramVarsHH, numVarsHH, weightVarsHH) variables &lt;- HHVars todas_variables &lt;- names(file) HHVars &lt;- intersect(todas_variables,variables) Luego, generamos un conjunto de datos con solo las columnas y filas que corresponden. En este caso son las variables del nivel hogar y las filas que corresponden al informante Kish, de manera tal que haya un caso por hogar. Bloque 11.41 Filtrar un caso por vivienda # Creamos un subconjunto de datos de file con hogares y variables HH fileHH &lt;- file[,HHVars] fileHH$Kish &lt;- file$Kish # Se deja un caso por cada hogar asignado en fileHH fileHH &lt;- fileHH[fileHH$Kish %in% 1,] fileHH &lt;- dplyr::select(fileHH, -Kish) Luego, se verifican las dimensiones del conjunto de datos con la función dim(). Bloque 11.42 Construir e inspeccionar dataframe de hogares # Se genera el dataset para medición de riesgo fileHH &lt;- data.frame(enc_idr = fileHH$enc_idr, enc_rpc = fileHH$enc_rpc, IH_residencia_habitual = fileHH$IH_residencia_habitual, Fact_Hog = fileHH$Fact_Hog) # Se verifican dimensiones del conjunto de datos dim(fileHH) ## [1] 18766 4 Y se genera el objeto SDC a nivel de hogar. Bloque 11.43 Crear objeto SDC # Se crea objeto SDC inicial para variables de nivel de hogar sdcHH &lt;- createSdcObj(dat = fileHH, keyVars = selectedKeyVarsHH, numVars = numVarsHH, weightVar = weightVarsHH) Por último, se guarda en un vector la cantidad de hogares para uso posterior. Bloque 11.44 Almacenar número de hogares # Se genera variable con número de hogares numHH &lt;- length(fileHH[,1]) # número de hogares Primero, revisamos las medidas globales de riesgo. Se observa que no hay hasta el momento observaciones que tengan un riesgo superior que la mayoría de los datos. Bloque 11.45 Medidas globales de riesgo print(sdcHH, &quot;risk&quot;) ## Risk measures: ## ## Number of observations with higher risk than the main part of the data: 0 ## Expected number of re-identifications: 0.16 (0.00 %) Ahora medimos el riesgo de manera individual. Se observan 0 casos con riesgo sobre el 1%. ::: {.example #bloque46nbm} Riesgo individual ::: # Observations with risk above certain threshold (0.01) nrow(fileHH[sdcHH@risk$individual[, &quot;risk&quot;] &gt; 0.01,]) ## [1] 0 Revisamos el k-anonimato para los casos ponderados.No hay casos que violen ningún nivel de k-anonimato. Para ello, se usa la función kAnon_violations(), indicando TRUE (T) como argumento para el parámetro de pesos (weighted) y el valor de k a evaluar. Bloque 11.46 K-anonimato kAnon_violations(sdcHH, weighted = T, k = 2) ## [1] 0 ## attr(,&quot;k&quot;) ## [1] 2 ## attr(,&quot;weighted&quot;) ## [1] TRUE kAnon_violations(sdcHH, weighted = T, k = 3) ## [1] 0 ## attr(,&quot;k&quot;) ## [1] 3 ## attr(,&quot;weighted&quot;) ## [1] TRUE kAnon_violations(sdcHH, weighted = T, k = 5) ## [1] 0 ## attr(,&quot;k&quot;) ## [1] 5 ## attr(,&quot;weighted&quot;) ## [1] TRUE En resumen, se observa que para el nivel hogar los riesgos ya cumplen con los umbrales establecidos por el estándar de anonimización. Por lo que se prosigue analizando el riesgo a nivel de personas. 11.3.2.2 Medición de riesgos de divulgación a nivel persona En este siguiente paso, se procede a seleccionar todas las variables de ambos niveles, para crear el objeto sdcMicro considerando la estructura jerárquica hasta el nivel persona. Bloque 11.47 Comandos para construir el objeto SDC a nivel de persona # Se indican variables clave (nivel individual) selectedKeyVarsIND &lt;- c(&#39;enc_rpc&#39;, &#39;rph_edad&#39;, &#39;rph_sexo&#39;, &#39;rph_idgen&#39;, &#39;rph_pertenencia_indigena&#39;, &#39;rph_nacionalidad&#39;, &#39;rph_situacion_ocupacional&#39;) # Se indica factor de expansión de personas WeightVarIND &lt;- c(&#39;Fact_Ind&#39;) # ID Hogares selectedHouseholdID &lt;- c(&#39;enc_idr&#39;) # Recombinación de conjuntos de datos HH anónimos y variables de nivel individuales indVars &lt;- c(&quot;enc_idr&quot;, &quot;rph_ID&quot;, selectedKeyVarsIND,WeightVarIND,sensibles) # HID and all non HH variables fileInd &lt;- file[indVars] # subset of file without HHVars fileCombined &lt;- dplyr::inner_join(fileInd, select(fileHH, -enc_rpc), by= c(&#39;enc_idr&#39;)) dim(fileCombined) ## [1] 47344 15 # Objetos SDC con todas las variables y variables HH tratadas para # anonimización de variables de nivel individual sdcCombined &lt;- createSdcObj(dat = fileCombined, keyVars = selectedKeyVarsIND, hhId = selectedHouseholdID, weightVar = WeightVarIND, sensibleVar = sensibles) Primero, revisamos las medidas globales de riesgo. Se observa una cantidad relevante de observaciones con riesgo alto, y también un porcentaje alto de re-identificaciones esperadas, lo que se acentúa al considerar la estructura jerárquica. Esta supera el umbral establecido de no más del 10%. Bloque 11.48 Medidas globales de riesgo print(sdcCombined, &quot;risk&quot;) ## Risk measures: ## ## Number of observations with higher risk than the main part of the data: 3108 ## Expected number of re-identifications: 2048.36 (4.33 %) ## ## Information on hierarchical risk: ## Expected number of re-identifications: 5412.30 (11.43 %) ## ---------------------------------------------------------------------- Ahora medimos el riesgo de manera individual. Para ello, se revisa la cantidad de observaciones con riesgo mayor a cada umbral de riesgo individual. Se observa que casi todos los casos presentan un riesgo superior al 1%, lo que incumple el umbral establecido. Al filtrar por porcentajes de riesgo más alto, se observa aún una cantidad muy alta de observaciones con riesgo altísimo, con 261 observaciones con riesgo superior al 50%. Bloque 11.49 Riesgo individual # Observaciones con riesgo individual superior al 1%: nrow(fileCombined[sdcCombined@risk$individual[, &quot;risk&quot;] &gt; 0.01,]) ## [1] 43123 # Observaciones con riesgo individual superior al 5%: nrow(fileCombined[sdcCombined@risk$individual[, &quot;risk&quot;] &gt; 0.05,]) ## [1] 8862 # Observaciones con riesgo individual superior al 25%: nrow(fileCombined[sdcCombined@risk$individual[, &quot;risk&quot;] &gt; 0.25,]) ## [1] 812 # Observaciones con riesgo individual superior al 50%: nrow(fileCombined[sdcCombined@risk$individual[, &quot;risk&quot;] &gt; 0.5,]) ## [1] 261 Luego, revisamos el k-anonimato para los casos ponderados. Se detectan casos que incumplen el k-anonimato, incluso con ponderación. Bloque 11.50 K-anonimato # 2-anonimato kAnon_violations(sdcCombined, weighted = T, k = 2) ## [1] 153 ## attr(,&quot;k&quot;) ## [1] 2 ## attr(,&quot;weighted&quot;) ## [1] TRUE # 3-anonimato kAnon_violations(sdcCombined, weighted = T, k = 3) ## [1] 225 ## attr(,&quot;k&quot;) ## [1] 3 ## attr(,&quot;weighted&quot;) ## [1] TRUE # 5-anonimato kAnon_violations(sdcCombined, weighted = T, k = 5) ## [1] 388 ## attr(,&quot;k&quot;) ## [1] 5 ## attr(,&quot;weighted&quot;) ## [1] TRUE Finalmente, medimos el l-diversity, que es una medida complementaria al k-anonimato. Esta indica cuantos valores de respuesta tienen las variables sensibles para cada combinación de las variables clave. Se espera obtener valores superiores a 1, dado que este valor indica que hay una única respuesta para cada combinación, lo que implica que un intruso podría saber el valor de respuesta a pesar de que se cumplan los umbrales de k-anonimato. En este sentido, esta métrica de riesgo es complementaria y da respaldo a lo evaluado a partir del k-anonimato. Bloque 11.51 L-Diversity # Generamos el objeto de l-diversity med_riesgo &lt;- ldiversity(sdcCombined, ldiv_index = sensibles, l_recurs_c = 2, missing = NA) # revisamos las medidas de riesgo de l-diversity med_riesgo@risk$ldiversity ## -------------------------- ## L-Diversity Measures ## -------------------------- ## P17_Distinct_Ldiversity P24_Distinct_Ldiversity DEN_AGREG_Distinct_Ldiversity ## Min. :1.000 Min. :1.000 Min. :1.000 ## 1st Qu.:1.000 1st Qu.:1.000 1st Qu.:1.000 ## Median :1.000 Median :1.000 Median :1.000 ## Mean :1.021 Mean :1.024 Mean :1.022 ## 3rd Qu.:1.000 3rd Qu.:1.000 3rd Qu.:1.000 ## Max. :3.000 Max. :3.000 Max. :3.000 Como se señaló previamente, el valor 1 indica un mínimo nivel de diversidad en las variables sensibles para cada combinación de variables clave. En este sentido, el que la media y promedio del l-diversity se aproximen a 1 nos indica que tenemos pocas combinaciones, lo que es señal de un mayor riesgo de que el intruso logre llegar al valor de las variables sensibles. 11.3.3 Evaluación de riesgos de divulgación CONCLUSIÓN DE LA EVALUACIÓN DE RIESGOS Dado que, a nivel jerárquico, considerando hasta el nivel de persona, se incumplen los umbrales requeridos por el estándar de anonimización a nivel global, individual y de k-anonimato, además de que se observa un valor riesgoso en el l-diversity, se confirma la necesidad de aplicar métodos SDC para asegurar la confidencialidad de los datos. Estos métodos se continúan aplicando sobre el nivel de personas del conjunto de datos, dado que a nivel hogares ya se cumplen los umbrales requeridos. 11.4 Paso Cuatro: Selección y aplicación de métodos SDC En esta sección se aplicarán iterativamente métodos SDC intentando alcanzar los umbrales de riesgo requeridos. Como veremos, al ser un proceso iterativo, también considerará de forma recurrente la re-medición del riesgo, que corresponde en estricto rigor a la primera parte del paso cinco. Esto es necesario para ir evaluando si es necesario aplicar métodos adicionales o distintos. 11.4.1 Primer conjunto de métodos SDC El primer método a aplicar es la recodificación global para la variable de edad,pasando de semi continua a ordinal. Los tramos etarios escogidos corresponden a una adaptación más desagregada de los tramos etarios utilizados en la publicación de tabulados en versiones anteriores de la encuesta. Se procede con este método primero dado que, por experiencia de los analistas de la encuesta, es uno de los que tiene mayor impacto en la reducción de riesgos. Para ello, aplicamos la función globalRecode(). Esta función implementa el método de recodificación global descrito en la guía de anonimización. El método toma cuatro argumentos: el objeto SDC, la columna a recodificar, los límites de los intervalos a generar, y las etiquetas que debe asignar a cada tramo. Bloque 11.52 Recodificar edad sdcCombined &lt;- globalRecode(sdcCombined, column = &quot;rph_edad&quot;, breaks=c(-1,14,19,24,29,39,49,59,69,79,89,120), labels=0:10) Alternativamente, se podría simplemente haber ocupado otras funciones de R base o de Tidyverse para recodificar esta variable en tramos, como, por ejemplo, las funciones ifelse() o case_when(). Sin embargo, esta aproximación tiene la desventaja de que requiere generar nuevamente el objeto SDC por completo, por lo que se pierde la trazabilidad de las ediciones realizadas y de la reducción del riesgo desde la línea base inicial. Por este motivo, es que se recomienda usar globalRecode(). Luego de haber aplicado este método SDC, procedemos a medir el impacto de esta modificación en las medidas de riesgo. 11.4.2 Re-medición del riesgo para primer conjunto de métodos Primero, revisamos las medidas globales de riesgo con los datos tratados. Se observa una mejora en los resultados, llegando a umbrales aceptables (&lt;10%). No obstante, es necesario revisar el resto de las métricas, donde se está más lejos de cumplir con los estándares requeridos. Bloque 11.53 Riesgo global print(sdcCombined, &quot;risk&quot;) ## Risk measures: ## ## Number of observations with higher risk than the main part of the data: ## in modified data: 2169 ## in original data: 3108 ## Expected number of re-identifications: ## in modified data: 1488.69 (3.14 %) ## in original data: 2048.36 (4.33 %) ## ## Information on hierarchical risk: ## Expected number of re-identifications: ## in modified data: 4006.48 (8.46 %) ## in original data: 5412.30 (11.43 %) ## ---------------------------------------------------------------------- Ahora medimos el riesgo de manera individual. Se observa que 30.922 de los casos tiene un riesgo superior al 1%. Al filtrar por porcentajes de riesgo más alto, se observa aún una cantidad importante de observaciones con riesgo altísimo, con 189 observaciones con riesgo superior al 50%, lo que aún es demasiado alto. Bloque 11.54 Riesgo individual # Observaciones con riesgo individual superior al 1%: nrow(fileCombined[sdcCombined@risk$individual[, &quot;risk&quot;] &gt; 0.01,]) ## [1] 30922 # Observaciones con riesgo individual superior al 5%: nrow(fileCombined[sdcCombined@risk$individual[, &quot;risk&quot;] &gt; 0.05,]) ## [1] 6169 # Observaciones con riesgo individual superior al 25%: nrow(fileCombined[sdcCombined@risk$individual[, &quot;risk&quot;] &gt; 0.25,]) ## [1] 569 # Observaciones con riesgo individual superior al 50%: nrow(fileCombined[sdcCombined@risk$individual[, &quot;risk&quot;] &gt; 0.5,]) ## [1] 189 Revisamos el k-anonimato para los casos ponderados. Aún se observan 116 casos que incumplen el 2-anonimato. Bloque 11.55 K-anonimato # 2-anonimato kAnon_violations(sdcCombined, weighted = T, k = 2) ## [1] 116 ## attr(,&quot;k&quot;) ## [1] 2 ## attr(,&quot;weighted&quot;) ## [1] TRUE # 3-anonimato kAnon_violations(sdcCombined, weighted = T, k = 3) ## [1] 166 ## attr(,&quot;k&quot;) ## [1] 3 ## attr(,&quot;weighted&quot;) ## [1] TRUE # 5-anonimato kAnon_violations(sdcCombined, weighted = T, k = 5) ## [1] 280 ## attr(,&quot;k&quot;) ## [1] 5 ## attr(,&quot;weighted&quot;) ## [1] TRUE Luego medimos el l-diversity, donde observamos aún valores muy cercanos a 1, para las tres variables sensibles. Bloque 11.56 L-diveristy # Generamos el objeto de l-diversity med_riesgo &lt;- ldiversity(sdcCombined, ldiv_index = sensibles, l_recurs_c = 2, missing = NA) # revisamos las medidas de riesgo de l-diversity med_riesgo@risk$ldiversity ## -------------------------- ## L-Diversity Measures ## -------------------------- ## P17_Distinct_Ldiversity P24_Distinct_Ldiversity DEN_AGREG_Distinct_Ldiversity ## Min. :1.000 Min. :1.000 Min. :1.000 ## 1st Qu.:1.000 1st Qu.:1.000 1st Qu.:1.000 ## Median :1.000 Median :1.000 Median :1.000 ## Mean :1.219 Mean :1.252 Mean :1.229 ## 3rd Qu.:1.000 3rd Qu.:1.000 3rd Qu.:1.000 ## Max. :6.000 Max. :6.000 Max. :6.000 En conclusión, si bien se cumplen los umbrales a nivel global, los umbrales a nivel individual, el k-anonimato y el l-diversity nos indican que se requiere aplicar más métodos SDC para asegurar la anonimización de los datos. 11.4.3 Segundo conjunto de métodos SDC El hecho de estar aplicando nuevamente el paso 4 nos indica una característica fundamental de los procesos de anonimización, que es que estos son procesos iterativos, donde es necesario ir aplicando métodos progresivamente y monitorear los niveles de riesgo en cada iteración. Como veremos en este ejercicio aplicado, serán varias iteraciones antes de llegar a un resultado satisfactorio de niveles de riesgo. Retomando el proceso, el segundo método a aplicar es la eliminación de la variable de comuna. En cambio, se incluye la variable de región, ya que deja de ser redundante. Esto, dado que previamente se había retirado en el paso de consolidación de variables puesto que la comuna es una variable anidada en la variable de región. Los pasos aplicados en el siguiente bloque de código son los mismos que se aplicaron la primera vez que se construyó el objeto sdcCombined. La única diferencia es que se reemplaza la variable enc_rpc por enc_region dentro del vector de variables clave selectedKeyVarsIND. Bloque 11.57 Reconstruir el objeto SDC a nivel persona con variable región # Se indican variables clave (nivel individual) selectedKeyVarsIND &lt;- c(&#39;enc_region&#39;, &#39;rph_edad&#39;, &#39;rph_sexo&#39;, &#39;rph_idgen&#39;, &#39;rph_pertenencia_indigena&#39;, &#39;rph_nacionalidad&#39;, &#39;rph_situacion_ocupacional&#39;) # Se indica factor de expansión de personas WeightVarIND &lt;- c(&#39;Fact_Ind&#39;) # ID Hogares selectedHouseholdID &lt;- c(&#39;enc_idr&#39;) # Recombinación de conjuntos de datos HH anónimos y variables de nivel individuales indVars &lt;- c(&quot;enc_idr&quot;, &quot;rph_ID&quot;, selectedKeyVarsIND,WeightVarIND,sensibles) # HID and all non HH variables fileInd &lt;- file[indVars] # subset of file without HHVars fileCombined &lt;- dplyr::inner_join(fileInd, select(fileHH, -enc_rpc), by= c(&#39;enc_idr&#39;)) dim(fileCombined) ## [1] 47344 15 # Objetos SDC con todas las variables y variables HH tratadas para # anonimización de variables de nivel individual sdcCombined &lt;- createSdcObj(dat = fileCombined, keyVars = selectedKeyVarsIND, hhId = selectedHouseholdID, weightVar = WeightVarIND, sensibleVar = sensibles) Además, como en este caso fue necesario crear nuevamente el objeto SDC, hay que aplicar nuevamente la recodificación de la variable edad con la función globalRecode(). Bloque 11.58 Recodificar edad nuevamente sdcCombined &lt;- globalRecode(sdcCombined, column = &quot;rph_edad&quot;, breaks=c(-1,14,19,24,29,39,49,59,69,79,89,120), labels=0:10) 11.4.4 Re-medición del riesgo para segundo conjunto de métodos Nuevamente, revisamos las medidas globales de riesgo. Se observa que a nivel global obtenemos valores aceptables de riesgo, ya que se habían logrado en la primera iteración. Bloque 11.59 Riesgo global print(sdcCombined, &quot;risk&quot;) ## Risk measures: ## ## Number of observations with higher risk than the main part of the data: ## in modified data: 1035 ## in original data: 2471 ## Expected number of re-identifications: ## in modified data: 762.14 (1.61 %) ## in original data: 1683.54 (3.56 %) ## ## Information on hierarchical risk: ## Expected number of re-identifications: ## in modified data: 2216.99 (4.68 %) ## in original data: 4524.60 (9.56 %) ## ---------------------------------------------------------------------- Ahora medimos el riesgo de manera individual. Se observa que 15.463 de los casos (32,7% del total) presentan un riesgo superior al 1%, lo que aún incumple el umbral establecido, que indica el 20% de los casos. Por otro lado, se observa que 3.000 de las personas (6,3% del total) presentan un riesgo mayor al 5%, lo que cumple con el umbral (no más de 15%). Por otro lado, se observa que 286 y un 92 de los casos tienen riesgos superiores al 25% y 50%, respectivamente. Esto incumple con los umbrales establecidos ya que se espera que no haya observaciones con estos niveles de riesgo. Bloque 11.60 Riesgo individual # Observaciones con riesgo individual superior al 1%: nrow(fileCombined[sdcCombined@risk$individual[, &quot;risk&quot;] &gt; 0.01,]) ## [1] 15463 # Observaciones con riesgo individual superior al 5%: nrow(fileCombined[sdcCombined@risk$individual[, &quot;risk&quot;] &gt; 0.05,]) ## [1] 3000 # Observaciones con riesgo individual superior al 25%: nrow(fileCombined[sdcCombined@risk$individual[, &quot;risk&quot;] &gt; 0.25,]) ## [1] 286 # Observaciones con riesgo individual superior al 50%: nrow(fileCombined[sdcCombined@risk$individual[, &quot;risk&quot;] &gt; 0.5,]) ## [1] 92 Revisamos el k-anonimato para los casos ponderados. Aún hay 54 casos que incumplen el 2-anonimato. Bloque 11.61 K-anonimato # 2-anonimato kAnon_violations(sdcCombined, weighted = T, k = 2) ## [1] 54 ## attr(,&quot;k&quot;) ## [1] 2 ## attr(,&quot;weighted&quot;) ## [1] TRUE # 3-anonimato kAnon_violations(sdcCombined, weighted = T, k = 3) ## [1] 85 ## attr(,&quot;k&quot;) ## [1] 3 ## attr(,&quot;weighted&quot;) ## [1] TRUE # 5-anonimato kAnon_violations(sdcCombined, weighted = T, k = 5) ## [1] 132 ## attr(,&quot;k&quot;) ## [1] 5 ## attr(,&quot;weighted&quot;) ## [1] TRUE Luego medimos el l-diversity. Se observa una leve mejora en el l-diversity, al observarse ahora una diversidad de 2 en promedio para las distintas combinaciones de variables clave en relación con las variables sensibles. Bloque 11.62 L-diversity # Generamos el objeto de l-diversity med_riesgo &lt;- ldiversity(sdcCombined, ldiv_index = sensibles, l_recurs_c = 2, missing = NA) # revisamos las medidas de riesgo de l-diversity med_riesgo@risk$ldiversity ## -------------------------- ## L-Diversity Measures ## -------------------------- ## P17_Distinct_Ldiversity P24_Distinct_Ldiversity DEN_AGREG_Distinct_Ldiversity ## Min. : 1.0 Min. : 1.0 Min. : 1.00 ## 1st Qu.: 1.0 1st Qu.: 1.0 1st Qu.: 1.00 ## Median : 1.0 Median : 2.0 Median : 1.00 ## Mean : 2.2 Mean : 2.4 Mean : 2.27 ## 3rd Qu.: 3.0 3rd Qu.: 3.0 3rd Qu.: 3.00 ## Max. :13.0 Max. :14.0 Max. :13.00 En suma, debido a los riesgos individuales, k-anonimato y l-diversity, aún se requiere seguir aplicando métodos SDC. 11.4.5 Tercer conjunto de métodos SDC Como tercera iteración, se aplican varios métodos para poder reducir los riesgos individuales y el incumplimiento de 2-anonimato, que son las métricas que han presentado mayor dificultad para disminuir. Primero, se recodifican globalmente las variables de pertenencia indígena y nacionalidad. Para esto se ocupa una función distinta, groupAndRename(), que permite también recodificar variables categóricas. También se fusionan categorías de situación laboral, lo que equivale a posteriormente eliminar la variable de razón de inactividad de la base de datos. Esto porque esta variable corresponde a una consolidación de variables (revisar paso 2.1.4). Bloque 11.63 Recodificar de variables # Recodificamos pertenencia indígena sdcCombined &lt;- groupAndRename(sdcCombined, var=&quot;rph_pertenencia_indigena&quot;, before=c(1:9), after=c(1)) sdcCombined &lt;- groupAndRename(sdcCombined, var=&quot;rph_pertenencia_indigena&quot;, before=c(10), after=c(2)) # Recodificamos nacionalidad sdcCombined &lt;- groupAndRename(sdcCombined, var=&quot;rph_nacionalidad&quot;, before=c(2:9), after=c(2)) Luego, se aplica supresión local en las variables de menor prioridad. Se seleccionan estas variables cuidadosamente, dado que se aplicará un método drástico como es la supresión local, teniendo como criterio las propiedades estadísticas que se buscan preservar en la base de datos. Por otro lado, los umbrales que se entregan como argumento a esta función en el parámetro threshold dependen de la data y se debe probar iterativamente hasta lograr los umbrales deseados. Se debe introducir en los argumentos umbrales de riesgo no tan bajos, evitando sobre-anonimizar, dado que esto nos llevaría a perder más utilidad de la necesaria. En este caso, se indican umbrales de 0.1, es decir, del 10% de riesgo individual como objetivo. Bloque 11.64 Supresión local # supresión local para riesgos globales e individuales sdcCombined &lt;- localSupp(sdcCombined, keyVar=&#39;rph_idgen&#39;, threshold=0.1) sdcCombined &lt;- localSupp(sdcCombined, keyVar=&#39;rph_pertenencia_indigena&#39;, threshold=0.1) sdcCombined &lt;- localSupp(sdcCombined, keyVar=&#39;rph_nacionalidad&#39;, threshold=0.1) sdcCombined &lt;- localSupp(sdcCombined, keyVar=&#39;rph_situacion_ocupacional&#39;, threshold=0.1) Como veremos en el siguiente paso,los métodos aplicados en esta tercera iteración logran alcanzar los umbrales requeridos. Con esto, podemos pasar al Paso Cinco y evaluar de forma completa el proceso SDC, consirando tanto la evaluación del riesgo como de la utilidad. 11.5 Paso Cinco: Evaluar proceso SDC 11.5.1 Re-medición del riesgo Primero, revisamos las medidas globales de riesgo. Se observa, valores mucho menores de riesgo global, aun cuando esto ya cumplía previamente con los niveles esperados. Bloque 11.65 Riesgo global print(sdcCombined, &quot;risk&quot;) ## Risk measures: ## ## Number of observations with higher risk than the main part of the data: ## in modified data: 0 ## in original data: 2471 ## Expected number of re-identifications: ## in modified data: 151.03 (0.32 %) ## in original data: 1683.54 (3.56 %) ## ## Information on hierarchical risk: ## Expected number of re-identifications: ## in modified data: 459.40 (0.97 %) ## in original data: 4524.60 (9.56 %) ## ---------------------------------------------------------------------- Ahora medimos el riesgo de manera individual. Se observa que el 19,3% de los casos presentan un riesgo superior al 1%, lo que cumple el umbral establecido, que indica el 20% de los casos. Por otro lado, se observa que hay 1.078 registros con riesgo individual superior al 5%, lo que equivale al 2,3% de los casos, lo que cumple con el umbral establecido (&lt;15%). Finalmente, no se observan casos con riesgo individual superior al 25%. Bloque 11.66 Riesgo individual # Observaciones con riesgo individual superior al 1%: nrow(fileCombined[sdcCombined@risk$individual[, &quot;risk&quot;] &gt; 0.01,]) ## [1] 3970 # Observaciones con riesgo individual superior al 5%: nrow(fileCombined[sdcCombined@risk$individual[, &quot;risk&quot;] &gt; 0.05,]) ## [1] 480 # Observaciones con riesgo individual superior al 25%: nrow(fileCombined[sdcCombined@risk$individual[, &quot;risk&quot;] &gt; 0.25,]) ## [1] 0 # Observaciones con riesgo individual superior al 50%: nrow(fileCombined[sdcCombined@risk$individual[, &quot;risk&quot;] &gt; 0.5,]) ## [1] 0 Revisamos el k-anonimato para los casos ponderados. Ahora, no hay casos que violen ningún nivel de k-anonimato, por lo que se cumpliría de buena forma lo planteado para estos umbrales. Bloque 11.67 K-anonimato # 2-anonimato kAnon_violations(sdcCombined, weighted = T, k = 2) ## [1] 0 ## attr(,&quot;k&quot;) ## [1] 2 ## attr(,&quot;weighted&quot;) ## [1] TRUE # 3-anonimato kAnon_violations(sdcCombined, weighted = T, k = 3) ## [1] 0 ## attr(,&quot;k&quot;) ## [1] 3 ## attr(,&quot;weighted&quot;) ## [1] TRUE # 5-anonimato kAnon_violations(sdcCombined, weighted = T, k = 5) ## [1] 0 ## attr(,&quot;k&quot;) ## [1] 5 ## attr(,&quot;weighted&quot;) ## [1] TRUE Luego medimos el l-diversity. Se observa que los valores de promedio y mediana de l-diversity son levemente superiores, lo que indican un menor nivel de riesgo de que el intruso logre acertar a los valores de las variables sensibles. Si bien estos no son valores ideales, se decide no proseguir con métodos SDC para no perder más utilidad de los datos. Bloque 11.68 L-diversity # Generamos el objeto de l-diversity med_riesgo &lt;- ldiversity(sdcCombined, ldiv_index = sensibles, l_recurs_c = 2, missing = NA) # revisamos las medidas de riesgo de l-diversity med_riesgo@risk$ldiversity ## -------------------------- ## L-Diversity Measures ## -------------------------- ## P17_Distinct_Ldiversity P24_Distinct_Ldiversity DEN_AGREG_Distinct_Ldiversity ## Min. : 1.000 Min. : 1.000 Min. : 1.000 ## 1st Qu.: 1.000 1st Qu.: 1.000 1st Qu.: 1.000 ## Median : 5.000 Median : 6.000 Median : 5.000 ## Mean : 9.127 Mean : 9.608 Mean : 9.429 ## 3rd Qu.:14.000 3rd Qu.:14.000 3rd Qu.:14.000 ## Max. :70.000 Max. :71.000 Max. :71.000 Los resultados aquí expuestos cumplen con los umbrales, por lo que ahora corresponde volver a medir la utilidad. 11.5.2 Evaluar proceso SDC - Volver a medir utilidad 11.5.2.1 Extracción de datos tratados y medición de perdida de información. Primero, extraemos la data tratada. Para ello se usa la función extractManipData(). Bloque 11.69 Extraer datos tratados fileTratada &lt;- extractManipData(sdcCombined) Luego evaluamos cuántos valores perdidos tenemos debido a la supresión local. Para ello, imprimimos el porcentaje de celdas perdidas pre y post anonimización. Primero vemos que, por flujo algunas variables tienen celdas vacías. La comparación consiste en ver si luego estos porcentajes aumentan. Bloque 11.70 Celdas vacías previo a anomización # % de celdas vacías pre-anonimización for(i in 1:length(names(fileCombined))){ print(names(fileCombined)[i]) print(sum(is.na(fileCombined[[names(fileCombined)[i]]]))/nrow(fileCombined)*100) } ## [1] &quot;enc_idr&quot; ## [1] 0 ## [1] &quot;rph_ID&quot; ## [1] 0 ## [1] &quot;enc_region&quot; ## [1] 0 ## [1] &quot;rph_edad&quot; ## [1] 0 ## [1] &quot;rph_sexo&quot; ## [1] 0 ## [1] &quot;rph_idgen&quot; ## [1] 14.81075 ## [1] &quot;rph_pertenencia_indigena&quot; ## [1] 0 ## [1] &quot;rph_nacionalidad&quot; ## [1] 0 ## [1] &quot;rph_situacion_ocupacional&quot; ## [1] 14.81075 ## [1] &quot;Fact_Ind&quot; ## [1] 0 ## [1] &quot;P17&quot; ## [1] 60.36245 ## [1] &quot;P24&quot; ## [1] 60.36245 ## [1] &quot;DEN_AGREG&quot; ## [1] 60.36245 ## [1] &quot;IH_residencia_habitual&quot; ## [1] 0 ## [1] &quot;Fact_Hog&quot; ## [1] 0 Acá vemos los porcentajes de valores perdidos en los datos tratados. Vemos que en las variables de identidad de género (rph_idgen), pertenencia indígena (rph_pertenencia_indigena) y nacionalidad (rph_nacionalidad), hay un leve aumento de celdas en blanco. Esto es muy marginal, siendo menos de 2% de celdas vacías adicionales en identidad de género y menos de 1% adicional de celdas vacías en las otras dos variables. Además, se observa que para el caso de situación ocupacional (rph_situacion_ocupacional), el algoritmo de supresión local no eliminó valores, dado que los umbrales ya se habían cumplido. Bloque 11.71 Celdas vacías después de anomización for(i in 1:length(names(fileTratada))){ print(names(fileTratada)[i]) print(sum(is.na(fileTratada[[names(fileTratada)[i]]]))/nrow(fileTratada)*100) } ## [1] &quot;enc_idr&quot; ## [1] 0 ## [1] &quot;rph_ID&quot; ## [1] 0 ## [1] &quot;enc_region&quot; ## [1] 0 ## [1] &quot;rph_edad&quot; ## [1] 0 ## [1] &quot;rph_sexo&quot; ## [1] 0 ## [1] &quot;rph_idgen&quot; ## [1] 15.40216 ## [1] &quot;rph_pertenencia_indigena&quot; ## [1] 0.2513518 ## [1] &quot;rph_nacionalidad&quot; ## [1] 0.084488 ## [1] &quot;rph_situacion_ocupacional&quot; ## [1] 14.83821 ## [1] &quot;Fact_Ind&quot; ## [1] 0 ## [1] &quot;P17&quot; ## [1] 60.36245 ## [1] &quot;P24&quot; ## [1] 60.36245 ## [1] &quot;DEN_AGREG&quot; ## [1] 60.36245 ## [1] &quot;IH_residencia_habitual&quot; ## [1] 0 ## [1] &quot;Fact_Hog&quot; ## [1] 0 En el resto de las variables, no hay pérdida de información. 11.5.2.2 Propiedades estadísticas priorizadas Ahora, se procede a evaluar si se mantienen las propiedades estadísticas priorizadas de los datos. Primero, se genera una variable de edad a partir de la marca de clase de los tramos etarios, para evaluar si se mantiene la relación con los indicadores principales. Esto no se evaluará inmediatamente, pero se genera para uso posterior. Es importante aclarar que esta recodificación se realiza solo con fines analíticos para determinar la utilidad de los datos anonimizados, no siendo utilizada para los datos a liberar (en estos se mantienen los tramos etarios). Bloque 11.72 Generar variable de marcas de clase de edad fileTratada$rph_edad_mc &lt;- dplyr::case_when( fileTratada$rph_edad == 1 ~ 7.5, fileTratada$rph_edad == 2 ~ 17, fileTratada$rph_edad == 3 ~ 22, fileTratada$rph_edad == 4 ~ 27, fileTratada$rph_edad == 5 ~ 34.5, fileTratada$rph_edad == 6 ~ 44.5, fileTratada$rph_edad == 7 ~ 54.5, fileTratada$rph_edad == 8 ~ 64.5, fileTratada$rph_edad == 9 ~ 74.5, fileTratada$rph_edad == 10 ~ 84.5, fileTratada$rph_edad == 11 ~ 90 ) fileTratada$rph_edad_mc &lt;- as.numeric(fileTratada$rph_edad_mc) table(fileTratada$rph_edad_mc) ## ## 7.5 17 22 27 34.5 44.5 54.5 64.5 74.5 84.5 90 ## 7012 2216 2228 2114 4324 4282 4274 4304 4397 4348 7845 Luego, se pegan las variables de diseño muestral e indicadores a evaluar, ya que no se encuentran dentro del conjunto de datos con que se trabajó durante el proceso de anonimización. Bloque 11.73 Añadir variables de diseño muestral fileTratada &lt;- dplyr::left_join(fileTratada, file[,c(&#39;rph_ID&#39;,&#39;Fact_Pers&#39;,&#39;Fact_Hog&#39;, &#39;Conglomerado&#39;,&#39;VarStrat&#39;, &#39;VA_DC&#39;,&#39;VP_DC&#39;,&#39;Kish&#39;)]) ## Joining with `by = join_by(rph_ID, Fact_Hog)` A continuación, se comparan los resultados de los datos originales con los tratados en lo que refiere al cálculo de indicadores principales con desagregaciones. Para ello, primero se establece el diseño complejo para personas y para hogares. Bloque 11.74 Declarar diseño complejo # generamos un conjunto de datos tratados donde solo tenemos las filas del informante Kish fileTratada_kish &lt;- fileTratada[fileTratada$Kish %in% 1,] # fijamos las opciones del diseño complejo options(survey.lonely.psu = &quot;certainty&quot;) # generamos el diseño complejo para el factor de expansión de personas dc_pers_trat &lt;- svydesign(ids = ~Conglomerado, strata = ~VarStrat, data = fileTratada_kish, weights = ~Fact_Pers) # generamos el diseño complejo para el factor de expansión de hogares dc_hog_trat &lt;- svydesign(ids = ~Conglomerado, strata = ~VarStrat, data = fileTratada_kish, weights = ~Fact_Hog) Previamente, calculamos estas desagregaciones con los datos no tratados. A continuación, se recalculan con los datos tratados y se comparan los resultados calculando la diferencia. Esta se visualiza a través de la función summary(). Victimización agregada de delitos consumados, desagregado por región: Bloque 11.75 Estimar Victimización Agregada a nivel regional, con estandar de calidad INE insumos_prop &lt;- create_prop(var = &#39;VA_DC&#39;, domains = &#39;enc_region&#39;, design = dc_hog_trat) VA_DC_REG_TRAT &lt;- assess(insumos_prop) summary(VA_DC_REG_PRE$objetivo - VA_DC_REG_TRAT$objetivo) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## Victimización personal de delitos consumados, desagregado por sexo: Bloque 11.76 Estimar Victimización Personal según sexo, con estandar de calidad INE insumos_prop &lt;- create_prop(var = &#39;VP_DC&#39;, domains = &#39;rph_sexo&#39;, design = dc_pers_trat) VP_DC_SEXO_TRAT &lt;- assess(insumos_prop) summary(VP_DC_SEXO_PRE$objetivo - VP_DC_SEXO_TRAT$objetivo) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## Victimización personal de delitos consumados, desagregado por región: Bloque 11.77 Estimar Victimización Personal a nivel regional, con estandar de calidad INE insumos_prop &lt;- create_prop(var = &#39;VP_DC&#39;, domains = &#39;enc_region&#39;, design = dc_pers_trat) VP_DC_REG_TRAT &lt;- assess(insumos_prop) summary(VP_DC_REG_PRE$objetivo - VP_DC_REG_TRAT$objetivo) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## Victimización personal de delitos consumados, desagregado por sexo y región: Bloque 11.78 Estimar Victimización Personal a nivel regional y según sexo, con estandar de calidad INE insumos_prop &lt;- create_prop(var = &#39;VP_DC&#39;, domains = &#39;rph_sexo+enc_region&#39;, design = dc_pers_trat) VP_DC_REG_SEXO_TRAT &lt;- assess(insumos_prop) summary(VP_DC_REG_SEXO_PRE$objetivo - VP_DC_REG_SEXO_TRAT$objetivo) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## En resumen, se cumple para todos los casos que no hay diferencias en las estimaciones al calcular con los datos originales y los tratados. Por último, se evalúa si se mantiene la relación entre la variable de edad y el indicador de Victimización Personal, utilizando las marcas de clase de los tramos etarios presentes en los datos tratados. Si bien, los modelos obtenidos no son buenos predictores de la victimización, ya que es un fenómeno influenciado por múltiples factores y acá solo se está considerando la edad, si se aprecia que los resultados son similares a los de los datos sin tratar. En particular el coeficiente beta de la variable de edad en el modelo logit de victimización personal es prácticamente el mismo que en los datos no tratados. Se genera un dataframe “data” para trabajar con el modelo Primero, se cargan los datos, y se filtran dejando solo al informante Kish. Bloque 11.79 Generar dataframe para modelo data &lt;- fileTratada_kish Dividir datos en training and testing sets Luego, se dividen los datos en sets de training y testing. Bloque 11.80 Dividir datos en training y testing sets library(caTools) set.seed(2022) ids_train &lt;- sample(data$rph_ID, nrow(data)/3*2) training&lt;- sjlabelled::remove_all_labels(data[data$rph_ID %in% ids_train,]) testing&lt;- sjlabelled::remove_all_labels(data[!data$rph_ID %in% ids_train,]) Construir modelo Luego, construimos el modelo utilizando la función glm(). Bloque 11.81 Construir modelo modelo&lt;-glm(VP_DC~rph_edad_mc, data=training, family = &quot;binomial&quot;) summary(modelo) ## ## Call: ## glm(formula = VP_DC ~ rph_edad_mc, family = &quot;binomial&quot;, data = training) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -0.7857 -0.7670 -0.7317 -0.7004 1.7468 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -1.3416201 0.0556848 -24.093 &lt; 2e-16 *** ## rph_edad_mc 0.0036047 0.0008517 4.232 2.31e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 13933 on 12509 degrees of freedom ## Residual deviance: 13915 on 12508 degrees of freedom ## AIC: 13919 ## ## Number of Fisher Scoring iterations: 4 Validación de modelo Luego aplicamos el test de Hosmer Lemeshow para validar el modelo. Bloque 11.82 Validación de modelo library(ResourceSelection) hoslem.test(modelo$y,fitted(modelo),g=10) # Test de Hosmer Lemeshow ## ## Hosmer and Lemeshow goodness of fit (GOF) test ## ## data: modelo$y, fitted(modelo) ## X-squared = 156.47, df = 6, p-value &lt; 2.2e-16 library(pROC) indiceC.trainig&lt;-roc(modelo$y,fitted(modelo)) # Curva ROC ## Setting levels: control = 0, case = 1 ## Setting direction: controls &lt; cases indiceC.trainig ## ## Call: ## roc.default(response = modelo$y, predictor = fitted(modelo)) ## ## Data: fitted(modelo) in 9444 controls (modelo$y 0) &lt; 3066 cases (modelo$y 1). ## Area under the curve: 0.5302 Punto de corte óptimo Se calcula el punto de corte óptimo utilizando la función coords(). Bloque 11.83 Calcular punto de corte óptimo ptocorteop.training&lt;-coords(indiceC.trainig,x=&quot;best&quot;, input=&quot;threshold&quot;, best.method=&quot;youden&quot;) ptocorteop.training ## threshold specificity sensitivity ## 1 0.2636494 0.8235917 0.2524462 library(ROCR) ROC.training&lt;-performance(prediction.obj = prediction(predictions = fitted(modelo), labels = as.factor(modelo$y)), &quot;tpr&quot;, &quot;fpr&quot;) Luego, visualizamos el punto de corte óptimo utilizando la función plot(). Bloque 11.84 Visualizar punto de corte óptimo plot(ROC.training, colorize=TRUE, print.cutoffs.at=seq(0.1, by=0.1)) abline(a=0,b=1) abline(v=ptocorteop.training$threshold,col=&quot;red&quot;) Figura 11.3: Punto de corte óptimo con datos tratados Predicciones y matriz de confusión Se realizan predicciones y se genera una matriz de confusión. Bloque 11.85 Predicciones y matriz de confusión pred.training&lt;-predict(modelo, data=training, type=&quot;response&quot;) table(ActualValue=training$VP_DC, PredictValue=pred.training&gt;ptocorteop.training$threshold) ## PredictValue ## ActualValue FALSE TRUE ## 0 7778 1666 ## 1 2292 774 A continuación, se continua la evaluación del modelo con datos de prueba. Validación de modelo (con datos de prueba) Aplicamos nuevamente la validación con el test de Hosmer Lemeshow, esta vez con los datos de prueba. Bloque 11.86 Validación de modelo con datos de prueba hoslem.test(testing$VP_DC,predict(modelo,newdata=testing,type=&quot;response&quot;),g=5) # Test de Hosmer Lemeshow ## ## Hosmer and Lemeshow goodness of fit (GOF) test ## ## data: testing$VP_DC, predict(modelo, newdata = testing, type = &quot;response&quot;) ## X-squared = 66.467, df = 3, p-value = 2.431e-14 indiceC.testing=roc(testing$VP_DC,predict(modelo,newdata=testing,type=&quot;response&quot;)) # Curva ROC ## Setting levels: control = 0, case = 1 ## Setting direction: controls &lt; cases indiceC.testing ## ## Call: ## roc.default(response = testing$VP_DC, predictor = predict(modelo, newdata = testing, type = &quot;response&quot;)) ## ## Data: predict(modelo, newdata = testing, type = &quot;response&quot;) in 4666 controls (testing$VP_DC 0) &lt; 1590 cases (testing$VP_DC 1). ## Area under the curve: 0.5243 Punto de corte óptimo (con datos de prueba) Se calcula el punto de corte óptimo utilizando la función coords(). Bloque 11.87 Calcular de corte óptimo con datos de prueba ptocorteop.testing&lt;-coords(indiceC.testing,x=&quot;best&quot;,input=&quot;threshold&quot;,best.method=&quot;youden&quot;) ptocorteop.testing ## threshold specificity sensitivity ## 1 0.2636494 0.8317617 0.2440252 ROC.testing&lt;-performance(prediction(predict(modelo,newdata=testing,type=&quot;response&quot;), as.factor(testing$VP_DC)),&quot;tpr&quot;,&quot;fpr&quot;) Luego, visualizamos el punto de corte óptimo utilizando la función plot(). Bloque 11.88 Visualizar de corte óptimo con datos de prueba plot(ROC.testing, colorize=TRUE, print.cutoffs.at=seq(0.1, by=0.1)) abline(a=0,b=1) abline(v=ptocorteop.testing$threshold,col=&quot;red&quot;) Figura 11.4: Punto de corte óptimo con datos de prueba a partir de datos tratados Predicciones y matriz de confusión (con datos de prueba) Se realizan predicciones y se genera una matriz de confusión. Bloque 11.89 Predicciones y matriz de confusión con datos de prueba pred.testing&lt;-predict(modelo, testing, type=&quot;response&quot;) table(ActualValue=testing$VP_DC, PredictValue=pred.testing&gt;ptocorteop.testing$threshold) ## PredictValue ## ActualValue FALSE TRUE ## 0 3881 785 ## 1 1202 388 Compara área bajo la curva, umbral, sensibilidad y especificidad Finalmente, comparamos el área bajo la curva, umbral, sensibilidad y especificidad, a partir de los resultados del modelo con los datos de entrenamiento y con los datos de prueba. Bloque 11.90 Comparar área bajo la curva, umbral, sensibilidad y especificidad auc &lt;-indiceC.trainig$auc - indiceC.testing$auc corte &lt;-ptocorteop.training$threshold - ptocorteop.testing$threshold sens &lt;- ptocorteop.training$sensitivity - ptocorteop.testing$sensitivity spe &lt;- ptocorteop.training$specificity - ptocorteop.testing$specificity La siguiente tabla muestra las estimaciones del coeficiente beta de la variable independiente de edad en los modelos, para los datos originales y los datos tratados. Se observa que ambas estimaciones son equivalentes, sin diferencias estadísticamente significativas a partir de su intervalo de confianza: Datos Estimación Lim. Inf. Lim. Sup. Originales 0,0035 0,0020 0,0050 Tratados 0,0036 0,0019 0,0053 En suma, se observa que se mantienen las propiedades estadísticas priorizadas de la base de datos, por lo que cumple con las condiciones para su liberación. 11.6 Paso Seis: Generar Reportes y Liberar Datos 11.6.1 Reportes Al realizar un ejercicio de anonimización como el recién expuesto, se debe elaborar un reporte que documente el proceso de anonimización, con sus antecedentes y resultados. Para ello, debe basarse en el modelo de reporte de anonimización descrito en la guía de anonimización. 11.6.2 Liberación de datos A partir del objeto file, que son los datos originales, se genera un objeto data.frame para su exportación como archivo de datos que será liberado. Primero se verifica que el orden de registros sea idéntico entra datos originales y tratados. Esto permite sobre-escribir columnas completas, sabiendo que los registros coincidirán bien. En este caso, es importante usar el folio que corresponde a persona, ya que cada fila es una persona (en contraposición al folio de viviendas que cubre varias filas dependiendo de las personas que las componen). Bloque 11.91 Verificar coincidencia de folios # Se espera que esta función regrese TRUE all(file$rph_ID == fileTratada$rph_ID) ## [1] TRUE Luego, se reemplazan variables tratadas en datos originales y se eliminan las variables que están de más. Estas son, comuna y razón de inactividad, ya que esta última permitiría deshacer la recodificación que se realizó en la variable consolidada de situación ocupacional. Bloque 11.92 Eliminar variables file$enc_rpc &lt;- NULL file$rph_p14 &lt;- NULL Luego, se reemplazan variables tratadas de edad, identidad de género, pertenencia indígena y nacionalidad. Bloque 11.93 Reemplazar variables originales por variables tratadas file$rph_edad &lt;- fileTratada$rph_edad file$rph_idgen &lt;- fileTratada$rph_idgen file$rph_pertenencia_indigena &lt;- fileTratada$rph_pertenencia_indigena file$rph_nacionalidad &lt;- fileTratada$rph_nacionalidad Se eliminan los valores de rph_p9 a rph_p13 para los casos suprimidos en situación ocupacional Bloque 11.94 Suprimir valores # se eliminan los valores que corresponden file$rph_p9[is.na(fileTratada$rph_situacion_ocupacional)] &lt;- NA file$rph_p10[is.na(fileTratada$rph_situacion_ocupacional)] &lt;- NA file$rph_p11[is.na(fileTratada$rph_situacion_ocupacional)] &lt;- NA file$rph_p12[is.na(fileTratada$rph_situacion_ocupacional)] &lt;- NA file$rph_p13[is.na(fileTratada$rph_situacion_ocupacional)] &lt;- NA # Luego eliminamos situación ocupacional ya que no se usará más file$rph_situacion_ocupacional &lt;- NULL Luego, se elimina los valores de rph_migración que son acompañados de un NA en nacionalidad, ya que sería un error de flujo de la encuesta mantenerlos. Bloque 11.95 Suprimir valores en nacionalidad file$rph_migracion[is.na(file$rph_nacionalidad)] &lt;- NA Por último, se exporta archivo de datos ocupando la librería haven. Bloque 11.96 Ejemplo de código para exportar datos anonimizados #haven::write_sav(file, &#39;ENUSC2020_anonimizada.sav&#39;) 11.6.3 Anexo : Tablas de indicadores con desagregaciones Se deja como anexo los tabulados con datos tratados y no tratados por si se considera necesario compararlos de forma manual. Bloque 11.97 Ejemplo de código para exportar datos de indicadores con datos tratados y no tratados #anexo &lt;- list(&#39;P1 Regional Original&#39; = P1_REG_PRE, # &#39;P1 Regional Tratado&#39; = P1_REG_TRAT, # &#39;P1 Sexo Original&#39; = P1_SEXO_PRE, # &#39;P1 Sexo Tratado&#39; = P1_SEXO_TRAT, # &#39;P1 Regional Sexo Original&#39; = P1_REG_SEXO_PRE, # &#39;P1 Regional Sexo Tratado&#39; = P1_REG_SEXO_TRAT, # &#39;Vict. Pers. Regional Original&#39; = VP_DC_REG_PRE, # &#39;Vict. Pers. Regional Tratado&#39; = VP_DC_REG_TRAT, # &#39;Vict. Pers. Sexo Original&#39; = VP_DC_SEXO_PRE, # &#39;Vict. Pers. Sexo Tratado&#39; = VP_DC_SEXO_TRAT, # &#39;Vict. Pers. Regional Sexo Original&#39; = VP_DC_REG_SEXO_PRE, # &#39;Vict. Pers. Regional Sexo Tratado&#39; = VP_DC_REG_SEXO_TRAT, # &#39;Vict. Agr. Regional Original&#39; = VA_DC_REG_PRE, # &#39;Vict. Agr. Regional Tratado&#39; = VA_DC_REG_TRAT) # #openxlsx::write.xlsx(anexo, &quot;Anexo_Medicion_Utilidad.xlsx&quot;) Referencias "],["taller-sdc-video.html", "Capítulo 12 Taller SDC Video", " Capítulo 12 Taller SDC Video El Instituto Nacional de Estadísticas (INE) realizó el 14 de abril de 2021 el “Taller sobre proceso de control a la divulgación estadística en microdatos, INE 2021”. El objetivo principal del taller fue revisar aspectos teóricos y prácticos del control a la divulgación estadística en microdatos (SDC, por su sigla en inglés), abordando motivaciones técnicas para su aplicación, sus etapas, beneficios y áreas de atención, entre otros puntos claves. El taller fue liderado por el analista estadístico Julio Guerrero Rojas y el analista socioeconómico Nicolás Berho Montalvo, del DMIE y la Subdirección Técnica (SDT), respectivamente. En la primera parte del taller, los expositores presentaron una introducción al SDC, destacando su importancia para garantizar la confidencialidad y privacidad de los datos personales en la difusión de microdatos. En la segunda parte, los expositores abordaron las motivaciones técnicas para la aplicación del SDC, así como sus etapas, beneficios y áreas de atención. En la tercera parte, los asistentes tuvieron la oportunidad de realizar preguntas y comentarios. Dejamos en video de la experiencia: "],["referencias-1.html", "Referencias", " Referencias "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
