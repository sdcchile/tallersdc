\PassOptionsToPackage{unicode=true}{hyperref} % options for packages loaded elsewhere
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames*,x11names*}{xcolor}
%
\documentclass[]{book}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provides euro and other symbols
\else % if luatex or xelatex
  \usepackage{unicode-math}
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage[]{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\usepackage{xcolor}
\usepackage{hyperref}
\hypersetup{
            pdftitle={Gu√≠a para el Control de Divulgaci√≥n Estad√≠stica en Microdatos},
            pdfauthor={Subdepartamento de Investigaci√≥n Estad√≠stica},
            colorlinks=true,
            linkcolor=Maroon,
            filecolor=Maroon,
            citecolor=Blue,
            urlcolor=blue,
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs}
% Fix footnotes in tables (requires footnote package)
\IfFileExists{footnote.sty}{\usepackage{footnote}\makesavenoteenv{longtable}}{}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

% set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\usepackage{booktabs}
\usepackage{amsthm}
\makeatletter
\def\thm@space@setup{%
  \thm@preskip=8pt plus 2pt minus 4pt
  \thm@postskip=\thm@preskip
}
\makeatother
\usepackage{float}
\floatplacement{figure}{H}
\renewcommand{\figurename}{Figura}
\renewcommand{\tablename}{Tabla}
\renewcommand{\contentsname}{√çndice}
\renewcommand{\chaptername}{Cap√≠tulo}
\renewcommand{\bibname}{Bibliograf√≠a}

% https://tex.stackexchange.com/questions/82993/how-to-change-the-name-of-document-elements-like-figure-contents-bibliogr
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
\usepackage[]{natbib}
\bibliographystyle{plainnat}

\title{Gu√≠a para el Control de Divulgaci√≥n Estad√≠stica en Microdatos}
\author{Subdepartamento de Investigaci√≥n Estad√≠stica}
\date{2023-09-07}

\usepackage{amsthm}
\newtheorem{theorem}{Teorema}[chapter]
\newtheorem{lemma}{Lema}[chapter]
\newtheorem{corollary}{Corolario}[chapter]
\newtheorem{proposition}{Proposici√≥n}[chapter]
\newtheorem{conjecture}{Conjetura}[chapter]
\theoremstyle{definition}
\newtheorem{definition}{Definici√≥n}[chapter]
\theoremstyle{definition}
\newtheorem{example}{Bloque}[chapter]
\theoremstyle{definition}
\newtheorem{exercise}{Ejercicio}[chapter]
\theoremstyle{definition}
\newtheorem{hypothesis}{Hipotesis}[chapter]
\theoremstyle{remark}
\newtheorem*{remark}{Remarca}
\newtheorem*{solution}{Soluci√≥n}
\begin{document}
\maketitle

{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{prefacio}{%
\chapter{Prefacio}\label{prefacio}}

Los datos son un recurso valioso que proporciona informaci√≥n cr√≠tica para estad√≠sticos, cient√≠ficos sociales y cient√≠ficos de datos. Estos datos se utilizan para generar perspectivas detalladas y oportunas que responden a las necesidades de informaci√≥n de una amplia gama de partes interesadas.

En un mundo donde cada vez m√°s grandes vol√∫menes de datos provienen de un n√∫mero creciente de proveedores, las Oficinas Nacionales de Estad√≠stica (ONE) est√°n utilizando enfoques innovadores para mantener est√°ndares y definiciones de datos, sistemas de gesti√≥n de privacidad y confidencialidad, e intercambio responsable de datos.

Las ONE tienen un papel de liderazgo que desempe√±ar en el establecimiento de formas seguras y transparentes de compartir datos, experiencias y mejores pr√°cticas para respaldar el uso de datos con fines de prueba, evaluaci√≥n, educaci√≥n y desarrollo. Con la integridad y la confidencialidad de los datos a la vanguardia, las ONE est√°n posicionandose cada vez m√°s para proporcionar herramientas, m√©todos y enfoques para promover el intercambio responsable de datos, a fin de satisfacer las necesidades de un n√∫mero creciente de partes interesadas en este √°mbito que est√° en constante cambio.

Las ONE reconocen que se debe cumplir con el llamado a una mayor apertura y transparencia de los datos. Sin embargo, tambi√©n se comprometen a proteger la confidencialidad y la privacidad integradas en sus tenencias de datos.

Se reconoce ampliamente que la difusi√≥n de informaci√≥n que es a la vez √∫til y completamente segura, no puede lograrse en su totalidad. Por lo tanto, la seguridad es un concepto relativo, no absoluto, y se debe entender como una m√©trica, no un estado.

Es dentro de este contexto que las ONE deben establecer protocolos para la difusi√≥n segura de datos y m√©tricas para medir la utilidad de la informaci√≥n estad√≠stica publicada y el grado de protecci√≥n de las unidades, ya sean personas naturales o jur√≠dicas, e informaci√≥n recopilada de la cual se deriva.

Esta gu√≠a es para aquellos que trabajan en una ONE u oficina estatal que est√°n involucrados en la gesti√≥n del acceso a datos estad√≠sticos, y que deseen explorar herramientas de protecci√≥n de datos para que los usuarios accedan a ellos. La gu√≠a destaca algunas aplicaciones exitosas recientes de control a la divulgaci√≥n estad√≠stica en microdatos en el Instituto Nacional de Estad√≠sticas de Chile (INE), y presenta un marco general sobre medici√≥n y evaluaci√≥n de riesgos, t√©cnicas para generar datos anonimizados, y sobre las medidas de utilidad que se pueden usar para evaluar qu√© tan bien los datos anonimizados satisfacen las necesidades anal√≠ticas de los usuarios. La gu√≠a tambi√©n incluye recomendaciones sobre qu√© enfoques utilizar en diferentes situaciones, as√≠ como consejos pr√°cticos y recursos para que los profesionales comiencen su experiencia en la implementaci√≥n de proceso de control a la divulgaci√≥n estad√≠stica.

Esta gu√≠a se basa en Statistical Disclosure Control: A Practice Guide (Benschop, Machingauta, y Welch, 2021) y en la \href{https://www.ine.gob.cl/docs/default-source/buenas-practicas/directrices-metodologicas/guias-y-orientaciones-metodologicas/documentos/gu\%C3\%ADa-control-divulgaci\%C3\%B3n-estad\%C3\%ADstica-microdatos.pdf?sfvrsn=b6bdd28f_2}{Gu√≠a para el control de divulgaci√≥n estad√≠stica en microdatos}, elaborada por el INE en 2021, que es el primer esfuerzo en esta materia en instituciones del Estado en Chile. Sin embargo, a√∫n puede enriquecerse a partir de nuevos conocimientos y experiencias que tanto investigadores como profesionales puedan aportar.

¬°Esperamos que esta gu√≠a lo ayude en su viaje hacia la implementaci√≥n de procesos de control a la divulgaci√≥n estad√≠stica en su organizaci√≥n!

\hypertarget{autores-de-esta-guuxeda}{%
\section{Autores de esta gu√≠a}\label{autores-de-esta-guuxeda}}

Jonathan Gonz√°lez Mej√≠as, Subdepartamento de Estad√≠sticas Socioecon√≥micas, Subdirecci√≥n T√©cnica en Instituto Nacional de Estad√≠sticas de Chile.

Jos√© Bustos Melo, Subdepartamento de Investigaci√≥n Estad√≠stica, Departamento de Metodolog√≠as e Innovaci√≥n Estad√≠stica en Instituto Nacional de Estad√≠sticas de Chile.

Julio Guerrero Rojas, Subdepartamento de Investigaci√≥n Estad√≠stica, Departamento de Metodolog√≠as e Innovaci√≥n Estad√≠stica en Instituto Nacional de Estad√≠sticas de Chile.

Lissette Bast√≠as Navarro, Subdepartamento de Calidad y Est√°ndares, Departamento de Metodolog√≠as e Innovaci√≥n Estad√≠stica en Instituto Nacional de Estad√≠sticas de Chile.

Nicol√°s Berh√≥ Montalvo, Subdepartamento de Estad√≠sticas de Condiciones de Vida, Subdirecci√≥n T√©cnica en Instituto Nacional de Estad√≠sticas de Chile.

\hypertarget{reconocimientos}{%
\section{Reconocimientos}\label{reconocimientos}}

Aqu√≠ escribir si se quiere agradecer o reconocer la colaboraci√≥n de alguna persona o equipo.

\hypertarget{introducciuxf3n}{%
\chapter{Introducci√≥n}\label{introducciuxf3n}}

Como Instituto Nacional de Estad√≠stica (en adelante, INE) tenemos la responsabilidad de la recopilaci√≥n y difusi√≥n de estad√≠sticas oficiales, tomando resguardos para cumplir con la Ley de Secreto Estad√≠stico (Art.29, Ley 17.374 \citep{ley1970}), la Ley sobre Protecci√≥n de la Vida Privada (Art.2e, Ley 19.628 \citep{ley1999}) y la legislaci√≥n propia de las entidades p√∫blicas, todas en la l√≠nea de la protecci√≥n y privacidad de la informaci√≥n difundida. Por otro lado, a nivel pa√≠s, en los √∫ltimos a√±os, ha existido un aumento constante en transparentar y disponer informaci√≥n tanto a nivel privado como p√∫blico, mediante la ``ley de transparencia'' (Ley 20.285 \citep{ley2008}), promulgada en a√±o 2008.

Es en esta misma l√≠nea que las Naciones Unidas tambi√©n abogan por la libre difusi√≥n de los microdatos. Lo que permite a los usuarios contribuir con investigaci√≥n, aumenta la transparencia y la responsabilidad de los institutos nacionales de estad√≠stica y permite mejoras en la calidad a trav√©s de la retroalimentaci√≥n de los usuarios \citep{nacionesunidas}.

En paralelo la comunidad estad√≠stica ha reconocido la importancia de asegurar la informaci√≥n para mantener la confianza de las poblaciones a las que servimos. En este sentido, el C√≥digo Nacional de Buenas Pr√°cticas Estad√≠sticas del INE, en su principio 4 sobre confidencialidad estad√≠stica, establece que el ``INE y los dem√°s miembros del Sistema Estad√≠stico Nacional (SEN) deben garantizar la protecci√≥n y confidencialidad de la informaci√≥n con la que se producen las estad√≠sticas oficiales, as√≠ como evitar la identificaci√≥n de las fuentes'' \citep{institutonacionaldeestadisticas2015}.

Los principios en competencia de la seguridad de los datos y la difusi√≥n de microdatos se someten a arbitraje a trav√©s de un dominio de estad√≠sticas llamado Control de Divulgaci√≥n Estad√≠stica (SDC, por su sigla en ingl√©s). Los m√©todos SDC permiten proteger un conjunto de datos mediante la aplicaci√≥n de herramientas estad√≠sticas, lo que posibilita a la instituci√≥n difundir de manera segura el conjunto de datos.

La experiencia del INE en t√©rminos de control de divulgaci√≥n estad√≠stica ha ido avanzando, iniciando en junio del a√±o 2009, bajo la Resoluci√≥n exenta N¬∞ 1918, emitida en Santiago el 10 de junio de 2009, expone acerca de una experiencia localizada, sobre el tratamiento que se buscaba dar a datos econ√≥micos, luego en 2019, un equipo multidisciplinario de la producci√≥n estad√≠stica institucional, define los lineamientos para desarrollar un proceso estandarizado de control de divulgaci√≥n en las operaciones estad√≠sticas que desarrolla el INE, entregando como resultado una primera versi√≥n de la ``Gu√≠a para el control de divulgaci√≥n estad√≠stica en microdatos''. En diciembre del 2021 se transforma en un est√°ndar institucional disponible en la p√°gina web institucional \url{https://www.ine.gob.cl/calidad-estadistica/directrices-metodologicas} \citep{institutonacionaldeestadisticas2021}.

Este documento exige normar el subproceso de control a la divulgaci√≥n estad√≠stica o anonimizaci√≥n, a fin de responder de manera adecuada, oportuna y segura a los usuarios que requieren informaci√≥n de inter√©s y que solicitan las bases de microdatos, al mismo tiempo de tener procedimientos estandarizados en la producci√≥n de estad√≠sticas oficiales.

Esta gu√≠a busca brindar pasos pr√°cticos bajo lineamientos institucionales para aquellas operaciones estad√≠sticas que requieran desbloquear el acceso a sus datos de manera segura y garantizar que los datos sigan siendo aptos para su prop√≥sito.

\hypertarget{estableciendo-una-base-de-conocimiento}{%
\section{Estableciendo una base de conocimiento}\label{estableciendo-una-base-de-conocimiento}}

La publicaci√≥n de datos es importante, ya que permite a los investigadores y responsables pol√≠ticos replicar los resultados publicados oficialmente, generar nuevos conocimientos sobre los problemas, evitar la duplicaci√≥n de encuestas y proporcionar mayores retornos a la inversi√≥n en el proceso de encuesta.

Tanto la producci√≥n de informes, con tablas agregadas de indicadores y estad√≠sticas, como la publicaci√≥n de microdatos resultan en desaf√≠os de privacidad para el productor. En el pasado, para muchas ONE, el √∫nico requisito era publicar un informe y algunos indicadores clave. El reciente movimiento en torno a los datos abiertos, el gobierno abierto y la transparencia significa que las ONE est√°n bajo una mayor presi√≥n para liberar sus microdatos, para permitir un uso m√°s amplio de los datos recopilados a trav√©s de fondos p√∫blicos. Esta gu√≠a se centra en los m√©todos y procesos para la liberaci√≥n de microdatos, ya sea que estos provengan de encuestas, censos o registros estad√≠sticos generados por el INE. Por tanto, el alcance de los procesos que se describen en esta gu√≠a se ci√±e a proveer directriz circunscrita al campo de los microdatos, por lo que se excluyen los procesos de control de divulgaci√≥n estad√≠stica orientados a tabulados, estad√≠sticas geoespaciales, publicaciones web o visualizaciones de mapas, etc., que requieren enfoques diferentes al propuesto en esta gu√≠a. Asimismo, se distingue la necesidad de establecer lineamientos para el control de divulgaci√≥n estad√≠stica en la publicaci√≥n de tablas y publicaciones web, con el fin de cubrir m√°s √°mbitos de la producci√≥n estad√≠stica del INE.

Se requiere la difusi√≥n de datos de manera segura para proteger la integridad del sistema estad√≠stico, al garantizar que el INE cumpla con su compromiso con los encuestados de proteger su identidad. Las ONE no comparten ampliamente, en detalle sustancial, su conocimiento y experiencia usando SDC y los procesos para crear datos seguros con otras ONE. Esto lo hace dif√≠cil para las instituciones nuevas en el proceso para implementar soluciones. Para llenar esta brecha de experiencia y conocimiento, el equipo de la mesa de trabajo INE (en adelante mesa) evalu√≥ el uso de un amplio conjunto de m√©todos de SDC en una gama de microdatos de encuestas que cubren importantes temas de desarrollo relacionados con trabajo, seguridad ciudadana, empresas de ferrocarriles, tr√°mites de circulaci√≥n. Dado que sus productores ya hab√≠an tratado estos datos, no era posible, ni era objetivo de la mesa, emitir un juicio sobre la seguridad de estos datos, los cuales son de dominio p√∫blico. El enfoque se centr√≥ m√°s bien en medir los efectos que varios de los m√©todos tendr√≠an que ver con la relaci√≥n riesgo -- utilidad para los microdatos producidos para medir indicadores comunes de desarrollo. La experiencia de esta experimentaci√≥n es √∫til para informar la discusi√≥n de los procesos y m√©todos en esta gu√≠a.

\hypertarget{propuxf3sito-de-esta-guuxeda}{%
\section{Prop√≥sito de esta gu√≠a}\label{propuxf3sito-de-esta-guuxeda}}

Esta gu√≠a tiene como prop√≥sito presentar los lineamientos para la aplicaci√≥n del control de divulgaci√≥n estad√≠stica en microdatos derivados de censos, registros estad√≠sticos y encuestas por muestreo desarrollados por el INE, permitiendo establecer qu√© microdatos pueden ser liberados y bajo qu√© condiciones.

Esta gu√≠a no pretende prescribir o abogar por cambios en los m√©todos que los productores de datos espec√≠ficos ya est√°n utilizando y que han dise√±ado para ajustarse y cumplir con sus pol√≠ticas de difusi√≥n de datos existentes, empero, ordenarlos. Los m√©todos discutidos en esta gu√≠a provienen de una gran cantidad de literatura sobre SDC. Los procesos que subyacen a muchos de los m√©todos son objeto de una extensa investigaci√≥n acad√©mica y muchos, si no todos, son utilizados ampliamente por ONE con experiencia en la preparaci√≥n de microdatos para su publicaci√≥n.

Siempre que sea posible, para cada m√©todo y tema, se proporciona ejemplos elaborados, referencias al trabajo original o seminal que describe los m√©todos y algoritmos en detalle y las lecturas recomendadas. Esto, cuando se combina con la discusi√≥n del m√©todo y las consideraciones pr√°cticas en esta gu√≠a, deber√≠a permitir al lector comprender los m√©todos y sus fortalezas y debilidades. Tambi√©n proporciona suficientes detalles para que los lectores usen una soluci√≥n de \emph{software} adecuada para implementar los m√©todos.

Para los ejercicios de esta gu√≠a, se ha utilizado el paquete de c√≥digo abierto y gratuito para SDC llamado \texttt{sdcMicro}, as√≠ como el lenguaje y entorno de programaci√≥n estad√≠stico \texttt{R}. \texttt{sdcMicro} es un paquete adicional para el lenguaje \texttt{R}. El paquete fue desarrollado y es mantenido por Matthias Templ, Alexander Kowarik y Bernhard Meindl\protect\hyperlink{_ftn1}{{[}1{]}}. El lenguaje estad√≠stico \texttt{R} y el paquete \texttt{sdcMicro}, as√≠ como cualquier otro paquete necesario para el proceso SDC, est√°n disponibles gratuitamente en los \texttt{mirrors} de la Red Integral de Archivos \texttt{R} (CRAN\protect\hyperlink{_ftn2}{{[}2{]}}) (\url{http://cran.r-project.org}/). El lenguaje est√° disponible para los sistemas operativos Linux, Windows y Macintosh. Se ha elegido usar \texttt{R} y \texttt{sdcMicro} porque est√° disponible gratuitamente, admite todos los formatos de datos principales y es f√°cil de adaptar por el usuario. El Banco Mundial, a trav√©s de IHSN\protect\hyperlink{_ftn3}{{[}3{]}}, tambi√©n ha proporcionado fondos para el desarrollo del paquete \texttt{sdcMicro} para garantizar que cumpla con los requisitos de las ONE.

Esta gu√≠a no proporciona una revisi√≥n de todos los dem√°s paquetes disponibles para implementar el proceso SDC, pues se trata m√°s de proporcionar informaci√≥n pr√°ctica sobre la aplicaci√≥n de los m√©todos. Sin embargo, cabe destacar otro paquete de \emph{software} en particular que las ONE utilizan com√∫nmente: \texttt{ùúá-ARGUS}\protect\hyperlink{_ftn4}{{[}4{]}}. \texttt{ùúá-ARGUS} es desarrollado por Statistics Netherlands. \texttt{sdcMicro} y \texttt{ùúá-ARGUS} son ampliamente utilizados en oficinas de estad√≠stica en la Uni√≥n Europea e implementan muchos de los mismos m√©todos.

Las necesidades de usuario acerca de alg√∫n conocimiento de \texttt{R} para usar \texttt{sdcMicro} est√° m√°s all√° del alcance de esta gu√≠a, as√≠ como ense√±ar el uso de \texttt{R}, pero se presenta una serie de estudios de casos que incluyen el c√≥digo para el anonimato de una serie de conjuntos de datos de demostraci√≥n con \texttt{R}. A trav√©s de estos estudios de caso, se demuestra una serie de enfoques para el proceso de anonimizaci√≥n en \texttt{R}.

\hypertarget{esquema-de-esta-guuxeda}{%
\section{Esquema de esta gu√≠a}\label{esquema-de-esta-guuxeda}}

Esta gu√≠a est√° dividida en las siguientes secciones principales:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Introducci√≥n a sdcMicro}: donde se visualiza la necesidad de aplicar los m√©todos SDC y el trade off que se produce entre el riesgo versus la utilidad.
\item
  \textbf{Tipos de liberaci√≥n de datos}: en este apartado encontrar√°n los tres tipos de m√©todos de divulgaci√≥n, archivos de uso p√∫blico (PUF, por sus siglas en ingl√©s), archivos de uso cient√≠fico (SUF, por sus siglas en ingl√©s) y microdatos disponibles en un centro de datos de investigaci√≥n controlado.
\item
  \textbf{Medici√≥n de riesgos}: las medidas de riesgo que se utilizan y la determinaci√≥n si un archivo de datos es lo suficientemente seguro para su divulgaci√≥n.
\item
  \textbf{M√©todos SDC}: una descripci√≥n de los m√©todos m√°s utilizados para anonimizar.
\item
  \textbf{Medici√≥n de utilidad y p√©rdida de informaci√≥n}: en este apartado se profundiza acerca del trade off entre la medici√≥n de la utilidad y la p√©rdida de informaci√≥n.
\item
  \textbf{Procesos SDC INE 2021}: caso pr√°ctico implementado en el INE en la mesa de anonimizaci√≥n institucional.
\item
  \textbf{Caso de estudio: Enusc}: caso pr√°ctico para aplicar el m√©todo SDC en la Encuesta Nacional Urbana de Seguridad Ciudadana (ENUSC) con datos sint√©ticos.
\end{enumerate}

\protect\hyperlink{_ftnref1}{{[}1{]}} Matthias Templ, Alexander Kowarik, Bernhard Meindl (2015). Statistical Disclosure Control for Micro-Data Using the R Package sdcMicro. Journal of Statistical Software 67 (October): 1--36. \url{https://doi.org/10.18637/jss.v067.i04.}

\protect\hyperlink{_ftnref2}{{[}2{]}} En ingl√©s, Comprehensive R Archive Network.

\protect\hyperlink{_ftnref3}{{[}3{]}} En ingl√©s, International Household Survey Network.

\protect\hyperlink{_ftnref4}{{[}4{]}} \(\mu\)- ARGUS est√° disponible en: \url{https://research.cbs.nl/casc/mu.htm}

\hypertarget{acruxf3nimos-y-glosario}{%
\chapter{Acr√≥nimos y glosario}\label{acruxf3nimos-y-glosario}}

\hypertarget{acruxf3nimos}{%
\section{Acr√≥nimos}\label{acruxf3nimos}}

\begin{table}

\caption{\label{tab:tabAcron1}Lista de acr√≥nimos}
\centering
\begin{tabular}[t]{l|l}
\hline
Acr√≥nimo & Descripci√≥n\\
\hline
AEPD & Agencia Espa√±ola de Protecci√≥n de Datos\\
\hline
Bloque & Trozo de c√≥digo en R que permite cargar y procesar datos, realizar los an√°lisis estad√≠sticos e imprimir los resultados\\
\hline
CEPAL & Comisi√≥n Econ√≥mica para Am√©rica Latina y el Caribe\\
\hline
DANE & Departamento Administrativo Nacional de Estad√≠stica\\
\hline
ENUSC & Encuesta Nacional Urbana de Seguridad Ciudadana\\
\hline
FCYTE & Fundaci√≥n Espa√±ola de Ciencia y Tecnolog√≠a\\
\hline
GSBPM [1] & Modelo Gen√©rico del Proceso Estad√≠stico\\
\hline
IHSN [2] & Red Internacional de Encuestas de Hogares\\
\hline
INE & Instituto Nacional de Estad√≠sticas\\
\hline
INEGI & Instituto Nacional de Estad√≠stica y Geograf√≠a\\
\hline
MINSEGPRES & Ministerio Secretar√≠a General de la Presidencia\\
\hline
OCDE & Organizaci√≥n para la Cooperaci√≥n y el Desarrollo Econ√≥micos\\
\hline
ONE & Oficina Nacional de Estad√≠stica\\
\hline
PITEC & Panel de Innovaci√≥n tecnol√≥gica\\
\hline
PRAM [3] & M√©todo de Post-Aleatorizaci√≥n\\
\hline
PUF [4] & Archivo de Uso P√∫blico\\
\hline
RUT & Rol √önico Tributario\\
\hline
ROL & Identifica a una propiedad o bien ra√≠z\\
\hline
SEN & Sistema Estad√≠stico Nacional\\
\hline
SDC [5] & Control de Divulgaci√≥n Estad√≠stica\\
\hline
sdcMicro & Paquete de implementaci√≥n bajo el *software* R\\
\hline
STATCAN [6] & Estad√≠sticas de Canad√°\\
\hline
SUF [7] & Archivo de Uso Cient√≠fico\\
\hline
UNECE [8] & Comisi√≥n Econ√≥mica de las Naciones Unidas para Europa\\
\hline
\end{tabular}
\end{table}

{[}1{]} En ingl√©s, \emph{Generic Statistical Business Process Model}.\\
{[}2{]} En ingl√©s, \emph{International Household Survey Network}.\\
{[}3{]} En ingl√©s, \emph{Post Randomization Method}.\\
{[}4{]} En ingl√©s, \emph{Public Use File}.\\
{[}5{]} En ingl√©s, \emph{Statistical Disclosure Control}.\\
{[}6{]} En ingl√©s, \emph{Statistics Canada}.\\
{[}7{]} En ingl√©s, \emph{Scientific Use File}.\\
{[}8{]} En ingl√©s, \emph{United Nations Economic Commission for Europe}.

\hypertarget{glosario}{%
\section{Glosario}\label{glosario}}

Respecto a los t√©rminos, conceptos o categor√≠as utilizadas en esta gu√≠a se detallan aquellos que son relevantes para la comprensi√≥n del subproceso.

\begin{table}

\caption{\label{tab:unnamed-chunk-1}Glosario de t√©rminos y conceptos}
\begin{tabu} to \linewidth {>{\raggedright}X>{\raggedright}X>{\raggedright}X}
\hline
T√©rmino & Definici√≥n & Referencia\\
\hline
\textbf{Adici√≥n de ruido} & M√©todo basado en agregar o multiplicar un n√∫mero aleatorio a los valores originales para proteger los datos de la coincidencia exacta con archivos externos. La adici√≥n de ruido se aplica t√≠picamente a variables continuas. & [@benschop2021], p√°g. 9\\
\hline
\textbf{Anonimizaci√≥n} & Proceso t√©cnico que consiste en transformar los datos individuales de las unidades de observaci√≥n, de tal modo que no sea posible identificar sujetos o caracter√≠sticas individuales de la fuente de informaci√≥n, preservando as√≠ las propiedades estad√≠sticas en los resultados. & [@institutonacionaldeestadisticas2022]\\
\hline
\textbf{Archivo de datos para uso cient√≠fico} & Archivo de uso cient√≠fico (SUF, por su sigla en ingl√©s, Scientific Use File), es un tipo de publicaci√≥n del archivo de microdatos, que solo est√° disponible para investigadores seleccionados bajo un acuerdo. Tambi√©n conocido como ‚Äúarchivo con licencia‚Äù, ‚Äúmicrodatos bajo contrato‚Äù o ‚Äúarchivo de investigaci√≥n‚Äù. & [@benschop2021], p√°g. 10\\
\hline
\textbf{Archivo de datos para uso en centro de datos de investigaci√≥n controlado o enclave} & Son los archivos que pueden ofrecerse a los usuarios bajo condiciones estrictas en un enclave de datos. Se trata de una sala equipada con computadores que no est√°n conectados a Internet ni a una red externa, y del que no se puede descargar informaci√≥n a trav√©s de puertos USB u otras unidades. Los enclaves de datos contienen datos que son particularmente sensibles o permiten la identificaci√≥n directa o f√°cil de los informantes. Los ejemplos incluyen conjuntos de datos completos de censos de poblaci√≥n, encuestas empresariales, etc. & Adaptado de¬†[@benschop2021], p√°g. 20\\
\hline
\textbf{Archivo de datos para uso p√∫blico} & Archivo de uso p√∫blico (PUF, por sus siglas en ingl√©s, Public Use File), es un tipo de publicaci√≥n del archivo de microdatos, que est√° disponible gratuitamente para cualquier usuario, por ejemplo, en el sitio web del INE. & [@benschop2021], p√°g. 10\\
\hline
\textbf{Barajado (En ingl√©s, shuffling)} & M√©todo que consiste en enmascarar una variable considerada confidencial mediante la generaci√≥n de una distribuci√≥n condicional. & [@benschop2021], p√°g. 74\\
\hline
\textbf{Base de datos} & Una colecci√≥n l√≥gica de informaci√≥n que est√° interrelacionada y que se gestiona y almacena como una unidad, por ejemplo, en el mismo archivo inform√°tico. & [@oecd]\\
\hline
\textbf{Celdas confidenciales} & Las celdas de una tabla que no son publicables debido al riesgo de divulgaci√≥n estad√≠stica se denominan celdas confidenciales. & [@oecd]\\
\hline
\textbf{Clave} & Combinaci√≥n o patr√≥n de variables clave o cuasi ‚Äì identificadores. Tambi√©n, es usado el t√©rmino llave. & [@benschop2021], p√°g. 9\\
\hline
\textbf{Codificaci√≥n superior o inferior} & Corresponde a la agrupaci√≥n de una variable continua en una categor√≠a en los extremos de los valores posibles que agrupa todos los valores mayores o menores a un n√∫mero (por ejemplo: valores mayores o iguales a 5 quedar√°n en la categor√≠a ‚Äú5 o m√°s‚Äù mientras que el resto conserva su valor). & Adaptado de¬†[@benschop2021], p√°g. 52\\
\hline
\textbf{Confidencialidad de los datos} & Es una propiedad de los datos, generalmente como resultado de medidas legislativas, que previenen su divulgaci√≥n no autorizada. & [@oecd]\\
\hline
\textbf{Control de Divulgaci√≥n Estad√≠stica (SDC)} & Proceso que busca tratar y alterar los datos para que puedan publicarse o difundirse sin revelar la informaci√≥n confidencial que contiene, mientras que, al mismo tiempo, limitan la p√©rdida de informaci√≥n debido al anonimato de los datos. En el GSBPM, estos m√©todos est√°n relacionados con la etapa de difusi√≥n y generalmente se basan en restringir la cantidad o modificar los datos publicados. & [@australianbureauofstatistics2021]\\
\hline
Convenio & Contrato, convenci√≥n o acuerdo que se desarrolla en funci√≥n de un asunto espec√≠fico destinado a crear, transferir, modificar o extinguir una obligaci√≥n.
- Es un acuerdo de voluntades entre dos o m√°s organismos p√∫blicos con personalidad jur√≠dica, sobre cualquier cuesti√≥n pendiente de resolver.
- Son instrumentos jur√≠dicos, suscritos por dos o m√°s organismos de la Administraci√≥n del Estado, que tienen por finalidad, comprometer la colaboraci√≥n mutua entre ellos, dentro de las facultades que la ley les confiere para satisfacer necesidades actuales o futuras y que requieren de su formalizaci√≥n, mediante actos administrativos, para producir efectos jur√≠dicos.
Tipos de convenios:
1. Marco: establece las bases para el intercambio de informaci√≥n, mediante convenios espec√≠ficos.
\textbf{2. Espec√≠fico: consiste en la materializaci√≥n de un convenio marco, y tiene por objeto se√±alar espec√≠ficamente las obligaciones de cada parte, detallando los compromisos que adquiere cada instituci√≥n.} & Fiscal√≠a INE\\
\hline
\textbf{Datos personales} & Son datos de car√°cter personal o datos personales, ‚Äúlos relativos a cualquier informaci√≥n concerniente a personas naturales, identificadas o identificables‚Äù. & [Ley N¬∞ 19628 1999]\\
\hline
\textbf{Datos originales} & Datos a los que no se les aplica alg√∫n m√©todo de anonimizaci√≥n. Tambi√©n se denominan ‚Äúdatos brutos‚Äù o ‚Äúdatos no tratados‚Äù. & [@benschop2021], p√°g. 11\\
\hline
\textbf{Divulgaci√≥n} & Se produce cuando una persona u organizaci√≥n reconoce o aprende algo que no sab√≠a sobre otra persona u organizaci√≥n a trav√©s de los datos divulgados. Ver tambi√©n Divulgaci√≥n de identidad, Divulgaci√≥n de atributos y Divulgaci√≥n inferencial. & [@benschop2021], p√°g. 9\\
\hline
\textbf{Divulgaci√≥n de atributos} & La divulgaci√≥n de atributos ocurre cuando un usuario puede determinar nuevas caracter√≠sticas de un individuo u organizaci√≥n con base en la informaci√≥n disponible en los datos publicados. A este usuario se le denominar√° intruso, ver intruso. & [@benschop2021], p√°g. 8\\
\hline
\textbf{Divulgaci√≥n de identidad} & La divulgaci√≥n de identidad ocurre cuando un intruso asocia a un individuo (o grupo) u organizaci√≥n conocida, con un registro de datos publicado. & [@benschop2021], p√°g. 9\\
\hline
\textbf{Divulgaci√≥n inferencial} & La divulgaci√≥n inferencial ocurre si un intruso puede determinar, a partir de los datos publicados, el valor de alguna caracter√≠stica de un individuo u organizaci√≥n con mayor precisi√≥n que lo pretendido. & [@benschop2021], p√°g. 9\\
\hline
\textbf{Encuesta} & Investigaci√≥n sobre las caracter√≠sticas de una poblaci√≥n particular, que utiliza procedimientos estandarizados para recopilar informaci√≥n de la poblaci√≥n de estudio (incluidos censos, encuestas de muestra, la recopilaci√≥n de datos de registros administrativos y actividades estad√≠sticas derivadas) para estimar sus caracter√≠sticas mediante el uso sistem√°tico de la metodolog√≠a estad√≠stica. & [@institutonacionaldeestadisticas2022]\\
\hline
\textbf{Escenario de divulgaci√≥n} & Describe la informaci√≥n potencialmente disponible para un tercero (por ejemplo: datos del censo, padrones electorales, registro de poblaci√≥n, datos recopilados por empresas privadas o incluso datos de encuestas publicadas por el INE), para identificar a los encuestados y las formas en que dicha informaci√≥n se puede combinar con los microdatos establecidos para ser publicados y utilizados para la re-identificaci√≥n de registros en el conjunto de datos. & [@benschop2021], p√°gs. 25-26\\
\hline
\textbf{Estructura jer√°rquica} & Datos que se componen de colecciones de registros que est√°n interconectados a trav√©s de enlaces, por ejemplo, individuos que pertenecen a grupos/hogares o empleados que pertenecen a empresas. & [@benschop2021], p√°g. 9\\
\hline
\textbf{Identificador} & Variable/informaci√≥n (o grupo de variables) que puede utilizarse para establecer la identidad de un individuo u organizaci√≥n. Los identificadores pueden conducir a una identificaci√≥n directa o indirecta. & [@benschop2021], p√°g. 9\\
\hline
\textbf{Identificadores directos} & Son variables que identifican inequ√≠vocamente unidades estad√≠sticas, como, RUT, ROL, n√∫mero de seguro social, o nombres y direcciones de empresas o personas. Los identificadores directos deben eliminarse como primer paso del proceso de anonimizaci√≥n. & [@benschop2021], p√°g. 9\\
\hline
\textbf{Identificadores indirectos} & Son variables que, si bien no identifican inequ√≠vocamente unidades estad√≠sticas, en combinaci√≥n se pueden vincular a informaci√≥n externa para re-identificar a los informantes en el conjunto de datos publicado. Tambi√©n se les denomina ‚Äúcuasi-identificadores‚Äù o ‚Äúvariables clave‚Äù. & [@benschop2021], p√°g. 9\\
\hline
\textbf{Informante} & Empresas, autoridades, personas individuales, etc., de quienes se recopilan datos e informaci√≥n asociada para su uso en la compilaci√≥n de estad√≠sticas. & Adaptado de¬†[@oecd]\\
\hline
\textbf{Intervalo} & Un conjunto de n√∫meros entre dos cotas designadas que pueden o no estar incluidos (abiertos, semiabiertos o cerrados). Los corchetes (por ejemplo, [0, 1]) denotan un intervalo cerrado, que incluye los puntos finales 0 y 1. Los par√©ntesis, por ejemplo, (0, 1) denotan un intervalo abierto, que no incluye los puntos finales. & Adaptado de¬†[@benschop2021], p√°g. 9\\
\hline
\textbf{Intruso} & Usuario que hace mal uso de los datos publicados al tratar de identificar y divulgar informaci√≥n sobre un individuo u organizaci√≥n, utilizando un conjunto de caracter√≠sticas conocidas por el usuario. & [@benschop2021], p√°g. 9\\
\hline
\textbf{K-anonimato} & La medida de riesgo ùëò-anonimato se basa en el principio de que, en un conjunto de datos seguro, el n√∫mero de individuos que comparten la misma combinaci√≥n de valores (claves) de identificadores indirectos categ√≥ricos debe ser superior a un umbral especificado ùëò. Es una medida de riesgo basada en los microdatos que se liberar√°n, ya que solo tiene en consideraci√≥n la muestra. & [@benschop2021], p√°g. 28\\
\hline
Metadatos & Son datos que entregan la informaci√≥n necesaria para el uso e interpretaci√≥n adecuada de las estad√≠sticas por parte de las personas usuarias. Los metadatos describen los datos producidos por medio de la documentaci√≥n de contenidos relacionados, por ejemplo, con la metodolog√≠a; el trabajo de campo; el procesamiento; an√°lisis y la calidad; entre otros, de una operaci√≥n estad√≠stica particular.
Contexto: Generalmente se hace una distinci√≥n entre metadatos estructurales y de referencia.‚Äã
Los metadatos estructurales se utilizan para identificar y describir formalmente: nombres de dimensiones, diccionarios de variables, descripciones t√©cnicas de conjuntos de datos, ubicaciones de conjuntos de datos, palabras clave para buscar datos, etc‚Äã
\textbf{Los metadatos de referencia (a veces llamados metadatos explicativos) describen los contenidos y la calidad de los resultados estad√≠sticos. Incluye documentaci√≥n descriptiva sobre el contexto de la informaci√≥n producida, como, por ejemplo, las metodolog√≠as para la recolecci√≥n y an√°lisis de datos, as√≠ como caracter√≠sticas de la calidad y difusi√≥n de la operaci√≥n.} & [@institutonacionaldeestadisticas2022]\\
\hline
\textbf{M√©todos determin√≠sticos} & M√©todos que siguen cierto algoritmo y producen los mismos resultados si se aplican repetidamente a los mismos datos con el mismo conjunto de par√°metros. & [@benschop2021], p√°g. 8\\
\hline
\textbf{M√©todos no perturbativos} & M√©todos que reducen los detalles en los datos o suprimen ciertos valores (enmascaramiento) sin distorsionar la estructura de datos. & [@benschop2021], p√°g. 9\\
\hline
\textbf{M√©todos perturbativos} & M√©todos que alteran los valores para limitar el riesgo de divulgaci√≥n al crear incertidumbre en torno a los valores verdaderos, al tiempo que conservan la mayor cantidad de contenido y estructura posible, por ejemplo, microagregaci√≥n y adici√≥n de ruido. & [@benschop2021], p√°g. 9\\
\hline
\textbf{M√©todos probabil√≠sticos} & M√©todos que dependen de un mecanismo de probabilidad o un mecanismo de generaci√≥n de n√∫meros aleatorios. Cada vez que se utiliza un m√©todo probabil√≠stico se genera un resultado diferente. & [@benschop2021], p√°g. 9\\
\hline
\textbf{Microagregaci√≥n} & M√©todo que se basa en la sustituci√≥n de valores para una determinada variable con un valor com√∫n para un grupo de registros. La agrupaci√≥n de registros se basa en una medida de proximidad de variables de inter√©s. Los grupos de registros tambi√©n se utilizan para calcular el valor de reemplazo. & [@benschop2021], p√°g. 9\\
\hline
\textbf{Microdatos} & Corresponde a los datos sobre las caracter√≠sticas asociadas a las unidades estad√≠sticas que se encuentran consolidadas en una base de datos. Son observaciones no agregadas o mediciones de las caracter√≠sticas de la o las unidades estad√≠sticas, siendo la forma primaria en la que se almacenan los datos y que a partir de esta se derivan los resultados. El conjunto de microdatos es uno de los resultados y/o producto de la recolecci√≥n de datos y del procesamiento de los datos. & [@institutonacionaldeestadisticas2022]\\
\hline
\textbf{Muestra √∫nica} & Un registro de la muestra con un conjunto particular de caracter√≠sticas que no se repite en otras observaciones, de modo que el individuo u organizaci√≥n se puede distinguir de otras unidades de la muestra en funci√≥n de ese conjunto de caracter√≠sticas. & [@benschop2021], p√°g. 10\\
\hline
Operaci√≥n estad√≠stica & Aplicaci√≥n de un conjunto interrelacionado de procesos, que comprende la detecci√≥n de necesidades, el dise√±o, construcci√≥n, recolecci√≥n de datos, procesamiento, an√°lisis, difusi√≥n y evaluaci√≥n, lo cual conduce a la obtenci√≥n de resultados estad√≠sticos sobre un tema de estudio.
Contexto: cuando se hace referencia al concepto se deben tener las siguientes consideraciones.
‚Ä¢ El concepto de operaci√≥n estad√≠stica permite identificar e individualizar un proceso estad√≠stico sobre un tema o √°mbito particular; por ejemplo, el √çndice de Precios al Consumidor, la Encuesta Nacional de Empleo o el Censo de Poblaci√≥n y Viviendas, corresponden a operaciones espec√≠ficas que se realizan implementando un proceso compuesto por subprocesos, tareas y actividades.
\textbf{‚Ä¢ Las operaciones estad√≠sticas que realizan las oficinas estad√≠sticas o unidades del sistema estad√≠stico pueden ser clasificadas y agrupadas por medio de inventarios o catastros permitiendo la coordinaci√≥n y planificaci√≥n estad√≠stica, los cuales constituyen la base para la formulaci√≥n de los Planes Nacionales de Recopilaci√≥n Estad√≠stica (PNRE).} & [@institutonacionaldeestadisticas2022]\\
\hline
\textbf{P√©rdida de informaci√≥n} & Se refiere a la reducci√≥n del contenido de informaci√≥n en los datos liberados en relaci√≥n con el contenido de informaci√≥n en los datos sin procesar. A menudo se mide con el uso de medidas anal√≠ticas comunes, como regresiones e indicadores. Ver tambi√©n Utilidad de los datos. & [@benschop2021], p√°g. 9\\
\hline
\textbf{Poblaci√≥n √∫nica} & Un registro en la poblaci√≥n con un conjunto particular de caracter√≠sticas que no se repite en la poblaci√≥n, de modo que el individuo u organizaci√≥n puede distinguirse de otras unidades de la poblaci√≥n en funci√≥n de ese conjunto de caracter√≠sticas. & [@benschop2021], p√°g. 10\\
\hline
\textbf{Post Randomization Method¬†(PRAM)} & M√©todo en el que los puntajes de una variable categ√≥rica se alteran de acuerdo con ciertas probabilidades. Por lo tanto, es una clasificaci√≥n err√≥nea intencional con probabilidades de clasificaci√≥n err√≥nea conocidas & [@benschop2021], p√°g. 10\\
\hline
Privacidad & Es un concepto que se aplica a las unidades, mientras que la confidencialidad se aplica a los datos.
\textbf{El concepto se define de la siguiente manera: ‚ÄúEs el estatus otorgado a los datos que ha sido acordado entre la persona u organizaci√≥n que proporciona los datos y la organizaci√≥n que los recibe y que describe el grado de protecci√≥n que se brindar√°‚Äù.} & [@oecd]\\
\hline
\textbf{Producto estad√≠stico} & Resultados f√≠sicos o digitales de una operaci√≥n estad√≠stica, en general corresponden a publicaciones de informaci√≥n mediante la presentaci√≥n de datos y metadatos, que buscan satisfacer las necesidades de la comunidad usuaria. & [@institutonacionaldeestadisticas2022]\\
\hline
\textbf{Protecci√≥n de datos} & Se refiere al conjunto de leyes, pol√≠ticas y procedimientos motivados por la privacidad que tienen como objetivo minimizar la intrusi√≥n en la privacidad de los informantes causada por la recopilaci√≥n, el almacenamiento y la difusi√≥n de datos personales. & [@oecd]\\
\hline
\textbf{Recodificaci√≥n} & M√©todo en el que se agrupan categor√≠as o valores existentes y se reemplazan con nuevos valores, por ejemplo, las categor√≠as ‚Äúprotestante‚Äù y ‚Äúcat√≥lico‚Äù se reemplazan por ‚Äúcristiano‚Äù. La recodificaci√≥n reduce los detalles en los datos y, para las variables continuas, conduce a una transformaci√≥n de continua a categ√≥rica, por ejemplo, creando bandas de ingresos. & [@benschop2021], p√°g. 10\\
\hline
\textbf{Registro} & Un conjunto de datos derivados de un objeto/unidad de estudio, por ejemplo, un individuo (en datos a nivel individual), un hogar (en datos a nivel de hogar) o una empresa (en datos de la empresa). Los registros tambi√©n se denominan ‚Äúobservaciones‚Äù. & [@benschop2021], p√°g. 10\\
\hline
Registro administrativo & Conjunto de datos recopilados y utilizados para fines administrativos por una entidad p√∫blica o privada sobre un tipo de hecho, evento, acci√≥n, objeto, sujeto, obtenidos sistem√°ticamente con base en un formato espec√≠fico ya sea impreso, digital u otro y dentro del marco de sus atribuciones.
\textbf{Contexto: a modo de ejemplo, se consideran registros administrativos las bases de datos con identificadores √∫nicos asociados a n√∫meros de identificaci√≥n personal, n√∫meros de identificaci√≥n tributaria u otros, los datos geogr√°ficos que permitan identificar o ubicar espacialmente los datos, as√≠ como los listados de unidades y transacciones administrados por los integrantes del SEN, as√≠ como entidades privadas de inter√©s para las oficinas estad√≠sticas.} & [@institutonacionaldeestadisticas2022]\\
\hline
\textbf{Regresi√≥n} & Proceso estad√≠stico para medir la relaci√≥n entre el valor medio de una variable y los valores correspondientes de otras variables. & [@benschop2021], p√°g. 10\\
\hline
\textbf{Riesgo de divulgaci√≥n} & Se refiere a la probabilidad de que ocurra efectivamente una divulgaci√≥n de la informaci√≥n confidencial de un informante, o una divulgaci√≥n exacta con un alto nivel de confianza. & Adaptado de¬†[@benschop2021], p√°g. 9\\
\hline
\textbf{Riesgo global} & Es una medida sobre todo el conjunto de datos que agrega los riesgos individuales como la proporci√≥n esperada de individuos en una muestra que pueden ser correctamente re-identificados por un intruso. Hay que utilizar con cuidado esta medida, ya que puede esconder altos riesgos individuales con un riesgo global aceptable. & [@benschop2021], p√°g. 40\\
\hline
\textbf{Riesgo individual} & Es la probabilidad de una correcta re-identificaci√≥n de individuos en los datos divulgados. & Adaptado de¬†[@benschop2021], p√°g. 28\\
\hline
\textbf{Riesgo jer√°rquico} & Es la probabilidad de una correcta re-identificaci√≥n de unidades tomando en cuenta la estructura jer√°rquica de los datos. La estructura jer√°rquica de un conjunto de datos puede estar dado por ser miembros de un hogar, trabajadores de una empresa o alumnos de un colegio, entre otros ejemplos, el riesgo entonces tomar√° en cuenta que si se identifica alg√∫n miembro de este hogar, empresa o colegio puede que se identifique al resto de sus miembros. & Adaptado de¬†[@benschop2021], p√°g. 41\\
\hline
\textbf{sdcMicro} & Un paquete basado en R creado por Templ, M., Kowarik, A. y Meindl, B. con herramientas para la anonimizaci√≥n de microdatos, es decir, para la creaci√≥n de archivos de uso p√∫blico y cient√≠fico con cierto est√°ndar de anonimato en las observaciones. & [@benschop2021], p√°g. 11\\
\hline
\textbf{Supresi√≥n de datos} & La supresi√≥n de datos implica no divulgar informaci√≥n que se considera insegura porque no se aplican las reglas de confidencialidad. A veces esto se hace reemplazando valores que significan atributos individuales con valores faltantes (por ejemplo, pasando del nivel de ingresos de un hogar a un ‚Äúmissing‚Äù o ‚Äúsin dato‚Äù para proteger la identidad del hogar). En el contexto de esta gu√≠a, generalmente para lograr el nivel deseado de¬†k¬†‚Äì anonimato. & [@benschop2021], p√°g. 11\\
\hline
\textbf{Tabulados} & Expresi√≥n gr√°fica que sintetiza un valor o estimaci√≥n producto del cruce entre dos o m√°s variables. & [Instituto Nacional de Estad√≠sticas 2020]¬†p√°g. 60\\
\hline
\textbf{T√©cnicas de control de divulgaci√≥n estad√≠stica} & Se pueden definir como el conjunto de m√©todos para reducir el riesgo de divulgar informaci√≥n sobre personas, empresas u otras organizaciones.¬†Dichos m√©todos solo est√°n relacionados con el paso de difusi√≥n y generalmente se basan en restringir la cantidad o modificar los datos publicados. & [@oecd]\\
\hline
\textbf{Umbral de riesgo} & Nivel, valor, margen o punto establecido a partir del cual se produce la identificaci√≥n de unidades. Si no es seguro, se deber√°n tomar medidas adicionales para reducir el riesgo de identificaci√≥n. & [@benschop2021], p√°g. 11\\
\hline
\textbf{Unidad de observaci√≥n} & Unidad identificable sobre la que se obtiene informaci√≥n (o son informados), registran y compilan datos estad√≠sticos. & [@institutonacionaldeestadisticas2022]\\
\hline
\textbf{Usuario final} & El usuario del archivo de microdatos liberado despu√©s de la anonimizaci√≥n. & Adaptado de¬†[@benschop2021], p√°g. 9\\
\hline
\textbf{Utilidad de los datos} & Describe el valor de una publicaci√≥n de datos determinada como recurso anal√≠tico. Esto comprende la integridad anal√≠tica de los datos y su validez anal√≠tica. Los m√©todos de control de divulgaci√≥n suelen tener un efecto adverso en la utilidad de los datos. Idealmente, el objetivo de cualquier r√©gimen de control de divulgaci√≥n deber√≠a ser maximizar la utilidad de los datos al tiempo que se minimiza el riesgo de divulgaci√≥n. En la pr√°ctica, las decisiones de control de divulgaci√≥n son una compensaci√≥n entre la utilidad y el riesgo de divulgaci√≥n. & [@oecd]\\
\hline
\textbf{Valor at√≠pico} & Un valor inusual que se informa correctamente pero que no es t√≠pico del resto de la poblaci√≥n. Los valores at√≠picos (outliers, en ingl√©s) tambi√©n pueden ser observaciones con una combinaci√≥n inusual de valores para variables, como la viuda de 20 a√±os. En su propia edad, 20 y viuda no son valores inusuales, pero su combinaci√≥n puede serlo. & [@benschop2021], p√°g. 10\\
\hline
\textbf{Variable} & Cualquier caracter√≠stica, n√∫mero o cantidad que se puede medir o contar para cada unidad de observaci√≥n. & [@benschop2021], p√°g. 11\\
\hline
\textbf{Variable categ√≥rica} & Una variable discreta que toma valores sobre un conjunto finito, por ejemplo, sexo representado por los n√∫meros 1 o 0 para hombre y mujer. Tambi√©n llamado factor en R. & [@benschop2021], p√°g. 8\\
\hline
\textbf{Variable continua} & Una variable que puede tomar valores sobre un conjunto denso. Ejemplos son los ingresos, la altura del cuerpo y el tama√±o de la parcela. & Adaptado de¬†[@benschop2021], p√°g. 8\\
\hline
\textbf{Variables de no identificaci√≥n} & Son variables que no pueden utilizarse para la re-identificaci√≥n de los informantes o fuentes. Esto podr√≠a deberse a que estas variables no est√°n contenidas en ning√∫n otro archivo de datos u otra fuente externa. Estas variables son importantes en el procedimiento del control a la divulgaci√≥n, ya que pueden contener variables sensibles. & [@benschop2021], p√°g. 24\\
\hline
\textbf{Variable factor} & Son una forma de clasificar variables categ√≥ricas en factores, que pueden ser ordenadas o no. & [@benschop2021], p√°g. 9\\
\hline
\textbf{Variable semicontinua (discreta)} & Es una variable que toma valores contenidos en un conjunto discreto. Un ejemplo es la edad medida en a√±os, que podr√≠a tomar valores en el conjunto \{0, 1, . . ., 100\}. La naturaleza finita de los valores para estas variables significa que pueden tratarse como variables categ√≥ricas a los efectos de SDC. & Adaptado de¬†[@benschop2021], p√°g. 24\\
\hline
Variable sensible & Variable contenida en un registro de datos, adem√°s de las variables clave, que pertenecen al dominio privado de los informantes que no quisieran que se divulgaran.
Algunos datos son claramente sensibles, como la posesi√≥n de antecedentes penales o la condici√≥n m√©dica, pero hay otros casos en los que la distinci√≥n depende de las circunstancias, por ejemplo, los ingresos de una persona pueden considerarse como una variable sensible en algunos pa√≠ses.
\textbf{La determinaci√≥n de variables sensibles a menudo est√° sujeta a preocupaciones legales y √©ticas.} & [@oecd]\\
\hline
\end{tabu}
\end{table}

\hypertarget{tipos-de-liberaciuxf3n-de-datos}{%
\chapter{Tipos de liberaci√≥n de datos}\label{tipos-de-liberaciuxf3n-de-datos}}

Esta secci√≥n expone sobre la liberaci√≥n de microdatos, cuyos lineamientos se extrajeron de la gu√≠a elaborada por el Banco Mundial \citep{benschop2021}, que a su vez recoge el trabajo conjunto realizado por el Banco Mundial y sus socios en la Red Internacional de Encuestas de Hogares IHSN\footnote{En ingl√©s, \emph{International Household Survey Network}.} \citep{dupriez2010}.

El balance entre riesgo y utilidad en el proceso SDC depende en gran medida de qui√©nes son los usuarios y bajo qu√© condiciones se difunde o libera un archivo de microdatos.

En general, se practican tres tipos de m√©todos de liberaci√≥n de datos para diferentes grupos objetivo, a saber: archivo de uso p√∫blico (PUF), archivo de uso cient√≠fico (SUF) y enclave de datos. En la Tabla \ref{tab:tbl2lbn} se resumen los tipos de liberaci√≥n y su aplicabilidad en el INE, dado el marco legal vigente en Chile. Como se podr√° observar, el tipo \textbf{PUF es el √∫nico tipo de liberaci√≥n de microdatos que es aplicable para el INE} dado el marco legal vigente en Chile.

\begin{table}

\caption{\label{tab:tbl2lbn}Resumen de tipos de liberaci√≥n de microdatos}
\begin{tabu} to \linewidth {>{\raggedright}X>{\raggedright}X>{\raggedright}X}
\hline
Tipo & Descripci√≥n & Aplicabilidad con el marco legal vigente\\
\hline
Archivo de Uso P√∫blico (PUF) & Los datos est√°n disponibles directamente para cualquier persona interesada, por ejemplo, en el sitio web del INE. Estos datos se hacen f√°cilmente accesibles debido a que los riesgos de identificar a las unidades individuales se consideran m√≠nimos.
En el contexto INE, el PUF se puede entregar a nivel de microdatos mediante las siguientes formas:
i. Base de datos publicadas (BP) que se dispone en la p√°gina web del INE y en la p√°gina web de la instituci√≥n demandante, seg√∫n corresponda.
\textbf{ii. Base de datos a solicitar por transparencia (BST) que se entrega directamente al usuario responsable de la solicitud.} & Aplicable.\\
\hline
Archivo de Uso Cient√≠fico (SUF) & La difusi√≥n est√° restringida a los usuarios que han recibido autorizaci√≥n para acceder a ellos despu√©s de enviar una solicitud documentada y firmar un acuerdo que rige el uso de los datos. Si bien los archivos con licencia general tambi√©n se anonimizan para garantizar que el riesgo de identificar a las unidades (personas, hogares o establecimientos) se minimice cuando se usan de forma aislada, a√∫n pueden (potencialmente) contener datos identificables si se vinculan con otros archivos de datos.
\textbf{Este tipo de liberaci√≥n de datos tambi√©n es conocido como archivo con licencia, microdatos bajo contrato o archivo de investigaci√≥n.} & No aplicable.\\
\hline
\textbf{Enclave de datos o centro de datos de investigaci√≥n controlado} & Algunos archivos pueden ofrecerse a los usuarios bajo condiciones estrictas en un enclave de datos. Esta es una instalaci√≥n (puede ser una instalaci√≥n al interior del INE) equipada con computadoras que no est√°n conectadas a Internet o una red externa y desde las cuales no se puede descargar informaci√≥n a trav√©s de puertos USB, CD ‚Äì DVD u otras unidades. Los enclaves de datos contienen datos que son particularmente sensibles o permiten la identificaci√≥n directa o f√°cil de los informantes. & No aplicable.\\
\hline
\end{tabu}
\end{table}

\hypertarget{condiciones-para-la-liberaciuxf3n-de-datos-bajo-versiuxf3n-puf}{%
\section{Condiciones para la liberaci√≥n de datos bajo versi√≥n PUF}\label{condiciones-para-la-liberaciuxf3n-de-datos-bajo-versiuxf3n-puf}}

En general, los datos que se consideran p√∫blicos est√°n abiertos a cualquier persona con acceso al sitio web del INE. Sin embargo, es una buena pr√°ctica incluir declaraciones de principios que definan los usos adecuados y las precauciones que se adoptar√°n utilizando los datos. Si bien estos pueden no ser legalmente vinculantes, sirven para sensibilizar al usuario. Prohibiciones como intentos de vincular los datos a otras fuentes puede ser parte de la ``declaraci√≥n de uso'', requerida para el uso de datos. La difusi√≥n de archivos de microdatos implica necesariamente la aplicaci√≥n de reglas o principios.

A continuaci√≥n, se listan principios b√°sicos o ``declaraciones de uso'' aplicables a una liberaci√≥n PUF:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Los datos y otros materiales proporcionados por el INE no ser√°n redistribuidos o vendidos a otras personas, instituciones u organizaciones sin el acuerdo por escrito del INE.
\item
  Los datos se usar√°n solo para fines de investigaci√≥n estad√≠stica y cient√≠fica. Ser√°n empleados √∫nicamente para reportar informaci√≥n agregada, incluido el modelado, y no para investigar individuos u organizaciones espec√≠ficos.
\item
  No se intentar√° volver a identificar a los informantes, y no se usar√° la identidad de ninguna persona o establecimiento descubierto inadvertidamente. Cualquier descubrimiento de este tipo se informar√° inmediatamente al INE.
\item
  No se intentar√° crear enlaces entre conjuntos de datos proporcionados por el INE o entre datos del INE y otros conjuntos de datos que podr√≠an identificar individuos u organizaciones.
\item
  Libros, art√≠culos, documentos de conferencias, tesis, disertaciones, informes u otras publicaciones que empleen datos obtenidos del INE citar√° la fuente, de acuerdo con el requisito de cita provisto con el conjunto de datos, en caso de no haber sido proporcionado, se debe citar de acuerdo a la norma APA m√°s actualizada.
\item
  Se enviar√° al INE una copia electr√≥nica de todas las publicaciones basadas en los datos descargados.
\item
  El recolector original de los datos, el INE y las agencias de financiamiento relevantes no tienen responsabilidad por el uso o interpretaci√≥n de los datos o inferencias basadas en ellos.
\end{enumerate}

\begin{quote}
\textbf{Nota:} Los puntos 3 y 6 de la lista requieren que los usuarios reciban una manera f√°cil de comunicarse con el INE. Es una buena pr√°ctica proporcionar un n√∫mero de contacto, una direcci√≥n de correo electr√≥nico y, posiblemente, un sistema de ``suministro de comentarios'' en l√≠nea.
\end{quote}

\hypertarget{proceso-sdc-una-introducciuxf3n}{%
\chapter{Proceso SDC: Una introducci√≥n}\label{proceso-sdc-una-introducciuxf3n}}

\hypertarget{necesidad-por-control-de-divulgaciuxf3n-estaduxedstica-proceso-sdc}{%
\section{Necesidad por control de divulgaci√≥n estad√≠stica (proceso SDC)}\label{necesidad-por-control-de-divulgaciuxf3n-estaduxedstica-proceso-sdc}}

La protecci√≥n de la confidencialidad ha sido una preocupaci√≥n de las Oficinas Nacionales de Estad√≠sticas (ONE), lo que ha sido foco de atenci√≥n recientemente, esto debido a que en las √∫ltimas d√©cadas se ha experimentado un avance tecnol√≥gico importante, junto con el desarrollo de t√©cnicas de re-identificaci√≥n, por ejemplo, basado en \emph{machine learning}. Por lo tanto, proteger los datos personales de los informantes y resguardar la vida personal se hace un imperativo \citep{Yazdani}. Por esta raz√≥n, hoy en d√≠a, resolver la tensi√≥n entre la protecci√≥n de la informaci√≥n personal y el suministro de datos es realmente un desaf√≠o que deben asumir las ONE. En esta situaci√≥n, tres motivaciones empujan a las ONE a preservar la confidencialidad.

El primer motivo para mantener la confidencialidad proviene del cumplimiento del marco normativo entre los cuales se establecen las funciones de la ONE. Existe una obligaci√≥n legal y √©tica de los productores para garantizar que los datos proporcionados por los informantes se utilicen √∫nicamente con fines estad√≠sticos. La ONE debe respetar la confianza de los informantes, cuidar su privacidad y mantenerlos alejados de cualquier da√±o que pueda surgir de la informaci√≥n que han proporcionado. La ONE debe velar por resguardar el cumplimiento del marco normativo y las normas √©ticas.

El segundo motivo subyace en el deseo de la ONE de obtener la cooperaci√≥n de los informantes y obtener datos m√°s precisos. Los informantes que conf√≠an que su informaci√≥n permanecer√° confidencial tienen m√°s probabilidades de participar en la encuesta y reportar con precisi√≥n su informaci√≥n privada. Cualquier duda sobre la confidencialidad puede reducir la disposici√≥n de los posibles informantes a cooperar en una encuesta y puede afectar la calidad de las respuestas \citep{Yazdani}.

El √∫ltimo motivo es la obligaci√≥n impuesta a la ONE por la legislaci√≥n vigente, as√≠ como por compromisos internacionales. La fuerza de la sociedad sobre los gobiernos ha llevado al establecimiento de entornos legales para salvaguardar la privacidad y la ONE est√° mandada a respetar estas restricciones legales \citep{Duncan}. Adem√°s, como lo aprob√≥ por unanimidad la Asamblea General de las Naciones Unidas en enero de 2014, el principio 6 de los Principios Fundamentales de las Estad√≠sticas Oficiales postula que ``Los datos individuales que re√∫nan los organismos de estad√≠stica para la compilaci√≥n estad√≠stica, se refieran a personas naturales o jur√≠dicas, deben ser estrictamente confidenciales y utilizarse exclusivamente para fines estad√≠sticos''.

Los motivos se√±alados anteriormente son de naturaleza moral, √©tica y legal. El proceso SDC busca tratar y procesar los datos individuales para que cumplan el marco normativo y as√≠, puedan publicarse o difundirse respetando el secreto estad√≠stico, pero al mismo tiempo, controlar la p√©rdida de informaci√≥n debido al tratamiento de los datos.

El objetivo de anonimizar los microdatos es transformar los conjuntos de datos para lograr un ``nivel aceptable'' de riesgo de divulgaci√≥n. El nivel de aceptabilidad del riesgo de divulgaci√≥n y la necesidad de anonimizaci√≥n generalmente quedan a discreci√≥n del productor de datos y guiado por la legislaci√≥n. Estos se formulan en las pol√≠ticas y programas de difusi√≥n de los proveedores de datos y se basan en consideraciones que incluyen ``{[}. . .{]} los costos y la experiencia involucrados; cuestiones de calidad de los datos, posible uso indebido y malentendidos de los datos por parte de los usuarios; asuntos legales y √©ticos; y mantener la confianza y el apoyo de los encuestados''\citep[p.~33]{benschop}.

\hypertarget{balance-riesgo-utilidad-en-el-proceso-sdc}{%
\section{Balance riesgo-utilidad en el proceso SDC}\label{balance-riesgo-utilidad-en-el-proceso-sdc}}

Por otra parte, el proceso SDC se caracteriza por el balance entre el riesgo de divulgaci√≥n y la utilidad de los datos para los usuarios finales. La escala riesgo-utilidad se extiende entre dos extremos:

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\tightlist
\item
  No se difunden datos (riesgo cero de divulgaci√≥n) y, por lo tanto, los usuarios no obtienen ninguna utilidad de los datos,
\item
  Los datos se difunden sin ning√∫n tratamiento y, por lo tanto, con el m√°ximo riesgo de divulgaci√≥n, pero con la m√°xima utilidad para el usuario (es decir, sin p√©rdida de informaci√≥n).
\end{enumerate}

El objetivo de un proceso SDC bien implementado es encontrar el punto √≥ptimo en el que la utilidad para los usuarios finales se maximice a un nivel de riesgo aceptable.

En el balance entre Riesgo y Utilidad que se muestra en la Figura \ref{fig:balance}, por un extremo, el tri√°ngulo corresponde a los datos sin procesar, los que no tienen p√©rdida de informaci√≥n, pero generalmente tienen un riesgo de divulgaci√≥n m√°s alto que el nivel aceptable. El otro extremo es el cuadrado, que corresponde a la no publicaci√≥n de datos. En ese caso, no hay riesgo de divulgaci√≥n, pero tampoco hay utilidad de los datos para los usuarios. Los puntos intermedios corresponden a diferentes opciones de m√©todos SDC y/o par√°metros aplicados a diferentes variables. El proceso SDC busca m√©todos y par√°metros, que son aplicados de una manera que produce una reducci√≥n del riesgo de forma muchas veces satisfactoria, minimiz√°ndose generalmente la p√©rdida de informaci√≥n.

\begin{figure}

{\centering \includegraphics[width=16.92in]{fig1} 

}

\caption{Balance Riesgo-Utilidad en un conjunto de datos. Imagen extra√≠da de [@benschop,p.15].}\label{fig:balance}
\end{figure}

El proceso SDC no puede lograr la eliminaci√≥n total del riesgo, pero puede reducir el riesgo a un nivel aceptable. Cualquier aplicaci√≥n de m√©todos SDC suprimir√° o alterar√° los valores en los datos y, como tal, disminuir√° la utilidad (es decir, dar√° como resultado una p√©rdida de informaci√≥n) en comparaci√≥n con los datos originales. Un hilo com√∫n que se enfatizar√° a lo largo de esta gu√≠a ser√° que el proceso SDC debe priorizar el objetivo de proteger a los informantes y, al mismo tiempo, tener en cuenta a los usuarios de datos para limitar la p√©rdida de informaci√≥n. En general, cuanto menor es el riesgo de divulgaci√≥n, mayor es la p√©rdida de informaci√≥n y menor es la utilidad de los datos para los usuarios finales.
En la pr√°ctica, la elecci√≥n de m√©todos SDC es un proceso iterativo: despu√©s de aplicar los m√©todos, el riesgo de divulgaci√≥n y la utilidad de datos se vuelven a medir y se comparan con los resultados de otros m√©todos SDC y par√°metros aplicados. Si el resultado es satisfactorio, los datos pueden ser liberados. Como se ver√° m√°s adelante, a menudo el primer intento no ser√° el √≥ptimo. El riesgo puede no ser reducido lo suficiente o la p√©rdida de informaci√≥n puede ser demasiado alta y el proceso debe repetirse con diferentes m√©todos o par√°metros hasta que se encuentre una soluci√≥n satisfactoria. El riesgo de divulgaci√≥n, la utilidad de los datos y la p√©rdida de informaci√≥n en el contexto de proceso SDC y c√≥mo medirlos se analizan en cap√≠tulos posteriores de esta gu√≠a.

Nuevamente, debe enfatizarse que el nivel de SDC y los m√©todos aplicados dependen en gran medida de todo el marco de publicaci√≥n de datos. Por ejemplo, una consideraci√≥n clave es a qui√©n y bajo qu√© condiciones se liberar√°n los datos (ver secci√≥n \protect\hyperlink{tipos-de-liberaciuxf3n-de-datos}{Tipos de liberaci√≥n de datos}). Si los datos se van a difundir como datos de uso p√∫blico, entonces el nivel de SDC aplicado solo tendr√° que ser mayor que en los casos en que los datos se difundan bajo condiciones de licencia a usuarios confiables, despu√©s de un examen cuidadoso \footnote{Esto no aplica en el caso del INE DE chile, pues solo es aplicable, seg√∫n el marco legal vigente, la difusi√≥n de datos mediante formato PUF.} . Se discutir√° c√≥mo se podr√≠a lograr esto m√°s adelante en la gu√≠a.
Esto ha dispuesto que entidades internacionales desarrollen diferentes t√©cnicas de anonimizaci√≥n, que se ajustan a diferentes tipos de datos, consiguiendo de mejor manera resguardar la calidad de ellos.
El INE, igualmente deber√° tener en cuenta este balance al publicar sus datos, velando porque se ponga a disposici√≥n de la ciudadan√≠a informaci√≥n de la mayor calidad posible, cumpliendo el marco normativo relativo a la protecci√≥n de datos, manteniendo as√≠ la confianza de los informantes.

\hypertarget{introducciuxf3n-a-sdcmicro}{%
\chapter{Introducci√≥n a sdcMicro}\label{introducciuxf3n-a-sdcmicro}}

\hypertarget{introducciuxf3n-1}{%
\section{Introducci√≥n}\label{introducciuxf3n-1}}

El paquete \texttt{R} \texttt{sdcMicro} \citet{templ2015} sirve para evaluar y anonimizar conjuntos de microdatos confidenciales, facilita el manejo de m√©todos SDC mediante una implementaci√≥n de clase S4 orientada a objetos. Incluye todos los m√©todos populares de perturbaci√≥n y riesgo de divulgaci√≥n. El paquete realiza un nuevo c√°lculo autom√°tico de recuentos de frecuencia, medidas de riesgo individuales y globales, p√©rdida de informaci√≥n y estad√≠sticas de utilidad de datos despu√©s de cada paso de anonimizaci√≥n. Todos los m√©todos est√°n altamente optimizados en t√©rminos de costos computacionales para poder trabajar con grandes conjuntos de datos. Los profesionales tambi√©n pueden utilizar f√°cilmente las funciones de generaci√≥n de informes que resumen el proceso de anonimizaci√≥n. Describimos el paquete y demostramos su funcionalidad con un complejo conjunto de datos de prueba procedente de encuestas de hogares, que ha sido distribuido por la Red Internacional de Encuestas de Hogares.

Para m√°s informaci√≥n ver \url{https://cran.r-project.org/web/packages/sdcMicro/sdcMicro.pdf}

\hypertarget{instalaciuxf3n-de-r-sdcmicro-y-otros-paquetes}{%
\section{\texorpdfstring{Instalaci√≥n de \texttt{R}, \texttt{sdcMicro} y otros paquetes}{Instalaci√≥n de R, sdcMicro y otros paquetes}}\label{instalaciuxf3n-de-r-sdcmicro-y-otros-paquetes}}

Esta gu√≠a se basa en el paquete de \emph{software} \texttt{sdcMicro}, que es un paquete adicional para el lenguaje de programaci√≥n estad√≠stico \texttt{R}. Tanto \texttt{R} como \texttt{sdcMicro}, as√≠ como otros paquetes de \texttt{R}, est√°n disponibles gratuitamente en el sitio web de CRAN (Comprehensive R Archive Network) para Linux, Mac y Windows (\url{http://cran.r-project.org} ). Este sitio web tambi√©n ofrece descripciones de paquetes. Adem√°s de la versi√≥n est√°ndar de \texttt{R}, existe una interfaz de usuario m√°s f√°cil de usar para \texttt{R}: RStudio. RStudio tambi√©n est√° disponible gratuitamente para Linux, Mac y Windows (\url{http://www.rstudio.com} ). El paquete \texttt{sdcMicro} tiene dependencia de otros paquetes \texttt{R} que deben instalarse en su computadora antes de usar \texttt{sdcMicro}. Se instalar√°n autom√°ticamente al instalar \texttt{sdcMicro}. Para algunas funcionalidades, usamos otros paquetes (como \texttt{foreign} para leer datos y algunos paquetes gr√°ficos). Si es as√≠, esto se indica en la secci√≥n correspondiente de esta gu√≠a. \texttt{R}, RStudio, el paquete \texttt{sdcMicro} y sus dependencias y otros paquetes tienen actualizaciones peri√≥dicas. Se recomienda encarecidamente comprobar peri√≥dicamente si hay actualizaciones: esto requiere instalar una nueva versi√≥n para una actualizaci√≥n de \texttt{R}; con el comando \texttt{update.packages()} o usando las opciones de men√∫ en \texttt{R} o RStudio se pueden actualizar los paquetes instalados.

Al iniciar \texttt{R} o RStudio, es necesario especificar cada vez qu√© paquetes se est√°n utilizando carg√°ndolos. Esta carga de paquetes se puede realizar con la funci√≥n \texttt{library()} o \texttt{require()}. Ambas opciones se ilustran en el Bloque \ref{exm:bloqueMicro1}.

\begin{example}
\protect\hypertarget{exm:bloqueMicro1}{}{\label{exm:bloqueMicro1} }Cargando paquetes requeridos
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(sdcMicro) }\CommentTok{# cargando paquete sdcMicro}
\KeywordTok{require}\NormalTok{(sdcMicro) }\CommentTok{# cargando paquete sdcMicro}
\end{Highlighting}
\end{Shaded}

Todos los paquetes y funciones est√°n documentados. La forma m√°s f√°cil de acceder a la documentaci√≥n de una funci√≥n espec√≠fica es usar la ayuda integrada, que generalmente brinda una descripci√≥n general de los par√°metros de las funciones, as√≠ como algunos ejemplos. La ayuda de una funci√≥n espec√≠fica se puede llamar con un signo de interrogaci√≥n seguido del nombre de la funci√≥n sin ning√∫n argumento. El Bloque \ref{exm:bloqueMicro2} muestra c√≥mo llamar al archivo de ayuda para la funci√≥n \texttt{microaggregation()} del paquete \texttt{sdcMicro} \footnote{A menudo, tambi√©n es √∫til buscar ayuda en Internet sobre funciones espec√≠ficas en \texttt{R}. Hay muchos foros donde los usuarios de \texttt{R} discuten los problemas que encuentran. Un sitio particularmente √∫til es \emph{stackoverflow.com}}. La p√°gina de descarga de cada paquete en el sitio web de CRAN tambi√©n proporciona un manual de referencia con una descripci√≥n completa de las funciones del paquete.

\begin{example}
\protect\hypertarget{exm:bloqueMicro2}{}{\label{exm:bloqueMicro2} }Visualizaci√≥n de ayuda para funciones
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{?microaggregation }\CommentTok{# ayuda para la funci√≥n microagregaci√≥n}
\end{Highlighting}
\end{Shaded}

Cuando se encuentran problemas o errores en el paquete \texttt{sdcMicro}, se pueden publicar comentarios o sugerencias para los desarrolladores de \texttt{sdcMicro} en su GitHub (\url{https://github.com/sdcTools/sdcMicro/issues}).

\hypertarget{leer-funciones-en-r}{%
\section{\texorpdfstring{Leer funciones en \texttt{R}}{Leer funciones en R}}\label{leer-funciones-en-r}}

El primer paso en el proceso SDC cuando se usa \texttt{sdcMicro} es leer los datos en \texttt{R} y crear un marco de datos\footnote{Un marco de datos es una clase de objeto en \texttt{R}, que es similar a una tabla o matriz de datos} \texttt{R} es compatible con la mayor√≠a de los formatos de datos estad√≠sticos y proporciona funciones de lectura para la mayor√≠a de los tipos de datos. Para esas funciones de lectura, a veces es necesario instalar paquetes adicionales y sus dependencias en \texttt{R}. En la Tabla \ref{tab:tabMicro1} se proporciona una descripci√≥n general de los formatos de datos, las funciones y los paquetes que contienen estas funciones . Estas funciones tambi√©n est√°n disponibles como escritura (por ejemplo, \texttt{write\_dta()}) para guardar los datos an√≥nimos en el formato requerido \footnote{No todas las funciones son compatibles con todas las versiones del paquete de \emph{software} respectivo. Nos referimos a los archivos de ayuda de las funciones de lectura y escritura para m√°s informaci√≥n.}.

\begin{table}

\caption{\label{tab:tabMicro1}Paquetes y funciones para lectura de datos en `R`}
\centering
\begin{tabular}[t]{c|c|c|c}
\hline
Tipo/software & Extensi√≥n & Paquete & Funci√≥n\\
\hline
SPSS & .sav & `haven` & `read\_sav()`\\
\hline
STATA (v.5-14) & .dta & `haven` & `read\_dta()`\\
\hline
SAS & .sas7bdat & `haven` & `read\_sas()`\\
\hline
Excel & .csv & `utils` (paquete base) & `read\_csv()`\\
\hline
Excel & .xls/.xlsx & `readxl` & `read\_xlsx()`\\
\hline
\end{tabular}
\end{table}

La mayor√≠a de estas funciones tienen opciones que especifican c√≥mo manejar los valores faltantes y las variables con niveles de factor y etiquetas de valor. El Bloque \ref{exm:bloqueMicro3}, el Bloque \ref{exm:bloqueMicro4} y el Bloque \ref{exm:bloqueMicro5} proporcionan c√≥digo de ejemplo para leer un archivo STATA (.dta), un archivo de valores separados por ; (.csv) y un archivo SPSS (.sav), respectivamente.

\begin{example}
\protect\hypertarget{exm:bloqueMicro3}{}{\label{exm:bloqueMicro3} }Lectura en un archivo STATA
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{setwd}\NormalTok{(}\StringTok{"../Capacitaci√≥n/GitHub"}\NormalTok{) }\CommentTok{# directorio de trabajo}


\NormalTok{fname =}\StringTok{ "data.dta"} \CommentTok{# nombre del archivo}
\KeywordTok{library}\NormalTok{(haven) }\CommentTok{# carga el paquete requerido para la funci√≥n de lectura/escritura}
               \CommentTok{# para archivos STATA}
\NormalTok{file <-}\StringTok{ }\KeywordTok{read_dta}\NormalTok{(fname)}
\CommentTok{# lee los datos en el marco de datos tbl llamado file}
\end{Highlighting}
\end{Shaded}

\begin{example}
\protect\hypertarget{exm:bloqueMicro4}{}{\label{exm:bloqueMicro4} }Lectura en un archivo csv
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{setwd}\NormalTok{(}\StringTok{"../Capacitaci√≥n/GitHub"}\NormalTok{) }\CommentTok{# directorio }
                                                                              \CommentTok{# de}
                                                                              \CommentTok{# trabajo}
\NormalTok{fname =}\StringTok{ "data.csv"} \CommentTok{# nombre del archivo}
\NormalTok{file <-}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(fname, }\DataTypeTok{header =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{sep =} \StringTok{";"}\NormalTok{, }\DataTypeTok{dec =} \StringTok{"."}\NormalTok{)}
\CommentTok{# lee los datos hacia un dataframe llamado file,}
\CommentTok{# la primera l√≠nea contiene los nombres de las variables,}
\CommentTok{# campos son separados con comas, posiciones decimales se indican con ‚Äò;‚Äô}
\end{Highlighting}
\end{Shaded}

\begin{example}
\protect\hypertarget{exm:bloqueMicro5}{}{\label{exm:bloqueMicro5} }Lectura en un archivo SPSS
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{setwd}\NormalTok{(}\StringTok{"../Capacitaci√≥n/GitHub"}\NormalTok{) }\CommentTok{# directorio }
                                                                              \CommentTok{# de}
                                                                              \CommentTok{# trabajo}
\NormalTok{fname =}\StringTok{ "data.sav"} \CommentTok{# nombre del archivo}
\KeywordTok{library}\NormalTok{(haven) }\CommentTok{# carga paquete requerido para la funci√≥n lectura/escritura}
               \CommentTok{# para archivos SPSS}
\NormalTok{file <-}\StringTok{ }\KeywordTok{read_sav}\NormalTok{(fname)}
\CommentTok{# lee los datos hacia un dataframe llamado file}
\end{Highlighting}
\end{Shaded}

El tama√±o m√°ximo de datos en \texttt{R} est√° t√©cnicamente restringido. El tama√±o m√°ximo depende de la versi√≥n \texttt{R} (32 o 64 bits) y del sistema operativo. Algunos m√©todos SDC requieren largos tiempos de c√°lculo para grandes conjuntos de datos (consulte la Secci√≥n \protect\hyperlink{tiempo-de-cuxf3mputo}{Tiempo de c√≥mputo}).

\hypertarget{valores-faltantes}{%
\section{Valores faltantes}\label{valores-faltantes}}

La forma est√°ndar en que los valores faltantes se representan en \texttt{R} es mediante el s√≠mbolo \texttt{NA}, que es diferente a los valores imposibles, como la divisi√≥n por cero o el logaritmo de un n√∫mero negativo, que se representan con el s√≠mbolo \texttt{NaN}. El valor \texttt{NA} se usa tanto para variables num√©ricas como categ√≥ricas\footnote{Esto es independientemente de la clase de la variable en \texttt{R}. Consulte la secci√≥n \protect\hyperlink{clases-en-r}{Clases en \texttt{R}} para obtener m√°s informaci√≥n sobre las clases en \texttt{R}.}. Los valores suprimidos por la rutina \texttt{localSuppression()} tambi√©n se reemplazan por el s√≠mbolo \texttt{NA}. Algunos conjuntos de datos y \emph{software} estad√≠stico pueden usar diferentes valores para los valores faltantes, como `999' o cadenas. Es posible incluir argumentos en las funciones de lectura para especificar c√≥mo se deben tratar los valores faltantes en el conjunto de datos y recodificar autom√°ticamente los valores faltantes a \texttt{NA}. Por ejemplo, la funci√≥n \texttt{read.table()} tiene el argumento \texttt{na.strings}, que reemplaza las cadenas especificadas con valores \texttt{NA}.

Los valores faltantes tambi√©n se pueden recodificar despu√©s de leer los datos en \texttt{R}. Esto puede ser necesario si hay varios c√≥digos de valores perdidos diferentes en los datos, c√≥digos de valores perdidos diferentes para diferentes variables o la funci√≥n de lectura para el tipo de datos no permite especificar los c√≥digos de valores perdidos. Al preparar los datos, es importante volver a codificar cualquier valor faltante que no est√© codificado como \texttt{NA} a \texttt{NA} en \texttt{R} antes de iniciar el proceso de anonimizaci√≥n para garantizar la medici√≥n correcta del riesgo (por ejemplo, k-anonimato), as√≠ como para asegurar que muchos de los m√©todos se aplican correctamente a los datos. El Bloque \ref{exm:bloqueMicro6} muestra c√≥mo recodificar el valor `99' a \texttt{NA} para la variable ``TOILET''.

\begin{example}
\protect\hypertarget{exm:bloqueMicro6}{}{\label{exm:bloqueMicro6} }Recodificaci√≥n de valores perdidos a \texttt{NA}
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{file[file[,}\StringTok{'TOILET'}\NormalTok{] }\OperatorTok{==}\StringTok{ }\DecValTok{99}\NormalTok{,}\StringTok{'TOILET'}\NormalTok{] <-}\StringTok{ }\OtherTok{NA}
\CommentTok{# Recodificar el c√≥digo de valor faltante 99 a NA para la variable TOILET}
\end{Highlighting}
\end{Shaded}

\hypertarget{clases-en-r}{%
\section{\texorpdfstring{Clases en \texttt{R}}{Clases en R}}\label{clases-en-r}}

Todos los objetos en \texttt{R} son de una clase espec√≠fica, como un n√∫mero entero, un car√°cter, una matriz, un factor o un marco de datos. La clase de un objeto es un atributo que hereda de la clase base, haci√©ndolo miembro e instancia de esta clase. Para averiguar la clase de un objeto, se puede utilizar la funci√≥n \texttt{class()}. Las funciones en \texttt{R} pueden requerir objetos o argumentos de ciertas clases o funciones que pueden tener una funcionalidad diferente seg√∫n la clase del argumento. Algunos ejemplos son las funciones de escritura que requieren marcos de datos y la mayor√≠a de las funciones en el paquete \texttt{sdcMicro} que requieren marcos de datos u objetos \texttt{sdcMicro}. La funcionalidad de las funciones en el paquete \texttt{sdcMicro} difiere para marcos de datos y objetos \texttt{sdcMicro}. Es f√°cil cambiar el atributo de clase de un objeto con funciones que comienzan con ``as.'', seguido del nombre de la clase (por ejemplo, \texttt{as.factor()}, \texttt{as.matrix()}, \texttt{as.data.frame()}). El Bloque \ref{exm:bloqueMicro7} muestra c√≥mo verificar la clase de un objeto y cambiar la clase a ``data.frame''. Antes de cambiar el atributo de clase del objeto ``file'', estaba en la clase ``matrix''. Una clase importante definida y utilizada en el paquete \texttt{sdcMicro} es la clase denominada \texttt{sdcMicroObj}. Esta clase se describe en la siguiente secci√≥n.

\begin{example}
\protect\hypertarget{exm:bloqueMicro7}{}{\label{exm:bloqueMicro7} }Cambiando la clase de un objeto en \texttt{R}
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Averiguar la clase del objeto 'file'}
\KeywordTok{class}\NormalTok{(file)}
\StringTok{"matrix"}

\CommentTok{# Cambiar la clase al marco de datos (data frame)}
\NormalTok{file <-}\StringTok{ }\KeywordTok{as.data.frame}\NormalTok{(file)}

\CommentTok{# Comprobando la clase del resultado (file)}
\StringTok{"data.frame"}
\end{Highlighting}
\end{Shaded}

\hypertarget{objetos-de-la-clase-sdcmicroobj}{%
\section{\texorpdfstring{Objetos de la clase \texttt{sdcMicroObj}}{Objetos de la clase sdcMicroObj}}\label{objetos-de-la-clase-sdcmicroobj}}

El paquete \texttt{sdcMicro} se basa en objetos \footnote{La clase \texttt{sdcMicroObj} tiene objetos S4, que tienen elementos o atributos y permiten la programaci√≥n orientada a objetos.} de la clase \texttt{sdcMicroObj}, una clase especialmente definida para el paquete \texttt{sdcMicro}. Cada componente de esta clase tiene una estructura determinada con elementos que contienen informaci√≥n sobre el proceso de anonimizaci√≥n (consulte la Tabla \ref{tab:tabMicro2} para obtener una descripci√≥n de todos los elementos o propiedades (\emph{slots}, en ingl√©s)). Antes de evaluar el riesgo y la utilidad y aplicar m√©todos SDC, se recomienda crear un objeto de clase \texttt{sdcMicro}. Todos los ejemplos de esta gu√≠a se basan en estos objetos. La funci√≥n utilizada para crear un objeto \texttt{sdcMicro} es \texttt{createSdcObj()}. La mayor√≠a de las funciones en el paquete \texttt{sdcMicro}, como \texttt{microaggregation()} o \texttt{localSuppression()}, usan autom√°ticamente la informaci√≥n requerida (por ejemplo, identificadores indirectos, pesos de muestra) del objeto \texttt{sdcMicro} si se aplica a un objeto de clase \texttt{sdcMicro}.

Los argumentos de la funci√≥n \texttt{createSdcObj()} permiten especificar el archivo de datos original y categorizar las variables en este archivo de datos antes del inicio del proceso de anonimizaci√≥n.

En el Bloque \ref{exm:bloqueMicro8}, mostramos todos los argumentos de la funci√≥n \texttt{createSdcObj()}, y primero definimos vectores con los nombres de las diferentes variables. Esta pr√°ctica brinda una mejor visi√≥n general y luego permite cambios r√°pidos en las opciones de variables si es necesario. Elegimos los identificadores indirectos categ√≥ricos (keyVars); las variables vinculadas a los identificadores indirectos categ√≥ricos que necesitan el mismo patr√≥n de supresi√≥n (ghostVars, consulte la secci√≥n \protect\hyperlink{sup-loc}{Supresi√≥n local}); los identificadores indirectos num√©ricos (numVars); las variables seleccionadas para aplicar PRAM (pramVars); una variable con pesos muestrales (weightVar); el identificador de agrupaci√≥n (hhId, por ejemplo, un identificador de hogar, consulte la secci√≥n \protect\hyperlink{riesgo-jeruxe1rquico-o-del-hogar}{Riesgo jer√°rquico (o del hogar)}); una variable que especifica los estratos (strataVar) y las variables sensibles especificadas para el c√°lculo de \emph{l-diversity} (sensibleVar, consulte la secci√≥n \protect\hyperlink{l-diversity}{l-diversity}).

La mayor√≠a de los m√©todos SDC en el paquete \texttt{sdcMicro} se aplican autom√°ticamente dentro de los estratos, si se especifica el argumento `strataVar'.

Los ejemplos son la supresi√≥n local y PRAM. No se deben especificar todas las variables, por ejemplo, si no hay una estructura jer√°rquica (hogar), se puede omitir el argumento `hhId'. Los nombres de las variables corresponden a los nombres de las variables en el marco de datos que contiene los microdatos a anonimizar. La selecci√≥n de variables es importante para las medidas de riesgo que se calculan autom√°ticamente. Adem√°s, varios m√©todos se aplican por defecto a todas las variables de un tipo, por ejemplo, microagregaci√≥n a todas las variables clave \footnote{A menos que se especifique lo contrario en los argumentos de la funci√≥n.}. Despu√©s de seleccionar estas variables, podemos crear el objeto sdcMicro. Para obtener un resumen del objeto, es suficiente escribir el nombre del objeto.

\begin{example}
\protect\hypertarget{exm:bloqueMicro8}{}{\label{exm:bloqueMicro8} }Seleccionando variables y creando un objeto de clase \texttt{sdcMicroObj} para el proceso SDC en \texttt{R}
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Seleccionar variables para crear objeto sdcMicro}

\CommentTok{# Selecci√≥n de variables categ√≥ricas}
\NormalTok{selectedKeyVars <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{'URBRUR'}\NormalTok{, }\StringTok{'REGION'}\NormalTok{, }\StringTok{'HHSIZE'}\NormalTok{)}

\CommentTok{# Variables clave continuas}
\NormalTok{selectedNumVar <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{'TANHHEXP'}\NormalTok{, }\StringTok{'INCTOTGROSSHH'}\NormalTok{)}

\CommentTok{# PRAM variables}
\NormalTok{selectedPramVars <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{'ROOF'}\NormalTok{, }\StringTok{'TOILET'}\NormalTok{, }\StringTok{'WATER'}\NormalTok{, }\StringTok{'ELECTCON'}\NormalTok{,}
                \StringTok{'FUELCOOK'}\NormalTok{, }\StringTok{'OWNMOTORCYCLE'}\NormalTok{, }\StringTok{'CAR'}\NormalTok{, }\StringTok{'TV'}\NormalTok{, }\StringTok{'LIVESTOCK'}\NormalTok{)}

\CommentTok{# Peso del hogar}
\NormalTok{selectedWeightVar <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{'WGTPOP'}\NormalTok{)}


\CommentTok{# Creando el objeto sdcMicro con las variables asignadas}
\NormalTok{sdcInitial <-}\StringTok{ }\KeywordTok{createSdcObj}\NormalTok{(}\DataTypeTok{dat          =}\NormalTok{ file,}
                           \DataTypeTok{keyVars      =}\NormalTok{ selectedKeyVars,}
                           \DataTypeTok{numVar       =}\NormalTok{ selectedNumVar,}
                           \DataTypeTok{weightVar    =}\NormalTok{ selectedWeightVar,}
                           \DataTypeTok{pramVars     =}\NormalTok{ selectedPramVars)}

\CommentTok{# Resumen del objeto}
\NormalTok{sdcInitial}

\CommentTok{## ---------------------------------------------------------------------------}
\end{Highlighting}
\end{Shaded}

La Tabla \ref{tab:tabMicro2} presenta los nombres de los elementos y sus respectivos contenidos. Los nombres de los elementos se pueden listar usando la funci√≥n \texttt{slotNames()}, que se ilustra en el Bloque \ref{exm:bloqueMicro9}. Algunos espacios se llenan solo despu√©s de aplicar ciertos m√©todos, por ejemplo, evaluar una medida de riesgo espec√≠fica. Se puede acceder a ciertos elementos de los objetos mediante funciones de acceso (por ejemplo, \texttt{extractManipData} para extraer los datos an√≥nimos) o funciones de impresi√≥n (por ejemplo, \texttt{print()}) con los argumentos apropiados. Tambi√©n se puede acceder directamente al contenido de un espacio con el operador `@' y el nombre del espacio. Esto se ilustra para el elemento o atributo de riesgo en el Bloque \ref{exm:bloqueMicro9}. Esta funcionalidad puede ser pr√°ctica para guardar resultados intermedios y comparar los resultados de diferentes m√©todos. Adem√°s, para cambios manuales en los datos durante el proceso SDC, como cambiar c√≥digos de valores faltantes o recodificaci√≥n manual, es √∫til el acceso directo de los datos en los elementos o propiedades con los datos manipulados (es decir, nombres de elemento que comienzan con `manip'). Dentro de cada elemento generalmente hay varios elementos. Sus nombres se pueden mostrar con la funci√≥n \texttt{names()} y se puede acceder a ellos con el operador `\$'. Esto se muestra para el elemento con el riesgo individual en el elemento de riesgo.

\begin{example}
\protect\hypertarget{exm:bloqueMicro9}{}{\label{exm:bloqueMicro9} }Visualizaci√≥n de nombres de elementos o propiedades y acceso a elementos o propiedades de un objeto S4
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Lista de todos los slots de objeto sdcMicro}
\KeywordTok{slotNames}\NormalTok{(sdcInitial)}

\CommentTok{# Accediendo al slot de riesgos}
\NormalTok{sdcInitial}\OperatorTok{@}\NormalTok{risk}

\CommentTok{# Lista de nombres dentro del slot de riesgo}
\KeywordTok{names}\NormalTok{(sdcInitial}\OperatorTok{@}\NormalTok{risk)}
\CommentTok{## [1] "global"  "individual"  "numeric"}

\CommentTok{# Dos formas de acceder al riesgo individual dentro del slot de riesgo}
\NormalTok{sdcInitial}\OperatorTok{@}\NormalTok{risk}\OperatorTok{$}\NormalTok{individual}
\KeywordTok{get.sdcMicroObj}\NormalTok{(sdcInitial, }\StringTok{"risk"}\NormalTok{)}\OperatorTok{$}\NormalTok{individual}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:tabMicro2}Nombres de elementos o propiedades y descripci√≥n de los elementos o propiedades del objeto `sdcMicro`}
\centering
\begin{tabular}[t]{l|l}
\hline
Nombre de elemento & Contenido\\
\hline
`origData` & datos originales como se especifica en el argumento dat de la funci√≥n `createSdcObj()`.\\
\hline
`keyVars` & √≠ndices de columnas en `origData` con variables clave categ√≥ricas especificadas.\\
\hline
`pramVars` & √≠ndices de columnas en `origData` con variables PRAM especificadas.\\
\hline
`numVars` & √≠ndices de columnas en `origData` con variables clave num√©ricas especificadas.\\
\hline
`ghostVars` & √≠ndices de columnas en `origData` con `ghostVars` especificados.\\
\hline
`weightVar` & √≠ndices de columnas en `origData` con variable de peso especificada.\\
\hline
`hhId` & √≠ndices de columnas en `origData` con variable de cl√∫ster especificada.\\
\hline
`strataVar` & √≠ndices de columnas en `origData` con variable de estratos especificada.\\
\hline
`sensibleVar` & √≠ndices de columnas en `origData` con variables sensibles especificadas para *l-diversity*.\\
\hline
`manipKeyVars` & variables clave categ√≥ricas manipuladas despu√©s de aplicar m√©todos SDC (ver elemento `keyVars`).\\
\hline
`manipPramVars` & variables PRAM manipuladas despu√©s de aplicar PRAM (ver elemento `pramVars`).\\
\hline
`manipNumVar` & variables clave num√©ricas manipuladas despu√©s de aplicar m√©todos SDC (ver elemento `numVars`).\\
\hline
`manipGhostVars` & variables fantasma manipuladas (ver elemento `ghostVars`).\\
\hline
`manipStrataVar` & variables de estratos manipulados (ver elemento `strataVar`).\\
\hline
`originalRisk` & medidas de riesgo globales e individuales antes de la anonimizaci√≥n.\\
\hline
`risk` & medidas de riesgo global e individual despu√©s de la aplicaci√≥n de m√©todos SDC.\\
\hline
`utility` & medidas de utilidad (il1 y eigen).\\
\hline
`pram` & detalles sobre PRAM despu√©s de aplicar PRAM.\\
\hline
`localSuppression` & n√∫mero de supresi√≥n por variable despu√©s de la supresi√≥n local.\\
\hline
`options` & opciones especificadas.\\
\hline
`additionalResults` & resultados adicionales.\\
\hline
`set` & lista de elemento actualmente en uso (para uso interno).\\
\hline
`prev` & informaci√≥n para deshacer un paso con la funci√≥n `undo()`.\\
\hline
`deletedVars` & variables eliminadas (identificadores directos).\\
\hline
\end{tabular}
\end{table}

Hay dos opciones para guardar los resultados despu√©s de aplicar los m√©todos SDC:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Sobrescribir el objeto \texttt{sdcMicro} existente, o
\item
  creando un nuevo objeto \texttt{sdcMicro}. El objeto original no se modificar√° y se puede utilizar para comparar resultados. Esto es especialmente √∫til para comparar varios m√©todos y seleccionar la mejor opci√≥n.
\end{enumerate}

En ambos casos, el resultado de cualquier funci√≥n debe reasignarse a un objeto con el operador `\textless{}-'. Ambos m√©todos se ilustran en el Bloque \ref{exm:bloqueMicro10}.

\begin{example}
\protect\hypertarget{exm:bloqueMicro10}{}{\label{exm:bloqueMicro10} }Guardado de resultados de la aplicaci√≥n de m√©todos SDC
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Aplicar supresi√≥n local y reasignar los resultados al mismo objeto sdcMicro}
\NormalTok{sdcInitial <-}\StringTok{ }\KeywordTok{localSuppression}\NormalTok{(sdcInitial)}

\CommentTok{# Aplicar supresi√≥n local y asignar los resultados a un nuevo objeto sdcMicro}
\NormalTok{sdc1 <-}\StringTok{ }\KeywordTok{localSuppression}\NormalTok{(sdcInitial)}
\end{Highlighting}
\end{Shaded}

Si los resultados se reasignan al mismo objeto sdcMicro, es posible deshacer el √∫ltimo paso del proceso SDC. Esto es √∫til al cambiar los par√°metros. Sin embargo, los resultados del √∫ltimo paso se pierden despu√©s de deshacer ese paso.

La funci√≥n \texttt{undolast()} se puede usar para retroceder solo un paso, no varios. El resultado tambi√©n debe ser reasignado al mismo objeto. Esto se ilustra en el Bloque \ref{exm:bloqueMicro11}.

\begin{example}
\protect\hypertarget{exm:bloqueMicro11}{}{\label{exm:bloqueMicro11} }Deshacer √∫ltimo paso en proceso SDC
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Deshacer el √∫ltimo paso en el proceso SDC}
\NormalTok{sdcInitial <-}\StringTok{ }\KeywordTok{undolast}\NormalTok{(sdcInitial)}
\end{Highlighting}
\end{Shaded}

\hypertarget{estructura-del-hogar}{%
\section{Estructura del hogar}\label{estructura-del-hogar}}

Si los datos tienen una estructura jer√°rquica y algunas variables se miden en el nivel jer√°rquico m√°s alto y otras en el nivel m√°s bajo, el proceso SDC debe adaptarse en consecuencia (v√©anse tambi√©n la secci√≥n \protect\hyperlink{riesgo-jeruxe1rquico-o-del-hogar}{Riesgo jer√°rquico (o del hogar)}). Un ejemplo com√∫n en los datos de encuestas sociales son los conjuntos de datos con una estructura de hogar. Las variables que se miden a nivel del hogar son, por ejemplo, los ingresos del hogar, el tipo de vivienda y la regi√≥n. Las variables medidas a nivel individual son, por ejemplo, la edad, el nivel educativo y el estado civil. Algunas variables se miden a nivel individual, no obstante, son las mismas para todos los miembros del hogar en casi todos los hogares. Estas variables deben ser tratadas como medidas a nivel de hogar desde la perspectiva del SDC. Un ejemplo es la variable religi√≥n para algunos pa√≠ses.

El proceso SDC debe dividirse en dos etapas en los casos en que los datos tengan una estructura de hogar. Primero, las variables en el nivel superior (hogar) deben anonimizarse; posteriormente, las variables de nivel superior tratadas deben fusionarse con las variables individuales y anonimizarse conjuntamente. En esta secci√≥n, explicamos c√≥mo extraer variables del hogar de un archivo y fusionarlas con las variables de niveles individuales despu√©s del tratamiento en R. Ilustramos este proceso con un ejemplo de variables a nivel individual y del hogar.

Estos pasos se ilustran en el Bloque \ref{exm:bloqueMicro12}. Requerimos una identificaci√≥n individual y una identificaci√≥n familiar en el conjunto de datos; si faltan, deben generarse. La identificaci√≥n individual debe ser √∫nica para cada individuo en el conjunto de datos y la identificaci√≥n del hogar debe ser √∫nica para todos los hogares. El primer paso es extraer las variables del hogar y guardarlas en un nuevo marco de datos. Especificamos las variables que se miden a nivel del hogar en el vector de cadena ``HHVars'' y restamos solo estas variables del conjunto de datos. Este marco de datos tendr√° para cada hogar el mismo n√∫mero de entradas que miembros del hogar (por ejemplo, si un hogar tiene cuatro miembros, este hogar aparecer√° cuatro veces en el archivo). A continuaci√≥n, aplicamos la funci√≥n \texttt{unique()} para seleccionar solo un registro por hogar. Este argumento de la funci√≥n \texttt{unique()} es la identificaci√≥n del hogar, que es la misma para todos los miembros del hogar,

\begin{example}
\protect\hypertarget{exm:bloqueMicro12}{}{\label{exm:bloqueMicro12} }Crear un archivo a nivel de hogar con registros √∫nicos (eliminar duplicados) \footnote{Se recomienda verificar que el objeto fileHH tenga despu√©s de la aplicaci√≥n de la funci√≥n \texttt{unique()} la cantidad de filas esperadas (ej.: N¬∞ de viviendas encuestadas) y que no haya valores perdidos no esperados.}
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Crear subconjunto de archivo con solo variables medidas a nivel de hogar}
\NormalTok{HHVars <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{'IDH'}\NormalTok{, selectedKeyVars, selectedPramVars, selectedNumVar, selectedWeightVar)}
\NormalTok{fileHH <-}\StringTok{ }\NormalTok{file[,HHVars]}

\CommentTok{# Elimine las filas duplicadas en funci√≥n de la identificaci√≥n del hogar / }
\CommentTok{# solo cada hogar una vez en el fileHH}
\NormalTok{fileHH <-}\StringTok{ }\KeywordTok{unique}\NormalTok{(fileHH, }\DataTypeTok{by =} \KeywordTok{c}\NormalTok{(}\StringTok{'HID'}\NormalTok{))}

\CommentTok{# Dimensiones del fileHH (n√∫mero de hogares)}
\KeywordTok{dim}\NormalTok{(fileHH)}
\end{Highlighting}
\end{Shaded}

Despu√©s de anonimizar las variables del hogar con base en el marco de datos ``fileHH'', recombinamos las variables del hogar anonimizadas con las variables originales, que se miden a nivel individual. Podemos extraer las variables de nivel individual del conjunto de datos original usando ``INDVars'', un vector de cadena con los nombres de las variables de nivel individual. Para extraer los datos anonimizados del objeto sdcMicro, podemos usar la funci√≥n \texttt{extractManipData()} del paquete \texttt{sdcMicro}. A continuaci√≥n, fusionamos los datos usando la funci√≥n \texttt{merge()}. El argumento `by' en la funci√≥n \texttt{merge()} especifica la variable utilizada para la combinaci√≥n; en este caso, la identificaci√≥n del hogar, que tiene el mismo nombre de variable en ambos conjuntos de datos. Todas las dem√°s variables deben tener nombres diferentes en ambos conjuntos de datos. Estos pasos se ilustran en Bloque \ref{exm:bloqueMicro13}.

\begin{example}
\protect\hypertarget{exm:bloqueMicro13}{}{\label{exm:bloqueMicro13} }Fusi√≥n de variables anonimizadas a nivel de hogar con variables a nivel individual
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Crea objeto sdcMicro inicial para variables de nivel de hogar}
\NormalTok{sdcHH <-}\StringTok{ }\KeywordTok{createSdcObj}\NormalTok{(}\DataTypeTok{dat =}\NormalTok{ fileHH, }\DataTypeTok{keyVars =}\NormalTok{ selectedKeyVars,}
                      \DataTypeTok{pramVars =}\NormalTok{ selectedPramVars, }\DataTypeTok{weightVar =}\NormalTok{ selectedWeightVar,}
                      \DataTypeTok{numVars =}\NormalTok{ selectedNumVar)}
\NormalTok{numHH <-}\StringTok{ }\KeywordTok{length}\NormalTok{(fileHH[,}\DecValTok{1}\NormalTok{]) }\CommentTok{# n√∫mero de hogares}

\CommentTok{# Extrae variables de nivel de hogar manipuladas del objeto SDC}
\NormalTok{HHmanip <-}\StringTok{ }\KeywordTok{extractManipData}\NormalTok{(sdcHH)}

\CommentTok{# Selecciona variables (nivel individual)}
\NormalTok{selectedKeyVarsIND =}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{'GENDER'}\NormalTok{, }\StringTok{'REL'}\NormalTok{, }\StringTok{'MARITAL'}\NormalTok{,}\StringTok{'AGEYRS'}\NormalTok{,}
                       \StringTok{'EDUCY'}\NormalTok{, }\StringTok{'INDUSTRY1'}\NormalTok{) }\CommentTok{# lista de variables clave seleccionadas}

\CommentTok{# Peso de la muestra (WGTHH, pesos individuales)}
\NormalTok{selectedWeightVarIND =}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{'WGTHH'}\NormalTok{)}

\CommentTok{# ID hogar}
\NormalTok{selectedHouseholdID =}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{'IDH'}\NormalTok{)}

\CommentTok{# Todas las variables individuales}
\NormalTok{INDVars <-}\StringTok{ }\KeywordTok{c}\NormalTok{(selectedKeyVarsIND)}

\CommentTok{# Recombinando los datos HH anonimizados y las variables a nivel individual}
\NormalTok{indVars <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"IDH"}\NormalTok{, }\StringTok{"IDP"}\NormalTok{, selectedKeyVarsIND, }\StringTok{"WGTHH"}\NormalTok{) }\CommentTok{# IDH y todas las variantes no HH}
\NormalTok{fileInd <-}\StringTok{ }\NormalTok{file[indVars] }\CommentTok{# subset de file sin HHVars}
\NormalTok{fileCombined <-}\StringTok{ }\KeywordTok{merge}\NormalTok{(HHmanip, fileInd, }\DataTypeTok{by.x =} \KeywordTok{c}\NormalTok{(}\StringTok{'IDH'}\NormalTok{))}
\NormalTok{fileCombined <-}\StringTok{ }\NormalTok{fileCombined[}\KeywordTok{order}\NormalTok{(fileCombined[,}\StringTok{'IDH'}\NormalTok{],  fileCombined[,}\StringTok{'IDP'}\NormalTok{]),]}

\KeywordTok{dim}\NormalTok{(fileCombined)}

\CommentTok{# Objeto SDC con solo las variables a nivel IND}
\NormalTok{sdcCombined <-}\StringTok{ }\KeywordTok{createSdcObj}\NormalTok{(}\DataTypeTok{dat =}\NormalTok{ fileCombined, }\DataTypeTok{keyVars =} \KeywordTok{c}\NormalTok{(selectedKeyVarsIND),}
                            \DataTypeTok{weightVar =}\NormalTok{ selectedWeightVarIND, }\DataTypeTok{hhId =}\NormalTok{ selectedHouseholdID)}

\CommentTok{# Objeto SDC con ambos niveles de variables, a HH y IND}
\NormalTok{sdcCombinedAll <-}\StringTok{ }\KeywordTok{createSdcObj}\NormalTok{(}\DataTypeTok{dat =}\NormalTok{ fileCombined,}
                               \DataTypeTok{keyVars =} \KeywordTok{c}\NormalTok{(selectedKeyVarsIND, selectedKeyVars ),}
                               \DataTypeTok{weightVar =}\NormalTok{ selectedWeightVarIND, }
                               \DataTypeTok{hhId =}\NormalTok{ selectedHouseholdID)}
\NormalTok{sdcCombinedAll}
\end{Highlighting}
\end{Shaded}

El archivo fileCombined se utiliza para el proceso SDC con todo el conjunto de datos. En el estudio de casos de la secci√≥n \protect\hyperlink{caso-de-estudio}{Caso de estudio} se ilustra c√≥mo tratar los datos con la estructura del hogar.

El tama√±o de un hogar tambi√©n puede ser un identificador indirecto, incluso si el tama√±o del hogar no est√° incluido en el conjunto de datos como variable. Con el fin de evaluar el riesgo de divulgaci√≥n, podr√≠a ser necesario crear dicha variable mediante un recuento de los miembros de cada hogar. El Bloque \ref{exm:bloqueMicro14} muestra c√≥mo generar la variable de tama√±o de hogar, con valores para cada individuo en funci√≥n de la identificaci√≥n del hogar (IDH). Se muestran dos casos: 1) el archivo ordenado por IDH y 2) el archivo no ordenado.

\begin{example}
\protect\hypertarget{exm:bloqueMicro14}{}{\label{exm:bloqueMicro14} }Generando la variable tama√±o del hogar
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Ordenado por IDH}
\NormalTok{file}\OperatorTok{$}\NormalTok{hhsize <-}\StringTok{ }\KeywordTok{rep}\NormalTok{(}\KeywordTok{unname}\NormalTok{(}\KeywordTok{table}\NormalTok{(file}\OperatorTok{$}\NormalTok{IDH)), }\KeywordTok{unname}\NormalTok{(}\KeywordTok{table}\NormalTok{(file}\OperatorTok{$}\NormalTok{IDH)))}

\CommentTok{# Desordenado}
\NormalTok{file}\OperatorTok{$}\NormalTok{hhsize <-}\StringTok{ }\KeywordTok{rep}\NormalTok{(}\KeywordTok{diff}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1} \OperatorTok{+}\StringTok{ }\KeywordTok{which}\NormalTok{(}\KeywordTok{diff}\NormalTok{(file}\OperatorTok{$}\NormalTok{IDH) }\OperatorTok{!=}\StringTok{ }\DecValTok{0}\NormalTok{), }\KeywordTok{length}\NormalTok{(file}\OperatorTok{$}\NormalTok{IDH) }\OperatorTok{+}\StringTok{ }\DecValTok{1}\NormalTok{)),}
                   \KeywordTok{diff}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1} \OperatorTok{+}\StringTok{ }\KeywordTok{which}\NormalTok{(}\KeywordTok{diff}\NormalTok{(file}\OperatorTok{$}\NormalTok{IDH) }\OperatorTok{!=}\StringTok{ }\DecValTok{0}\NormalTok{), }\KeywordTok{length}\NormalTok{(file}\OperatorTok{$}\NormalTok{IDH) }\OperatorTok{+}\StringTok{ }\DecValTok{1}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

En algunos casos, el orden de las personas dentro de los hogares puede proporcionar informaci√≥n que podr√≠a conducir a la reidentificaci√≥n.

Un ejemplo es la informaci√≥n sobre la relaci√≥n con el jefe de hogar. En muchos pa√≠ses, el primer miembro del hogar es el cabeza de familia, el segundo es la pareja del cabeza de familia y los siguientes son los hijos. Por lo tanto, el n√∫mero de l√≠nea dentro del hogar podr√≠a correlacionarse bien con una variable que contiene informaci√≥n sobre la relaci√≥n con el jefe de hogar. Una forma de evitar esta divulgaci√≥n involuntaria de informaci√≥n es cambiar el orden de los individuos dentro de cada hogar al azar. El Bloque \ref{exm:bloqueMicro15} ilustra una manera de hacer esto en R.

\begin{example}
\protect\hypertarget{exm:bloqueMicro15}{}{\label{exm:bloqueMicro15} }Cambiando el orden de los individuos dentro de los hogares
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Cargando datos anonimizados }
\NormalTok{dataAnon<-}\KeywordTok{readRDS}\NormalTok{(}\StringTok{"dataAnon.RDS"}\NormalTok{)}

\CommentTok{# Lista de tama√±os de hogar por hogar}
\NormalTok{hhsize <-}\StringTok{ }\KeywordTok{diff}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1} \OperatorTok{+}\StringTok{ }\KeywordTok{which}\NormalTok{(}\KeywordTok{diff}\NormalTok{(dataAnon}\OperatorTok{$}\NormalTok{IDH) }\OperatorTok{!=}\StringTok{ }\DecValTok{0}\NormalTok{), }\KeywordTok{length}\NormalTok{(dataAnon}\OperatorTok{$}\NormalTok{IDH) }\OperatorTok{+}\StringTok{ }\DecValTok{1}\NormalTok{))}

\CommentTok{# N√∫meros de l√≠nea asignados al azar dentro de cada hogar}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\NormalTok{dataAnon}\OperatorTok{$}\NormalTok{INDID <-}\StringTok{ }\KeywordTok{unlist}\NormalTok{(}\KeywordTok{lapply}\NormalTok{(hhsize,}
                                \ControlFlowTok{function}\NormalTok{(n)\{}\KeywordTok{sample}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\NormalTok{n, n, }\DataTypeTok{replace =} \OtherTok{FALSE}\NormalTok{,}
                                                   \DataTypeTok{prob =} \KeywordTok{rep}\NormalTok{(}\DecValTok{1}\OperatorTok{/}\NormalTok{n, n))\}))}

\CommentTok{# Ordene el archivo por IDH y INDID aleatorio (n√∫mero de l√≠nea)}
\NormalTok{dataAnon <-}\StringTok{ }\NormalTok{dataAnon[}\KeywordTok{order}\NormalTok{(dataAnon}\OperatorTok{$}\NormalTok{IDH, dataAnon}\OperatorTok{$}\NormalTok{INDID),]}
\end{Highlighting}
\end{Shaded}

\hypertarget{tiempo-de-cuxf3mputo}{%
\section{Tiempo de c√≥mputo}\label{tiempo-de-cuxf3mputo}}

Algunos m√©todos SDC pueden tardar mucho tiempo en evaluarse en t√©rminos de c√≥mputo. Por ejemplo, la supresi√≥n local con la funci√≥n \texttt{localSuppression()} del paquete \texttt{sdcMicro} en \texttt{R} puede tardar d√≠as en ejecutarse en grandes conjuntos de datos de m√°s de 30.000 personas que tienen muchos identificadores indirectos categ√≥ricos. El uso de la funci√≥n \texttt{groupVars()}, por ejemplo, no es computacionalmente intensivo, pero a√∫n puede llevar mucho tiempo si el conjunto de datos es grande y las medidas de riesgo deben volver a calcularse.

Nuestra experiencia revela que el tiempo de c√≥mputo es una funci√≥n de los siguientes factores: el m√©todo SDC aplicado; tama√±o de los datos, es decir, n√∫mero de observaciones, n√∫mero de variables y n√∫mero de categor√≠as o niveles de factores de cada variable categ√≥rica; complejidad de los datos (por ejemplo, el n√∫mero de diferentes combinaciones de valores de identificadores indirectos en los datos); as√≠ como las especificaciones de la computadora (procesador, la memoria RAM y los medios de almacenamiento).

El uso de la paralelizaci√≥n puede mejorar el rendimiento incluso en una sola computadora con un procesador con m√∫ltiples n√∫cleos. \texttt{R} no utiliza m√∫ltiples n√∫cleos a menos que se le indique que lo haga. La paralelizaci√≥n permite que los trabajos/escenarios \footnote{Aqu√≠, un escenario se refiere a una combinaci√≥n de m√©todos SDC y sus par√°metros.} en los conjuntos de datos puedan procesarse simult√°neamente a trav√©s de la asignaci√≥n eficiente de tareas a diferentes procesadores. Sin paralelizaci√≥n, dependiendo del servidor/computadora, solo se usa un n√∫cleo cuando se ejecutan los trabajos secuencialmente. Ejecutar el programa de anonimizaci√≥n sin paralelizaci√≥n conduce a un tiempo de ejecuci√≥n significativamente mayor. Sin embargo, tenga en cuenta que la paralelizaci√≥n en s√≠ misma tambi√©n provoca una sobrecarga. Por lo tanto, una suma de los tiempos que lleva ejecutar cada tarea en paralelo no equivale necesariamente al tiempo que puede llevar ejecutarlas secuencialmente. Sin embargo, el hecho de que la RAM se comparta podr√≠a reducir ligeramente las ganancias de la paralelizaci√≥n \footnote{El siguiente sitio web proporciona una descripci√≥n general de los paquetes y soluciones de paralelizaci√≥n en \texttt{R} : \url{http://cran.r-project.org/web/views/HighPerformanceComputing.html}. }.

\hypertarget{errores-comunes}{%
\section{Errores comunes}\label{errores-comunes}}

En esta secci√≥n, presentamos algunos errores comunes y sus causas, que pueden encontrarse al usar el paquete \texttt{sdcMicro} en \texttt{R} para la anonimizaci√≥n de microdatos:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  La clase de una determinada variable no es aceptada por la funci√≥n, por ejemplo, una variable categ√≥rica de clase num√©rica debe recodificarse primero a la clase requerida (por ejemplo, factor o data.frame). En la secci√≥n \protect\hyperlink{clases-en-r}{Clases en \texttt{R}} se muestra c√≥mo hacerlo.
\item
  Despu√©s de realizar cambios manualmente en las variables, el riesgo no cambi√≥, ya que no se actualiza autom√°ticamente y debe volver a calcularse manualmente mediante la funci√≥n \texttt{calcRisks()}.
\end{enumerate}

\hypertarget{mediciuxf3n-de-riesgos}{%
\chapter{Medici√≥n de riesgos}\label{mediciuxf3n-de-riesgos}}

\hypertarget{tipos-de-divulgaciuxf3n}{%
\section{Tipos de divulgaci√≥n}\label{tipos-de-divulgaciuxf3n}}

Medir el riesgo de divulgaci√≥n es una parte importante del proceso SDC: las medidas de riesgo se utilizan para juzgar si un archivo de datos es lo suficientemente seguro para su liberaci√≥n. Antes de medir el riesgo de divulgaci√≥n, debemos definir qu√© tipo de divulgaci√≥n es relevante para los datos disponibles, a saber: divulgaci√≥n de identidad, divulgaci√≥n de atributos y divulgaci√≥n inferencial (ver \citet{lambert1993} y \citet{hundepool2012}).

\begin{itemize}
\item
  \textbf{Divulgaci√≥n de identidad}, que ocurre si el intruso asocia a un individuo conocido con un registro de datos publicado. Por ejemplo, el intruso vincula un registro de datos publicado con informaci√≥n externa o identifica a un informante con valores de datos extremos. En este caso, un intruso puede explotar un peque√±o subconjunto de variables para realizar la vinculaci√≥n, y una vez que la vinculaci√≥n es exitosa, el intruso tiene acceso a toda la dem√°s informaci√≥n en los datos publicados relacionados con el informante espec√≠fico.
\item
  \textbf{Divulgaci√≥n de atributos}, que ocurre si el intruso puede determinar algunas caracter√≠sticas nuevas de un individuo en funci√≥n de la informaci√≥n disponible en los datos publicados. La divulgaci√≥n de atributos ocurre si se vuelve a identificar correctamente a un informante y el conjunto de datos incluye variables que contienen informaci√≥n que el intruso desconoc√≠a previamente. La divulgaci√≥n de atributos tambi√©n puede ocurrir sin divulgaci√≥n de identidad. Por ejemplo, si un hospital publica datos que muestran que todas las pacientes de 56 a 60 a√±os que tienen c√°ncer, un intruso conoce la condici√≥n m√©dica de cualquier paciente de 56 a 60 a√±os en el conjunto de datos sin tener que identificar a la persona espec√≠fica.
\item
  \textbf{Divulgaci√≥n inferencial}, que ocurre si el intruso es capaz de determinar el valor de alguna caracter√≠stica de un individuo con mayor precisi√≥n con los datos liberados de lo que hubiera sido posible de otro modo. Por ejemplo, con un modelo de regresi√≥n altamente predictivo, un intruso puede inferir la informaci√≥n confidencial de ingresos de un informante utilizando atributos registrados en los datos, lo que lleva a una divulgaci√≥n inferencial.
\end{itemize}

Los m√©todos SDC para microdatos est√°n destinados a evitar la divulgaci√≥n de identidades y atributos. La divulgaci√≥n inferencial generalmente no se aborda en SDC en el entorno de microdatos, ya que los microdatos se liberan precisamente para que los investigadores puedan hacer inferencias estad√≠sticas y comprender las relaciones entre las variables. En ese sentido, la inferencia no puede compararse con la divulgaci√≥n. Adem√°s, las inferencias est√°n dise√±adas para predecir el comportamiento agregado, no individual y, por lo tanto, suelen ser malos predictores de valores de datos individuales.

\hypertarget{clasificaciuxf3n-de-variables}{%
\section{Clasificaci√≥n de variables}\label{clasificaciuxf3n-de-variables}}

A los efectos del proceso SDC, utilizamos las clasificaciones de variables descritas en los siguientes p√°rrafos (consulte la Figura \ref{fig:clasVars} para obtener una descripci√≥n general). La clasificaci√≥n inicial de variables en variables de identificaci√≥n y no identificaci√≥n depende de la forma en que los intrusos pueden utilizar las variables para la reidentificaci√≥n:

\begin{itemize}
\item
  \textbf{Variables de identificaci√≥n}: contienen informaci√≥n que puede conducir a la identificaci√≥n de los informantes y se pueden clasificar en:

  \begin{itemize}
  \item
    \textbf{Los identificadores directos}, que revelan de manera directa e inequ√≠voca la identidad del informante. Algunos ejemplos son nombres, n√∫meros de pasaporte, n√∫meros de identificaci√≥n social y direcciones. Los identificadores directos deben eliminarse del conjunto de datos antes de su publicaci√≥n. La eliminaci√≥n de identificadores directos es un proceso sencillo y siempre es el primer paso para producir un conjunto de microdatos seguro para su publicaci√≥n. Sin embargo, la eliminaci√≥n de identificadores directos a menudo no es suficiente.
  \item
    \textbf{Los identificadores indirectos (cuasi-identificadores o variables clave)} contienen informaci√≥n que, cuando se combina con otros identificadores indirectos en el conjunto de datos, puede conducir a la reidentificaci√≥n de los informantes. Este es especialmente el caso cuando se pueden usar para hacer coincidir la informaci√≥n con otra informaci√≥n o datos externos. Ejemplos de identificadores indirectos son la raza, la fecha de nacimiento, el sexo y el c√≥digo postal, que pueden combinarse o vincularse f√°cilmente con informaci√≥n externa disponible p√∫blicamente y hacer posible la identificaci√≥n. Las combinaciones de valores de varios identificadores indirectos se denominan claves. Los valores de los identificadores indirectos por s√≠ mismos a menudo no conducen a la identificaci√≥n (por ejemplo, hombre/mujer), pero una combinaci√≥n de varios valores de identificador indirecto puede hacer que un registro sea √∫nico (por ejemplo, hombre, 18 a√±os, casado) y, por lo tanto, identificable. En general, no es aconsejable eliminar simplemente los identificadores indirectos de los datos para resolver el problema. En muchos casos, ser√°n variables importantes para cualquier an√°lisis sensato. En la pr√°ctica, cualquier variable en el conjunto de datos podr√≠a potencialmente usarse como un identificador indirecto. SDC aborda esto mediante la identificaci√≥n de variables como identificadores indirectos y anonimiz√°ndolas mientras mantiene la informaci√≥n en el conjunto de datos para su publicaci√≥n.
  \end{itemize}
\item
  \textbf{Las variables de no identificaci√≥n} son variables que no se pueden utilizar para volver a identificar a los informantes. Esto podr√≠a deberse a que estas variables no est√°n contenidas en ning√∫n otro archivo de datos u otras fuentes externas y no son observables por un intruso. No obstante, las variables de no identificaci√≥n son importantes en el proceso SDC, ya que pueden contener informaci√≥n confidencial/sensible, que puede resultar perjudicial si se produce una divulgaci√≥n como resultado de la divulgaci√≥n de la identidad basada en variables de identificaci√≥n.
\end{itemize}

Estas clasificaciones de variables dependen parcialmente de la disponibilidad de conjuntos de datos externos que pueden contener informaci√≥n que, cuando se combina con los datos actuales, podr√≠a conducir a la divulgaci√≥n. La identificaci√≥n y clasificaci√≥n de variables como identificadores indirectos depende, entre otros, de la disponibilidad de informaci√≥n en conjuntos de datos externos. Un paso importante en el proceso SDC es definir una lista de posibles escenarios de divulgaci√≥n en funci√≥n de c√≥mo los identificadores indirectos podr√≠an combinarse entre s√≠ y la informaci√≥n en conjuntos de datos externos, y luego tratar los datos para evitar la divulgaci√≥n. Analizamos los escenarios de divulgaci√≥n con m√°s detalle en la secci√≥n \protect\hyperlink{escenarios-de-divulgaciuxf3n}{Escenarios de divulgaci√≥n}.

Para el proceso SDC, tambi√©n es √∫til clasificar a√∫n m√°s los identificadores indirectos en variables categ√≥ricas, continuas y semicontinuas o discretas. Esta clasificaci√≥n es importante para determinar los m√©todos SDC apropiados para esa variable, as√≠ como la validez de las medidas de riesgo.

\begin{itemize}
\item
  \textbf{Las variables categ√≥ricas} toman valores sobre un conjunto finito, y cualquier operaci√≥n aritm√©tica que las utilice generalmente no tiene sentido o no est√° permitida. Ejemplos de variables categ√≥ricas son g√©nero, regi√≥n y nivel educativo.
\item
  \textbf{Las variables continuas} pueden tomar un n√∫mero infinito de valores en un conjunto denso. Algunos ejemplos son los ingresos, la altura del cuerpo y el tama√±o del terreno. Las variables continuas se pueden transformar en variables categ√≥ricas mediante la construcci√≥n de intervalos (como bandas de ingresos)\footnote{Recodificar una variable continua a veces es √∫til en los casos en que los datos contienen solo unas pocas variables continuas. Veremos en la secci√≥n \protect\hyperlink{riesgo-individual}{Riesgo individual} que muchos m√©todos utilizados para el c√°lculo del riesgo dependen de si las variables son categ√≥ricas. Tambi√©n veremos que es m√°s f√°cil para la medici√≥n del riesgo si los datos contienen solo variables categ√≥ricas o solo continuas.}.
\item
  \textbf{Las variables semicontinuas o discretas} son variables continuas que toman valores limitados a un conjunto finito. Un ejemplo es la edad medida en a√±os, que podr√≠a tomar valores en el conjunto \{0, 1,\ldots{}, 100\}. La naturaleza finita de los valores de estas variables significa que pueden tratarse como variables categ√≥ricas a los efectos de SDC \footnote{Esto se discute con mayor detalle en las siguientes secciones. En los casos en que el n√∫mero de valores posibles sea grande, se recomienda recodificar la variable, o partes del conjunto en el que toma valores, para obtener menos valores distintos.}.
\end{itemize}

Adem√°s de estas clasificaciones de variables, el proceso SDC clasifica a√∫n m√°s las variables seg√∫n su sensibilidad o confidencialidad. Tanto las variables identificadoras indirectas como las de no identificaci√≥n pueden clasificarse como sensibles (o confidenciales) o no sensibles (o no confidenciales). Esta distinci√≥n no es importante para los identificadores directos, ya que los identificadores directos se eliminan de los datos publicados.

\begin{itemize}
\item
  \textbf{Las variables sensibles} contienen informaci√≥n confidencial que no debe liberarse sin un tratamiento adecuado, utilizando los m√©todos de SDC para reducir el riesgo de divulgaci√≥n. Algunos ejemplos son los ingresos, la religi√≥n, la afiliaci√≥n pol√≠tica y las variables relativas a la salud. Que una variable sea sensible depende del contexto y del pa√≠s: una determinada variable puede considerarse sensible en un pa√≠s y no sensible en otro.
\item
  \textbf{Las variables no sensibles} contienen informaci√≥n no confidencial sobre el informante, como el lugar de residencia o el √°rea de residencia rural/urbana. Sin embargo, la clasificaci√≥n de una variable como no sensible no significa que no deba ser considerada en el proceso de SDC. Las variables no sensibles a√∫n pueden servir como identificadores indirectos cuando se combinan con otras variables u otros datos externos.
\end{itemize}

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{Imagenes/clasi_vars} 

}

\caption{Clasificaci√≥n de las variables.}\label{fig:clasVars}
\end{figure}

\hypertarget{escenarios-de-divulgaciuxf3n}{%
\section{Escenarios de divulgaci√≥n}\label{escenarios-de-divulgaciuxf3n}}

La evaluaci√≥n del riesgo de divulgaci√≥n se lleva a cabo con referencia a las fuentes de datos disponibles en el entorno donde se liberar√° el conjunto de datos. En este contexto, el riesgo de divulgaci√≥n es la posibilidad de volver a identificar correctamente a una unidad en el archivo de microdatos publicado \footnote{No todos los datos externos son necesariamente de dominio p√∫blico. Tambi√©n se deben tener en cuenta los conjuntos de datos de propiedad privada o los conjuntos de datos que no se divulgan para determinar el escenario de divulgaci√≥n adecuado.} comparando sus datos con un archivo externo basado en un conjunto de identificadores indirectos. La evaluaci√≥n de riesgos se realiza mediante la identificaci√≥n de los llamados escenarios de divulgaci√≥n o intrusi√≥n. Un escenario de divulgaci√≥n describe la informaci√≥n potencialmente disponible para el intruso (por ejemplo, datos del censo, padrones electorales, registros de poblaci√≥n o datos recopilados por empresas privadas) para identificar a los informantes y las formas en que dicha informaci√≥n puede combinarse con el conjunto de microdatos que se liberar√° y utilizar√° para reidentificaci√≥n de registros en el conjunto de datos. Normalmente, estos conjuntos de datos externos incluyen identificadores directos. En ese caso, la reidentificaci√≥n de los registros en el conjunto de datos publicado conduce a la divulgaci√≥n de la identidad y, posiblemente, de los atributos. El principal resultado de la evaluaci√≥n de los escenarios de divulgaci√≥n es la identificaci√≥n de un conjunto de identificadores indirectos (es decir, variables clave) que deben tratarse durante el proceso SDC (ver \citet{elliot2010}).

Un ejemplo de un escenario de divulgaci√≥n podr√≠a ser el reconocimiento espont√°neo de un informante por parte de un investigador. Por ejemplo, mientras revisa los datos, el investigador reconoce a una persona con una combinaci√≥n inusual de las variables edad y estado civil. Por supuesto, esto solo puede suceder si la persona es bien conocida o es conocida por el investigador. Otro ejemplo de un escenario de divulgaci√≥n para un archivo disponible p√∫blicamente ser√≠a si las variables en los datos pudieran vincularse a un registro electoral disponible p√∫blicamente. Un intruso podr√≠a hacer coincidir todo el conjunto de datos con las personas del registro. Sin embargo, esto puede ser dif√≠cil y requerir experiencia especializada, o \emph{software}, y se deben cumplir otras condiciones. Los ejemplos son que el momento en el que se recopilaron los conjuntos de datos debe coincidir aproximadamente y el contenido de las variables debe ser (casi) id√©ntico. Si no se cumplen estas condiciones, la coincidencia exacta es mucho menos probable.

La evaluaci√≥n del riesgo de divulgaci√≥n se basa en los identificadores indirectos, que se identifican en el an√°lisis de escenarios de riesgo de divulgaci√≥n. El riesgo de divulgaci√≥n depende directamente de la inclusi√≥n o exclusi√≥n de variables en el conjunto de identificadores indirectos elegidos. Por lo tanto, este paso en el proceso SDC (hacer la elecci√≥n de los identificadores indirectos) debe abordarse con gran reflexi√≥n y cuidado. Veremos m√°s adelante, cuando discutamos los pasos en el proceso de SDC con m√°s detalle, que el primer paso para cualquier oficina de estad√≠stica es realizar un ejercicio en el que se compila un inventario de todos los conjuntos de datos disponibles en el pa√≠s. Se consideran tanto los conjuntos de datos publicados por la oficina nacional de estad√≠stica (como el INE) como por otras fuentes y se analiza su disponibilidad para los intrusos, as√≠ como las variables incluidas en estos conjuntos de datos.

\hypertarget{niveles-de-riesgo}{%
\section{Niveles de riesgo}\label{niveles-de-riesgo}}

Con microdatos de encuestas y censos, a menudo tenemos que preocuparnos por la divulgaci√≥n a nivel individual o de unidad, es decir, identificar a los informantes individuales. Los informantes individuales suelen ser personas f√≠sicas, pero tambi√©n pueden ser unidades, como empresas, escuelas, centros de salud, etc. Los archivos de microdatos suelen tener una estructura jer√°rquica en la que las unidades individuales pertenecen a grupos, por ejemplo, las personas pertenecen a hogares. La estructura jer√°rquica m√°s com√∫n en los microdatos es la estructura del hogar en los datos de las encuestas de hogares. Por lo tanto, en esta gu√≠a, a veces llamamos al riesgo de divulgaci√≥n de datos con una estructura jer√°rquica ``riesgo hogar''. Sin embargo, los conceptos se aplican por igual a los datos del establecimiento y otros datos con estructuras jer√°rquicas, como los datos de la escuela con los alumnos y profesores o los datos de la empresa con los empleados.

Veremos que es importante tener en cuenta esta estructura jer√°rquica al medir el riesgo de divulgaci√≥n. Para los datos jer√°rquicos, la informaci√≥n recopilada en el nivel jer√°rquico superior (por ejemplo, nivel del hogar) ser√≠a la misma para todos los individuos del grupo que pertenecen a ese nivel jer√°rquico superior (por ejemplo, el hogar) {[}Los supuestos para esta medida de riesgo son estrictos y el riesgo se estima en muchos casos mayor que el riesgo real. Entre otras suposiciones, se supone que todos los individuos de la muestra tambi√©n est√°n incluidos en el archivo externo utilizado por el intruso para compararlos. Si no es as√≠, el riesgo es mucho menor; si el individuo en el archivo liberado no est√° incluido en el archivo externo, la probabilidad de una coincidencia correcta es cero. Otras suposiciones son que los archivos no contienen errores y que ambos conjuntos de datos se recopilaron simult√°neamente, es decir, contienen la misma informaci√≥n. Estos supuestos a menudo no se cumplen en general, pero son necesarios para el c√°lculo de una medida. Un ejemplo de una violaci√≥n de las √∫ltimas suposiciones podr√≠a ocurrir si los conjuntos de datos se recopilan en diferentes puntos en el tiempo y los registros han cambiado. Esto podr√≠a suceder cuando las personas se mudan o cambian de trabajo y hace imposible la coincidencia correcta. \textbf{Los supuestos son conservadores y asumen el mayor riesgo de divulgaci√≥n}.{]}. Algunos ejemplos t√≠picos de variables que tendr√≠an los mismos valores para todos los miembros de una misma unidad jer√°rquica superior son, en el caso de los hogares, las relativas a la vivienda y los ingresos del hogar. Estas variables difieren de una encuesta a otra y de un pa√≠s a otro \footnote{Consulte la secci√≥n \protect\hyperlink{objetos-de-la-clase-sdcmicroobj}{Objetos de la clase \texttt{sdcMicroObj}} para obtener m√°s informaci√≥n sobre los \emph{slots} y la estructura del objeto \texttt{sdcMicro}.}. Esta estructura jer√°rquica crea un mayor nivel de riesgo de divulgaci√≥n por dos razones:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  si se reidentifica a una persona del hogar, la estructura del hogar permite la reidentificaci√≥n de los dem√°s miembros del hogar en el mismo hogar,
\item
  los valores de las variables para otros miembros del hogar que son comunes para todos los miembros del hogar pueden usarse para volver a identificar a otro individuo del mismo hogar. Esto se analiza con m√°s detalle en la secci√≥n \protect\hyperlink{riesgo-jeruxe1rquico-o-del-hogar}{Riesgo jer√°rquico (o del hogar)}.
\end{enumerate}

A continuaci√≥n, primero analizamos las medidas de riesgo utilizadas para evaluar el riesgo de divulgaci√≥n en ausencia de una estructura jer√°rquica. Esto incluye medidas de riesgo que buscan agregar el riesgo individual para todos los individuos en el archivo de microdatos; el objetivo es cuantificar una medida de riesgo de divulgaci√≥n global para el archivo. Luego discutimos c√≥mo cambian las medidas de riesgo cuando se tiene en cuenta la estructura jer√°rquica de los datos.

Tambi√©n discutiremos c√≥mo las medidas de riesgo difieren para los identificadores indirectos categ√≥ricos y continuos. Para las variables categ√≥ricas, utilizaremos el concepto de unicidad de combinaciones de valores de identificadores indirectos (las llamadas ``claves'') que se utilizan para identificar a las personas en riesgo. El concepto de unicidad, sin embargo, no es √∫til para variables continuas, ya que es probable que todos o muchos individuos tengan valores √∫nicos para esa variable, por definici√≥n de una variable continua. Las medidas de riesgo para variables categ√≥ricas son generalmente medidas a priori, es decir, pueden evaluarse antes de aplicar m√©todos de anonimizaci√≥n ya que se basan en el principio de unicidad. Las medidas de riesgo para variables continuas son medidas a posteriori; se basan en la comparaci√≥n de los microdatos antes y despu√©s de la anonimizaci√≥n y son, por ejemplo, basadas en la proximidad de observaciones entre conjuntos de datos originales y tratados (anonimizados).

Los archivos que se limitan solo a identificadores indirectos categ√≥ricos o continuos son los m√°s f√°ciles para medir el riesgo. Veremos en secciones posteriores que, en los casos en que ambos tipos de variables est√°n presentes, la recodificaci√≥n de variables continuas en categor√≠as es un enfoque para simplificar el proceso SDC, pero tambi√©n veremos que desde una perspectiva de utilidad esto puede no ser deseable. Un ejemplo podr√≠a ser el uso de quintiles de ingresos en lugar de las variables de ingresos reales. Veremos que medir el riesgo de divulgaci√≥n con base en las variables categ√≥ricas y continuas por separado generalmente no es un enfoque v√°lido.

Las medidas de riesgo discutidas en la siguiente secci√≥n se basan en varios supuestos. En general, estas medidas se basan en suposiciones bastante restrictivas y, a menudo, conducir√°n a estimaciones de riesgo conservadoras. Estas medidas de riesgo conservadoras pueden exagerar el riesgo ya que suponen el peor de los casos. Sin embargo, se deben cumplir dos suposiciones para que las medidas de riesgo sean v√°lidas y significativas; los microdatos deben ser una muestra de una poblaci√≥n m√°s grande (no censo) y las ponderaciones de la muestra deben estar disponibles.

\hypertarget{riesgo-individual}{%
\section{Riesgo individual}\label{riesgo-individual}}

\hypertarget{identificadores-indirectos-categuxf3ricos-y-recuentos-de-frecuencia}{%
\subsection{Identificadores indirectos categ√≥ricos y recuentos de frecuencia}\label{identificadores-indirectos-categuxf3ricos-y-recuentos-de-frecuencia}}

El enfoque principal de la medici√≥n del riesgo para los identificadores indirectos categ√≥ricos es la divulgaci√≥n de la identidad. La medici√≥n del riesgo de divulgaci√≥n se basa en la evaluaci√≥n de la probabilidad de reidentificaci√≥n correcta de las personas en los datos publicados. Utilizamos medidas basadas en los microdatos reales que se publicar√°n. En general, cuanto m√°s rara sea la combinaci√≥n de valores de los identificadores indirectos (es decir, clave) de una observaci√≥n en la muestra, mayor ser√° el riesgo de revelaci√≥n de identidad. Un intruso que intente hacer coincidir a una persona que tiene una clave relativamente rara dentro de los datos de muestra con un conjunto de datos externo en el que existe la misma clave tendr√° una mayor probabilidad de encontrar una coincidencia correcta que cuando un n√∫mero mayor de personas comparten la misma clave. Esto se puede ilustrar con el siguiente ejemplo que se ilustra en la Tabla \ref{tab:tabMR1}.

La Tabla \ref{tab:tabMR1} muestra los valores de 10 informantes para los identificadores indirectos ``√°rea'', ``g√©nero'', ``nivel educacional'' y ``situaci√≥n laboral''. En los datos, encontramos siete combinaciones √∫nicas de valores de identificadores indirectos (es decir, patrones o claves) de los cuatro identificadores indirectos. Ejemplos de claves son \{`urbano', `femenino', `secundaria incompleta', `ocupado'\} y \{`urbano', `femenino', `primaria incompleta', `no FL'\}. Sea \(f_{k}\) la frecuencia de muestreo de la \emph{k-√©sima} clave, es decir, el n√∫mero de individuos de la muestra con valores de los identificadores indirectos que coinciden con la clave \emph{k}. Este ser√≠a 2 para la clave \{urbano, femenino, secundaria incompleta, ocupado\}, ya que esta clave es compartida por los individuos 1 y 2 y 1 para la clave \{`urbano', `femenino', `primaria incompleta', `no FL'\}, que es exclusivo del individuo 3. Por definici√≥n, \(f_{k}\) es el mismo para cada registro que comparte una clave particular.

\begin{table}

\caption{\label{tab:tabMR1}Conjunto de datos de ejemplo que muestra frecuencias de muestra, frecuencias de poblaci√≥n y riesgo de divulgaci√≥n individual}
\centering
\begin{tabular}[t]{c|c|c|c|c|c|c|c|c}
\hline
Id & √Årea & G√©nero & Nivel educacional & Situaci√≥n laboral & Peso (\$w\_\{i\}\$) & \$f\_\{k\}\$ & \$F\_\{k\}\$  & Riesgo (\$r\_\{k\}\$)\\
\hline
1 & Urbano & Femenino & Secundaria incompleta & Ocupado & 180 & 2 & 360 & 0.0054\\
\hline
2 & Urbano & Femenino & Secundaria incompleta & Ocupado & 180 & 2 & 360 & 0.0054\\
\hline
3 & Urbano & Femenino & Primaria incompleta & No FL & 215 & 1 & 215 & 0.0251\\
\hline
4 & Urbano & Masculino & Secundaria completa & Ocupado & 76 & 2 & 152 & 0.0126\\
\hline
5 & Rural & Femenino & Secundaria completa & Desocupado & 186 & 1 & 186 & 0.0282\\
\hline
6 & Urbano & Masculino & Secundaria completa & Ocupado & 76 & 2 & 152 & 0.0126\\
\hline
7 & Urbano & Femenino & Primaria completa & No FL & 180 & 1 & 180 & 0.029\\
\hline
8 & Urbano & Masculino & Post secundaria & Desocupado & 215 & 1 & 215 & 0.0251\\
\hline
9 & Urbano & Femenino & Secundaria incompleta & No FL & 186 & 2 & 262 & 0.0074\\
\hline
10 & Urbano & Femenino & Secundaria incompleta & No FL & 76 & 2 & 262 & 0.0074\\
\hline
\end{tabular}
\end{table}

Fuente: Adaptaci√≥n de \citep[p.28]{benschop}

Cuanto menos personas con las que una persona comparte su combinaci√≥n de identificadores indirectos, m√°s probable es que la persona coincida correctamente en otro conjunto de datos que contenga estos identificadores indirectos. Incluso cuando los identificadores directos se eliminan del conjunto de datos, esa persona tiene un mayor riesgo de divulgaci√≥n que otras, suponiendo que sus pesos de muestra sean los mismos. La Tabla \ref{tab:tabMR1} reporta las frecuencias de muestreo \(f_{k}\) de las llaves para todos los individuos. Las personas con las mismas claves tienen la misma frecuencia de muestreo. Si \(f_{k}=1\), este individuo tiene una combinaci√≥n √∫nica de valores de identificadores indirectos y se denomina ``muestra √∫nica''. El conjunto de datos de la Tabla \ref{tab:tabMR1} contiene cuatro muestras √∫nicas. Las medidas de riesgo se basan en esta frecuencia de muestreo.

En el Bloque \ref{exm:bloqueMR1}, mostramos c√≥mo usar el paquete \texttt{sdcMicro} para crear una lista de frecuencias de muestra \(f_{k}\) para cada registro en un conjunto de datos. Esto se hace usando la funci√≥n \texttt{sdcMicro} \texttt{freq()}. Un valor de 2 para una observaci√≥n significa que en la muestra hay un individuo m√°s con exactamente la misma combinaci√≥n de valores para los identificadores indirectos seleccionados. En el Bloque \ref{exm:bloqueMR1}, la funci√≥n \texttt{freq()} se aplica a ``sdcInitial'', que es un objeto \texttt{sdcMicro}. Los objetos se usan cuando se hace SDC con \texttt{sdcMicro}. La funci√≥n \texttt{freq()} muestra la frecuencia de muestreo de las claves construidas sobre un conjunto definido de identificadores indirectos. El Bloque \ref{exm:bloqueMR1} corresponde a los datos de la Tabla \ref{tab:tabMR1}.

\begin{example}
\protect\hypertarget{exm:bloqueMR1}{}{\label{exm:bloqueMR1} }C√°lculo \(f_{k}\) usando \texttt{sdcMicro}
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{setwd}\NormalTok{(}\StringTok{"..\textbackslash{}Capacitaci√≥n\textbackslash{}GitHub"}\NormalTok{) }\CommentTok{# directorio de trabajo}

\KeywordTok{library}\NormalTok{(sdcMicro) }\CommentTok{# carga paquete sdcMicro}
\CommentTok{# Set up conjunto de datos}
\NormalTok{data <-}\StringTok{ }\KeywordTok{as.data.frame}\NormalTok{(}\KeywordTok{cbind}\NormalTok{(}\KeywordTok{as.factor}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{'Urbano'}\NormalTok{, }\StringTok{'Urbano'}\NormalTok{, }\StringTok{'Urbano'}\NormalTok{, }\StringTok{'Urbano'}\NormalTok{,}
                                        \StringTok{'Rural'}\NormalTok{, }\StringTok{'Urbano'}\NormalTok{, }\StringTok{'Urbano'}\NormalTok{, }\StringTok{'Urbano'}\NormalTok{,}
                                        \StringTok{'Urbano'}\NormalTok{, }\StringTok{'Urbano'}\NormalTok{)),}
                            \KeywordTok{as.factor}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{'Femenino'}\NormalTok{, }\StringTok{'Femenino'}\NormalTok{, }\StringTok{'Femenino'}\NormalTok{,}
                                        \StringTok{'Masculino'}\NormalTok{,}\StringTok{'Femenino'}\NormalTok{, }\StringTok{'Masculino'}\NormalTok{,}
                                        \StringTok{'Femenino'}\NormalTok{, }\StringTok{'Masculino'}\NormalTok{, }\StringTok{'Femenino'}\NormalTok{,}
                                        \StringTok{'Femenino'}\NormalTok{)),}
                            \KeywordTok{as.factor}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{'Sec in'}\NormalTok{, }\StringTok{'Sec in'}\NormalTok{, }\StringTok{'Prim in'}\NormalTok{, }\StringTok{'Sec com'}\NormalTok{,}
                                        \StringTok{'Sec com'}\NormalTok{, }\StringTok{'Sec com'}\NormalTok{, }\StringTok{'Prim com'}\NormalTok{, }\StringTok{'Post-sec'}\NormalTok{,}
                                        \StringTok{'Sec in'}\NormalTok{, }\StringTok{'Sec in'}\NormalTok{)),}
                            \KeywordTok{as.factor}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{'Ocu'}\NormalTok{, }\StringTok{'Ocu'}\NormalTok{, }\StringTok{'No-FL'}\NormalTok{, }\StringTok{'Ocu'}\NormalTok{, }\StringTok{'Desocu'}\NormalTok{, }\StringTok{'Ocu'}\NormalTok{,}
                                        \StringTok{'No-FL'}\NormalTok{, }\StringTok{'Desocu'}\NormalTok{, }\StringTok{'No-FL'}\NormalTok{,}\StringTok{'No-FL'}\NormalTok{)),}
                            \KeywordTok{as.factor}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{'S√≠'}\NormalTok{, }\StringTok{'S√≠'}\NormalTok{, }\StringTok{'S√≠'}\NormalTok{, }\StringTok{'S√≠'}\NormalTok{, }\StringTok{'S√≠'}\NormalTok{, }\StringTok{'No'}\NormalTok{, }\StringTok{'No'}\NormalTok{,}
                                        \StringTok{'S√≠'}\NormalTok{, }\StringTok{'No'}\NormalTok{, }\StringTok{'S√≠'}\NormalTok{)),}
                            \KeywordTok{c}\NormalTok{(}\DecValTok{180}\NormalTok{, }\DecValTok{180}\NormalTok{, }\DecValTok{215}\NormalTok{, }\DecValTok{76}\NormalTok{, }\DecValTok{186}\NormalTok{, }\DecValTok{76}\NormalTok{, }\DecValTok{180}\NormalTok{, }\DecValTok{215}\NormalTok{, }\DecValTok{186}\NormalTok{, }\DecValTok{76}\NormalTok{)}
\NormalTok{))}

\CommentTok{# Especificar nombres de variables}
\KeywordTok{names}\NormalTok{(data) <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{'√Årea'}\NormalTok{, }\StringTok{'G√©nero'}\NormalTok{, }\StringTok{'Educ'}\NormalTok{, }\StringTok{'SitLab'}\NormalTok{, }\StringTok{'Salud'}\NormalTok{, }\StringTok{'Pesos'}\NormalTok{)               }

\CommentTok{# Set up objeto sdcMicro con especificaci√≥n de identificadores indirectos y pesos}
\NormalTok{sdcInitial <-}\StringTok{ }\KeywordTok{createSdcObj}\NormalTok{(}\DataTypeTok{dat =}\NormalTok{ data, }\DataTypeTok{keyVars =} \KeywordTok{c}\NormalTok{(}\StringTok{'√Årea'}\NormalTok{, }\StringTok{'G√©nero'}\NormalTok{, }\StringTok{'Educ'}\NormalTok{, }\StringTok{'SitLab'}\NormalTok{),}
                           \DataTypeTok{weightVar =} \StringTok{'Pesos'}\NormalTok{)}
\NormalTok{data}\OperatorTok{$}\NormalTok{fk<-}\KeywordTok{freq}\NormalTok{(sdcInitial, }\DataTypeTok{type =} \StringTok{'fk'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Para datos de muestra, es m√°s interesante mirar \(F_{k}\), la frecuencia de poblaci√≥n de una combinaci√≥n de identificadores indirectos (clave) \emph{k}, que es el n√∫mero de individuos de la poblaci√≥n con la clave que corresponde a la clave \emph{k}. Se desconoce la frecuencia poblacional si los microdatos son una muestra y no un censo. Bajo ciertas suposiciones, el valor esperado de las frecuencias de la poblaci√≥n se puede calcular utilizando el peso del dise√±o de la muestra \(w_{i}\)(en una muestra simple, esta es la inversa de la probabilidad de inclusi√≥n) para cada individuo \emph{i}.

\[F_{k}=\sum_{i|individuo\,i\, correspondiente\, a\, la\, clave\, k} w_{i}\]

\(F_{k}\) es la suma de los pesos muestrales de todos los registros con la misma clave \emph{k}. Por lo tanto, como \(f_{k}\), \(F_{k}\) es el mismo para cada registro con clave \emph{k}. El riesgo de una reidentificaci√≥n correcta es la probabilidad de que la clave coincida con el individuo correcto de la poblaci√≥n. Dado que cada individuo en la muestra con clave \emph{k} corresponde a \(F_{k}\) individuos en la poblaci√≥n, la probabilidad de reidentificaci√≥n correcta es \(1/F_{k}\). Esta es la probabilidad de reidentificaci√≥n en el peor de los casos y puede interpretarse como riesgo de divulgaci√≥n. Los individuos con la misma clave tienen las mismas frecuencias, es decir, la frecuencia de la clave.

Si \(F_{k}=1\), la clave \emph{k} es tanto una muestra como una poblaci√≥n √∫nica y el riesgo de divulgaci√≥n ser√≠a 1. Las caracter√≠sticas √∫nicas de la poblaci√≥n son un factor importante a considerar al evaluar el riesgo y merecen especial atenci√≥n.

Adem√°s, \(f_{k}\), la frecuencia de muestreo de la clave \emph{k} (es decir, el n√∫mero de individuos en la muestra con la combinaci√≥n de identificadores indirectos correspondientes a la combinaci√≥n especificada en la clave \emph{k}) y \(F_{k}\), la frecuencia de poblaci√≥n estimada de \emph{k}, se puede visualizar en \texttt{sdcMicro}. El Bloque \ref{exm:bloqueMR2} ilustra c√≥mo devolver listas de longitud \emph{n} de frecuencias para todos los individuos. Las frecuencias se muestran para cada individuo y no para cada clave.

\begin{example}
\protect\hypertarget{exm:bloqueMR2}{}{\label{exm:bloqueMR2} }C√°lculo de frecuencias muestrales y poblacionales usando \texttt{sdcMicro}
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# frecuencia muestral de individuos}
\NormalTok{data}\OperatorTok{$}\NormalTok{fk<-}\KeywordTok{freq}\NormalTok{(sdcInitial, }\DataTypeTok{type =} \StringTok{'fk'}\NormalTok{)}
\CommentTok{# frecuencia poblacional de individuos}
\NormalTok{data}\OperatorTok{$}\NormalTok{FK<-}\KeywordTok{freq}\NormalTok{(sdcInitial, }\DataTypeTok{type =} \StringTok{'Fk'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

En la pr√°ctica, este enfoque conduce a estimaciones de riesgo conservadoras, ya que no tiene en cuenta adecuadamente los m√©todos de muestreo. En este caso, las estimaciones del riesgo de reidentificaci√≥n pueden ser demasiado altas. Si se utiliza este riesgo sobreestimado, los datos pueden estar sobreprotegidos (es decir, la p√©rdida de informaci√≥n ser√° mayor que la necesaria) al aplicar las medidas de SDC.

La medida del riesgo \(r_{k}\) es como \(f_{k}\) y \(F_{k}\), el mismo para todos los individuos que comparten el mismo patr√≥n de valores de identificadores indirectos y se denomina riesgo individual. Los valores \(r_{k}\) tambi√©n puede interpretarse como la probabilidad de divulgaci√≥n de los individuos o como la probabilidad de una coincidencia exitosa con individuos elegidos al azar de un archivo de datos externo con los mismos valores de los identificadores indirectos. Esta medida de riesgo se basa en ciertos supuestos \footnote{Los supuestos para esta medida de riesgo son estrictos y el riesgo se estima en muchos casos mayor que el riesgo real. Entre otras suposiciones, se supone que todos los individuos de la muestra tambi√©n est√°n incluidos en el archivo externo utilizado por el intruso para compararlos. Si no es as√≠, el riesgo es mucho menor; si el individuo en el archivo liberado no est√° incluido en el archivo externo, la probabilidad de una coincidencia correcta es cero. Otras suposiciones son que los archivos no contienen errores y que ambos conjuntos de datos se recopilaron simult√°neamente, es decir, contienen la misma informaci√≥n. Estos supuestos a menudo no se cumplen en general, pero son necesarios para el c√°lculo de una medida. Un ejemplo de una violaci√≥n de las √∫ltimas suposiciones podr√≠a ocurrir si los conjuntos de datos se recopilan en diferentes puntos en el tiempo y los registros han cambiado. Esto podr√≠a suceder cuando las personas se mudan o cambian de trabajo y hace imposible la coincidencia correcta. \textbf{Los supuestos son conservadores y asumen el mayor riesgo de divulgaci√≥n}.}, que son estrictos y pueden conducir a una medida de riesgo relativamente conservadora. En \texttt{sdcMicro}, la medida de riesgo \(r_{k}\) se calcula autom√°ticamente al crear un objeto \texttt{sdcMicro} y se guarda en el \emph{slot} de ``riesgo'' \footnote{Consulte la secci√≥n \protect\hyperlink{objetos-de-la-clase-sdcmicroobj}{Objetos de la clase \texttt{sdcMicroObj}} para obtener m√°s informaci√≥n sobre los \emph{slots} y la estructura del objeto \texttt{sdcMicro}.}. El Bloque \ref{exm:bloqueMR3} muestra c√≥mo recuperar las medidas de riesgo usando \texttt{sdcMicro} para nuestro ejemplo. Las medidas de riesgo tambi√©n se presentan en la Tabla \ref{tab:tabMR1}.

\begin{example}
\protect\hypertarget{exm:bloqueMR3}{}{\label{exm:bloqueMR3} }Slot de riesgo individual en el objeto \texttt{sdcMicro}
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sdcInitial}\OperatorTok{@}\NormalTok{risk}\OperatorTok{$}\NormalTok{individual}
\end{Highlighting}
\end{Shaded}

Los principales factores que influyen en el riesgo individual son las frecuencias de muestreo \(f_{k}\) y los pesos de dise√±o de muestreo \(w_{i}\). Si un individuo tiene un riesgo relativamente alto de divulgaci√≥n, en nuestro ejemplo ser√≠an los individuos 3, 5, 7 y 8 en la Tabla \ref{tab:tabMR1} y el Bloque \ref{exm:bloqueMR3}, la probabilidad de que un posible intruso relacione correctamente a estos individuos con un archivo de datos externo es relativamente alta. En nuestro ejemplo, la raz√≥n del alto riesgo es el hecho de que estos individuos son muestras √∫nicas (es decir, \(f_{k}=1\)). Este riesgo es el riesgo del peor de los casos y no implica que la persona sea reidentificada con certeza con esta probabilidad. Por ejemplo, si un individuo incluido en los microdatos no est√° incluido en el archivo de datos externo, la probabilidad de una coincidencia correcta es cero. No obstante, la medida del riesgo calculada a partir de las frecuencias ser√° positiva como medida de evaluaci√≥n.

\hypertarget{k-anonimato}{%
\subsection{k-anonimato}\label{k-anonimato}}

La medida del riesgo k- anonimato se basa en el principio de que, en un conjunto de datos seguro, el n√∫mero de personas que comparten la misma combinaci√≥n de valores (claves) de identificadores indirectos categ√≥ricos debe ser superior a un umbral especificado \emph{k}. El k-anonimato es una medida de riesgo basada en los microdatos a publicar, ya que solo tiene en cuenta la muestra. Un individuo viola el k-anonimato si la frecuencia de muestreo \(f_{k}\) para la llave \emph{k} es menor que el umbral especificado \emph{k}. Por ejemplo, si un individuo tiene la misma combinaci√≥n de identificadores indirectos que otros dos individuos en la muestra, estos individuos satisfacen el 3-anonimato pero violan el 4-anonimato. En el conjunto de datos de la Tabla \ref{tab:tabMR1}, seis personas satisfacen el 2-anonimato y cuatro violan el 2-anonimato. Los individuos que violan el 2-anonimato son muestras √∫nicas. La medida de riesgo es el n√∫mero de observaciones que violan el k-anonimato para un cierto valor de \emph{k}, que es

\[ \sum_{i} I(f_{k}<k), \]

donde \(I\) es la funci√≥n indicadora e \(i\) se refiere al \emph{i-√©simo} registro. Esto es simplemente un recuento del n√∫mero de personas con una frecuencia de muestreo de su clave inferior a \emph{k}. El recuento es mayor para los \emph{k} m√°s grandes, ya que si un registro satisface k-anonimato, tambi√©n satisface (k+1)- anonimato. La medida del riesgo k-anonimato no considera los pesos de la muestra, pero es importante considerar los pesos de la muestra al determinar el nivel requerido de k-anonimato. Si los pesos de la muestra son grandes, un individuo en el conjunto de datos representa a m√°s individuos en la poblaci√≥n objetivo, la probabilidad de una coincidencia correcta es menor y, por lo tanto, el umbral requerido puede ser m√°s bajo. Los pesos de muestra grandes van de la mano con conjuntos de datos m√°s peque√±os. En un conjunto de datos m√°s peque√±o, la probabilidad de encontrar otro registro con la misma clave es menor que en un conjunto de datos m√°s grande. Esta probabilidad est√° relacionada con el n√∫mero de registros en la poblaci√≥n con una clave particular a trav√©s de los pesos muestrales.

En \texttt{sdcMicro} podemos mostrar el n√∫mero de observaciones que violan un determinado umbral de k-anonimato. En el Bloque \ref{exm:bloqueMR4}, usamos \texttt{sdcMicro} para calcular la cantidad de infractores para los umbrales \(k=2\) y \(k=3\). Se da tanto el n√∫mero absoluto de infractores como el n√∫mero relativo como porcentaje del n√∫mero de individuos en la muestra. En el ejemplo, cuatro observaciones violan el 2-anonimato y las 10 observaciones violan el 3-anonimato.

\begin{example}
\protect\hypertarget{exm:bloqueMR4}{}{\label{exm:bloqueMR4} }Uso de la funci√≥n \texttt{print()} para mostrar observaciones que violan k-anonimato
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{print}\NormalTok{(sdcInitial, }\StringTok{'kAnon'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Para otros niveles de k-anonimato, es posible calcular el n√∫mero de personas infractoras utilizando los recuentos de frecuencia de muestreo en el objeto \texttt{sdcMicro}. El n√∫mero de infractores es el n√∫mero de personas con recuentos de frecuencia de muestreo inferiores al umbral especificado \emph{k}. En el Bloque \ref{exm:bloqueMR5}, mostramos un ejemplo de c√≥mo calcular cualquier umbral para \emph{k} usando las medidas de riesgo ya almacenadas disponibles despu√©s de configurar un objeto \texttt{sdcMicro} en \texttt{R}. \emph{k} se puede reemplazar con cualquier umbral requerido. La elecci√≥n del umbral requerido que deben cumplir todas las personas en el archivo de microdatos depende de muchos factores y se analiza m√°s adelante en la secci√≥n \protect\hyperlink{sup-loc}{Supresi√≥n local} sobre la supresi√≥n local. En muchas instituciones, los umbrales t√≠picamente requeridos para k-anonimato son 3 y 5.

\begin{example}
\protect\hypertarget{exm:bloqueMR5}{}{\label{exm:bloqueMR5} }Violaciones de k-anonimato para distintos valores de k
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{k=}\DecValTok{10}
\KeywordTok{sum}\NormalTok{(sdcInitial}\OperatorTok{@}\NormalTok{risk}\OperatorTok{$}\NormalTok{individual[,}\DecValTok{2}\NormalTok{] }\OperatorTok{<}\StringTok{ }\NormalTok{k)}
\end{Highlighting}
\end{Shaded}

Es importante tener en cuenta que los valores faltantes (\texttt{NA}s en \texttt{R} \footnote{En \texttt{sdcMicro}, es importante utilizar el c√≥digo de valor faltante est√°ndar \texttt{NA} en lugar de otros c√≥digos, como 9999 o cadenas. En la secci√≥n \protect\hyperlink{valores-faltantes}{Valores faltantes}, se analiz√≥ m√°s detalladamente c√≥mo establecer otros c√≥digos de valores faltantes de \texttt{NA} en \texttt{R}. Esto es necesario para garantizar que los m√©todos de \texttt{sdcMicro} funcionen correctamente. Cuando los valores faltantes tienen c√≥digos distintos de \texttt{NA}, los c√≥digos de valores faltantes se interpretan como un nivel de factor distinto en el caso de las variables categ√≥ricas.} ) se tratan como si fueran cualquier otro valor. Dos personas con claves \{`Masculino', \texttt{NA}, `Ocupado'\} y \{`Masculino', `Secundaria completa', `Ocupado'\} comparten la misma clave y, de manera similar, \{`Masculino', \texttt{NA}, `Ocupado'\} y \{`Masculino', `Secundaria incompleta', `Ocupado'\} tambi√©n comparten la misma clave. Por lo tanto, el valor que falta en la primera clave se interpreta primero como `Secundaria completa' y luego como `Secundaria incompleta'. Esto se ilustra en la Tabla \ref{tab:tabMR2}.

\begin{table}

\caption{\label{tab:tabMR2}Conjunto de datos de ejemplo para ilustrar el efecto de los valores faltantes en el k-anonimato}
\centering
\begin{tabular}[t]{c|c|c|c|c}
\hline
Id & G√©nero & Nivel educacional & Situaci√≥n laboral & \$f\_\{k\}\$\\
\hline
1 & Masculino & Secundaria completa & Ocupado & 2\\
\hline
2 & Masculino & Secundaria incompleta & Ocupado & 2\\
\hline
3 & Masculino & NA & Ocupado & 3\\
\hline
\end{tabular}
\end{table}

Fuente: Adaptaci√≥n de \citep[p.32]{benschop}

Si un conjunto de datos satisface k-anonimato, un intruso siempre encontrar√° al menos \emph{k} individuos con la misma combinaci√≥n de identificadores indirectos. El k-anonimato suele ser un requisito necesario para la anonimizaci√≥n de un conjunto de datos antes de su publicaci√≥n, pero no es necesariamente un requisito suficiente. La medida de k-anonimato solo se basa en recuentos de frecuencia y no tiene en cuenta (las diferencias en) los pesos de las muestras. Con frecuencia el k-anonimato se logra aplicando primero la recodificaci√≥n y luego la supresi√≥n local y, en algunos casos, mediante la microagregaci√≥n, antes de utilizar otras medidas de riesgo y m√©todos de divulgaci√≥n para reducir a√∫n m√°s el riesgo de divulgaci√≥n. Estos m√©todos se analizan en la secci√≥n \protect\hyperlink{muxe9todos-sdc}{M√©todos SDC}.

\hypertarget{l-diversity}{%
\subsection{l-diversity}\label{l-diversity}}

El k-anonimato ha sido criticado por no ser lo suficientemente restrictivo. La informaci√≥n confidencial puede divulgarse incluso si los datos satisfacen el k-anonimato. Esto puede ocurrir en los casos en que los datos contienen variables categ√≥ricas confidenciales (de no identificaci√≥n) que tienen el mismo valor para todas las personas que comparten la misma clave. Ejemplos de tales variables sensibles son aquellas que contienen informaci√≥n sobre el estado de salud de un individuo. La Tabla \ref{tab:tabMR3} ilustra este problema utilizando los mismos datos que se utilizaron anteriormente, pero agregando una variable sensible, ``salud''. Los dos primeros individuos cumplen 2-anonimato para los identificadores indirectos ``√°rea'', ``g√©nero'', ``nivel educacional'' y ``situaci√≥n laboral''. Esto significa que un intruso encontrar√° al menos dos personas al hacer coincidir el conjunto de microdatos publicado en funci√≥n de esos cuatro identificadores indirectos. Sin embargo, si el intruso sabe que alguien pertenece a la muestra y tiene la clave \{`Urbano', `Femenino', `Secundaria incompleta' y `Ocupado'\}, con certeza se revela el estado de salud (`s√≠'), porque para ambos las observaciones con esta clave tienen el mismo valor. Esta informaci√≥n se revela as√≠ sin la necesidad de coincidir exactamente con el individuo. Este no es el caso de los individuos con clave \{`Urbano', `Masculino', `Secundaria completa', `Ocupado'\}.

El concepto de l-diversity (distinto) aborda esta deficiencia del k-anonimato. Un conjunto de datos satisface l-diversity si para cada clave \emph{k} hay por lo menos \emph{l} diferentes valores para cada una de las variables sensibles. En el ejemplo, los primeros dos individuos satisfacen solo 1-diversity, los individuos 4 y 6 satisfacen 2-diversity. El nivel requerido de l-diversity depende del n√∫mero de valores posibles que puede tomar la variable sensible. Si la variable sensible es una variable binaria, el nivel m√°s alto de l-diversity que se puede conseguir es 2. Una muestra √∫nica siempre solo satisfar√° 1-diversity.

Para computar l-diversity para variables sensibles en \texttt{sdcMicro}, se puede usar la funci√≥n \texttt{ldiversity()}. Esto se ilustra en el Bloque \ref{exm:bloqueMR6}. Como argumentos, especificamos los nombres de las variables sensibles \footnote{Alternativamente, las variables sensibles se pueden especificar al crear el objeto \texttt{sdcMicro} usando la funci√≥n \texttt{createSdcObj()} en el argumento sensibleVar. Esto se explica con m√°s detalle en la secci√≥n \protect\hyperlink{objetos-de-la-clase-sdcmicroobj}{Objetos de la clase \texttt{sdcMicroObj}}. En ese caso, no es necesario especificar el argumento ldiv\_index en la funci√≥n \texttt{ldiversity()}, y las variables en el argumento sensibleVar se usar√°n autom√°ticamente para calcular l-diversity.} en el archivo, as√≠ como una constante para l-diversity \footnote{Adem√°s de l-diversity distintos, hay otros m√©todos de l-diversity: entrop√≠a y recursivo. l-diversity distinto es el m√°s utilizado.} y el c√≥digo de valores faltantes en los datos. La salida se guarda en el \emph{slot} de ``riesgo'' del objeto \texttt{sdcMicro}. El resultado muestra el m√≠nimo, m√°ximo, media y cuantiles de las l-puntuaciones de diversidad para todos los individuos de la muestra. El resultado del Bloque \ref{exm:bloqueMR6} reproduce los resultados seg√∫n los datos de la Tabla \ref{tab:tabMR3}.

\begin{table}

\caption{\label{tab:tabMR3}Ilustraci√≥n de l-diversity}
\centering
\begin{tabular}[t]{c|c|c|c|c|c|c|c|c}
\hline
Id & √Årea & G√©nero & Nivel educacional & Situaci√≥n laboral & Salud & \$f\_\{k\}\$ & \$F\_\{k\}\$  & l-diversity\\
\hline
1 & Urbano & Femenino & Secundaria incompleta & Ocupado & Enfermo & 2 & 360 & 1\\
\hline
2 & Urbano & Femenino & Secundaria incompleta & Ocupado & Enfermo & 2 & 360 & 1\\
\hline
3 & Urbano & Femenino & Primaria incompleta & No FL & Enfermo & 1 & 215 & 1\\
\hline
4 & Urbano & Masculino & Secundaria completa & Ocupado & Enfermo & 2 & 152 & 2\\
\hline
5 & Rural & Femenino & Secundaria completa & Desocupado & Enfermo & 1 & 186 & 1\\
\hline
6 & Urbano & Masculino & Secundaria completa & Ocupado & Sano & 2 & 152 & 2\\
\hline
7 & Urbano & Femenino & Primaria completa & No FL & Sano & 1 & 180 & 1\\
\hline
8 & Urbano & Masculino & Post secundaria & Desocupado & Enfermo & 1 & 215 & 1\\
\hline
9 & Urbano & Femenino & Secundaria incompleta & No FL & Sano & 2 & 262 & 2\\
\hline
10 & Urbano & Femenino & Secundaria incompleta & No FL & Enfermo & 2 & 262 & 2\\
\hline
\end{tabular}
\end{table}

Fuente: Adaptaci√≥n de \citep[p.33]{benschop}

\begin{example}
\protect\hypertarget{exm:bloqueMR6}{}{\label{exm:bloqueMR6} }Funci√≥n para l-diversity en \texttt{sdcMicro}
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
 \CommentTok{# Calculando l-diversity}

\NormalTok{ sdcInitial <-}\StringTok{ }\KeywordTok{ldiversity}\NormalTok{(}\DataTypeTok{obj =}\NormalTok{ sdcInitial, }\DataTypeTok{ldiv_index =} \KeywordTok{c}\NormalTok{(}\StringTok{"Salud"}\NormalTok{), }
                          \DataTypeTok{l_recurs_c =} \DecValTok{2}\NormalTok{, }\DataTypeTok{missing =} \OtherTok{NA}\NormalTok{)}
 \CommentTok{# Resultado para l-diversity}
\NormalTok{ sdcInitial}\OperatorTok{@}\NormalTok{risk}\OperatorTok{$}\NormalTok{ldiversity}
 
 \CommentTok{# l-diversity score para cada registro}
\NormalTok{ sdcInitial}\OperatorTok{@}\NormalTok{risk}\OperatorTok{$}\NormalTok{ldiversity[,}\StringTok{'Salud_Distinct_Ldiversity'}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

l-diversity es √∫til si los datos contienen variables sensibles categ√≥ricas que no son identificadores indirectos en s√≠ mismos. No es posible seleccionar identificadores indirectos para calcular la l-diversity. La l-diversity debe calcularse para cada variable sensible por separado.

\hypertarget{medidas-de-riesgo-para-variables-continuas}{%
\section{Medidas de riesgo para variables continuas}\label{medidas-de-riesgo-para-variables-continuas}}

El principio de rareza o unicidad de combinaciones de identificadores indirectos (claves) no es √∫til para variables continuas, porque es probable que todos o muchos individuos tengan claves √∫nicas. Por lo tanto, se explotan otros enfoques para medir el riesgo de divulgaci√≥n de las variables continuas. Estos m√©todos se basan en la unicidad de los valores en la vecindad de los valores originales. La unicidad se define de diferentes formas: en t√©rminos absolutos (medida de intervalo) o en t√©rminos relativos (vinculaci√≥n de registros). La mayor√≠a de las medidas son medidas a posteriori: se eval√∫an despu√©s de anonimizar los datos sin procesar, comparar los datos tratados con los datos sin procesar y evaluar para cada individuo la distancia entre los valores en los datos sin procesar y los tratados. Esto significa que estos m√©todos no son √∫tiles para identificar personas en riesgo dentro de los datos sin procesar, sino que muestra la distancia/diferencia entre el conjunto de datos antes y despu√©s de la anonimizaci√≥n y, por lo tanto, puede interpretarse como una evaluaci√≥n del m√©todo de anonimizaci√≥n. Por esa raz√≥n, se asemejan a las medidas de p√©rdida de informaci√≥n discutidas en la secci√≥n \protect\hyperlink{mediciuxf3n-de-la-utilidad-y-la-puxe9rdida-de-informaciuxf3n}{Medici√≥n de la utilidad y la p√©rdida de informaci√≥n}. Finalmente, las medidas de riesgo para identificadores indirectos continuos tambi√©n se basan en la detecci√≥n de valores at√≠picos. Los valores at√≠picos juegan un papel importante en la reidentificaci√≥n de estos registros.

\hypertarget{vinculaciuxf3n-de-registros-o-coincidencia-de-registros}{%
\subsection{Vinculaci√≥n de registros (o coincidencia de registros)}\label{vinculaciuxf3n-de-registros-o-coincidencia-de-registros}}

Vinculaci√≥n de registros (o Record linkage, en ingl√©s) es un m√©todo a posteriori que eval√∫a el n√∫mero de v√≠nculos correctos al vincular los valores perturbados con los valores originales. El algoritmo de vinculaci√≥n se basa en la distancia entre el original y los valores perturbados (es decir, vinculaci√≥n de registros basada en la distancia). Los valores perturbados se emparejan con el individuo m√°s cercano. Es importante se√±alar que este m√©todo no brinda informaci√≥n sobre el riesgo inicial, sino que es una medida para evaluar el algoritmo de perturbaci√≥n (es decir, est√° dise√±ado para indicar el nivel de incertidumbre introducido en la variable al contar la cantidad de registros que podr√≠a coincidir correctamente).

Los algoritmos de vinculaci√≥n de registros difieren con respecto a qu√© medida de distancia se utiliza. Cuando una variable tiene una escala muy diferente a la de otras variables continuas en el conjunto de datos, se recomienda volver a escalar las variables antes de usar la vinculaci√≥n de registros. Escalas muy diferentes pueden dar lugar a resultados no deseados al medir la distancia multivariada entre registros en funci√≥n de varias variables continuas. Dado que estos m√©todos se basan tanto en datos sin procesar como en datos tratados, los ejemplos de sus aplicaciones requieren la introducci√≥n de m√©todos SDC y, por lo tanto, se posponen a los estudios de casos en la secci√≥n \protect\hyperlink{caso-de-estudio}{Caso de estudio}.

Adem√°s de la vinculaci√≥n de registros basada en la distancia, otro m√©todo de vinculaci√≥n es la vinculaci√≥n de registros probabil√≠sticos. La literatura muestra, sin embargo, que los resultados de la vinculaci√≥n de registros basados en la distancia son mejores que los resultados de la vinculaci√≥n de registros probabil√≠sticos. Las personas en los datos tratados que est√°n vinculadas a las personas correctas en los datos sin procesar se consideran en riesgo de divulgaci√≥n.

\hypertarget{medida-de-intervalo}{%
\subsection{Medida de intervalo}\label{medida-de-intervalo}}

La aplicaci√≥n exitosa de un m√©todo SDC deber√≠a dar como resultado valores perturbados que no se consideran demasiado cercanos a sus valores iniciales; si el valor es relativamente cercano, la reidentificaci√≥n puede ser relativamente f√°cil. En la aplicaci√≥n de medidas de intervalo, se crean intervalos alrededor de cada valor perturbado y luego se determina si el valor original de esa observaci√≥n perturbada est√° contenido en este intervalo. Los valores que est√°n dentro del intervalo alrededor del valor inicial despu√©s de la perturbaci√≥n se consideran demasiado cercanos al valor inicial y, por lo tanto, no son seguros y necesitan m√°s perturbaciones. Los valores que est√°n fuera de los intervalos se consideran seguros. El tama√±o de los intervalos se basa en la desviaci√≥n est√°ndar de las observaciones y un par√°metro de escala. Este m√©todo est√° implementado en la funci√≥n \texttt{dRisk()} en \texttt{sdcMicro}. El Bloque \ref{exm:bloqueMR7} muestra c√≥mo imprimir o mostrar el valor de riesgo calculado por \texttt{sdcMicro} comparando las variables de ingresos antes y despu√©s de la anonimizaci√≥n. ``sdcObj'' es un objeto \texttt{sdcMicro} y ``compExp`` es un vector que contiene los nombres de las variables de ingresos. El tama√±o de los intervalos es \emph{k} veces la desviaci√≥n est√°ndar, donde \emph{k} es un par√°metro en la funci√≥n \texttt{dRisk()}. El m√°s largo \emph{k}, cuanto m√°s grandes son los intervalos y, por lo tanto, mayor es el n√∫mero de observaciones dentro del intervalo construidas alrededor de sus valores originales y mayor es la medida de riesgo. El resultado 1 indica que todas (100 por ciento) las observaciones est√°n fuera del intervalo de 0,1 veces la desviaci√≥n est√°ndar alrededor de los valores originales.

\begin{example}
\protect\hypertarget{exm:bloqueMR7}{}{\label{exm:bloqueMR7} }Ilustraci√≥n de medida de intervalo
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
 \KeywordTok{dRisk}\NormalTok{(}\DataTypeTok{obj =}\NormalTok{ sdcObj}\OperatorTok{@}\NormalTok{origData[,compExp], }\DataTypeTok{xm =}\NormalTok{ sdcObj}\OperatorTok{@}\NormalTok{manipNumVars[,compExp],}
       \DataTypeTok{k =} \FloatTok{0.1}\NormalTok{)}
\NormalTok{ [}\DecValTok{1}\NormalTok{] }\DecValTok{1}
\end{Highlighting}
\end{Shaded}

Para la mayor√≠a de los valores, este es un enfoque satisfactorio. Sin embargo, no es una medida suficiente para valores at√≠picos. Despu√©s de la perturbaci√≥n, los valores at√≠picos seguir√°n siendo valores at√≠picos y se pueden volver a identificar f√°cilmente, incluso si est√°n lo suficientemente lejos de sus valores iniciales. Por lo tanto, los valores at√≠picos deben tratarse con precauci√≥n.

\hypertarget{detecciuxf3n-de-valores-atuxedpicos}{%
\subsection{Detecci√≥n de valores at√≠picos}\label{detecciuxf3n-de-valores-atuxedpicos}}

Los valores at√≠picos son importantes para medir el riesgo de reidentificaci√≥n en microdatos continuos. Los datos continuos suelen estar sesgados, especialmente a la derecha. Esto significa que hay algunos valores at√≠picos con valores muy altos en relaci√≥n con las otras observaciones de la misma variable. Algunos ejemplos son los ingresos en los datos de los hogares, donde solo unas pocas personas/hogares pueden tener ingresos muy altos, o los datos de facturaci√≥n de empresas que son mucho m√°s grandes que otras empresas de la muestra. En casos como estos, incluso si estos valores se perturban, a√∫n puede ser f√°cil identificar estos valores at√≠picos, ya que seguir√°n siendo los valores m√°s grandes incluso despu√©s de la perturbaci√≥n (la perturbaci√≥n habr√° creado incertidumbre en cuanto al valor exacto, pero debido a que el valor comenz√≥ mucho m√°s lejos de otras observaciones, a√∫n puede ser f√°cil vincularlo con el individuo de altos ingresos o la empresa muy grande). Los ejemplos ser√≠an el √∫nico m√©dico en un √°rea geogr√°fica con altos ingresos o una sola gran empresa en un tipo de industria. Por lo tanto, la identificaci√≥n de valores at√≠picos en datos continuos es un paso importante cuando se identifican personas con alto riesgo. En la pr√°ctica, identificar los valores de una variable continua que son mayores que un valor predeterminado p\%-percentil podr√≠a ayudar a identificar valores at√≠picos y, por lo tanto, unidades con mayor riesgo de identificaci√≥n. El valor de \emph{p} depende de la asimetr√≠a de los datos.

Podemos calcular el p\%-percentil de una variable continua en \texttt{R} y mostrar los individuos que tienen ingresos superiores a este percentil. El Bloque \ref{exm:bloqueMR8} proporciona una ilustraci√≥n del percentil 90.

\begin{example}
\protect\hypertarget{exm:bloqueMR8}{}{\label{exm:bloqueMR8} }C√≥mputo del percentil 90 \% de la variable INCWAGE
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{setwd}\NormalTok{(}\StringTok{"../Capacitaci√≥n/GitHub"}\NormalTok{) }\CommentTok{# directorio de trabajo}

\NormalTok{fname =}\StringTok{ "data.dta"} \CommentTok{# nombre del archivo}
\KeywordTok{library}\NormalTok{(haven) }\CommentTok{# carga el paquete requerido para la funci√≥n de lectura/escritura}
               \CommentTok{# para archivos STATA}
\NormalTok{file <-}\StringTok{ }\KeywordTok{read_dta}\NormalTok{(fname) }

\CommentTok{# C√≥mputo de 90 % percentil para variable INCWAGE}
\NormalTok{ perc90 <-}\StringTok{ }\KeywordTok{quantile}\NormalTok{(file[,}\StringTok{'INCWAGE'}\NormalTok{], }\FloatTok{0.90}\NormalTok{, }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{)}

 \CommentTok{# Muestra ID de observaciones con valores para INCWAGE mayores al 90 % percentil}
\NormalTok{ file[(file[, }\StringTok{'INCWAGE'}\NormalTok{] }\OperatorTok{>=}\StringTok{ }\NormalTok{perc90), }\StringTok{'IDP'}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

Un segundo enfoque para la detecci√≥n de valores at√≠picos es una medida a posteriori que compara los datos tratados y sin procesar. Se construye un intervalo alrededor de los valores perturbados como se describe en la secci√≥n anterior. Si los valores originales caen dentro del intervalo alrededor de los valores perturbados, los valores perturbados se consideran inseguros ya que est√°n demasiado cerca de los valores originales. Existen diferentes formas de construir dichos intervalos, como intervalos basados en rangos e intervalos basados en desviaci√≥n est√°ndar. \citet{templ2008} proponen una alternativa robusta para estos intervalos. Construyen los intervalos en funci√≥n de la distancia robusta de Mahalanobis (RMD, por su sigla en ingl√©s) al cuadrado de los valores individuales. El RMD escala los intervalos de manera que los valores at√≠picos obtienen intervalos m√°s grandes y, por lo tanto, deben tener una perturbaci√≥n mayor para que se consideren seguros que los valores que no son at√≠picos. Este m√©todo se implementa en \texttt{sdcMicro} en la funci√≥n \texttt{dRiskRMD()}, que es una extensi√≥n de la funci√≥n \texttt{dRisk()}.

\hypertarget{riesgo-global}{%
\section{Riesgo global}\label{riesgo-global}}

Para construir una medida de riesgo agregado a nivel global para el conjunto de datos completo, podemos agregar las medidas de riesgo a nivel individual de varias maneras. Las medidas de riesgo global deben usarse con precauci√≥n: detr√°s de un riesgo global aceptable pueden esconderse algunos registros de muy alto riesgo que se compensan con muchos registros de bajo riesgo.

\hypertarget{media-de-las-medidas-de-riesgo-individuales}{%
\subsection{Media de las medidas de riesgo individuales}\label{media-de-las-medidas-de-riesgo-individuales}}

Una forma sencilla de agregar las medidas de riesgo individuales es tomar la media de todos los individuos de la muestra, que es igual a sumar todas las claves de la muestra si se multiplica por las frecuencias de muestra de estas claves y se divide por el tama√±o de la muestra, \(n\):

\[R_{1}=\frac{1}{n}\sum_{i} r_{k}=\frac{1}{n}\sum_{k}f_{k}r_{k},\]

donde \(r_{k}\) es el riesgo individual de clave \(k\) que el \emph{i-√©simo} registro comparte (ver la secci√≥n \protect\hyperlink{identificadores-indirectos-categuxf3ricos-y-recuentos-de-frecuencia}{Identificadores indirectos categ√≥ricos y recuentos de frecuencia}). Esta medida se informa como riesgo global en \texttt{sdcMicro}, se almacena en el \emph{slot} de ``riesgo'' y se puede imprimir como se muestra en el Bloque \ref{exm:bloqueMR9}. Indica que la probabilidad de reidentificaci√≥n promedio es 0,01582 o 0,1582\%.

\begin{example}
\protect\hypertarget{exm:bloqueMR9}{}{\label{exm:bloqueMR9} }C√≥mputo de la medida de riesgo global
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Riesgo global (probabilidad promedio de re-identificaci√≥n)}
\NormalTok{ sdcInitial}\OperatorTok{@}\NormalTok{risk}\OperatorTok{$}\NormalTok{global}\OperatorTok{$}\NormalTok{risk}
\end{Highlighting}
\end{Shaded}

El riesgo global en los datos de ejemplo de la Tabla \ref{tab:tabMR1} es 0,01582, que es la proporci√≥n esperada de todos los individuos de la muestra que un intruso podr√≠a volver a identificar. Otra forma de expresar el riesgo global es el n√∫mero de reidentificaciones esperadas, \(n*R_{1}\), que es en el ejemplo 10 * 0,01582. El n√∫mero esperado de reidentificaciones tambi√©n se guarda en el objeto \texttt{sdcMicro}. El Bloque \ref{exm:bloqueMR10} muestra c√≥mo imprimir esto.

\begin{example}
\protect\hypertarget{exm:bloqueMR10}{}{\label{exm:bloqueMR10} }C√≥mputo del n√∫mero esperado de reidentificaciones
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#  # Riesgo global(N√∫mero esperado de re-identificaciones)}
\NormalTok{ sdcInitial}\OperatorTok{@}\NormalTok{risk}\OperatorTok{$}\NormalTok{global}\OperatorTok{$}\NormalTok{risk_ER}
\end{Highlighting}
\end{Shaded}

\hypertarget{recuento-de-personas-con-riesgos-superiores-a-un-cierto-umbral}{%
\subsection{Recuento de personas con riesgos superiores a un cierto umbral}\label{recuento-de-personas-con-riesgos-superiores-a-un-cierto-umbral}}

Todos los individuos pertenecientes a la misma clave tienen el mismo riesgo individual, \(r_{k}\). Otra forma de expresar el riesgo total en la muestra es el n√∫mero total de observaciones que superan un determinado umbral de riesgo individual. La fijaci√≥n del umbral puede ser absoluta (por ejemplo, todas aquellas personas que tengan un riesgo de divulgaci√≥n superior a 0,05 o 5\%) o relativa (por ejemplo, todas aquellas personas con riesgos superiores al cuartil superior del riesgo individual). El Bloque \ref{exm:bloqueMR11} muestra c√≥mo utilizando \texttt{R}, se contar√≠a el n√∫mero de observaciones con un riesgo de reidentificaci√≥n individual superior al 5\%. En el ejemplo, ninguna persona tiene un riesgo de divulgaci√≥n superior a 0,05.

\begin{example}
\protect\hypertarget{exm:bloqueMR11}{}{\label{exm:bloqueMR11} }N√∫mero de personas con riesgo individual superior al umbral 0,05
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
 \KeywordTok{sum}\NormalTok{(sdcInitial}\OperatorTok{@}\NormalTok{risk}\OperatorTok{$}\NormalTok{individual[,}\DecValTok{1}\NormalTok{] }\OperatorTok{>}\StringTok{ }\FloatTok{0.05}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Estos c√°lculos se pueden usar para tratar los datos de las personas cuyos valores de riesgo est√°n por encima de un umbral predeterminado. M√°s adelante veremos que hay m√©todos en \texttt{sdcMicro}, como \texttt{localSupp()}, que se pueden usar para suprimir valores de ciertas variables clave para aquellas personas con riesgo por encima de un umbral espec√≠fico. Esto se explica con m√°s detalle en la secci√≥n \protect\hyperlink{sup-loc}{Supresi√≥n local}.

\hypertarget{riesgo-jeruxe1rquico-o-del-hogar}{%
\section{Riesgo jer√°rquico (o del hogar)}\label{riesgo-jeruxe1rquico-o-del-hogar}}

En muchas encuestas sociales, los datos tienen una estructura jer√°rquica donde un individuo pertenece a una entidad de nivel superior (ver la secci√≥n \protect\hyperlink{niveles-de-riesgo}{Niveles de riesgo}). Ejemplos t√≠picos son los hogares en las encuestas sociales o los alumnos en las escuelas. La reidentificaci√≥n de un miembro del hogar tambi√©n puede conducir a la reidentificaci√≥n de los otros miembros del hogar. Por tanto, es f√°cil ver que, si tenemos en cuenta la estructura del hogar, el riesgo de reidentificaci√≥n es el riesgo de que al menos uno de los miembros del hogar sea reidentificado.

\[r^h=P(A_{1}\bigcup A_{2}\bigcup \dots \bigcup A_{J})=1-\prod_{j=1}^J 1-P(A_{j}), \]
donde \(A_{j}\) es el evento que el \emph{j-√©simo} miembro del hogar sea identificado y \(P(A_{j})=r_{k}\) es el riesgo de divulgaci√≥n individual del \emph{j-√©simo} miembro. Por ejemplo, si un hogar tiene tres miembros con riesgos de divulgaci√≥n individuales en funci√≥n de sus respectivas claves 0,02, 0,03 y 0,03, respectivamente, el riesgo del hogar es

\[1-((1-0,02)(1-0,03)(1-0,03))=0,078\]

El riesgo jer√°rquico o del hogar no puede ser menor que el riesgo individual, y el riesgo del hogar es siempre el mismo para todos los miembros del hogar. El riesgo del hogar debe utilizarse en los casos en que los datos contengan una estructura jer√°rquica, es decir, cuando la estructura del hogar est√© presente en los datos. Usando \texttt{sdcMicro}, si se especifica un identificador de hogar (en el argumento hhId en la funci√≥n \texttt{createSdcObj()}) al crear un objeto \texttt{sdcMicro}, el riesgo del hogar se calcular√° autom√°ticamente. El Bloque \ref{exm:bloqueMR12} muestra c√≥mo imprimir estas medidas de riesgo.

\begin{example}
\protect\hypertarget{exm:bloqueMR12}{}{\label{exm:bloqueMR12} }C√≥mputo del riesgo del hogar y n√∫mero esperado de reidentificaciones
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Riesgo del hogar}
\NormalTok{ sdcInitial}\OperatorTok{@}\NormalTok{risk}\OperatorTok{$}\NormalTok{global}\OperatorTok{$}\NormalTok{hier_risk}

 \CommentTok{# Riesgo del hogar (N√∫mero esperado de reidentificaciones)}
\NormalTok{ sdcInitial}\OperatorTok{@}\NormalTok{risk}\OperatorTok{$}\NormalTok{global}\OperatorTok{$}\NormalTok{hier_risk_ER}
\end{Highlighting}
\end{Shaded}

El tama√±o de un hogar es un identificador importante en s√≠ mismo, especialmente para hogares grandes. Sin embargo, la supresi√≥n de la variable del tama√±o real (por ejemplo, el n√∫mero de miembros del hogar) no es suficiente para eliminar esta informaci√≥n del conjunto de datos, ya que un simple recuento de los miembros del hogar para un hogar en particular permitir√° reconstruir esta variable siempre que un ID del hogar est√© en los datos, lo que permite asignar individuos a los hogares. Se√±alamos esto para la atenci√≥n del lector ya que es importante.

\hypertarget{referencias}{%
\section{Referencias}\label{referencias}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{muxe9todos-sdc}{%
\chapter{M√©todos SDC}\label{muxe9todos-sdc}}

Esta secci√≥n describe los m√©todos SDC m√°s utilizados. Todos los m√©todos se pueden implementar en \texttt{R} utilizando el paquete \texttt{sdcMicro}. Discutimos qu√© m√©todo es m√°s adecuado para cada tipo de datos, tanto en t√©rminos de caracter√≠sticas como del tipo de dato. Adem√°s, se discuten opciones como los par√°metros espec√≠ficos de cada m√©todo, as√≠ como sus impactos. Las conclusiones pretenden ser orientativas, pero deben utilizarse con precauci√≥n, ya que cada operaci√≥n estad√≠stica genera datos con caracter√≠sticas diferentes y las recomendaciones del documento no siempre ser√°n las m√°s adecuadas para sus datos en particular.

Para determinar qu√© m√©todos de anonimizaci√≥n son adecuados para variables y/o conjuntos de datos espec√≠ficos, comenzamos presentando algunas clasificaciones de los m√©todos SDC.

\hypertarget{clasificaciuxf3n-de-los-muxe9todos-sdc}{%
\section{Clasificaci√≥n de los m√©todos SDC}\label{clasificaciuxf3n-de-los-muxe9todos-sdc}}

Los m√©todos SDC pueden clasificarse en no perturbativos y perturbativos \citep{HDFG12}.

\begin{itemize}
\tightlist
\item
  \textbf{Los m√©todos no perturbativos} reducen el detalle de los datos mediante la generalizaci√≥n o la supresi√≥n de ciertos valores (enmascaramiento) sin distorsionar la estructura de los datos.
\item
  \textbf{Los m√©todos perturbativos} no suprimen los valores del conjunto de datos, sino que alteran los valores para limitar el riesgo de divulgaci√≥n creando incertidumbre en torno a los valores reales.
  Tanto los m√©todos no perturbativos como los perturbativos pueden utilizarse para variables categ√≥ricas y continuas.
\end{itemize}

Tambi√©n distinguimos entre m√©todos probabil√≠sticos y deterministas SDC.

Los \textbf{m√©todos probabil√≠sticos} dependen de un mecanismo de probabilidad o de un mecanismo de generaci√≥n de n√∫meros aleatorios. Cada vez que se utiliza un m√©todo probabil√≠stico, se genera un resultado diferente. Para estos m√©todos se suele recomendar que se establezca una semilla (con la funci√≥n \texttt{set.seed()}) para el generador de n√∫meros aleatorios si se quiere producir resultados replicables.

Los \textbf{m√©todos deterministas} siguen un algoritmo determinado y producen los mismos resultados si se aplican repetidamente a los mismos datos con el mismo conjunto de par√°metros.

Los m√©todos SDC para microdatos pretenden evitar la revelaci√≥n de identidad y de atributos. Para cada tipo de control de la divulgaci√≥n se utilizan diferentes m√©todos SDC. M√©todos como la recodificaci√≥n y la supresi√≥n local se aplican a los identificadores indirectos para evitar la divulgaci√≥n de identidad, mientras que la codificaci√≥n superior de un identificador indirecto (por ejemplo, los ingresos) o la perturbaci√≥n de una variable sensible evitan la divulgaci√≥n de atributos.

Discutiremos los m√©todos SDC que se implementan en el paquete \texttt{sdcMicro} o que pueden implementarse f√°cilmente en R. Estos son los m√©todos m√°s com√∫nmente aplicados en la literatura y utilizados en la mayor√≠a de las agencias con experiencia en el uso de estos m√©todos. La Tabla \ref{tab:Tabla6} ofrece una visi√≥n general de los m√©todos de SDC discutidos en esta gu√≠a, su clasificaci√≥n, los tipos de datos a los que son aplicables y los nombres de sus funciones en el paquete \texttt{sdcMicro}.

\begin{table}

\caption{\label{tab:Tabla6}\label{tab:Tabla6}M√©todos SDC y funciones correspondientes en `sdcMicro` 
}
\centering
\begin{tabular}[t]{llll}
\toprule
M√©todo & Clasificaci√≥n   del m√©todo SDC & Tipo de datos & Funci√≥n en   `sdcMicro`\\
\midrule
Recodificaci√≥n Global & no   perturbativo, determinista & continuo   y categ√≥rico & `globalRecode` , `groupVars`\\
Codificaci√≥n Superior e Inferior & no   perturbativo, determinista & continuo   y categ√≥rico & `topBotCoding`\\
Supresi√≥n Local & no   perturbativo, determinista & categ√≥rico & `localSuppression`,`localSupp`\\
PRAM & perturbativo,   probabil√≠stico & categ√≥rico & `pram`\\
Micro agregaci√≥n & perturbativo,   probabil√≠stico & continuo & `microaggregation`\\
\addlinespace
Adici√≥n de Ruido & perturbativo,   probabil√≠stico & continuo & `addNoise`\\
Shuffling & perturbativo,   probabil√≠stico & continuo & `shuffle`\\
Rank swapping & perturbativo,   probabil√≠stico & continuo & `rankSwap`\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{muxe9todos-no-perturbativos}{%
\section{M√©todos no perturbativos}\label{muxe9todos-no-perturbativos}}

\hypertarget{recodificaciuxf3n}{%
\subsection{Recodificaci√≥n}\label{recodificaciuxf3n}}

La recodificaci√≥n es un m√©todo determinista utilizado para disminuir el n√∫mero de categor√≠as o valores distintos de una variable. Se realiza combinando o agrupando categor√≠as para las variables categ√≥ricas o construyendo intervalos para las variables continuas. La recodificaci√≥n se aplica a todas las observaciones de una determinada variable y no solo a las que corren el riesgo de ser reveladas. Existen dos tipos generales de recodificaci√≥n: la recodificaci√≥n global y la codificaci√≥n superior e inferior.

\hypertarget{recodificaciuxf3n-global}{%
\subsubsection{Recodificaci√≥n global}\label{recodificaciuxf3n-global}}

La recodificaci√≥n global combina varias categor√≠as de una variable categ√≥rica o construye intervalos para variables continuas. Esto reduce el n√∫mero de categor√≠as disponibles en los datos y, potencialmente, el riesgo de divulgaci√≥n, especialmente para las categor√≠as con pocas observaciones, pero tambi√©n, y esto es importante, reduce el nivel de detalle de la informaci√≥n disponible para el analista. Para ilustrar la recodificaci√≥n, utilizamos el siguiente ejemplo. Supongamos que tenemos cinco regiones en nuestro conjunto de datos. Algunas regiones son muy peque√±as y, cuando se combinan con otras variables clave del conjunto de datos, producen un alto riesgo de reidentificaci√≥n para algunos individuos de esas regiones. Una forma de reducir el riesgo ser√≠a combinar algunas de las regiones al recodificarlas. Podr√≠amos, por ejemplo, hacer tres grupos de los cinco, llamarlos ``Norte'', ``Centro'' y ``Sur'' y en consecuencia reetiquetar los valores. De este modo, el n√∫mero de categor√≠as de la regi√≥n variable se reduce de cinco a tres.

\begin{quote}
\textbf{Nota}: Cualquier agrupaci√≥n debe ser una agrupaci√≥n pertinente para los objetivos anal√≠ticos de la operaci√≥n estad√≠stica y no una uni√≥n aleatoria de categor√≠as.
\end{quote}

Algunos ejemplos ser√≠an agrupar las comunas en provincias, las regiones en macrozonas o las categor√≠as detalladas de agua limpia. Agrupar todas las regiones peque√±as sin proximidad geogr√°fica no es necesariamente la mejor opci√≥n desde el punto de vista de los servicios p√∫blicos. La Tabla \ref{tab:Tabla7} lo ilustra con un conjunto de datos de ejemplo muy simplificado. Antes de la recodificaci√≥n, tres individuos tienen claves distintas, mientras que despu√©s de la recodificaci√≥n (agrupando la ``Regi√≥n 1'' y la ``Regi√≥n 2'' en el ``Norte'', la ``Regi√≥n 3'' en el ``Centro'' y la ``Regi√≥n 4'' y la ``Regi√≥n 5'' en el ``Sur''), el n√∫mero de claves distintas se reduce a cuatro y la frecuencia de cada clave es de al menos dos, bas√°ndose en los tres identificadores indirectos seleccionados. Los recuentos de la frecuencia de las claves \(fk\) se muestran en la √∫ltima columna de la Tabla \ref{tab:Tabla7}. Un intruso encontrar√≠a al menos dos individuos para cada clave y no podr√≠a distinguir m√°s entre los individuos 1 - 3, los individuos 4 y 6, los individuos 5 y 7 y los individuos 8 - 10, bas√°ndose en las variables clave seleccionadas.

\begin{table}

\caption{\label{tab:Tabla7}\label{tab:Tabla7}Ilustraci√≥n del efecto de la recodificaci√≥n en los recuentos de frecuencia de las variables clave}
\centering
\begin{tabular}[t]{clllclllc}
\toprule
\multicolumn{5}{c}{Antes de recodificar} & \multicolumn{4}{c}{Despu√©s de recodificar} \\
\cmidrule(l{3pt}r{3pt}){1-5} \cmidrule(l{3pt}r{3pt}){6-9}
Individuo & Regi√≥n & Sexo & Religi√≥n & \$f\_k\$ & Regi√≥n & Sexo & Religi√≥n & \$f\_k\$\\
\midrule
1 & Regi√≥n 1 & Mujer & Cat√≥lica & 1 & Norte & Mujer & Cat√≥lica & 3\\
2 & Regi√≥n 2 & Mujer & Cat√≥lica & 2 & Norte & Mujer & Cat√≥lica & 3\\
3 & Regi√≥n 2 & Mujer & Cat√≥lica & 2 & Norte & Mujer & Cat√≥lica & 3\\
4 & Regi√≥n 3 & Mujer & Protestante & 2 & Centro & Mujer & Protestante & 2\\
5 & Regi√≥n 3 & Hombre & Protestante & 1 & Centro & Hombre & Protestante & 2\\
\addlinespace
6 & Regi√≥n 3 & Mujer & Protestante & 2 & Centro & Mujer & Protestante & 2\\
7 & Regi√≥n 3 & Hombre & Protestante & 2 & Centro & Hombre & Protestante & 2\\
8 & Regi√≥n 4 & Hombre & Musulm√°n & 2 & Sur & Hombre & Musulm√°n & 3\\
9 & Regi√≥n 4 & Hombre & Musulm√°n & 2 & Sur & Hombre & Musulm√°n & 3\\
10 & Regi√≥n 5 & Hombre & Musulm√°n & 1 & Sur & Hombre & Musulm√°n & 3\\
\bottomrule
\end{tabular}
\end{table}

La recodificaci√≥n suele ser el primer paso de un proceso de anonimizaci√≥n. Puede utilizarse para reducir el n√∫mero de combinaciones √∫nicas de valores de las variables clave. Por lo general, esto aumenta los recuentos de frecuencia de la mayor√≠a de las claves y reduce el riesgo de divulgaci√≥n. La reducci√≥n del n√∫mero de combinaciones posibles se ilustra en la Tabla \ref{tab:Tabla8} con los identificadores indirectos ``regi√≥n'', ``estado civil'' y ``edad''. La Tabla \ref{tab:Tabla8} muestra el n√∫mero de categor√≠as de cada variable y el n√∫mero de combinaciones te√≥ricamente posibles, que es el producto del n√∫mero de categor√≠as de cada identificador indirecto, antes y despu√©s de la recodificaci√≥n. La ``edad'' se interpreta como una variable semicontinua y se trata como una variable categ√≥rica. El n√∫mero de combinaciones posibles y, por tanto, el riesgo de reidentificaci√≥n se reducen en gran medida con la recodificaci√≥n. Hay que tener en cuenta que el n√∫mero de combinaciones posibles es un n√∫mero te√≥rico; en la pr√°ctica, pueden incluirse combinaciones muy improbables, como edad = 3 y estado civil = viudo, y el n√∫mero real de combinaciones en un conjunto de datos puede ser inferior.

\begin{table}

\caption{\label{tab:Tabla8}\label{tab:Tabla8}Ilustraci√≥n del efecto de la recodificaci√≥n en el n√∫mero de combinaciones te√≥ricamente posibles de un conjunto de datos}
\centering
\begin{tabular}[t]{clllc}
\toprule
N√∫mero de   categor√≠as & Regi√≥n & Estado civil & Edad & Posibles   combinaciones\\
\midrule
antes de la recodificaci√≥n & 20 & 8 & 100 & 16.000\\
despu√©s de la recodificaci√≥n & 6 & 6 & 15 & 540\\
\bottomrule
\end{tabular}
\end{table}

Los principales par√°metros para la recodificaci√≥n global son el tama√±o de los nuevos grupos, as√≠ como la definici√≥n de los valores que se agrupan en las nuevas categor√≠as.

\begin{quote}
\textbf{Nota}: Hay que tener cuidado de elegir las nuevas categor√≠as, deber√≠an generarse en funci√≥n del uso de los datos por parte de los usuarios finales y de minimizar la p√©rdida de informaci√≥n como resultado de la recodificaci√≥n.
\end{quote}

Podemos observarlo mediante tres ejemplos:

\begin{itemize}
\item
  \emph{Variable de edad}: Las categor√≠as de edad deben elegirse de forma que sigan permitiendo a los usuarios de los datos realizar c√°lculos relevantes para el tema que se est√° estudiando. Por ejemplo, si es necesario calcular indicadores para ni√±os de edades comprendidas entre los 6 y los 11 a√±os y entre los 12 y los 17 a√±os, adem√°s, es necesario agrupar la edad para reducir el riesgo, hay que tener cuidado de crear intervalos de edad que sigan permitiendo realizar los c√°lculos. Una agrupaci√≥n satisfactoria podr√≠a ser, por ejemplo, 0 - 5, 6 - 11, 12 - 17, etc., mientras que una agrupaci√≥n 0 - 10, 11 - 15, 16 - 18 destruir√≠a la utilidad de los datos para estos usuarios. Aunque es una pr√°ctica habitual crear intervalos (grupos) de igual anchura (tama√±o), tambi√©n es posible (si los usuarios de los datos lo requieren) recodificar solo una parte de las variables y dejar algunos valores como estaban originalmente. Esto podr√≠a hacerse, por ejemplo, recodificando todas las edades superiores a 20 a√±os, pero dejando las inferiores a 20 a√±os tal y como est√°n. Si los m√©todos SDC distintos de la recodificaci√≥n se van a utilizar m√°s tarde o en un paso siguiente, hay que tener cuidado al aplicar la recodificaci√≥n solo a una parte de la distribuci√≥n, ya que esto podr√≠a aumentar la p√©rdida de informaci√≥n debida a los otros m√©todos, ya que la agrupaci√≥n no protege las variables no agrupadas. La recodificaci√≥n parcial seguida de m√©todos de supresi√≥n como la supresi√≥n local puede, por ejemplo, conducir a un n√∫mero de supresiones mayor del deseado o necesario en caso de que la recodificaci√≥n se realice para todo el rango de valores (ver la siguiente secci√≥n de \ref{sup-loc} ). En el ejemplo anterior, el n√∫mero de supresiones de los valores inferiores a 20 ser√° probablemente mayor que para los valores del rango recodificado. El n√∫mero desproporcionadamente alto de supresiones en este rango de valores que no se recodifican puede conducir a una mayor p√©rdida de utilidad para estos grupos.
\item
  \emph{Variables geogr√°ficas}: Si los datos originales especifican informaci√≥n de nivel administrativo en detalle, por ejemplo, hasta el nivel de comuna, entonces potencialmente esos niveles inferiores podr√≠an ser recodificados o agregados en niveles administrativos superiores, por ejemplo, la provincia, para reducir el riesgo. Al hacerlo, hay que tener en cuenta lo siguiente: La agrupaci√≥n de comunas en niveles abstractos que se cruzan con diferentes provincias har√≠a que el an√°lisis de datos a nivel comunal o provincial fuera un reto. Se debe tener cuidado de entender lo que el usuario requiere y la intenci√≥n del estudio. Si un componente clave de la encuesta es realizar un an√°lisis a nivel comunal, la agregaci√≥n a nivel provincial podr√≠a perjudicar la utilidad de los datos para el usuario. La recodificaci√≥n deber√≠a aplicarse si el nivel de detalle de los datos no es necesario para la mayor√≠a de los usuarios de los datos y para evitar un gran n√∫mero de supresiones cuando se utilicen posteriormente otros m√©todos SDC. Si los usuarios necesitan informaci√≥n a un nivel m√°s detallado, otros m√©todos, como los \protect\hyperlink{muxe9todos-perturbativos}{M√©todos perturbativos}, podr√≠an ofrecer una soluci√≥n mejor que la recodificaci√≥n.
\item
  \emph{Instalaciones sanitarias}: Un ejemplo de una situaci√≥n en la que un alto nivel de detalle podr√≠a no ser necesario y la recodificaci√≥n podr√≠a hacer muy poco da√±o a la utilidad es el caso de una variable detallada de instalaciones sanitarias en el hogar que enumera las respuestas para 20 tipos de inodoros. Es posible que los investigadores solo necesiten distinguir entre instalaciones de inodoros mejoradas y no mejoradas y que no necesiten la clasificaci√≥n exacta de hasta 20 tipos. La informaci√≥n detallada de los tipos de inodoros puede utilizarse para volver a identificar a los hogares, mientras que la recodificaci√≥n en dos categor√≠as -instalaciones mejoradas y no mejoradas- reduce el riesgo de reidentificaci√≥n y, en este contexto, apenas reduce la utilidad de los datos. Este enfoque puede aplicarse a cualquier variable con muchas categor√≠as en las que los usuarios de los datos no est√©n interesados en los detalles, sino en algunas categor√≠as agregadas. La recodificaci√≥n aborda la agregaci√≥n para los usuarios de los datos y al mismo tiempo protege los microdatos. Es importante hacer un balance de las agregaciones utilizadas por los usuarios.
\end{itemize}

La recodificaci√≥n debe aplicarse solo si la eliminaci√≥n de la informaci√≥n detallada de los datos no perjudica a la mayor√≠a de las personas usuarias. Si los usuarios necesitan informaci√≥n a un nivel m√°s detallado, entonces la recodificaci√≥n no es apropiada y otros m√©todos, como los perturbativos, podr√≠an funcionar mejor.

En \texttt{sdcMicro} existen diferentes opciones de recodificaci√≥n global. En los siguientes p√°rrafos, damos ejemplos de recodificaci√≥n global con las funciones \texttt{groupAndRename()} y \texttt{globalRecode()}. La funci√≥n \texttt{groupAndRename()} se utiliza generalmente para las variables categ√≥ricas y la funci√≥n \texttt{globalRecode()} para las variables continuas. Por √∫ltimo, discutimos el uso del redondeo para reducir el detalle en las variables continuas.

\hypertarget{recodificaciuxf3n-de-una-variable-categuxf3rica-mediante-la-funciuxf3n-sdcmicro-groupandrename}{%
\paragraph{\texorpdfstring{Recodificaci√≥n de una variable categ√≥rica mediante la funci√≥n \texttt{sdcMicro} \texttt{groupAndRename()}}{Recodificaci√≥n de una variable categ√≥rica mediante la funci√≥n sdcMicro groupAndRename()}}\label{recodificaciuxf3n-de-una-variable-categuxf3rica-mediante-la-funciuxf3n-sdcmicro-groupandrename}}

Supongamos que se ha creado un objeto de la clase \texttt{sdcMicro}, que se llama \texttt{sdcInitial} (v√©ase el apartado \protect\hyperlink{objetos-de-la-clase-sdcmicroobj}{Objetos de la clase \texttt{sdcMicroObj}} c√≥mo crear objetos de la clase \texttt{sdcMicro}). En el Bloque \ref{exm:bloque15jgm}, la variable ``sizeRes'' tiene cuatro categor√≠as diferentes: ``capital'', ``ciudad grande'', ``ciudad peque√±a'', ``pueblo'' y ``campo''). Las tres primeras se recodifican o reagrupan como ``urbano'' y la categor√≠a ``campo'' pasa a llamarse ``rural''. En los argumentos de la funci√≥n, especificamos las categor√≠as que se van a agrupar (anterior) y los nombres de las categor√≠as despu√©s de la recodificaci√≥n (posterior). Es importante que los vectores ``anterior'' y ``posterior'' tengan la misma longitud. Por lo tanto, tenemos que repetir ``urbano'' tres veces en el vector (posterior) para que coincida con los tres valores diferentes que se recodifican en ``urbano''.

\begin{quote}
\textbf{Nota}: La funci√≥n \texttt{groupAndRename()} solo funciona en variables tipo factor.
\end{quote}

Nos referimos a la secci√≥n \protect\hyperlink{clases-en-r}{Clases en \texttt{R}} sobre c√≥mo cambiar la clase de una variable.

Cargar librer√≠as.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{require}\NormalTok{(dplyr)}
\KeywordTok{require}\NormalTok{(foreign)}
\KeywordTok{require}\NormalTok{(sdcMicro)}
\end{Highlighting}
\end{Shaded}

Cargaremos la base en formato de dta (stata).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#directorio de trabajo}
\CommentTok{#getwd()}
\NormalTok{fname <-}\StringTok{ "data/data.dta"}
\NormalTok{file <-}\StringTok{ }\KeywordTok{read.dta}\NormalTok{(fname, }\DataTypeTok{convert.factors =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\textbf{Ajustaremos las variables a factores.}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Crear variables √°rea y etnia para evaluar recodificaci√≥n}

\NormalTok{area_names <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"capital, large city"}\NormalTok{, }\StringTok{"small city"}\NormalTok{, }\StringTok{"town"}\NormalTok{, }\StringTok{"countryside"}\NormalTok{)}
\NormalTok{area <-}\StringTok{ }\KeywordTok{sample}\NormalTok{(area_names[}\DecValTok{1}\OperatorTok{:}\DecValTok{3}\NormalTok{], }\KeywordTok{nrow}\NormalTok{(file[file}\OperatorTok{$}\NormalTok{URBRUR}\OperatorTok{==}\DecValTok{1}\NormalTok{,]), }\DataTypeTok{replace=}\OtherTok{TRUE}\NormalTok{, }\DataTypeTok{prob=}\KeywordTok{c}\NormalTok{(}\FloatTok{0.60}\NormalTok{,}\FloatTok{0.27}\NormalTok{, }\FloatTok{0.13}\NormalTok{))}

\NormalTok{file <-}\StringTok{ }\NormalTok{file }\OperatorTok{%>%}\StringTok{ }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{sizeRes =} \KeywordTok{ifelse}\NormalTok{(URBRUR}\OperatorTok{==}\DecValTok{1}\NormalTok{, area, area_names[}\DecValTok{4}\NormalTok{])) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{relocate}\NormalTok{(sizeRes, }\DataTypeTok{.after =}\NormalTok{ URBRUR) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{sizeRes =} \KeywordTok{factor}\NormalTok{(sizeRes, }\DataTypeTok{levels =}\NormalTok{ area_names))}

\NormalTok{etnia_names <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"mapuche"}\NormalTok{,}\StringTok{"diaguita"}\NormalTok{,}\StringTok{"atacameno"}\NormalTok{,}\StringTok{"otra"}\NormalTok{,}\StringTok{"No aplica"}\NormalTok{)}
\NormalTok{etnia <-}\StringTok{ }\KeywordTok{sample}\NormalTok{(etnia_names, }\KeywordTok{nrow}\NormalTok{(file), }\DataTypeTok{replace=}\OtherTok{TRUE}\NormalTok{, }\DataTypeTok{prob=}\KeywordTok{c}\NormalTok{(}\FloatTok{0.2}\NormalTok{,}\FloatTok{0.1}\NormalTok{,}\FloatTok{0.1}\NormalTok{,}\FloatTok{0.1}\NormalTok{, }\FloatTok{0.95}\NormalTok{))}


\NormalTok{file <-}\StringTok{ }\NormalTok{file }\OperatorTok{%>%}\StringTok{ }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{etnia =}\NormalTok{ etnia) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{etnia =} \KeywordTok{factor}\NormalTok{(etnia, }\DataTypeTok{levels =}\NormalTok{ etnia_names))}


\NormalTok{selectedKeyVarsHH =}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"sizeRes"}\NormalTok{,}\StringTok{"AGEYRS"}\NormalTok{, }\StringTok{"GENDER"}\NormalTok{, }\StringTok{"REGION"}\NormalTok{, }\StringTok{"etnia"}\NormalTok{,}\StringTok{"RELIG"}\NormalTok{) }\CommentTok{#,}
\CommentTok{#selectedKeyVarsHH = c("URBRUR", "REGION", "HHSIZE", "OWNAGLAND", "RELIG")}

\NormalTok{file}\OperatorTok{$}\NormalTok{URBRUR    <-}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(file}\OperatorTok{$}\NormalTok{URBRUR)}
\NormalTok{file}\OperatorTok{$}\NormalTok{REGION    <-}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(file}\OperatorTok{$}\NormalTok{REGION)}
\NormalTok{file}\OperatorTok{$}\NormalTok{OWNHOUSE  <-}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(file}\OperatorTok{$}\NormalTok{OWNHOUSE)}
\NormalTok{file}\OperatorTok{$}\NormalTok{OWNAGLAND <-}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(file}\OperatorTok{$}\NormalTok{OWNAGLAND)}
\NormalTok{file}\OperatorTok{$}\NormalTok{RELIG     <-}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(file}\OperatorTok{$}\NormalTok{RELIG)}


\NormalTok{numVarsHH      <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"LANDSIZEHA"}\NormalTok{, }\StringTok{"TANHHEXP"}\NormalTok{, }\StringTok{"TFOODEXP"}\NormalTok{, }\StringTok{"TALCHEXP"}\NormalTok{, }\StringTok{"TCLTHEXP"}\NormalTok{, }\StringTok{"THOUSEXP"}\NormalTok{, }
                    \StringTok{"TFURNEXP"}\NormalTok{, }\StringTok{"THLTHEXP"}\NormalTok{, }\StringTok{"TTRANSEXP"}\NormalTok{, }\StringTok{"TCOMMEXP"}\NormalTok{, }\StringTok{"TRECEXP"}\NormalTok{, }\StringTok{"TEDUEXP"}\NormalTok{, }
                    \StringTok{"TRESTHOTEXP"}\NormalTok{, }\StringTok{"TMISCEXP"}\NormalTok{, }\StringTok{"INCTOTGROSSHH"}\NormalTok{, }\StringTok{"INCRMT"}\NormalTok{, }\StringTok{"INCWAGE"}\NormalTok{, }\StringTok{"INCFARMBSN"}\NormalTok{, }
                    \StringTok{"INCNFARMBSN"}\NormalTok{, }\StringTok{"INCRENT"}\NormalTok{, }\StringTok{"INCFIN"}\NormalTok{, }\StringTok{"INCPENSN"}\NormalTok{, }\StringTok{"INCOTHER"}\NormalTok{)}

\NormalTok{pramVarsHH     <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"ROOF"}\NormalTok{, }\StringTok{"TOILET"}\NormalTok{, }\StringTok{"WATER"}\NormalTok{, }\StringTok{"ELECTCON"}\NormalTok{, }\StringTok{"FUELCOOK"}\NormalTok{, }\StringTok{"OWNMOTORCYCLE"}\NormalTok{, }\StringTok{"CAR"}\NormalTok{, }\StringTok{"TV"}\NormalTok{, }\StringTok{"LIVESTOCK"}\NormalTok{)}
\NormalTok{weightVarHH    <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"WGTPOP"}\NormalTok{)}

\CommentTok{# Ajuste strata}

\NormalTok{file}\OperatorTok{$}\NormalTok{strata_region <-}\StringTok{ }\NormalTok{file}\OperatorTok{$}\NormalTok{REGION}
\NormalTok{strata_var <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"strata_region"}\NormalTok{)}

\CommentTok{# Ajuste para transformar factores}
\NormalTok{file[,}\KeywordTok{c}\NormalTok{(pramVarsHH)] <-}\StringTok{ }\KeywordTok{lapply}\NormalTok{(file[,}\KeywordTok{c}\NormalTok{(pramVarsHH)], as.factor)}


\NormalTok{HHVars <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"IDH"}\NormalTok{, selectedKeyVarsHH, pramVarsHH, numVarsHH, weightVarHH, strata_var) }\CommentTok{#agrega strata}
\NormalTok{fileHH <-}\StringTok{ }\NormalTok{file}
\NormalTok{fileHH <-}\StringTok{ }\NormalTok{fileHH[}\KeywordTok{which}\NormalTok{(}\OperatorTok{!}\KeywordTok{duplicated}\NormalTok{(fileHH}\OperatorTok{$}\NormalTok{IDH)),]}
\NormalTok{sdcHH <-}\StringTok{ }\KeywordTok{createSdcObj}\NormalTok{(}\DataTypeTok{dat=}\NormalTok{fileHH, }\DataTypeTok{keyVars=}\NormalTok{selectedKeyVarsHH, }\DataTypeTok{pramVars=}\NormalTok{pramVarsHH, }\DataTypeTok{weightVar=}\NormalTok{weightVarHH, }\DataTypeTok{numVars =}\NormalTok{ numVarsHH, }\DataTypeTok{strataVar =} \StringTok{"strata_region"}\NormalTok{)}

\NormalTok{sdcInitial <-}\StringTok{ }\NormalTok{sdcHH}
\NormalTok{sdc_respaldo <-}\StringTok{ }\NormalTok{sdcHH}
\end{Highlighting}
\end{Shaded}

\begin{example}
\protect\hypertarget{exm:bloque15jgm}{}{\label{exm:bloque15jgm} }Uso de la funci√≥n \texttt{sdcMicro} \texttt{groupAndRename()} para recodificar una variable categ√≥rica
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Frequencias de sizeRes antes de recodificar}
\KeywordTok{table}\NormalTok{(sdcInitial}\OperatorTok{@}\NormalTok{manipKeyVars}\OperatorTok{$}\NormalTok{sizeRes)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## capital, large city          small city                town         countryside 
##                 786                 359                 171                 684
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Recodificar urbano}
\NormalTok{sdcInitial  <-}\StringTok{  }\KeywordTok{groupAndRename}\NormalTok{(sdcInitial, }\DataTypeTok{var =} \StringTok{"sizeRes"}\NormalTok{,}
                          \DataTypeTok{before =} \KeywordTok{c}\NormalTok{(}\StringTok{"capital, large city"}\NormalTok{, }\StringTok{"small city"}\NormalTok{, }\StringTok{"town"}\NormalTok{),}
                          \DataTypeTok{after =} \KeywordTok{c}\NormalTok{(}\StringTok{"urban"}\NormalTok{, }\StringTok{"urban"}\NormalTok{, }\StringTok{"urban"}\NormalTok{))}

\CommentTok{# Recodificar rural}
\NormalTok{sdcInitial  <-}\StringTok{  }\KeywordTok{groupAndRename}\NormalTok{(}\DataTypeTok{obj =}\NormalTok{ sdcInitial, }\DataTypeTok{var =} \KeywordTok{c}\NormalTok{(}\StringTok{"sizeRes"}\NormalTok{),}
                          \DataTypeTok{before =} \KeywordTok{c}\NormalTok{(}\StringTok{"countryside"}\NormalTok{), }\DataTypeTok{after =} \KeywordTok{c}\NormalTok{(}\StringTok{"rural"}\NormalTok{))}

\CommentTok{# Frequencias de sizeRes despu√©s de recodificar}
\KeywordTok{table}\NormalTok{(sdcInitial}\OperatorTok{@}\NormalTok{manipKeyVars}\OperatorTok{$}\NormalTok{sizeRes)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## urban rural 
##  1316   684
\end{verbatim}

La \ref{fig:fig4} ilustra el efecto de la recodificaci√≥n de la variable ``sizeRes'' y muestra respectivamente los recuentos de frecuencia antes y despu√©s de la recodificaci√≥n. Vemos que el n√∫mero de categor√≠as se ha reducido de 4 a 2 y las categor√≠as peque√±as (``small city'' y ``town'') han desaparecido.

\begin{figure}
\includegraphics[width=1\linewidth]{bookdown-demo_files/figure-latex/fig4-1} \caption{Efecto de la recodificaci√≥n y recuentos de frecuencia antes y despu√©s de la recodificaci√≥n}\label{fig:fig4}
\end{figure}

\hypertarget{recodificaciuxf3n-de-una-variable-continua-mediante-la-funciuxf3n-sdcmicro-globalrecode}{%
\paragraph{\texorpdfstring{Recodificaci√≥n de una variable continua mediante la funci√≥n \texttt{sdcMicro}: \texttt{globalRecode()}}{Recodificaci√≥n de una variable continua mediante la funci√≥n sdcMicro: globalRecode()}}\label{recodificaciuxf3n-de-una-variable-continua-mediante-la-funciuxf3n-sdcmicro-globalrecode}}

La recodificaci√≥n global de las variables num√©ricas (continuas) puede lograrse en \texttt{sdcMicro} utilizando la funci√≥n \texttt{globalRecode()}, que permite especificar un vector con los puntos de quiebre entre los intervalos. La recodificaci√≥n de una variable continua la convierte en una variable categ√≥rica. Adem√°s, se puede especificar un vector de etiquetas para las nuevas categor√≠as. Por defecto, las etiquetas son los intervalos, por ejemplo, ``(0, 10{]}''. El Bloque \ref{exm:bloque16jgm} muestra c√≥mo recodificar la variable edad en intervalos de 10 a√±os para valores de edad entre 0 y 100.

\begin{quote}
\textbf{Nota}: A los valores que quedan fuera de los intervalos especificados se les asigna un valor perdido \texttt{NA}
\end{quote}

Por lo tanto, los intervalos deben cubrir todo el rango de valores de la variable.

\begin{example}
\protect\hypertarget{exm:bloque16jgm}{}{\label{exm:bloque16jgm} }Uso de la funci√≥n \texttt{sdcMicro} \texttt{globalRecode()} para recodificar una variable continua (edad)
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sdcInitial <-}\StringTok{ }\KeywordTok{globalRecode}\NormalTok{(sdcInitial, }\DataTypeTok{column =} \KeywordTok{c}\NormalTok{(}\StringTok{"AGEYRS"}\NormalTok{),}
                           \DataTypeTok{breaks =} \DecValTok{10} \OperatorTok{*}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{0}\OperatorTok{:}\DecValTok{10}\NormalTok{))}

\CommentTok{# Frecuencias de edad despu√©s de recodificar}
\KeywordTok{table}\NormalTok{(sdcInitial}\OperatorTok{@}\NormalTok{manipKeyVars}\OperatorTok{$}\NormalTok{AGEYRS)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##   (0,10]  (10,20]  (20,30]  (30,40]  (40,50]  (50,60]  (60,70]  (70,80] 
##        0       44      389      578      428      266      173       92 
##  (80,90] (90,100] 
##       27        3
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Guardo objeto de edad en tramos para volver a utilizar en localSupresion}
\NormalTok{sdcInitial_edad <-}\StringTok{ }\NormalTok{sdcInitial}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\includegraphics[width=1\linewidth]{bookdown-demo_files/figure-latex/fig5-1} \caption{Variable de edad antes y despu√©s de la recodificaci√≥n}\label{fig:fig5}
\end{figure}

En lugar de crear intervalos de igual anchura, tambi√©n podemos crear intervalos de anchura desigual. Esto se ilustra en el Bloque \ref{exm:bloque17jgm}, donde utilizamos los grupos de edad 1-5, 6-11, 12-17, 18-21, 22-25, 26-49, 50-64 y 65+. En este ejemplo, es un paso √∫til, ya que incluso despu√©s de recodificar en intervalos de 10 a√±os, las categor√≠as con valores de edad altos tienen frecuencias bajas. Elegimos los intervalos respetando los valores relevantes de la edad escolar y de la edad laboral (por ejemplo, la edad de jubilaci√≥n es de 65 a√±os en este ejemplo) de forma que los datos puedan seguir utiliz√°ndose para la investigaci√≥n com√∫n sobre educaci√≥n y empleo. La \ref{fig:fig6} muestra el efecto de la recodificaci√≥n de la variable ``edad''.

\begin{example}
\protect\hypertarget{exm:bloque17jgm}{}{\label{exm:bloque17jgm} }Uso de \texttt{globalRecode()} para crear intervalos de ancho desigual
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sdcInitial <-}\StringTok{ }\KeywordTok{undolast}\NormalTok{(sdcInitial)}

\NormalTok{sdcInitial <-}\StringTok{ }\KeywordTok{globalRecode}\NormalTok{(sdcInitial, }\DataTypeTok{column =} \KeywordTok{c}\NormalTok{(}\StringTok{"AGEYRS"}\NormalTok{),}
                           \DataTypeTok{breaks =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{11}\NormalTok{, }\DecValTok{17}\NormalTok{, }\DecValTok{21}\NormalTok{, }\DecValTok{25}\NormalTok{, }\DecValTok{49}\NormalTok{, }\DecValTok{65}\NormalTok{, }\DecValTok{100}\NormalTok{))}

\CommentTok{# Frecuencias de edad despu√©s de recodificar}
\KeywordTok{table}\NormalTok{(sdcInitial}\OperatorTok{@}\NormalTok{manipKeyVars}\OperatorTok{$}\NormalTok{AGEYRS)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##    (0,5]   (5,11]  (11,17]  (17,21]  (21,25]  (25,49]  (49,65] (65,100] 
##        0        0        6       52      122     1213      398      209
\end{verbatim}

\begin{figure}
\includegraphics[width=1\linewidth]{bookdown-demo_files/figure-latex/fig6-1} \caption{Variable de edad antes y despu√©s de la recodificaci√≥n}\label{fig:fig6}
\end{figure}

Precauci√≥n sobre el uso de la funci√≥n \texttt{globalRecode()} en \texttt{sdcMicro}: En la implementaci√≥n actual de \texttt{sdcMicro}, los intervalos se definen como abiertos a la izquierda. En t√©rminos matem√°ticos, esto significa que, en nuestro ejemplo, la edad 0 est√° excluida de los intervalos especificados. En notaci√≥n de intervalos, esto se denota como (0, 5{]} (como en las etiquetas del eje x en la \ref{fig:fig5} y la \ref{fig:fig6} para la variable recodificada). El intervalo (0, 5{]} se interpreta como de 0 a 5 y no incluye el 0, pero s√≠ el 5. \texttt{R} recodifica los valores que no est√°n contenidos en ninguno de los intervalos como perdidos (\texttt{NA}). Esta implementaci√≥n establecer√≠a en nuestro ejemplo todos los valores de edad 0 (ni√±os menores de 1 a√±o) como perdidos y podr√≠a significar potencialmente una gran p√©rdida de datos. La funci√≥n \texttt{globalRecode()} solo permite construir intervalos que queden abiertos. Este puede no ser un resultado deseable y la p√©rdida de las edades cero de los datos es claramente problem√°tica para un conjunto de datos del mundo real.

Para construir intervalos abiertos a la derecha, por ejemplo, en nuestro ejemplo, para los intervalos de edad {[}0,14), {[}15, 65), {[}66, 100), presentamos dos alternativas de recodificaci√≥n global:

\begin{itemize}
\tightlist
\item
  Una soluci√≥n para las variables semicontinuas\footnote{Este enfoque s√≥lo funciona para variables semicontinuas, porque en el caso de las variables continuas, puede haber valores que se encuentren entre el l√≠mite inferior del intervalo y el l√≠mite inferior del intervalo menos el n√∫mero menor. Por ejemplo, utilizando este m√©todo para los ingresos, tendr√≠amos un intervalo (9999, 19999} y el valor 9999,5 se clasificar√≠a err√≥neamente como perteneciente al intervalo {[}10000, 19999{]}.{]} que permitir√≠a utilizar \texttt{globalRecode()} ser√≠a restar un peque√±o n√∫mero a los intervalos l√≠mite, permitiendo as√≠ crear los intervalos deseados. En el siguiente ejemplo, restar 0,1 a cada intervalo obliga a \texttt{globalRecode()} a incluir el 0 en el intervalo inferior y permitir las pausas donde las queramos. Establecemos el l√≠mite superior del intervalo para que sea mayor que el valor m√°ximo de la variable ``edad''. Podemos utilizar la opci√≥n etiquetas para definir etiquetas claras para las nuevas categor√≠as. Esto se ilustra en el Bloque \ref{exm:bloque18jgm}.
\end{itemize}

\begin{example}
\protect\hypertarget{exm:bloque18jgm}{}{\label{exm:bloque18jgm} }Construcci√≥n de intervalos abiertos a la derecha para variables semicontinuas utilizando la funci√≥n incorporada de \texttt{sdcMicro}, \texttt{globalRecode()}
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sdcInitial <-}\StringTok{ }\KeywordTok{undolast}\NormalTok{(sdcInitial)}

\NormalTok{sdcInitial <-}\StringTok{ }\KeywordTok{globalRecode}\NormalTok{(sdcInitial, }\DataTypeTok{column =} \KeywordTok{c}\NormalTok{(}\StringTok{"AGEYRS"}\NormalTok{),}
                           \DataTypeTok{breaks =} \KeywordTok{c}\NormalTok{(}\OperatorTok{-}\FloatTok{0.1}\NormalTok{, }\FloatTok{14.9}\NormalTok{, }\FloatTok{64.9}\NormalTok{, }\FloatTok{99.9}\NormalTok{),}
                           \DataTypeTok{labels =} \KeywordTok{c}\NormalTok{(}\StringTok{'[0,15)'}\NormalTok{, }\StringTok{'[15,65)'}\NormalTok{, }\StringTok{'[65,100)'}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\includegraphics[width=1\linewidth]{bookdown-demo_files/figure-latex/figx1-1} \caption{Variable de edad antes y despu√©s de la recodificaci√≥n}\label{fig:figx1}
\end{figure}

\begin{itemize}
\tightlist
\item
  Tambi√©n es posible utilizar c√≥digo en \texttt{R} para recodificar manualmente las variables sin utilizar las funciones \texttt{sdcMicro}. Cuando se utilizan las funciones \texttt{sdcMicro}, el cambio en el riesgo despu√©s de la recodificaci√≥n se recalcula autom√°ticamente, pero si se recodifica manualmente no lo hace. En este caso, hay que dar un paso m√°s y recalcular el riesgo despu√©s de cambiar manualmente las variables en el objeto \texttt{sdcMicro}. Este enfoque tambi√©n es v√°lido para las variables continuas y se ilustra en el Bloque \ref{exm:bloque19jgm}.
\end{itemize}

\begin{example}
\protect\hypertarget{exm:bloque19jgm}{}{\label{exm:bloque19jgm} }Construcci√≥n de intervalos para variables semicontinuas y continuas mediante recodificaci√≥n manual en R
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sdcInitial <-}\StringTok{ }\KeywordTok{undolast}\NormalTok{(sdcInitial)}

\CommentTok{# Grupo edad 0-14}
\NormalTok{sdcInitial}\OperatorTok{@}\NormalTok{manipKeyVars}\OperatorTok{$}\NormalTok{AGEYRS[sdcInitial}\OperatorTok{@}\NormalTok{manipKeyVars}\OperatorTok{$}\NormalTok{AGEYRS }\OperatorTok{>=}\StringTok{ }\DecValTok{0} \OperatorTok{&}
\NormalTok{sdcInitial}\OperatorTok{@}\NormalTok{manipKeyVars}\OperatorTok{$}\NormalTok{AGEYRS }\OperatorTok{<}\StringTok{ }\DecValTok{15}\NormalTok{] <-}\StringTok{ }\DecValTok{0}

\CommentTok{# Grupo edad 15-64}
\NormalTok{sdcInitial}\OperatorTok{@}\NormalTok{manipKeyVars}\OperatorTok{$}\NormalTok{AGEYRS[sdcInitial}\OperatorTok{@}\NormalTok{manipKeyVars}\OperatorTok{$}\NormalTok{AGEYRS }\OperatorTok{>=}\StringTok{ }\DecValTok{15} \OperatorTok{&}
\NormalTok{sdcInitial}\OperatorTok{@}\NormalTok{manipKeyVars}\OperatorTok{$}\NormalTok{AGEYRS }\OperatorTok{<}\StringTok{ }\DecValTok{65}\NormalTok{] <-}\StringTok{ }\DecValTok{1}

\CommentTok{# Grupo edad 65-100}
\NormalTok{sdcInitial}\OperatorTok{@}\NormalTok{manipKeyVars}\OperatorTok{$}\NormalTok{AGEYRS[sdcInitial}\OperatorTok{@}\NormalTok{manipKeyVars}\OperatorTok{$}\NormalTok{AGEYRS }\OperatorTok{>=}\StringTok{ }\DecValTok{65} \OperatorTok{&}
\NormalTok{sdcInitial}\OperatorTok{@}\NormalTok{manipKeyVars}\OperatorTok{$}\NormalTok{AGEYRS }\OperatorTok{<=}\StringTok{ }\DecValTok{100}\NormalTok{] <-}\StringTok{ }\DecValTok{2}

\CommentTok{# A√±adir etiquetas para los nuevos valores}
\NormalTok{sdcInitial}\OperatorTok{@}\NormalTok{manipKeyVars}\OperatorTok{$}\NormalTok{AGEYRS <-}\KeywordTok{ordered}\NormalTok{(sdcInitial}\OperatorTok{@}\NormalTok{manipKeyVars}\OperatorTok{$}\NormalTok{AGEYRS,}
\DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{labels =} \KeywordTok{c}\NormalTok{(}\StringTok{"0-14"}\NormalTok{, }\StringTok{"15-64"}\NormalTok{, }\StringTok{"65-100"}\NormalTok{))}

\CommentTok{# Recalcular el riesgo tras una transformaci√≥n manual}
\NormalTok{sdcInitial <-}\StringTok{ }\KeywordTok{calcRisks}\NormalTok{(sdcInitial)}
\end{Highlighting}
\end{Shaded}

\hypertarget{cod-sup-inf}{%
\subsubsection{Codificaci√≥n superior e inferior}\label{cod-sup-inf}}

La codificaci√≥n superior e inferior es similar a la recodificaci√≥n global, pero en lugar de recodificar todos los valores, solo se recodifican los valores superiores y/o inferiores de la distribuci√≥n o las categor√≠as. Esto solo puede aplicarse a las variables categ√≥ricas ordinales y a las variables semi-continuas, ya que los valores tienen que estar al menos ordenados. La codificaci√≥n superior e inferior es especialmente √∫til si el grueso de los valores se encuentra en el centro de la distribuci√≥n y las categor√≠as perif√©ricas tienen pocas observaciones (valores at√≠picos). Los ejemplos son la edad y los ingresos; para estas variables, a menudo habr√° solo unas pocas observaciones por encima de ciertos umbrales, normalmente en las colas de la distribuci√≥n. Cuanto menor sea el n√∫mero de observaciones dentro de una categor√≠a, mayor ser√° el riesgo de identificaci√≥n. Una soluci√≥n podr√≠a ser agrupar los valores de las colas de la distribuci√≥n en una categor√≠a. Esto reduce el riesgo para esas observaciones y, lo que es m√°s importante, lo hace sin reducir la utilidad de los datos para las dem√°s observaciones de la distribuci√≥n.

Decidir d√≥nde aplicar el umbral y qu√© observaciones deben agruparse requiere:

\begin{itemize}
\tightlist
\item
  Revisar la distribuci√≥n global de la variable para identificar en qu√© punto las frecuencias caen por debajo del n√∫mero deseado de observaciones e identificar los valores at√≠picos en la distribuci√≥n. \ref{fig:fig7} muestra la distribuci√≥n de la variable edad y sugiere 65 (l√≠nea vertical roja) para el c√≥digo superior de edad.
\item
  Tener en cuenta el uso previsto de los datos y el prop√≥sito para el que se realiz√≥ la encuesta. Por ejemplo, si los datos se utilizan normalmente para medir la participaci√≥n en la fuerza laboral de las personas de 15 a 64 a√±os, la codificaci√≥n superior e inferior no debe interferir con las categor√≠as de 15 a 64 a√±os. De lo contrario, el analista se encontrar√≠a con la imposibilidad de crear las medidas deseadas para las que estaban destinados los datos. En el ejemplo, consideramos esto y codificamos todas las edades superiores a 64 a√±os.
\end{itemize}

\begin{figure}
\includegraphics[width=1\linewidth]{bookdown-demo_files/figure-latex/fig7-1} \caption{Utilizaci√≥n de la distribuci√≥n de frecuencias de la variable edad para determinar el umbral de la codificaci√≥n superior}\label{fig:fig7}
\end{figure}

La codificaci√≥n superior e inferior se puede hacer f√°cilmente con la funci√≥n \texttt{topBotCoding()} en \texttt{sdcMicro}. La codificaci√≥n superior y la inferior no pueden hacerse simult√°neamente en \texttt{sdcMicro}. El Bloque \ref{exm:bloque20jgm} ilustra c√≥mo recodificar valores de edad superior a 64 y valores de edad inferior a 5; 65 y 5 reemplazan los valores respectivamente. Para construir varias categor√≠as de codificaci√≥n superior o inferior, por ejemplo, edad de 65 a 80 a√±os y superior a 80 a√±os, se puede utilizar la funci√≥n \texttt{groupAndRename()} en sdcMicro o la recodificaci√≥n manual como se describe en la subsecci√≥n anterior.

\begin{example}
\protect\hypertarget{exm:bloque20jgm}{}{\label{exm:bloque20jgm} }Codificaci√≥n superior y codificaci√≥n inferior en \texttt{sdcMicro} utilizando la funci√≥n \texttt{topBotCoding()}
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sdcInitial <-}\StringTok{ }\NormalTok{sdc_respaldo }\CommentTok{# leo nuevamente la Tabla}

\CommentTok{# Top coding en edad 65}
\NormalTok{sdcInitial <-}\StringTok{ }\KeywordTok{topBotCoding}\NormalTok{(}\DataTypeTok{obj =}\NormalTok{ sdcInitial, }\DataTypeTok{value =} \DecValTok{65}\NormalTok{, }\DataTypeTok{replacement =} \DecValTok{65}\NormalTok{,}
                           \DataTypeTok{kind =} \StringTok{"top"}\NormalTok{, }\DataTypeTok{column =} \StringTok{"AGEYRS"}\NormalTok{)}

\CommentTok{# Bottom coding en edad 5}
\NormalTok{sdcInitial <-}\StringTok{ }\KeywordTok{topBotCoding}\NormalTok{(}\DataTypeTok{obj =}\NormalTok{ sdcInitial, }\DataTypeTok{value =} \DecValTok{5}\NormalTok{, }\DataTypeTok{replacement =} \DecValTok{5}\NormalTok{,}
                           \DataTypeTok{kind =} \StringTok{"bottom"}\NormalTok{, }\DataTypeTok{column =} \StringTok{"AGEYRS"}\NormalTok{)}

\CommentTok{#table(sdcInitial@manipKeyVars$AGEYRS)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\includegraphics[width=1\linewidth]{bookdown-demo_files/figure-latex/figx2-1} \caption{Distribuci√≥n de frecuencias de la variable edad con codificaci√≥n superior}\label{fig:figx2}
\end{figure}

\hypertarget{redondeo}{%
\subsubsection{Redondeo}\label{redondeo}}

El redondeo es similar a la agrupaci√≥n, pero se utiliza para las variables continuas. El redondeo es √∫til para evitar la coincidencia exacta con fuentes de datos externas. Adem√°s, puede utilizarse para reducir el nivel de detalle de los datos. Algunos ejemplos son la eliminaci√≥n de las cifras decimales o el redondeo a la unidad m√°s cercana.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sdcInitial <-}\StringTok{ }\NormalTok{sdc_respaldo }\CommentTok{# leo nuevamente la Tabla}

\KeywordTok{table}\NormalTok{(sdcInitial}\OperatorTok{@}\NormalTok{manipKeyVars}\OperatorTok{$}\NormalTok{AGEYRS)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## 12 14 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 
##  1  3  2  7 15 16 14 28 31 24 39 45 41 52 50 65 48 77 60 55 78 56 56 48 45 55 
## 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 
## 33 50 45 41 52 51 32 39 39 46 36 38 26 19 22 22 22 28 29 24 16 22 13 10 25 13 
## 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 90 91 
## 10 17 21 26 13  9 10  3 11  5  5 15  7 14  5  1  4  6  4  3  1  2  1  3
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Se redondea a la decena m√°s cercana}
\NormalTok{sdcInitial}\OperatorTok{@}\NormalTok{manipKeyVars}\OperatorTok{$}\NormalTok{AGEYRS <-}\StringTok{ }\KeywordTok{round}\NormalTok{(sdcInitial}\OperatorTok{@}\NormalTok{manipKeyVars}\OperatorTok{$}\NormalTok{AGEYRS,}\OperatorTok{-}\DecValTok{1}\NormalTok{)}

\KeywordTok{table}\NormalTok{(sdcInitial}\OperatorTok{@}\NormalTok{manipKeyVars}\OperatorTok{$}\NormalTok{AGEYRS)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  10  20  30  40  50  60  70  80  90 
##   4 176 493 559 326 233 122  77  10
\end{verbatim}

En la siguiente secci√≥n se analiza el m√©todo de supresi√≥n local. La recodificaci√≥n suele utilizarse antes de la supresi√≥n local para reducir el n√∫mero de supresiones necesarias.

\begin{quote}
Lectura recomendada de recodificaci√≥n:
- Hundepool, Anco, Josep Domingo-Ferrer, Luisa Franconi, Sarah Giessing, Rainer Lenz, Jane Naylor, Eric Schulte Nordholt, Giovanni Seri, and Peter Paul de Wolf. 2006. Handbook on Statistical Disclosure Control. ESSNet SDC. \url{http://neon.vb.cbs.nl/casc/handbook.htm}.
- Hundepool, Anco, Josep Domingo-Ferrer, Luisa Franconi, Sarah Giessing, Eric Schulte Nordholt, Keith Spicer, and Peter Paul de Wolf. 2012. Statistical Disclosure Control. Chichester: John Wiley \& Sons Ltd.~\url{doi:10.1002/9781118348239}.
- Templ, Matthias, Bernhard Meindl, Alexander Kowarik, and Shuang Chen. 2014. Statistical Disclosure Control (SDCMicro). \url{http://www.ihsn.org/home/software/disclosure-control-toolbox}. (accessed June 9, 2018).
- De Waal, A.G., and Willenborg, L.C.R.J. 1999. Information loss through global recoding and local suppression. Netherlands Official Statistics, 14:17-20, 1999. Special issue on SDC
\end{quote}

\hypertarget{sup-loc}{%
\subsection{Supresi√≥n local}\label{sup-loc}}

En las encuestas es frecuente encontrar valores para ciertas variables o combinaciones de identificadores indirectos que son compartidos por muy pocos individuos. Cuando esto ocurre, el riesgo de reidentificaci√≥n para esos encuestados es mayor que para el resto de los encuestados (v√©ase la secci√≥n \protect\hyperlink{k-anonimato}{k-anonimato}). A menudo se utiliza la supresi√≥n local tras reducir el n√∫mero de claves en los datos al recodificar las variables adecuadas. La recodificaci√≥n reduce el n√∫mero de supresiones necesarias, as√≠ como el tiempo de c√°lculo para la supresi√≥n. La supresi√≥n de valores significa que los valores de una variable se sustituyen por un valor ausente \texttt{NA} en \texttt{R}). En la secci√≥n \protect\hyperlink{k-anonimato}{k-anonimato} se analiza c√≥mo influyen los valores perdidos en los recuentos de frecuencia y en el \(k\)-anonimato. Es importante tener en cuenta que no se suprimen todos los valores de todos los individuos de una determinada variable, lo que ocurrir√≠a al eliminar un identificador directo, como el ``nombre''; solo se suprimen determinados valores de una variable concreta y de un encuestado o conjunto de encuestados concreto. Esto se ilustra en el siguiente ejemplo y en la Tabla \ref{tab:Tabla9}.

La Tabla \ref{tab:Tabla9} presenta un conjunto de datos con siete encuestados y tres identificadores indirectos. La combinaci√≥n \{``mujer'', ``rural'', ``superior''\} para las variables ``sexo'', ``regi√≥n'' y ``educaci√≥n'' es una combinaci√≥n poco segura, ya que es √∫nica en la muestra. Al suprimir el valor ``mujer'' o ``superior'', el encuestado ya no puede distinguirse de los dem√°s encuestados, ya que ese encuestado comparte la misma combinaci√≥n de variables clave con al menos otros tres encuestados. Solo se suprime el valor de la combinaci√≥n insegura del √∫nico encuestado en riesgo, no los valores de la misma variable de los dem√°s encuestados. La libertad de elegir qu√© valor se suprime puede utilizarse para minimizar el n√∫mero total de supresiones y, por tanto, la p√©rdida de informaci√≥n. Adem√°s, si una variable es muy importante para el usuario, podemos elegir no suprimir los valores de esta variable, a menos que sea estrictamente necesario. En el ejemplo, podemos elegir entre suprimir el valor ``mujer'' o ``mayor'' para conseguir un archivo de datos seguro; elegimos suprimir ``mayor''. Esta elecci√≥n debe hacerse teniendo en cuenta las necesidades de los usuarios de los datos. En este ejemplo, consideramos que ``sexo'' es m√°s importante que ``educaci√≥n''.

\begin{table}

\caption{\label{tab:Tabla9}\label{tab:Tabla9}Ilustraci√≥n de la supresi√≥n local - datos antes y despu√©s de la supresi√≥n}
\centering
\begin{tabular}[t]{clllcll}
\toprule
\multicolumn{4}{c}{Datos originales} & \multicolumn{3}{c}{Despu√©s de supresi√≥n local} \\
\cmidrule(l{3pt}r{3pt}){1-4} \cmidrule(l{3pt}r{3pt}){5-7}
ID & Sexo & Zona & Educaci√≥n & Sexo & Zona & Educaci√≥n\\
\midrule
1 & mujer & rural & superior & mujer & rural & NA / perdido\\
2 & hombre & rural & superior & hombre & rural & superior\\
3 & hombre & rural & superior & hombre & rural & superior\\
4 & hombre & rural & superior & hombre & rural & superior\\
5 & mujer & rural & media & mujer & rural & media\\
\addlinespace
6 & mujer & rural & media & mujer & rural & media\\
7 & mujer & rural & media & mujer & rural & media\\
\bottomrule
\end{tabular}
\end{table}

Dado que las variables continuas tienen un elevado n√∫mero de valores √∫nicos (por ejemplo, los ingresos en d√≥lares o la edad en a√±os), el \(k\)-anonimato y la supresi√≥n local no son adecuadas para las variables continuas o las variables con un n√∫mero muy elevado de categor√≠as. Una posible soluci√≥n en esos casos podr√≠a ser recodificar primero para producir menos categor√≠as (por ejemplo, recodificar la edad en intervalos de 10 a√±os o los ingresos en quintiles). No obstante, \textbf{tenga siempre presente el efecto que tendr√° cualquier recodificaci√≥n en la utilidad de los datos}.

El paquete \texttt{sdcMicro} incluye dos funciones para la supresi√≥n local: \texttt{localSuppression()} y \texttt{localSupp()}. La funci√≥n \texttt{localSuppression()} es la m√°s utilizada y permite el uso de la supresi√≥n en identificadores indirectos especificados para lograr un cierto nivel de \(k\)-anonimato para estos identificadores indirectos. El algoritmo utilizado busca minimizar el n√∫mero total de supresiones mientras se alcanza el umbral de \(k\)-anonimato requerido. Por defecto, el algoritmo tiene m√°s probabilidades de suprimir valores de variables con muchas categor√≠as o valores diferentes, y menos de suprimir variables con menos categor√≠as. Por ejemplo, es m√°s probable que se supriman los valores de una variable geogr√°fica, con 12 √°reas diferentes, que los valores de la variable ``sexo'', que suele tener solo dos categor√≠as. Si las variables con muchos valores diferentes son importantes para la utilidad de los datos y no se desea la supresi√≥n para ellas, es posible clasificar las variables por importancia en la funci√≥n \texttt{localSuppression()} y as√≠ especificar el orden en el que el algoritmo tratar√° de suprimir los valores dentro de los identificadores indirectos para lograr el \(k\)-anonimato. El algoritmo trata de aplicar menos supresiones a las variables de gran importancia que a las de menor importancia. Sin embargo, las supresiones en las variables con alta importancia pueden ser inevitables para lograr el nivel requerido de \(k\)-anonimato.

En el Bloque \ref{exm:bloque21jgm}, se aplica la supresi√≥n local para alcanzar el umbral de \(k\)-anonimato de 5 en los identificadores indirectos ``sexo'', ``regi√≥n'', ``religi√≥n'', ``edad'' y ``etnia''\footnote{Aqu√≠, el objeto \texttt{sdcMicro} ``sdcIntial'' contiene un conjunto de datos con 2.500 individuos y 103 variables. Seleccionamos cinco identificadores indirectos: ``sizeRes'', ``edad'', ``sexo'', ``regi√≥n'' y ``etnia''.}. Sin clasificar la importancia de las variables, el valor de la variable ``edad'' es m√°s probable que se suprima, ya que es la variable con m√°s categor√≠as. La variable ``edad'' tiene 10 categor√≠as despu√©s de la recodificaci√≥n. La variable ``sexo'' es la menos probable que se suprima, ya que solo tiene dos valores diferentes: ``hombre'' y ``mujer''. Las dem√°s variables tienen 4 categor√≠as (``tama√±oRes''), 2 (``regi√≥n'') y 8 (``etnia''). Despu√©s de aplicar la funci√≥n localSuppression(), mostramos el n√∫mero de supresiones por variable con la funci√≥n incorporada \texttt{print()} con la opci√≥n `ls' para la salida de supresi√≥n local. Como se esperaba, la variable ``edad'' es la que tiene m√°s supresiones (80). De hecho, solo la variable ``etnia'' de las dem√°s variables tambi√©n necesit√≥ supresiones (8) para alcanzar el umbral de \(k\)-anonimato de 5. La variable ``etnia'' es la segunda variable con mayor n√∫mero de supresiones. Posteriormente, deshacemos y rehacemos la supresi√≥n local en los mismos datos y reducimos el n√∫mero de supresiones en ``edad'' especificando el vector de importancia con alta importancia (poca supresi√≥n) en el identificador indirecto ``edad''. Tambi√©n,asignamos importancia a la variable ``sexo''. Esto se hace especificando un vector de importancia. Los valores del vector de importancia pueden ir de 1 a \emph{k}, el n√∫mero de identificadores indirectos. En nuestro ejemplo, \emph{k} es igual a 5. Las variables con valores m√°s bajos en los vectores de importancia tienen una importancia alta y, cuando es posible, reciben menos supresiones que las variables con valores m√°s altos.

Para asignar una importancia alta a las variables ``edad'' y ``sexo'', especificamos el vector de importancia como \texttt{c(5,\ 1,\ 1,\ 4,\ 4,\ 5)}, con el orden seg√∫n el orden de las variables especificadas en el objeto \texttt{sdcMicro}. El efecto es claro: no hay supresiones en las variables ``edad'' y ``sexo''. En cambio, las dem√°s variables, especialmente ``tama√±oRes'' y ``etnia'', recibieron muchas m√°s supresiones. El n√∫mero total de valores suprimidos ha aumentado de 88 a 166.

\begin{quote}
\textbf{Nota}: Un menor n√∫mero de supresiones en una variable aumenta el n√∫mero de supresiones necesarias en otras variables (v√©ase el Bloque \ref{exm:bloque21jgm}).
\end{quote}

Por lo general, el n√∫mero total de valores suprimidos necesarios para alcanzar el nivel requerido de \(k\)-anonimato aumenta cuando se especifica un vector de importancia, ya que el vector de importancia impide utilizar el patr√≥n de supresi√≥n √≥ptimo. El vector de importancia debe especificarse solo en los casos en que las variables con muchas categor√≠as desempe√±en un papel importante en la utilidad de los datos para los usuarios de los mismos\footnote{Esto puede evaluarse con medidas de utilidad.}.

\begin{example}
\protect\hypertarget{exm:bloque21jgm}{}{\label{exm:bloque21jgm} }Aplicaci√≥n de la supresi√≥n local con y sin vector de importancia
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Se comienza con la edad recodificada en tramos de 10 a√±os}
\NormalTok{sdcInitial <-}\StringTok{ }\NormalTok{sdcInitial_edad}
\CommentTok{#sdcInitial <- sdc_respaldo # leo nuevamente la Tabla}
\CommentTok{#sdcInitial <- undolast(sdcInitial)}

\CommentTok{# supresi√≥n local sin vector de importancia}
\NormalTok{sdcInitial <-}\StringTok{ }\KeywordTok{localSuppression}\NormalTok{(sdcInitial, }\DataTypeTok{k =} \DecValTok{2}\NormalTok{)}
\KeywordTok{print}\NormalTok{(sdcInitial, }\DataTypeTok{type=}\StringTok{"ls"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Local suppression (applied per strata given by variable(s) strata_region)
\end{verbatim}

\begin{verbatim}
##   KeyVar | Suppressions (#) | Suppressions (%)
##  sizeRes |                0 |            0.000
##   AGEYRS |              252 |           12.600
##   GENDER |                0 |            0.000
##   REGION |                0 |            0.000
##    etnia |               23 |            1.150
##    RELIG |               32 |            1.600
\end{verbatim}

\begin{verbatim}
## ----------------------------------------------------------------------
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Deshacer las supresiones}
\NormalTok{sdcInitial <-}\StringTok{ }\KeywordTok{undolast}\NormalTok{(sdcInitial)}

\CommentTok{# Supresi√≥n local con vector de importancia para evitar supresiones}
\CommentTok{# en las variables primera (sexo) y cuarta (edad)}

\NormalTok{sdcInitial <-}\StringTok{ }\KeywordTok{localSuppression}\NormalTok{(sdcInitial, }\DataTypeTok{importance =} \KeywordTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{), }\DataTypeTok{k =} \DecValTok{2}\NormalTok{) }\CommentTok{#  c(5, 1, 1, 5, 5), k = 5)}
\KeywordTok{print}\NormalTok{(sdcInitial, }\DataTypeTok{type=}\StringTok{"ls"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Local suppression (applied per strata given by variable(s) strata_region)
\end{verbatim}

\begin{verbatim}
##   KeyVar | Suppressions (#) | Suppressions (%)
##  sizeRes |              138 |            6.900
##   AGEYRS |               21 |            1.050
##   GENDER |                0 |            0.000
##   REGION |                0 |            0.000
##    etnia |               83 |            4.150
##    RELIG |               66 |            3.300
\end{verbatim}

\begin{verbatim}
## ----------------------------------------------------------------------
\end{verbatim}

La \ref{fig:fig8} demuestra el efecto del umbral de \(k\)-anonimato requerido y el vector de importancia en la utilidad de los datos utilizando varios indicadores relacionados con el mercado laboral de un conjunto de datos\footnote{I2D2 es un conjunto de datos relacionados con el mercado laboral.} antes y despu√©s de la anonimizaci√≥n. La \ref{fig:fig8} muestra los cambios relativos como porcentaje del valor inicial despu√©s de volver a calcular los indicadores con los datos a los que se aplic√≥ la supresi√≥n local. Los indicadores son la proporci√≥n de mujeres y hombres activos y el n√∫mero de mujeres y hombres en edad de trabajar. Los valores calculados a partir de los datos brutos son, respectivamente, 68\%, 12\%, 8.943 y 9.702. La l√≠nea vertical en 0 es el punto de referencia de la ausencia de cambios. Los n√∫meros indican el umbral de \(k\)-anonimato requerido (3 o 5) y los colores indican el vector de importancia: el rojo (sin s√≠mbolo) es ning√∫n vector de importancia, el azul (con s√≠mbolo *) es de alta importancia en la variable con la informaci√≥n sobre la situaci√≥n laboral y el verde oscuro (con s√≠mbolo +) es de alta importancia en la variable de edad.

Un umbral de \(k\)-anonimato m√°s alto conlleva una mayor p√©rdida de informaci√≥n (es decir, mayores desviaciones de los valores originales de los indicadores, los 5 est√°n m√°s alejados del punto de referencia de ning√∫n cambio que los correspondientes 3) causada por la supresi√≥n local. Reducir el n√∫mero de supresiones en la variable de situaci√≥n laboral especificando un vector de importancia no mejora los indicadores. En cambio, reducir el n√∫mero de supresiones en la edad reduce en gran medida la p√©rdida de informaci√≥n. Dado que los grupos de edad espec√≠ficos tienen una gran influencia en el c√°lculo de estos indicadores (los casos raros se encuentran en los extremos y se suprimir√°n), los √≠ndices de supresi√≥n elevados sobre la edad distorsionan los indicadores. En general, es √∫til comparar las medidas de utilidad (v√©ase la secci√≥n \protect\hyperlink{mediciuxf3n-de-la-utilidad-y-la-puxe9rdida-de-informaciuxf3n}{Medici√≥n de la utilidad y la p√©rdida de informaci√≥n}) para especificar el vector de importancia, ya que los efectos pueden ser imprevisibles.

\begin{figure}
\includegraphics[width=1\linewidth]{Imagenes/image7} \caption{Cambios en los indicadores del mercado laboral tras la anonimizaci√≥n de los datos de I2D2}\label{fig:fig8}
\end{figure}

El umbral de \(k\)-anonimato que debe fijarse depende de varios factores, que son, entre otros:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Los requisitos legales para un archivo de datos seguro.
\item
  Otros m√©todos que se aplicar√°n a los datos.
\item
  El n√∫mero de supresiones y la consiguiente p√©rdida de informaci√≥n resultante de umbrales m√°s altos.
\item
  El tipo de variable.
\item
  Las ponderaciones y el tama√±o de la muestra.
\item
  El tipo de publicaci√≥n (v√©ase la secci√≥n \protect\hyperlink{tipos-de-liberaciuxf3n-de-datos}{Tipos de liberaci√≥n de datos}).
\end{enumerate}

Los niveles aplicados habitualmente para el umbral de \(k\)-anonimato son 3 y 5.

La Tabla \ref{tab:Tabla10} ilustra la influencia del vector de importancia y el umbral de \(k\)-anonimato en el tiempo de ejecuci√≥n, el riesgo global tras la supresi√≥n y el n√∫mero total de supresiones necesarias para alcanzar este umbral de \(k\)-anonimato. El conjunto de datos contiene unos 63.000 individuos. Cuanto mayor sea el umbral de \(k\)-anonimato, m√°s supresiones ser√°n necesarias y menor ser√° el riesgo tras la supresi√≥n local (n√∫mero esperado de reidentificaciones). En este ejemplo concreto, el tiempo de c√°lculo es menor para los umbrales m√°s altos. Esto se debe al mayor n√∫mero de supresiones necesarias, lo que reduce la dificultad de la b√∫squeda de un patr√≥n de supresi√≥n √≥ptimo.

La variable edad se recodifica en intervalos de cinco a√±os y tiene 20 categor√≠as de edad. Esta es la variable con el mayor n√∫mero de categor√≠as. Dar prioridad a la supresi√≥n de otras variables conduce a un mayor n√∫mero total de supresiones y a un mayor tiempo de c√°lculo.

\begin{table}

\caption{\label{tab:Tabla10}\label{tab:Tabla10}Efecto de los vectores de importancia y umbrales de $k$-anonimato en el tiempo de ejecuci√≥n y n√∫mero total de supresiones}
\centering
\begin{tabular}[t]{clcccc}
\toprule
Umbral k-anonimato & Vector de importancia & N√∫mero total de supresiones & Umbral k-anonimato & Vector de importancia & N√∫mero total de supresiones\\
\midrule
3 & ninguno   (por defecto) & 6,676 & 5,387 & 293.0 & 11.8\\
3 & situaci√≥n   laboral & 7,254 & 5,512 & 356.5 & 13.1\\
3 & variable   de edad & 8,175 & 60 & 224.6 & 4.5\\
5 & ninguno   (por defecto) & 9,971 & 7,894 & 164.6 & 8.5\\
5 & situaci√≥n   laboral & 11,668 & 8,469 & 217.0 & 10.2\\
\addlinespace
5 & variable   de edad & 13,368 & 58 & 123.1 & 3.8\\
\bottomrule
\end{tabular}
\end{table}

En los casos en que hay un gran n√∫mero de identificadores indirectos y las variables tienen muchas categor√≠as, el n√∫mero de combinaciones posibles aumenta r√°pidamente (v√©ase \protect\hyperlink{k-anonimato}{k-anonimato}). Si el n√∫mero de variables y categor√≠as es muy grande, el tiempo de c√°lculo del algoritmo \texttt{localSuppression()} puede ser muy largo (v√©ase la secci√≥n \protect\hyperlink{tiempo-de-cuxf3mputo}{Tiempo de c√≥mputo} sobre el tiempo de c√°lculo). Adem√°s, es posible que el algoritmo no llegue a una soluci√≥n, o que llegue a una soluci√≥n que no cumpla el nivel de \(k\)-anonimato especificado. Por lo tanto, se recomienda reducir el n√∫mero de identificadores indirectos y/o categor√≠as antes de aplicar la supresi√≥n local. Esto puede hacerse recodificando las variables o seleccionando algunas variables para otros m√©todos (perturbativos), como el PRAM. De este modo se garantiza que el n√∫mero de supresiones sea limitado y, por tanto, la p√©rdida de datos se limite solo a los valores que suponen un mayor riesgo.

En algunos conjuntos de datos, puede resultar dif√≠cil reducir el n√∫mero de identificadores indirectos e incluso despu√©s de reducir el n√∫mero de categor√≠as mediante recodificaci√≥n, el algoritmo de supresi√≥n local tarda mucho tiempo en calcular las supresiones necesarias. Una soluci√≥n en estos casos puede ser el llamado ``enfoque \textbf{all-m}'' (v√©ase \citep{Wolf15}). El enfoque \textbf{all-m} consiste en aplicar el algoritmo de supresi√≥n local descrito anteriormente a todos los posibles subconjuntos de tama√±o \textbf{m} del conjunto total de identificadores indirectos. La ventaja de este enfoque es que los problemas parciales son m√°s f√°ciles de resolver y el tiempo de c√°lculo ser√° menor. Hay que tener cuidado, ya que este m√©todo no conduce necesariamente al \(k\)-anonimato en el conjunto completo de identificadores indirectos. Hay dos posibilidades para alcanzar el mismo nivel de protecci√≥n 1) elegir un umbral m√°s alto para \emph{k} o 2) volver a aplicar el algoritmo de supresi√≥n local en el conjunto completo de \emph{k} despu√©s de utilizar el m√©todo \textbf{all-m} para alcanzar el umbral requerido. En el segundo caso, el enfoque \textbf{all-m} conduce a un menor tiempo de c√°lculo a costa de un mayor n√∫mero total de supresiones.

\begin{quote}
\textbf{Nota}: El nivel requerido no se alcanza autom√°ticamente en todo el conjunto de identificadores indirectos si se utiliza el enfoque \textbf{all-m}.
\end{quote}

Por lo tanto, es importante evaluar cuidadosamente las medidas de riesgo despu√©s de utilizar el enfoque \textbf{all-m}.

En \texttt{sdcMicro} el enfoque \textbf{all-m} se implementa en el argumento `combs' de la funci√≥n \texttt{localSuppression()}. El valor de \textbf{m} se especifica en el argumento `combs' y tambi√©n puede tomar varios valores. Los subconjuntos de diferentes tama√±os se utilizan secuencialmente en el algoritmo de supresi√≥n local. Por ejemplo, si `combs' se establece como c(3,9), primero se consideran todos los subconjuntos de tama√±o 3 y posteriormente todos los subconjuntos de tama√±o 9. Establecer el √∫ltimo valor del argumento combs en el n√∫mero total de variables clave garantiza la consecuci√≥n del \(k\)-anonimato para el conjunto de datos completo. Tambi√©n es posible especificar diferentes valores de k para cada tama√±o de subconjunto en el argumento \emph{k}. Si quisi√©ramos lograr el anonimato de 5 en los subconjuntos de tama√±o 3 y posteriormente el anonimato de 3 en los subconjuntos de tama√±o 9, establecer√≠amos el argumento \emph{k} como c(5,3). El Bloque \ref{exm:bloque22jgm} ilustra el uso del enfoque \textbf{all-m} en \texttt{sdcMicro}.

\begin{example}
\protect\hypertarget{exm:bloque22jgm}{}{\label{exm:bloque22jgm} }El enfoque \textbf{all-m} en \texttt{sdcMicro}
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sdcInitial <-}\StringTok{ }\KeywordTok{undolast}\NormalTok{(sdcInitial)}

\CommentTok{# Aplicar k-anonimato con umbral 5 a todos los subconjuntos de dos variables clave y}
\CommentTok{# posteriormente al conjunto de datos completo}
\NormalTok{sdcInitial <-}\StringTok{ }\KeywordTok{localSuppression}\NormalTok{(sdcInitial, }\DataTypeTok{k =} \DecValTok{5}\NormalTok{, }\DataTypeTok{combs =} \KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{5}\NormalTok{))}
\KeywordTok{print}\NormalTok{(sdcInitial, }\DataTypeTok{type=}\StringTok{"ls"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Local suppression (applied per strata given by variable(s) strata_region)
\end{verbatim}

\begin{verbatim}
##   KeyVar | Suppressions (#) | Suppressions (%)
##  sizeRes |                0 |            0.000
##   AGEYRS |              445 |           22.250
##   GENDER |                1 |            0.050
##   REGION |                0 |            0.000
##    etnia |               82 |            4.100
##    RELIG |               77 |            3.850
\end{verbatim}

\begin{verbatim}
## ----------------------------------------------------------------------
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sdcInitial <-}\StringTok{ }\KeywordTok{undolast}\NormalTok{(sdcInitial)}
\CommentTok{# Aplicar k-anonimato con umbral 5 a todos los subconjuntos de tres variables clave y}
\CommentTok{# posteriormente con el umbral 2 al conjunto de datos completo}
\NormalTok{sdcInitial <-}\StringTok{ }\KeywordTok{localSuppression}\NormalTok{(sdcInitial, }\DataTypeTok{k =} \KeywordTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{, }\DecValTok{5}\NormalTok{), }\DataTypeTok{combs =} \KeywordTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\KeywordTok{print}\NormalTok{(sdcInitial, }\DataTypeTok{type=}\StringTok{"ls"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Local suppression (applied per strata given by variable(s) strata_region)
\end{verbatim}

\begin{verbatim}
##   KeyVar | Suppressions (#) | Suppressions (%)
##  sizeRes |                0 |            0.000
##   AGEYRS |              376 |           18.800
##   GENDER |                0 |            0.000
##   REGION |                0 |            0.000
##    etnia |               40 |            2.000
##    RELIG |               55 |            2.750
\end{verbatim}

\begin{verbatim}
## ----------------------------------------------------------------------
\end{verbatim}

La Tabla \ref{tab:Tabla11} presenta los resultados de utilizar el enfoque \textbf{all-m} de un conjunto de datos de prueba con 9 variables clave y 4.000 registros. La Tabla muestra los argumentos \emph{k} y ``combs'' de la funci√≥n \texttt{localSuppression()}, el n√∫mero de violaciones de \(k\)-anonimato para diferentes niveles de \emph{k}, as√≠ como el n√∫mero total de supresiones. Observamos que las diferentes combinaciones no siempre conducen al nivel de \(k\)-anonimato requerido. Por ejemplo, cuando se establece \emph{k=3}, y ``combs'' 3 y 7, todav√≠a hay 15 registros en el conjunto de datos (con un total de 9 identificadores indirectos) que violan el anonimato 3 despu√©s de la supresi√≥n local. Debido al menor tama√±o de la muestra, las ganancias en tiempo de ejecuci√≥n no son todav√≠a evidentes en este ejemplo, ya que la ejecuci√≥n del algoritmo varias veces consume tiempo. Un conjunto de datos m√°s grande se beneficiar√≠a m√°s del enfoque \textbf{all-m}, ya que el algoritmo tardar√≠a m√°s tiempo.

\begin{table}

\caption{\label{tab:Tabla11}\label{tab:Tabla11}Efecto del enfoque **all-m** en el $k$-anonimato}
\centering
\begin{tabular}[t]{ccccccc}
\toprule
\multicolumn{2}{c}{Argumentos} & \multicolumn{3}{c}{N√∫mero de incumplimientos para diferentes niveles de \$k\$-anonimato en el conjunto completo} & \multicolumn{1}{c}{N√∫mero total de supresiones} & \multicolumn{1}{c}{Tiempo de ejecuci√≥n (segundos)} \\
\cmidrule(l{3pt}r{3pt}){1-2} \cmidrule(l{3pt}r{3pt}){3-5} \cmidrule(l{3pt}r{3pt}){6-6} \cmidrule(l{3pt}r{3pt}){7-7}
\multicolumn{1}{c}{k} & \multicolumn{1}{c}{combs} & \multicolumn{1}{c}{k = 2} & \multicolumn{1}{c}{k = 3} & \multicolumn{1}{c}{k = 5} & \multicolumn{1}{c}{.} & \multicolumn{1}{c}{.} \\
\cmidrule(l{3pt}r{3pt}){1-1} \cmidrule(l{3pt}r{3pt}){2-2} \cmidrule(l{3pt}r{3pt}){3-3} \cmidrule(l{3pt}r{3pt}){4-4} \cmidrule(l{3pt}r{3pt}){5-5} \cmidrule(l{3pt}r{3pt}){6-6} \cmidrule(l{3pt}r{3pt}){7-7}
Antes supresi√≥n & de la local & 2,464 & 3,324 & 3,877 & 0 & 0.00\\
\midrule
3 & . & 0 & 0 & 1,766 & 2,264 & 17.08\\
5 & . & 0 & 0 & 0 & 3,318 & 10.57\\
3 & 3 & 2,226 & 3,202 & 3,819 & 3,873 & 13.39\\
3 & 3,7 & 15 & 108 & 1,831 & 6,164 & 46.84\\
3 & 3,9 & 0 & 0 & 1,794 & 5,982 & 31.38\\
\addlinespace
3 & 5,9 & 0 & 0 & 1,734 & 6,144 & 62.30\\
5 & 3 & 2,047 & 3,043 & 3,769 & 3,966 & 12.88\\
5 & 3,7 & 0 & 6 & 86 & 7,112 & 46.57\\
5 & 3,9 & 0 & 0 & 0 & 7,049 & 24.13\\
5 & 5,9 & 0 & 0 & 0 & 7,129 & 54.76\\
\addlinespace
5,3 & 3,7 & 11 & 108 & 1,859 & 6,140 & 45.60\\
5,3 & 3,9 & 0 & 0 & 1,766 & 2,264 & 30.07\\
5,3 & 5,9 & 0 & 0 & 0 & 3,318 & 51.25\\
\bottomrule
\end{tabular}
\end{table}

A menudo el conjunto de datos contiene variables relacionadas con las variables clave utilizadas para la supresi√≥n local. Ejemplos de ello son las variables rural/urbano a las regiones en caso de que las regiones sean completamente rurales o urbanas o las variables que solo se responden para categor√≠as espec√≠ficas (por ejemplo, el sector para los que trabajan, las variables relacionadas con la escolaridad para ciertos rangos de edad). En esos casos, las variables rural/urbana o sector podr√≠an no ser identificadores indirectos en s√≠ mismas, pero podr√≠an permitir al intruso reconstruir valores suprimidos en los identificadores indirectos regi√≥n o situaci√≥n laboral. Por ejemplo, si la regi√≥n 1 es completamente urbana y todas las dem√°s regiones son solo semiurbanas o rurales, una supresi√≥n en la variable regi√≥n para un registro de la regi√≥n 1 puede reconstruirse simplemente mediante la variable rural/urbana. Por lo tanto, es √∫til suprimir los valores correspondientes a las supresiones en esas variables vinculadas. El Bloque \ref{exm:bloque23jgm} ilustra c√≥mo suprimir los valores de la variable ``urbrur'' correspondientes a las supresiones en la variable regi√≥n. Todos los valores de ``urbrur'' que corresponden a un valor suprimido \texttt{NA} en la variable ``region'' se suprimen (se ponen a \texttt{NA}).

\begin{example}
\protect\hypertarget{exm:bloque23jgm}{}{\label{exm:bloque23jgm} }Suprimir manualmente los valores de las variables vinculadas.
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Suprimir los valores de urbrur en el archivo si la regi√≥n est√° suprimida}
\NormalTok{file[}\KeywordTok{is.na}\NormalTok{(sdcInitial}\OperatorTok{@}\NormalTok{manipKeyVars}\OperatorTok{$}\NormalTok{region) }\OperatorTok{&}
\StringTok{    }\OperatorTok{!}\KeywordTok{is.na}\NormalTok{(sdcInitial}\OperatorTok{@}\NormalTok{origData}\OperatorTok{$}\NormalTok{region),}\StringTok{'sizRes'}\NormalTok{] <-}\StringTok{ }\OtherTok{NA}
\end{Highlighting}
\end{Shaded}

Como alternativa, las variables vinculadas pueden especificarse al crear el objeto \texttt{sdcMicro}. Las variables vinculadas se denominan variables ``fantasma''. Cualquier supresi√≥n en la variable clave conducir√° a una supresi√≥n en las variables vinculadas a esa variable clave. El Bloque \ref{exm:bloque24jgm} muestra c√≥mo especificar la vinculaci√≥n entre ``regi√≥n'' y ``urbrur'' con variables fantasma.

\begin{example}
\protect\hypertarget{exm:bloque24jgm}{}{\label{exm:bloque24jgm} }Suprimir valores en variables enlazadas especificando variables fantasma
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Las variables fantasma (vinculadas) se especifican como una lista de v√≠nculos}
\NormalTok{ghostVars <-}\StringTok{ }\KeywordTok{list}\NormalTok{()}

\CommentTok{# Cada enlace es una lista, con la variable clave en el primer elemento y}
\CommentTok{# la(s) variable(s) vinculada(s) en el segundo elemento}
\NormalTok{ghostVars[[}\DecValTok{1}\NormalTok{]] <-}\StringTok{ }\KeywordTok{list}\NormalTok{()}
\NormalTok{ghostVars[[}\DecValTok{1}\NormalTok{]][[}\DecValTok{1}\NormalTok{]] <-}\StringTok{ "REGION"}
\NormalTok{ghostVars[[}\DecValTok{1}\NormalTok{]][[}\DecValTok{2}\NormalTok{]] <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"URBRUR"}\NormalTok{)}

\CommentTok{# Crear sdcMicroObj}

\NormalTok{sdcInitial <-}\StringTok{ }\KeywordTok{createSdcObj}\NormalTok{(}\DataTypeTok{dat=}\NormalTok{fileHH, }\DataTypeTok{keyVars=}\NormalTok{selectedKeyVarsHH, }\DataTypeTok{pramVars=}\NormalTok{pramVarsHH, }\DataTypeTok{weightVar=}\NormalTok{weightVarHH, }\DataTypeTok{numVars =}\NormalTok{ numVarsHH, }\DataTypeTok{ghostVars =}\NormalTok{ ghostVars)}

\CommentTok{# Las variables fantasma manipuladas se encuentran en manipGhostVars}
\KeywordTok{head}\NormalTok{(sdcInitial}\OperatorTok{@}\NormalTok{manipGhostVars,}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    URBRUR
## 1       2
## 8       1
## 12      2
## 20      1
## 31      2
## 38      1
## 42      1
## 44      1
## 46      2
## 47      1
\end{verbatim}

La alternativa m√°s sencilla para la funci√≥n \texttt{localSuppression()} en \texttt{sdcMicro} es la funci√≥n \texttt{localSupp()}. La funci√≥n \texttt{localSupp()} puede utilizarse para suprimir los valores de ciertas variables clave de los individuos con riesgos superiores a un determinado umbral. En este caso, se suprimir√°n todos los valores de la variable especificada para los encuestados con un riesgo superior al umbral especificado. La medida de riesgo utilizada es el riesgo individual (v√©ase la secci√≥n \protect\hyperlink{riesgo-individual}{Riesgo individual}. Esto es √∫til si una variable tiene valores sensibles que no deben publicarse para los individuos con alto riesgo de reidentificaci√≥n. Lo que se considera alta probabilidad de reidentificaci√≥n depende de los requisitos legales. En el siguiente ejemplo, los valores de la variable ``educaci√≥n'' se suprimen para todos los individuos cuyo riesgo individual es superior a 0,08, lo que se ilustra en el Bloque \ref{exm:bloque25jgm}. Para obtener una visi√≥n general de los valores de riesgo individuales, puede ser √∫til observar las estad√≠sticas resumidas de los valores de riesgo individuales, as√≠ como el n√∫mero de supresiones.

\begin{example}
\protect\hypertarget{exm:bloque25jgm}{}{\label{exm:bloque25jgm} }Aplicaci√≥n de la funci√≥n integrada \texttt{sdcMicro} \texttt{localSupp()}
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Estad√≠sticas resumidas}
\KeywordTok{summary}\NormalTok{(sdcInitial}\OperatorTok{@}\NormalTok{risk}\OperatorTok{$}\NormalTok{individual[,}\DecValTok{1}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
## 4.436e-05 6.405e-04 2.870e-03 4.816e-03 6.194e-03 8.541e-02
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# N√∫mero de individuos con riesgo individual superior al 0,1}
\KeywordTok{sum}\NormalTok{(sdcInitial}\OperatorTok{@}\NormalTok{risk}\OperatorTok{$}\NormalTok{individual[,}\DecValTok{1}\NormalTok{] }\OperatorTok{>}\StringTok{ }\FloatTok{0.08}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# supresi√≥n local}
\NormalTok{sdcInitial <-}\StringTok{ }\KeywordTok{localSupp}\NormalTok{(sdcInitial, }\DataTypeTok{threshold =} \FloatTok{0.08}\NormalTok{, }\DataTypeTok{keyVar =} \StringTok{"etnia"}\NormalTok{)}

\KeywordTok{print}\NormalTok{(sdcInitial, }\DataTypeTok{type=}\StringTok{"ls"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Local suppression:
\end{verbatim}

\begin{verbatim}
##   KeyVar | Suppressions (#) | Suppressions (%)
##  sizeRes |                0 |            0.000
##   AGEYRS |                0 |            0.000
##   GENDER |                0 |            0.000
##   REGION |                0 |            0.000
##    etnia |                1 |            0.050
##    RELIG |                0 |            0.000
\end{verbatim}

\begin{verbatim}
## ----------------------------------------------------------------------
\end{verbatim}

\hypertarget{muxe9todos-perturbativos}{%
\section{M√©todos perturbativos}\label{muxe9todos-perturbativos}}

Los m√©todos perturbativos no suprimen los valores del conjunto de datos, sino que perturban (alteran) los valores para limitar el riesgo de divulgaci√≥n creando incertidumbre en torno a los valores reales. Un intruso no sabe si una coincidencia entre los microdatos y un archivo externo es correcta o no. La mayor√≠a de los m√©todos perturbativos se basan en el principio del enmascaramiento matricial, es decir, el conjunto de datos alterado \(Z\) se calcula como

\[Z = AXB + C\]

donde \(X\) son los datos originales, \(A\) es una matriz utilizada para transformar los registros, \(B\) es una matriz para transformar las variables y \(C\) es una matriz con ruido aditivo.

\begin{quote}
\textbf{Nota}: Las medidas de riesgo basadas en el recuento de frecuencias de las claves dejan de ser v√°lidas tras aplicar los m√©todos perturbativos.
\end{quote}

Esto puede verse en la Tabla \ref{tab:Tabla12}, que muestra los mismos datos antes y despu√©s de intercambiar algunos valores. Los valores intercambiados aparecen en cursiva. Tanto antes como despu√©s de perturbar los datos, todas las observaciones violan el \(k\)-anonimato en el nivel 3 (es decir, cada clave no aparece m√°s de dos veces en el conjunto de datos). No obstante, el riesgo de reidentificaci√≥n \textbf{correcta} de los registros se reduce y, por tanto, es posible que no se revele la informaci√≥n contenida en otras variables (sensibles). Con cierta probabilidad, una coincidencia de los microdatos con un archivo de datos externo ser√° err√≥nea. Por ejemplo, un intruso encontrar√≠a un individuo con la combinaci√≥n \{``hombre'', ``urbano'', ``superior''\}, que es una muestra √∫nica. Sin embargo, esta coincidencia no es correcta, ya que el conjunto de datos original no conten√≠a ning√∫n individuo con estas caracter√≠sticas y, por tanto, el individuo coincidente no puede ser una coincidencia correcta. El intruso no puede saber con certeza si la informaci√≥n revelada de otras variables para ese registro es correcta.

\begin{table}

\caption{\label{tab:Tabla12}\label{tab:Tabla12}Efecto del enfoque **all-m** en el $k$-anonimato}
\centering
\begin{tabular}[t]{ccccccc}
\toprule
\multicolumn{1}{c}{Variable} & \multicolumn{3}{c}{Datos originales} & \multicolumn{3}{c}{Despu√©s de perturbar los datos} \\
\cmidrule(l{3pt}r{3pt}){1-1} \cmidrule(l{3pt}r{3pt}){2-4} \cmidrule(l{3pt}r{3pt}){5-7}
ID & Sexo & Zona & Educaci√≥n & Sexo & Zona & Educaci√≥n\\
\midrule
1 & mujer & rural & superior & mujer & rural & superior\\
2 & mujer & rural & superior & mujer & rural & *media*\\
3 & hombre & rural & media & hombre & rural & media\\
4 & hombre & rural & media & *mujer* & rural & media\\
5 & mujer & urbana & media & *hombre* & urbana & *superior*\\
\addlinespace
6 & mujer & urbana & media & mujer & urbana & media\\
\bottomrule
\end{tabular}
\end{table}

Una de las ventajas de los m√©todos perturbativos es que se reduce la p√©rdida de informaci√≥n, ya que no se suprimir√°n valores, dependiendo del nivel de perturbaci√≥n. Una desventaja es que los usuarios de los datos pueden tener la impresi√≥n de que los datos no se han anonimizado antes de su publicaci√≥n y estar√°n menos dispuestos a participar en futuras encuestas. Por lo tanto, es necesario elaborar informes tanto para uso interno como externo (v√©ase \protect\hyperlink{etapa-6.4.5-generar-reportes-y-liberar-datos}{Etapa 6.4.5: Generar reportes y liberar datos}).

Una alternativa a los m√©todos perturbativos es la generaci√≥n de archivos de datos sint√©ticos con las mismas caracter√≠sticas que los archivos de datos originales. Los archivos de datos sint√©ticos no se discuten en estas directrices. Aqu√≠ abordamos cinco m√©todos perturbativos: El m√©todo de post aleatorizaci√≥n (PRAM), la microagregaci√≥n, la adici√≥n de ruido, el shuffling y el rank swapping.

\hypertarget{pram-muxe9todo-de-post-aleatorizaciuxf3n}{%
\subsection{PRAM (M√©todo de Post-Aleatorizaci√≥n)}\label{pram-muxe9todo-de-post-aleatorizaciuxf3n}}

PRAM es un m√©todo perturbativo para datos categ√≥ricos. Este m√©todo reclasifica los valores de una o m√°s variables, de manera que los intrusos que intentan reidentificar a los individuos en los datos lo hacen, sin embargo, con probabilidad positiva, la reidentificaci√≥n realizada es con el individuo equivocado. Esto significa que el intruso puede ser capaz de hacer coincidir varios individuos entre los archivos externos y los archivos de datos liberados, pero no puede estar seguro de que estas coincidencias correspondan al individuo correcto.

PRAM se define mediante la matriz de transici√≥n \(P\), que especifica las probabilidades de transici√≥n, es decir, la probabilidad de que un valor de una determinada variable permanezca inalterado o se cambie a cualquiera de los otros \(k-1\) valores. \(k\) es el n√∫mero de categor√≠as o niveles del factor dentro de la variable que se va a PRAM. Por ejemplo, si la variable regi√≥n tiene 10 regiones diferentes, \(k\) es igual a 10. En el caso de PRAM para una sola variable, la matriz de transici√≥n es de tama√±o \(k‚àók\). Ilustramos el PRAM con un ejemplo de la variable ``regi√≥n'', que tiene tres valores diferentes: ``capital'', ``rural1'' y ``rural2''. La matriz de transici√≥n para aplicar PRAM a esta variable es de tama√±o 3*3:

\begin{split}
P = 
\begin{bmatrix}
1 & 0 & 0 \\
0.05 & 0.8 & 0.15 \\
0.05 & 0.15 & 0.8 \\
\end{bmatrix}
\end{split}

Los valores de la diagonal son las probabilidades de que un valor de la categor√≠a correspondiente no se modifique. El valor 1 en la posici√≥n (1,1) de la matriz significa que todos los valores ``capital'' permanecen ``capital''; esto podr√≠a ser una decisi√≥n √∫til, ya que la mayor√≠a de los individuos viven en la capital y no necesitan protecci√≥n. El valor 0,8 en la posici√≥n (2,2) significa que un individuo con valor ``rural1'' se quedar√° con probabilidad 0,8 ``rural1''. Los valores 0,05 y 0,15 en la segunda fila de la matriz indican que el valor ``rural1'' se cambiar√° a ``capital'' o ``rural2'' con una probabilidad de 0,05 y 0,15, respectivamente. Si en el fichero inicial ten√≠amos 5.000 individuos con valor ``capital'' y respectivamente 500 y 400 con valores ``rural1'' y ``rural2'', esperamos despu√©s de aplicar PRAM tener 5.045 individuos con capital, 460 con rural1 y 395 con rural2 {[}9{]}. La recodificaci√≥n se realiza de forma independiente para cada individuo. Vemos que la tabulaci√≥n de la variable ``regi√≥n'' arroja resultados diferentes antes y despu√©s de PRAM, que se muestran en la Tabla \ref{tab:Tabla13}. La desviaci√≥n de la expectativa se debe a que PRAM es un m√©todo probabil√≠stico, es decir, los resultados dependen de un mecanismo de generaci√≥n de probabilidades; en consecuencia, los resultados pueden diferir cada vez que aplicamos PRAM a las mismas variables de un conjunto de datos.

\begin{quote}
\textbf{Nota}:El n√∫mero de valores modificados es mayor de lo que podr√≠a pensarse al inspeccionar las tabulaciones de la Tabla \ref{tab:Tabla13}. No todos los 5.000 individuos con valor ``capital'' despu√©s de PRAM ten√≠an este valor antes de PRAM y los 457 individuos en rural1 despu√©s de PRAM no est√°n todos incluidos en los 500 individuos antes de PRAM. El n√∫mero de cambios es mayor que las diferencias en la tabulaci√≥n (v√©ase la matriz de transici√≥n).
\end{quote}

Dado que la matriz de transici√≥n es conocida por los usuarios finales, hay varias formas de corregir el an√°lisis estad√≠stico de los datos por las distorsiones introducidas por el PRAM.

\begin{table}

\caption{\label{tab:Tabla13}\label{tab:Tabla13}Tabulaci√≥n de la variable "regi√≥n" antes y despu√©s del PRAM}
\centering
\begin{tabular}[t]{ccc}
\toprule
Valor & Tabulaci√≥n antes de PRAM & Tabulaci√≥n despu√©s de PRAM\\
\midrule
rural1 & 500 & 457\\
rural2 & 400 & 391\\
\bottomrule
\end{tabular}
\end{table}

Una forma de garantizar la consistencia entre las tabulaciones antes y despu√©s de PRAM es elegir la matriz de transici√≥n de forma que, en la expectativa, las tabulaciones antes y despu√©s de aplicar PRAM sean las mismas para todas las variables. {[}10{]} Este m√©todo se llama PRAM invariante y se implementa en \texttt{sdcMicro} en la funci√≥n \texttt{pram()}. El m√©todo \texttt{pram()} determina la matriz de transici√≥n que satisface los requisitos de PRAM invariante.

\begin{quote}
El PRAM invariante no garantiza que las tabulaciones cruzadas de las variables (a diferencia de las tabulaciones univariantes) permanezcan iguales.
\end{quote}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Ejecutamos nuevamente las variables clave}

\NormalTok{selectedKeyVarsHH <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"URBRUR"}\NormalTok{, }\StringTok{"REGION"}\NormalTok{, }\StringTok{"HHSIZE"}\NormalTok{, }\StringTok{"OWNAGLAND"}\NormalTok{, }\StringTok{"RELIG"}\NormalTok{)}


\NormalTok{HHVars <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"IDH"}\NormalTok{, selectedKeyVarsHH, pramVarsHH, numVarsHH, weightVarHH, strata_var) }\CommentTok{#agrega strata}
\NormalTok{fileHH <-}\StringTok{ }\NormalTok{file}
\NormalTok{fileHH <-}\StringTok{ }\NormalTok{fileHH[}\KeywordTok{which}\NormalTok{(}\OperatorTok{!}\KeywordTok{duplicated}\NormalTok{(fileHH}\OperatorTok{$}\NormalTok{IDH)),]}
\NormalTok{sdcHH <-}\StringTok{ }\KeywordTok{createSdcObj}\NormalTok{(}\DataTypeTok{dat=}\NormalTok{fileHH, }\DataTypeTok{keyVars=}\NormalTok{selectedKeyVarsHH, }\DataTypeTok{pramVars=}\NormalTok{pramVarsHH, }\DataTypeTok{weightVar=}\NormalTok{weightVarHH, }\DataTypeTok{numVars =}\NormalTok{ numVarsHH, }\DataTypeTok{strataVar =} \StringTok{"strata_region"}\NormalTok{)}

\NormalTok{sdcInitial <-}\StringTok{ }\NormalTok{sdcHH}
\NormalTok{sdc_respaldo <-}\StringTok{ }\NormalTok{sdcHH}
\end{Highlighting}
\end{Shaded}

En el Bloque \ref{exm:bloque26jgm}, damos un ejemplo de PRAM invariante utilizando \texttt{sdcMicro}\footnote{En este ejemplo y en los siguientes de esta secci√≥n, el objeto \texttt{sdcMicro} ``sdcIntial'' contiene un conjunto de datos con 2.000 individuos y 39 variables. Seleccionamos cinco identificadores indirectos categ√≥ricos y 9 variables para PRAM: ``ROOF'', ``TOILET'', ``WATER'', ``ELECTCON'', ``FUELCOOK'', ``OWNMOTORCYCLE'', ``CAR'', ``TV'' y ``LIVESTOCK''. Estas variabels PRAM se seleccionaron en funci√≥n de los requisitos de este conjunto de datos concreto y con fines ilustrativos.}. PRAM es un m√©todo probabil√≠stico y los resultados pueden diferir cada vez que aplicamos PRAM a las mismas variables de un conjunto de datos. Para superar esto y hacer que los resultados sean reproducibles, es una buena pr√°ctica establecer una semilla para el generador de n√∫meros aleatorios en R, de modo que se generen los mismos n√∫meros aleatorios cada vez\footnote{El m√©todo PRAM en \texttt{sdcMicro} a veces produce el siguiente error: Error in factor(xpramed, labels = lev) : invalid `labels'; length 6 should be 1 or 5. En algunas circunstancias, cambiar la semilla puede resolver este error.}. Tambi√©n, se muestra el n√∫mero de registros modificados por variable.

\hypertarget{section}{%
\subsubsection{}\label{section}}

\begin{example}
\protect\hypertarget{exm:bloque26jgm}{}{\label{exm:bloque26jgm} }Producci√≥n de resultados reproducibles de PRAM utilizando \texttt{set.seed()}
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# establecer la semilla para la generaci√≥n de n√∫meros aleatorios}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{) }
\NormalTok{sdcInitial_edit <-}\StringTok{ }\KeywordTok{pram}\NormalTok{(}\DataTypeTok{obj =}\NormalTok{ sdcInitial)}

\NormalTok{sdcInitial_edit}\OperatorTok{@}\NormalTok{pram}\OperatorTok{$}\NormalTok{summary}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        variable nrChanges percChanges
## 1          ROOF        81        4.05
## 2        TOILET       247       12.35
## 3         WATER       177        8.85
## 4      ELECTCON         7        0.35
## 5      FUELCOOK       160        8.00
## 6 OWNMOTORCYCLE        62        3.10
## 7           CAR        19        0.95
## 8            TV       106        5.30
## 9     LIVESTOCK        23        1.15
\end{verbatim}

La Tabla \ref{tab:Tabla14} muestra la tabulaci√≥n de la variable despu√©s de aplicar el PRAM invariante. Podemos ver que las desviaciones de las tabulaciones iniciales, que tienen expectativa 0, son menores que la matriz de transici√≥n que no cumple la propiedad de invariancia. Las desviaciones restantes se deben a la aleatoriedad.

\begin{table}

\caption{\label{tab:Tabla14}\label{tab:Tabla14}Tabulaci√≥n de la variable "regi√≥n" antes y despu√©s del PRAM (invariante)}
\centering
\begin{tabular}[t]{lccc}
\toprule
Valor & Tabulaci√≥n antes de PRAM & Tabulaci√≥n despu√©s de PRAM & Tabulaci√≥n despu√©s del PRAM invariante\\
\midrule
capital & 5,000 & 5,052 & 4,998\\
rural1 & 500 & 457 & 499\\
rural2 & 400 & 391 & 403\\
\bottomrule
\end{tabular}
\end{table}

La Tabla \ref{tab:Tabla15} presenta las tabulaciones cruzadas con la variable sexo. Antes de aplicar PRAM invariante, la proporci√≥n de hombres en la ciudad es mucho mayor que la de mujeres (alrededor del 60\%). Esta propiedad no se mantiene despu√©s de PRAM invariante (los porcentajes de hombres y mujeres en la ciudad son aproximadamente iguales), aunque se mantienen las tabulaciones univariantes. Una soluci√≥n es aplicar PRAM por separado para los hombres y las mujeres de este ejemplo\footnote{Esto tambi√©n puede lograrse con matrices de transici√≥n multidimensionales. En ese caso, la probabilidad no se especifica para ``masculino'' -\textgreater{} ``feminino'', sino para ``masculino'' + " rural " -\textgreater{} ``feminino'' + " rural " y para ``masculino'' + ``urbano'' -\textgreater{} ``feminino'' + ``urbano''. Esto no est√° implementado en \texttt{sdcMicro}, pero se puede lograr mediante PRAMming masculino y feminino por separado. En este ejemplo, esto podr√≠a hacerse especificando el g√©nero como variable de estrato en la funci√≥n \texttt{pram()} de \texttt{sdcMicro}.}. Esto puede hacerse especificando el argumento de los estratos en la funci√≥n \texttt{pram()} de \texttt{sdcMicro} (v√©ase m√°s adelante).

\begin{table}

\caption{\label{tab:Tabla15}\label{tab:Tabla15}Tabulaci√≥n cruzada de la variable "regi√≥n" y la variable "sexo" antes y despu√©s del PRAM invariante}
\centering
\begin{tabular}[t]{lcccc}
\toprule
\multicolumn{1}{c}{ } & \multicolumn{2}{c}{Tabulaci√≥n antes de PRAM} & \multicolumn{2}{c}{Tabulaci√≥n despu√©s del PRAM invariante} \\
\cmidrule(l{3pt}r{3pt}){2-3} \cmidrule(l{3pt}r{3pt}){4-5}
Valor & hombre & mujer & hombre & mujer\\
\midrule
capital & 3,056 & 1,944 & 2,623 & 2,375\\
rural1 & 157 & 343 & 225 & 274\\
rural2 & 113 & 287 & 187 & 216\\
\bottomrule
\end{tabular}
\end{table}

La funci√≥n \texttt{pram()} en \texttt{sdcMicro} tiene varias opciones relacionadas a estratificaci√≥n (\emph{strata\_variables}), entradas diagonales m√≠nimas para utilizar una matriz de transici√≥n P personalizada (\emph{pd}) y la cantidad de perturbaci√≥n para el m√©todo Pram invariante, entregada mediante un vector num√©rico de longitud 1 (que se reciclar√° si es necesario) o un vector de la misma longitud que el n√∫mero de variables.

\begin{quote}
\textbf{Nota}: Si no se establece ninguna opci√≥n y el m√©todo PRAM se aplica a un objeto \texttt{sdcMicro}, todas las variables PRAM seleccionadas en el objeto \texttt{sdcMicro} se utilizan autom√°ticamente para PRAM y esta se aplica dentro de los estratos seleccionados (v√©ase la secci√≥n \protect\hyperlink{objetos-de-la-clase-sdcmicroobj}{Objetos de la clase \texttt{sdcMicroObj}} sobre los objetos \texttt{sdcMicro} para m√°s detalles).
\end{quote}

\hypertarget{section-1}{%
\subsubsection{}\label{section-1}}

\begin{example}
\protect\hypertarget{exm:bloque27jgm}{}{\label{exm:bloque27jgm} }Selecci√≥n de variables para aplicar PRAM
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{) }\CommentTok{# establecer la semilla para la generaci√≥n de n√∫meros aleatorios}
\CommentTok{# Aplicar PRAM solo a la variable TOILET}
\NormalTok{sdcInitial <-}\StringTok{ }\KeywordTok{pram}\NormalTok{(}\DataTypeTok{obj =}\NormalTok{ sdcInitial, }\DataTypeTok{variables =} \KeywordTok{c}\NormalTok{ (}\StringTok{"TOILET"}\NormalTok{))}
\NormalTok{sdcInitial}\OperatorTok{@}\NormalTok{pram}\OperatorTok{$}\NormalTok{summary}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   variable nrChanges percChanges
## 1   TOILET       106         5.3
\end{verbatim}

Los resultados de PRAM difieren si se aplican simult√°neamente a varias variables o posteriormente a cada variable por separado. No es posible especificar toda la matriz de transici√≥n en \texttt{sdcMicro}, pero podemos establecer valores m√≠nimos (entre 0 y 1) para las entradas diagonales. Las entradas diagonales especifican la probabilidad de que un determinado valor permanezca igual despu√©s de aplicar PRAM. Si fijamos el valor m√≠nimo en 1, no habr√° cambios en esta categor√≠a. Por defecto, este valor es 0,8, que se aplica a todas las categor√≠as. Tambi√©n es posible especificar un vector con valor para cada elemento diagonal de la transformaci√≥n matriz/categor√≠a. En el Bloque \ref{exm:bloque28jgm} los valores de la primera regi√≥n tienen menos probabilidades de cambiar que los valores de las otras regiones.

\begin{quote}
\textbf{Nota}: El m√©todo PRAM invariante requiere que la matriz de transici√≥n tenga un valor propio unitario.
\end{quote}

Por lo tanto, no se pueden utilizar todos los conjuntos de restricciones (por ejemplo, el valor m√≠nimo 1 en cualquiera de las categor√≠as).

\hypertarget{section-2}{%
\subsubsection{}\label{section-2}}

\begin{example}
\protect\hypertarget{exm:bloque28jgm}{}{\label{exm:bloque28jgm} }Especificaci√≥n de los valores m√≠nimos de la diagonal de la matriz de transici√≥n PRAM
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sdcInitial <-}\StringTok{ }\NormalTok{sdc_respaldo }\CommentTok{# reasignar}

\NormalTok{sdcInitial <-}\StringTok{ }\KeywordTok{pram}\NormalTok{(}\DataTypeTok{obj =}\NormalTok{ sdcInitial, }\DataTypeTok{variables =} \KeywordTok{c}\NormalTok{(}\StringTok{"TOILET"}\NormalTok{), }\DataTypeTok{pd =} \KeywordTok{c}\NormalTok{(}\FloatTok{0.9}\NormalTok{)) }\CommentTok{#un valor por variable}

\NormalTok{sdcInitial}\OperatorTok{@}\NormalTok{pram}\OperatorTok{$}\NormalTok{summary}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   variable nrChanges percChanges
## 1   TOILET       133        6.65
\end{verbatim}

En el m√©todo PRAM invariante, tambi√©n podemos especificar la cantidad de perturbaciones especificando el par√°metro alfa. Esta elecci√≥n se refleja en la matriz de transici√≥n. Por defecto, el valor de alfa es 0,5. Cuanto mayor sea alfa, mayores ser√°n las perturbaciones. Un valor de alfa igual a cero no produce cambios. El valor m√°ximo de alfa es 1.

PRAM es especialmente √∫til cuando un conjunto de datos contiene muchas variables y la aplicaci√≥n de otros m√©todos de anonimizaci√≥n, como la recodificaci√≥n y la supresi√≥n local, conducir√≠a a una p√©rdida significativa de informaci√≥n. Las comprobaciones del riesgo y la utilidad son importantes despu√©s de PRAM.

Para hacer inferencia estad√≠stica sobre las variables a las que se aplic√≥ PRAM, el investigador necesita conocer el m√©todo PRAM, as√≠ como la matriz de transici√≥n. Sin embargo, la matriz de transici√≥n, junto con la semilla de n√∫meros aleatorios, puede conducir a la divulgaci√≥n mediante la reconstrucci√≥n de los valores no perturbados. Por lo tanto, \textbf{se recomienda publicar la matriz de transici√≥n, pero nunca la semilla aleatoria}.

Una desventaja del uso de PRAM es que se pueden generar combinaciones muy improbables, como la de una persona de 63 a√±os que va a la escuela. Por lo tanto, es necesario auditar las variables PRAM para evitar que tales combinaciones se produzcan en el archivo de datos publicado. En principio, la matriz de transici√≥n puede dise√±arse de forma que ciertas transiciones no sean posibles (probabilidad 0). Por ejemplo, para los que van a la escuela, la edad debe oscilar entre los 6 y los 18 a√±os y solo se permiten esos cambios. En \texttt{sdcMicro} la matriz de transici√≥n no puede especificarse exactamente. Una alternativa √∫til es construir estratos y aplicar PRAM dentro de los estratos. De este modo, los cambios entre variables solo se aplicar√°n dentro de los estratos. El Bloque \ref{exm:bloque29jgm} ilustra esto aplicando PRAM a la variable ``toilet'' dentro de los estratos generados por la ``region''. Esto evita que se produzcan cambios en la variable ``toilet'', donde se intercambian los tipos de inodoros de una determinada regi√≥n con los de otras regiones. Por ejemplo, en la regi√≥n de la capital no se utilizan ciertos tipos de inodoros no mejorados y, por lo tanto, estas combinaciones no deber√≠an producirse despu√©s de aplicar PRAM. Los valores solo se cambian con los que est√°n disponibles en el mismo estrato. Los estratos pueden estar formados por cualquier variable categ√≥rica, por ejemplo, sexo, grupos de edad, nivel de educaci√≥n.

\hypertarget{section-3}{%
\subsubsection{}\label{section-3}}

\begin{example}
\protect\hypertarget{exm:bloque29jgm}{}{\label{exm:bloque29jgm} }Minimizar las combinaciones improbables aplicando el PRAM por estratos
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sdcInitial <-}\StringTok{ }\NormalTok{sdc_respaldo }\CommentTok{# reasignar}

\CommentTok{#Aplicar PRAM dentro de los estratos formados por la variable educ}
\NormalTok{sdcInitial <-}\StringTok{ }\KeywordTok{pram}\NormalTok{(}\DataTypeTok{obj =}\NormalTok{ sdcInitial, }\DataTypeTok{variables =} \KeywordTok{c}\NormalTok{(}\StringTok{"TOILET"}\NormalTok{), }\DataTypeTok{strata_variables =} \KeywordTok{c}\NormalTok{(}\StringTok{"REGION"}\NormalTok{))}

\NormalTok{sdcInitial}\OperatorTok{@}\NormalTok{pram}\OperatorTok{$}\NormalTok{summary}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   variable nrChanges percChanges
## 1   TOILET       158         7.9
\end{verbatim}

\begin{quote}
Lectura recomendada de PRAM:
- Gouweleeuw, J. M, P Kooiman, L.C.R.J Willenborg, and P.P de Wolf. ``Post Randomization for Statistical Disclosure Control: Theory and Implementation.'' Journal of Official Statistics 14, no. 4 (1998a): 463-478. Available at \url{http://www.jos.nu/articles/abstract.asp?article=144463}
- Gouweleeuw, J. M, P Kooiman, L.C.R.J Willenborg, and Peter Paul de Wolf. ``The Post Randomization Method for Protecting Microdata.'' Q√ºestii√≥, Quaderns d'Estad√≠stica i Investigaci√≥ Operativa 22, no. 1 (1998b): 145-156. Available at \url{http://www.raco.cat/index.php/Questiio/issue/view/2250}
- Mar√©s, Jordi, and Vicen√ß Torra. 2010.''PRAM Optimization Using an Evolutionary Algorithm.'' In Privacy in Statistical Databases, by Josep Domingo-Ferrer and Emmanouil Magkos, 97-106. Corf√∫, Greece: Springer.
- Warner, S.L. ``Randomized Response: A Survey Technique for Eliminating Evasive Answer Bias.'' Journal of American Statistical Association 57 (1965): 622-627.
\end{quote}

\hypertarget{microagregaciuxf3n}{%
\subsection{Microagregaci√≥n}\label{microagregaciuxf3n}}

La microagregaci√≥n es m√°s adecuada para las variables continuas, pero puede extenderse en algunos casos a las variables categ√≥ricas\footnote{La microagregaci√≥n tambi√©n se puede utilizar para datos categ√≥ricos, siempre que exista la posibilidad de formar grupos y se pueda calcular una sustituci√≥n agregada para los valores del grupo. Este es el caso de las variables ordinales.}. Es m√°s √∫til cuando se han predeterminado reglas de confidencialidad (por ejemplo, se ha establecido un determinado umbral de \(k\)-anonimato) que permiten la divulgaci√≥n de datos solo si las combinaciones de variables son compartidas por m√°s de un n√∫mero umbral predeterminado de encuestados (\(k\)). El primer paso en la microagregaci√≥n es la formaci√≥n de peque√±os grupos de individuos que sean homog√©neos con respecto a los valores de las variables seleccionadas, como grupos con ingresos o edad similares. Posteriormente, los valores de las variables seleccionadas de todos los miembros del grupo se sustituyen por un valor com√∫n, por ejemplo, la media de ese grupo. Los m√©todos de microagregaci√≥n difieren en cuanto a (i) c√≥mo se define la homogeneidad de los grupos, (ii) los algoritmos utilizados para encontrar grupos homog√©neos y (iii) la determinaci√≥n de los valores de sustituci√≥n. En la pr√°ctica, la microagregaci√≥n funciona mejor cuando los valores de las variables de los grupos son m√°s homog√©neos. En ese caso, la p√©rdida de informaci√≥n debida a la sustituci√≥n de valores por valores comunes para el grupo ser√° menor que en los casos en que los grupos son menos homog√©neos.

En el caso univariante, y tambi√©n para las variables categ√≥ricas ordinales, la formaci√≥n de grupos homog√©neos es sencilla: los grupos se forman ordenando primero los valores de la variable y luego creando \(g\) grupos de tama√±o \(n_i\) para todos los grupos \(i\) en \(1, ..., g\). Esto maximiza la homogeneidad dentro del grupo, que se mide por la suma al cuadrado de los residuos dentro de los grupos (\(SSE\))

\[
SSE = \sum_{i = 1}^{g}{\sum_{j = 1}^{n_{i}}{\left( x_{ij} - {\overline{x}}_{i} \right)^{T}\left( x_{ij} - {\overline{x}}_{i} \right)}}
\]

Cuanto menor sea \(SSE\), mayor ser√° la homogeneidad dentro del grupo. El tama√±o de los grupos puede variar entre ellos, pero a menudo se utilizan grupos de igual tama√±o para simplificar la b√∫squeda\footnote{En este caso, todos los grupos pueden tener diferentes tama√±os (es decir, n√∫mero de individuos en un grupo). En la pr√°ctica, la b√∫squeda de grupos homog√©neos se simplifica imponiendo tama√±os de grupo iguales para todos los grupos.}.

La funci√≥n \texttt{microaggregation()} de sdcMicro puede utilizarse para la microagregaci√≥n univariante. El argumento ``aggr'' especifica el tama√±o del grupo. La formaci√≥n de grupos es m√°s f√°cil si todos los grupos -excepto quiz√° el √∫ltimo grupo de los restantes- tienen el mismo tama√±o. Este es el caso en la implementaci√≥n en \texttt{sdcMicro}, ya que no es posible tener grupos de diferentes tama√±os. El Bloque \ref{exm:bloque30jgm} muestra c√≥mo utilizar la funci√≥n \texttt{microaggregation()} en \texttt{sdcMicro}\footnote{En este ejemplo y en los siguientes de esta secci√≥n, el objeto \texttt{sdcMicro} ``sdcIntial'' contiene un conjunto de datos con 2.000 individuos y 39 variables. Seleccionamos cinco identificadores indirectos categ√≥ricos y tres identificadores indirectos continuos: ``INC'', ``EXP'' y ``WEALTH''.}. El tama√±o de grupo por defecto es 3, pero el usuario puede especificar cualquier tama√±o de grupo deseado. La elecci√≥n del tama√±o del grupo depende de la homogeneidad dentro de los grupos y del nivel de protecci√≥n requerido. En general, cuanto m√°s grande sea el grupo, mayor ser√° la protecci√≥n. Una desventaja de los grupos de igual tama√±o es que los datos pueden ser inadecuados para ello. Por ejemplo, si dos individuos tienen un ingreso bajo (por ejemplo, 832 y 966) y cuatro individuos tienen un ingreso alto (por ejemplo, 3.313, 3.211, 2.987, 3.088), la media de dos grupos de tama√±o tres (por ejemplo, (832 + 966 + 2.987) / 3 = 1.595 y (3.088 + 3.211 + 3.313) / 3 = 3.204) no representar√≠a ni el ingreso bajo ni el alto.

\hypertarget{section-4}{%
\subsubsection{}\label{section-4}}

\begin{example}
\protect\hypertarget{exm:bloque30jgm}{}{\label{exm:bloque30jgm} }Aplicaci√≥n de la microagregaci√≥n con la funci√≥n \texttt{sdcMicro} \texttt{microaggregation()}
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sdcInitial <-}\StringTok{ }\NormalTok{sdc_respaldo }\CommentTok{# reasignar}

\NormalTok{sdcInitial <-}\StringTok{ }\KeywordTok{microaggregation}\NormalTok{(}\DataTypeTok{obj =}\NormalTok{ sdcInitial, }\DataTypeTok{variables =} \StringTok{"INCTOTGROSSHH"}\NormalTok{, }\DataTypeTok{aggr =} \DecValTok{3}\NormalTok{, }\DataTypeTok{method =} \StringTok{"mdav"}\NormalTok{, }\DataTypeTok{measure =} \StringTok{"mean"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Por defecto, la funci√≥n de microagregaci√≥n sustituye los valores por la media del grupo. Un enfoque alternativo y m√°s robusto es reemplazar los valores del grupo con la mediana. Esto puede especificarse en el argumento ``measure'' de la funci√≥n \texttt{microaggregation()}. En los casos en que se elige la mediana, un individuo de cada grupo mantiene el mismo valor si los grupos tienen tama√±os impares. En los casos en los que hay un alto grado de heterogeneidad dentro de los grupos (suele ser el caso de los grupos m√°s grandes), se prefiere la mediana para preservar la informaci√≥n de los datos. Un ejemplo es el ingreso, donde un valor at√≠pico puede dar lugar a m√∫ltiples valores at√≠picos cuando se utiliza la microagregaci√≥n. Esto se ilustra en la Tabla \ref{tab:Tabla16}. Si elegimos la media como reemplazo de todos los valores, que se agrupan con el valor at√≠pico (6,045 en el grupo 2), a estos registros se les asignar√°n valores alejados de sus valores originales. Si elegimos la mediana, los ingresos de los individuos 1 y 2 no se ven alterados, pero ning√∫n valor es un valor at√≠pico. Por supuesto, esto puede plantear problemas en s√≠ mismo. En el caso de que la microagregaci√≥n se aplique a variables categ√≥ricas, se utiliza la mediana (el valor en el grupo que m√°s se repite) para calcular el valor de reemplazo de aquel grupo.

\begin{quote}
\textbf{Nota}: Si la microagregaci√≥n altera los valores at√≠picos, esto puede tener un impacto significativo en el c√°lculo de algunas medidas sensibles a los valores at√≠picos, como el √≠ndice GINI.
\end{quote}

\begin{table}

\caption{\label{tab:Tabla16}\label{tab:Tabla16}Ilustraci√≥n del efecto de la elecci√≥n de la media frente a la mediana para la microagregaci√≥n cuando se trata de valores at√≠picos}
\centering
\begin{tabular}[t]{ccccc}
\toprule
ID & Grupo & Ingresos & Microagregaci√≥n (media) & Microagregaci√≥n (mediana)\\
\midrule
1 & 1 & 2,300 & 2,245 & 2,300\\
2 & 2 & 2,434 & 3,608 & 2,434\\
3 & 1 & 2,123 & 2,245 & 2,300\\
4 & 1 & 2,312 & 2,245 & 2,300\\
5 & 2 & 6,045 & 3,608 & 2,434\\
\addlinespace
6 & 2 & 2,345 & 3,608 & 2,434\\
\bottomrule
\end{tabular}
\end{table}

En el caso de m√∫ltiples variables candidatas a la microagregaci√≥n, una posibilidad es aplicar la microagregaci√≥n univariante a cada una de las variables por separado. La ventaja de la microagregaci√≥n univariante es la m√≠nima p√©rdida de informaci√≥n, ya que los cambios en las variables son limitados. Sin embargo, la literatura muestra que el riesgo de divulgaci√≥n puede ser muy alto si la microagregaci√≥n univariante se aplica a varias variables por separado y no se aplican t√©cnicas adicionales de anonimizaci√≥n \citep{DMOT02}. Para superar este inconveniente, una alternativa a la microagregaci√≥n univariante es la microagregaci√≥n multivariante.

La microagregaci√≥n multivariada se utiliza ampliamente en las estad√≠sticas oficiales \citep{benschop2019statistical}. El primer paso de la agregaci√≥n multivariante es la creaci√≥n de grupos homog√©neos basados en varias variables. Los grupos se forman a partir de las distancias multivariadas entre los individuos. Posteriormente, los valores de todas las variables para todos los miembros del grupo se sustituyen por los mismos valores. La Tabla \ref{tab:Tabla17} lo ilustra con tres variables. Vemos que la agrupaci√≥n por ingresos, gastos y patrimonio conduce a una agrupaci√≥n diferente, como en el caso de la Tabla \ref{tab:Tabla16}, en la que los grupos se formaron bas√°ndose solo en los ingresos.

\begin{table}

\caption{\label{tab:Tabla17}\label{tab:Tabla17}Ilustraci√≥n de la microagregaci√≥n multivariante}
\centering
\begin{tabular}[t]{cccccccc}
\toprule
\multicolumn{2}{c}{ } & \multicolumn{3}{c}{Antes de microagregaci√≥n} & \multicolumn{3}{c}{Despu√©s de microagregaci√≥n} \\
\cmidrule(l{3pt}r{3pt}){3-5} \cmidrule(l{3pt}r{3pt}){6-8}
ID & Grupo & Ingreso & Gasto & Patrimonio & Ingreso & Gasto & Patrimonio\\
\midrule
1 & 1 & 2,300 & 1,714 & 5.3 & 2,285.7 & 1,846.3 & 6.3\\
2 & 1 & 2,434 & 1,947 & 7.4 & 2,285.7 & 1,846.3 & 6.3\\
3 & 1 & 2,123 & 1,878 & 6.3 & 2,285.7 & 1,846.3 & 6.3\\
4 & 2 & 2,312 & 1,950 & 8.0 & 3,567.3 & 2,814.0 & 8.3\\
5 & 2 & 6,045 & 4,569 & 9.2 & 3,567.3 & 2,814.0 & 8.3\\
\addlinespace
6 & 2 & 2,345 & 1,923 & 7.8 & 3,567.3 & 2,814.0 & 8.3\\
\bottomrule
\end{tabular}
\end{table}

Existen varios m√©todos de microagregaci√≥n multivariante que difieren en cuanto al algoritmo utilizado para crear grupos de individuos. Adem√°s, existe un trade-off entre la velocidad del algoritmo y la homogeneidad dentro del grupo, que est√° directamente relacionada con la p√©rdida de informaci√≥n. En el caso de los grandes conjuntos de datos, esto es especialmente dif√≠cil. En este art√≠culo se analiza con m√°s detalle el algoritmo de distancia m√°xima al vector medio (MDAV). El algoritmo MDAV fue introducido por primera vez por \citep{DoTo05} y representa una buena opci√≥n con respecto a la compensaci√≥n entre el tiempo de c√°lculo y la homogeneidad del grupo, calculada por el \(SSE\) dentro del grupo. El algoritmo MDAV est√° implementado en \texttt{sdcMicro}.

El algoritmo calcula un registro medio o centroide \(C\), que contiene los valores medios de todas las variables incluidas. Seleccionamos un individuo \(A\) con la mayor distancia euclidiana al cuadrado respecto a \(C\), y construimos un grupo de \(k\) registros alrededor de \(A\). El grupo de \(k\) registros est√° formado por \(A\) y los \(k-1\) registros m√°s cercanos a \(A\) medidos por la distancia euclidiana. A continuaci√≥n, seleccionamos otro individuo \(B\), con la mayor distancia euclidiana al cuadrado desde el individuo \(A\). Con los registros restantes, construimos un grupo de \(k\) registros alrededor de \(B\). De la misma manera, seleccionamos un individuo \(D\) con la mayor distancia desde \(B\) y, con los registros restantes, construimos un nuevo grupo de \(k\) registros alrededor de \(D\). El proceso se repite hasta que nos queden menos de \(2‚àók\) registros. El algoritmo MDAV crea grupos de igual tama√±o con la excepci√≥n, quiz√°, de un √∫ltimo grupo con los remanentes. El conjunto de datos microagregados se calcula sustituyendo cada registro del conjunto de datos original por los valores medios del grupo al que pertenece. Sin embargo, los tama√±os de grupo iguales pueden no ser ideales para los datos caracterizados por tener una alta variabilidad. En \texttt{sdcMicro} la microagregaci√≥n multivariante tambi√©n se implementa en la funci√≥n \texttt{microaggregation()}. El Bloque \ref{exm:bloque31jgm} muestra c√≥mo elegir el algoritmo MDAV en \texttt{sdcMicro}.

\hypertarget{section-5}{%
\subsubsection{}\label{section-5}}

\begin{example}
\protect\hypertarget{exm:bloque31jgm}{}{\label{exm:bloque31jgm} }Microagregaci√≥n multivariada con el algoritmo de distancia m√°xima al vector medio (MDAV) en \texttt{sdcMicro}
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sdcInitial <-}\StringTok{ }\KeywordTok{createSdcObj}\NormalTok{(}\DataTypeTok{dat=}\NormalTok{fileHH, }\DataTypeTok{keyVars=}\NormalTok{selectedKeyVarsHH, }\DataTypeTok{pramVars=}\NormalTok{pramVarsHH, }\DataTypeTok{weightVar=}\NormalTok{weightVarHH, }\DataTypeTok{numVars =}\NormalTok{ numVarsHH) }\CommentTok{# reasignar sin strata var}

\NormalTok{sdcInitial <-}\StringTok{ }\KeywordTok{microaggregation}\NormalTok{(}\DataTypeTok{obj =}\NormalTok{ sdcInitial, }\DataTypeTok{variables =} \KeywordTok{c}\NormalTok{(}\StringTok{"INCTOTGROSSHH"}\NormalTok{, }\StringTok{"TANHHEXP"}\NormalTok{), }\DataTypeTok{method =} \StringTok{"mdav"}\NormalTok{)}

\CommentTok{#sdc_respaldo@origData %>% view()}
\end{Highlighting}
\end{Shaded}

Tambi√©n es posible agrupar las variables solo dentro de los estratos. Esto reduce el tiempo de c√°lculo y a√±ade una capa adicional de protecci√≥n a los datos, debido a la mayor incertidumbre producida \footnote{Adem√°s, la homogeneidad en los grupos ser√° generalmente menor, lo que dar√° lugar a cambios mayores, a una mayor protecci√≥n, tambi√©n una mayor p√©rdida de informaci√≥n, a menos que la variable de estrato est√© correlacionada con la variable de microagregaci√≥n.}. En \texttt{sdcMicro} esto puede lograrse especificando las variables de estrato, como se muestra en el Bloque \ref{exm:bloque32jgm}.

\hypertarget{section-6}{%
\subsubsection{}\label{section-6}}

\begin{example}
\protect\hypertarget{exm:bloque32jgm}{}{\label{exm:bloque32jgm} }Especificaci√≥n de variables de estrato para la microagregaci√≥n
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sdcInitial <-}\StringTok{ }\NormalTok{sdc_respaldo }\CommentTok{# reasignar con variable de estrato incluida}

\NormalTok{sdcInitial <-}\StringTok{ }\KeywordTok{microaggregation}\NormalTok{(}\DataTypeTok{obj =}\NormalTok{ sdcInitial, }\DataTypeTok{variables =} \KeywordTok{c}\NormalTok{(}\StringTok{"INCTOTGROSSHH"}\NormalTok{, }\StringTok{"TANHHEXP"}\NormalTok{), }\DataTypeTok{method =} \StringTok{"mdav"}\NormalTok{)}\CommentTok{#}

\CommentTok{# No corre el estrato en opci√≥n: strata_variables = c("strata_region")}
\end{Highlighting}
\end{Shaded}

Adem√°s del m√©todo MDAV, hay algunos otros m√©todos de agrupaci√≥n implementados en \texttt{sdcMicro} \citep{TeMK14}. La Tabla \ref{tab:Tabla18} ofrece un resumen de estos m√©todos. Mientras que el m√©todo ``MDAV'' utiliza la distancia euclidiana, el m√©todo ``rmd'' utiliza la distancia de Mahalanobis. Una alternativa a estos m√©todos es la clasificaci√≥n de los encuestados basada en el primer componente principal (CP), que es la proyecci√≥n de todas las variables en un espacio unidimensional que maximiza la varianza de esta proyecci√≥n. El rendimiento de este m√©todo depende de la parte de la varianza total de los datos que explica el primer CP. El m√©todo ``rmd'' es m√°s intensivo desde el punto de vista computacional debido al c√°lculo de las distancias de Mahalanobis, pero proporciona mejores resultados con respecto a la homogeneidad de los grupos. Se recomienda para conjuntos de datos m√°s peque√±os \citep{TeMK14}.

\begin{table}

\caption{\label{tab:Tabla18}\label{tab:Tabla18}M√©todos de agrupaci√≥n para la microagregaci√≥n que son implementados en `sdcMicro`}
\centering
\begin{tabular}[t]{ll}
\toprule
M√©todo / opci√≥n en `sdcMicro` & Descripci√≥n\\
\midrule
mdav & la agrupaci√≥n se basa en medidas de distancia cl√°sicas (euclidianas)\\
rmd & la agrupaci√≥n se basa en medidas de distancia multivariante robusta (Mahalanobis)\\
pca & la agrupaci√≥n se basa en el an√°lisis de componentes principales, mientras que los datos se clasifican seg√∫n el primer componente principal\\
clustpppca & la agrupaci√≥n se basa en el clustering y en el an√°lisis de componentes   principales (robusto) para cada cluster\\
influence & la agrupaci√≥n se basa en el clustering y la agregaci√≥n se realiza dentro de los clusters\\
\bottomrule
\end{tabular}
\end{table}

En el caso de que se utilicen m√∫ltiples variables para la microagregaci√≥n, se recomienda examinar primero la matriz de covarianza o de correlaci√≥n de estas variables. Si no todas las variables est√°n bien correlacionadas, pero dos o m√°s conjuntos de variables muestran una alta correlaci√≥n, se producir√° una menor p√©rdida de informaci√≥n al aplicar la microagregaci√≥n por separado a estos conjuntos de variables. En general, si las variables est√°n muy correlacionadas, se producir√° una menor p√©rdida de informaci√≥n al aplicar la microagregaci√≥n multivariante. La ventaja de sustituir los valores por la media de los grupos en lugar de otros valores de sustituci√≥n tiene la ventaja de que se conservan las medias globales de las variables.

\begin{quote}
Lectura recomendada de microagregaci√≥n:
- Domingo-Ferrer, Josep, and Josep Maria Mateo-Sanz. 2002.''Practical data-oriented microaggregation for statistical disclosure control.'' IEEE Transactions on Knowledge and Data Engineering 14 (2002): 189-201.
- Hansen, Stephen Lee, and Sumitra Mukherjee. 2003. ``A polynomial algorithm for univariate optimal.'' IEEE Transactions on Knowledge and Data Engineering 15 (2003): 1043-1044.
- Hundepool, Anco, Josep Domingo-Ferrer, Luisa Franconi, Sarah Giessing, Rainer Lenz, Jane Naylor, Eric Schulte Nordholt, Giovanni Seri, and Peter Paul de Wolf. 2006. Handbook on Statistical Disclosure Control. ESSNet SDC. \url{http://neon.vb.cbs.nl/casc/handbook.htm}
- Hundepool, Anco, Josep Domingo-Ferrer, Luisa Franconi, Sarah Giessing, Eric Schulte Nordholt, Keith Spicer, and Peter Paul de Wolf. 2012. Statistical Disclosure Control. Chichester: John Wiley \& Sons Ltd.~\url{doi:10.1002/9781118348239}.
- Templ, Matthias, Bernhard Meindl, Alexander Kowarik, and Shuang Chen. 2014, August. ``International Household Survey Network (IHSN).'' \url{http://www.ihsn.org/home/software/disclosure-control-toolbox}. (accessed July 9, 2018).
\end{quote}

\hypertarget{adiciuxf3n-de-ruido}{%
\subsection{Adici√≥n de ruido}\label{adiciuxf3n-de-ruido}}

La adici√≥n de ruido o enmascaramiento, consiste en a√±adir o restar valores (peque√±os) a los valores originales de una variable, y es lo m√°s adecuado para proteger las variables continuas (v√©ase \citep{Bran02} para una visi√≥n general). La adici√≥n de ruido puede impedir la coincidencia exacta de las variables continuas. Las ventajas de la adici√≥n de ruido son que el ruido es t√≠picamente continuo con media cero, y la coincidencia exacta con archivos externos no ser√° posible. Sin embargo, dependiendo de la magnitud del ruido a√±adido, la comparaci√≥n aproximada de intervalos puede ser posible.

Cuando se utiliza la adici√≥n de ruido para proteger los datos, es importante tener en cuenta el tipo de datos, el uso previsto de los mismos y las propiedades de los datos antes y despu√©s de la adici√≥n de ruido, es decir, la distribuci√≥n -en particular la media-, la covarianza y la correlaci√≥n entre los conjuntos de datos perturbados y los originales.

Dependiendo de los datos, tambi√©n puede ser √∫til comprobar que los valores perturbados est√°n dentro de un rango de valores con sentido. La \ref{fig:fig10} ilustra los cambios en la distribuci√≥n de los datos con niveles crecientes de ruido. En el caso de los datos que tienen valores at√≠picos, es importante se√±alar que cuando la distribuci√≥n de los datos perturbados es similar a la distribuci√≥n de los datos originales (por ejemplo, con niveles de ruido bajos), la adici√≥n de ruido no proteger√° los valores at√≠picos. Despu√©s de la adici√≥n de ruido, estos valores at√≠picos generalmente pueden seguir detect√°ndose como tales y, por tanto, identificarse f√°cilmente. Un ejemplo es un √∫nico valor de ingreso muy elevado en una determinada regi√≥n. Despu√©s de perturbar este valor de ingreso, el valor seguir√° siendo reconocido como el ingreso m√°s alto de esa regi√≥n y, por tanto, puede utilizarse para la reidentificaci√≥n. Esto se ilustra en la \ref{fig:fig9}, donde se representan 10 observaciones originales (c√≠rculos abiertos) y las observaciones anonimizadas (tri√°ngulos rojos). La d√©cima observaci√≥n es un valor at√≠pico. Los valores de las nueve primeras observaciones est√°n suficientemente protegidos por la adici√≥n de ruido: su magnitud y orden han cambiado y se puede evitar con √©xito la coincidencia exacta o por intervalos. El valor at√≠pico no est√° suficientemente protegido, ya que, tras la adici√≥n de ruido, el valor at√≠pico puede seguir identific√°ndose f√°cilmente. El hecho de que el valor absoluto haya cambiado no es una protecci√≥n suficiente. Por otro lado, con niveles de ruido elevados, la protecci√≥n es mayor incluso para los valores at√≠picos, pero la estructura de los datos no se conserva y la p√©rdida de informaci√≥n es grande, lo que no es una situaci√≥n ideal. Una forma de sortear el problema de los valores at√≠picos es a√±adir ruido de mayor magnitud a los valores at√≠picos que a los dem√°s valores.

\begin{figure}
\includegraphics[width=1\linewidth]{Imagenes/image8} \caption{Ilustraci√≥n del efecto de la adici√≥n de ruido a los valores at√≠picos}\label{fig:fig9}
\end{figure}

Existen varios algoritmos de adici√≥n de ruido. La versi√≥n m√°s simple de la adici√≥n de ruido es el ruido aditivo no correlacionado normalmente distribuido, donde \(x_j\), los valores originales de la variable \(j\) son reemplazados por

\[z_{j} = x_{j} + \varepsilon_{j},\]

donde \(\varepsilon_{j} \sim N(0, \sigma_{\varepsilon_{j}}^{2})\) y \(\sigma_{\varepsilon_{j}} = \alpha * \sigma_{j}\) con \(\sigma_{j}\) la desviaci√≥n est√°ndar de los datos originales. De este modo, se conservan la media y las covarianzas, pero no las varianzas ni el coeficiente de correlaci√≥n. Si el nivel de ruido a√±adido \(\alpha\), se da a conocer al usuario, se pueden estimar muchos estad√≠sticos de forma coherente a partir de los datos perturbados. El ruido a√±adido es proporcional a la varianza de la variable original. La magnitud del ruido a√±adido se especifica mediante el par√°metro Œ±, que especifica esta proporci√≥n. La desviaci√≥n est√°ndar de los datos perturbados es \(1 + \alpha\) veces la desviaci√≥n est√°ndar de los datos perturbados. La decisi√≥n sobre la magnitud del ruido a√±adido debe estar informada por la situaci√≥n legal relativa a la privacidad de los datos, la sensibilidad de los datos y los niveles aceptables de riesgo de divulgaci√≥n y p√©rdida de informaci√≥n. En general, el nivel de ruido es una funci√≥n de la varianza de las variables originales, el nivel de protecci√≥n necesario y el rango de valores deseado tras la anonimizaci√≥n\footnote{Los valores habituales de \(\alpha\) est√°n entre 0,5 y 2. El valor predeterminado en la funci√≥n \texttt{addNoise()} de \texttt{sdcMicro} es 150, que es demasiado grande para la mayor√≠a de los conjuntos de datos; el nivel de ruido debe establecerse en el argumento ``noise''.}. Un valor \(\alpha\) demasiado peque√±o dar√° lugar a una protecci√≥n insuficiente, mientras que un valor \(\alpha\) demasiado alto har√° que los datos sean in√∫tiles para los usuarios.

En \texttt{sdcMicro} la adici√≥n de ruido se implementa en la funci√≥n \texttt{addNoise()}. El algoritmo y el par√°metro pueden especificarse como argumentos en la funci√≥n \texttt{addNoise()}. La adici√≥n de ruido simple se implementa en la funci√≥n \texttt{addNoise()} con el valor ``additive'' para el argumento ``method''. El Bloque \ref{exm:bloque33jgm} muestra c√≥mo utilizar \texttt{sdcMicro} para a√±adir ruido no correlacionado a las variables de gasto, donde la desviaci√≥n est√°ndar del ruido a√±adido es igual a la mitad de la desviaci√≥n est√°ndar de las variables originales\footnote{En este ejemplo y en los siguientes de esta secci√≥n, el objeto \texttt{sdcMicro} ``sdcIntial'' contiene un conjunto de datos con 2.000 individuos y 39 variables. Seleccionamos cinco identificadores indirectos categ√≥ricos y 12 identificadores indirectos continuos. Se trata de los componentes de gasto ``TFOODEXP'', ``TALCHEXP'', ``TCLTHEXP'', ``THOUSEXP'', ``TFURNEXP'', ``THLTHEXP'', ``TTRANSEXP'', ``TCOMMEXP'', ``TRECEXP'', ``TEDUEXP'', ``TRESTHOTEXP'', ``TMISCEXP''.}. El ruido se a√±ade a todas las variables seleccionadas.

\hypertarget{section-7}{%
\subsubsection{}\label{section-7}}

\begin{example}
\protect\hypertarget{exm:bloque33jgm}{}{\label{exm:bloque33jgm} }Adici√≥n de ruido no correlacionado
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sdcInitial <-}\StringTok{ }\KeywordTok{addNoise}\NormalTok{(}\DataTypeTok{obj =}\NormalTok{ sdcInitial, }\DataTypeTok{variables =} \KeywordTok{c}\NormalTok{(}\StringTok{"TFOODEXP"}\NormalTok{, }\StringTok{"TALCHEXP"}\NormalTok{, }\StringTok{"TCLTHEXP"}\NormalTok{, }\StringTok{"THOUSEXP"}\NormalTok{, }
                                                       \StringTok{"TFURNEXP"}\NormalTok{, }\StringTok{"THLTHEXP"}\NormalTok{, }\StringTok{"TTRANSEXP"}\NormalTok{, }\StringTok{"TCOMMEXP"}\NormalTok{,}
                                                       \StringTok{"TRECEXP"}\NormalTok{, }\StringTok{"TEDUEXP"}\NormalTok{, }\StringTok{"TRESTHOTEXP"}\NormalTok{, }\StringTok{"TMISCEXP"}\NormalTok{), }
                       \DataTypeTok{noise =} \FloatTok{0.5}\NormalTok{, }\DataTypeTok{method =} \StringTok{"additive"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

La \ref{fig:fig10} muestra la distribuci√≥n de frecuencias de una variable num√©rica continua y la distribuci√≥n antes y despu√©s de la adici√≥n de ruido con diferentes niveles de ruido (0.1, 0.5, 1, 2 y 5). El primer gr√°fico muestra la distribuci√≥n de los valores originales. Los histogramas muestran claramente que el ruido de grandes magnitudes (valores altos de alfa) conduce a una distribuci√≥n de los datos alejada de los valores originales. La distribuci√≥n de los datos pasa a ser una distribuci√≥n normal cuando la magnitud del ruido crece respectivamente a la varianza de los datos. La media de los datos se conserva, pero, al aumentar el nivel de ruido, la varianza de los datos perturbados crece. Tras a√±adir un ruido de magnitud 5, la distribuci√≥n de los datos originales queda completamente alterada.

\begin{figure}
\includegraphics[width=1\linewidth]{Imagenes/image9} \caption{Distribuci√≥n de frecuencias de una variable continua antes y despu√©s de la adici√≥n de ruido}\label{fig:fig10}
\end{figure}

La \ref{fig:fig11} muestra el rango de valores de una variable antes de a√±adir ruido (sin ruido) y despu√©s de a√±adir varios niveles de ruido (Œ± de 0,1 a 1,5 con incrementos de 0,1). En la figura se representan el valor m√≠nimo, los percentiles 20, 30 y 40, la mediana, los percentiles 60, 70, 80 y 90 y el valor m√°ximo. La mediana (percentil 50) se indica con el s√≠mbolo rojo ``\(\color {red}{\text{+}}\)''. De las \ref{fig:fig10} y \ref{fig:fig11} se desprende que el rango de valores se ampl√≠a tras la adici√≥n de ruido, y que la mediana se mantiene aproximadamente en el mismo nivel, al igual que la media por construcci√≥n. Cuanto mayor sea la magnitud del ruido a√±adido, mayor ser√° el rango de valores. En los casos en que la variable debe permanecer en un determinado rango de valores (por ejemplo, solo valores positivos, entre 0 y 100), esto puede ser una desventaja de la adici√≥n de ruido. Por ejemplo, las variables de gasto suelen tener valores no negativos, pero la adici√≥n de ruido a estas variables puede generar valores negativos, que son dif√≠ciles de interpretar. Una forma de evitar este problema es poner a cero los valores negativos. Sin embargo, este truncamiento de los valores por debajo de un determinado umbral distorsionar√° la distribuci√≥n (matriz de media y varianza) de los datos perturbados. Esto significa que las caracter√≠sticas que se preservaron con la adici√≥n de ruido, como la conservaci√≥n de la media y la matriz de covarianza, se pierden y el usuario, incluso con el conocimiento de la magnitud del ruido, ya no puede utilizar los datos para una estimaci√≥n coherente.

Otra forma de evitar los valores negativos es la aplicaci√≥n de ruido multiplicativo en lugar de aditivo. En ese caso, las variables se multiplican por un factor aleatorio con esperanza 1 y varianza positiva. Esto tambi√©n dar√° lugar a mayores perturbaciones (en valor absoluto) de los valores at√≠picos. Si la varianza del ruido a√±adido es peque√±a, no habr√° factores negativos o ser√°n pocos y, por tanto, habr√° menos cambios de signo que en el caso del enmascaramiento por ruido aditivo. El enmascaramiento de ruido multiplicativo no est√° implementado en \texttt{sdcMicro}, pero puede implementarse con relativa facilidad en \emph{R base} generando un vector de n√∫meros aleatorios y multiplicando los datos con este vector. Para m√°s informaci√≥n sobre el enmascaramiento de ruido multiplicativo y las propiedades de los datos despu√©s del enmascaramiento, nos remitimos a \citep{KiWi03}.

\begin{figure}
\includegraphics[width=1\linewidth]{Imagenes/image10} \caption{Niveles de ruido y el impacto en el rango de valores (percentiles)}\label{fig:fig11}
\end{figure}

Si se seleccionan dos o m√°s variables para la adici√≥n de ruido, se prefiere la adici√≥n de ruido correlacionado para preservar la estructura de correlaci√≥n en los datos. En este caso, la matriz de covarianza del ruido \(\Sigma_{\varepsilon}\) es proporcional a la matriz de covarianza de los datos originales \(\Sigma_{X}\):

\[\Sigma_{\varepsilon} = \alpha \Sigma_{X}\]

En la funci√≥n \texttt{addNoise()} del paquete sdcMicro, se puede utilizar la adici√≥n de ruido correlacionado especificando los m√©todos ``correlated'' o ``correlated2''. El m√©todo ``correlated'' asume que las variables se distribuyen aproximadamente de forma normal. El m√©todo ``correlated2'' es una versi√≥n del m√©todo ``correlated'', que es robusto contra el supuesto de normalidad. El Bloque \ref{exm:bloque34jgm} muestra c√≥mo utilizar el m√©todo ``correlated2''. La normalidad de las variables puede investigarse en R, con, por ejemplo, un test Jarque-Bera o Shapiro-Wilk\footnote{La prueba de Shapiro-Wilk se implementa en la funci√≥n \texttt{shapiro.test()} del paquete \emph{stats} en R. La prueba de Jarque-Bera tiene varias implementaciones en R, por ejemplo, en la funci√≥n \texttt{jarque.bera.test()} del paquete \emph{tseries}.}.

\hypertarget{section-8}{%
\subsubsection{}\label{section-8}}

\begin{example}
\protect\hypertarget{exm:bloque34jgm}{}{\label{exm:bloque34jgm} }Adici√≥n de ruido correlacionado
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sdcInitial <-}\StringTok{ }\KeywordTok{addNoise}\NormalTok{(}\DataTypeTok{obj =}\NormalTok{ sdcInitial, }\DataTypeTok{variables =} \KeywordTok{c}\NormalTok{(}\StringTok{"TFOODEXP"}\NormalTok{, }\StringTok{"TALCHEXP"}\NormalTok{, }\StringTok{"TCLTHEXP"}\NormalTok{, }\StringTok{"THOUSEXP"}\NormalTok{, }
                                                       \StringTok{"TFURNEXP"}\NormalTok{, }\StringTok{"THLTHEXP"}\NormalTok{, }\StringTok{"TTRANSEXP"}\NormalTok{, }\StringTok{"TCOMMEXP"}\NormalTok{, }
                                                       \StringTok{"TRECEXP"}\NormalTok{, }\StringTok{"TEDUEXP"}\NormalTok{, }\StringTok{"TRESTHOTEXP"}\NormalTok{, }\StringTok{"TMISCEXP"}\NormalTok{), }
                       \DataTypeTok{noise =} \FloatTok{0.5}\NormalTok{, }\DataTypeTok{method =} \StringTok{"correlated2"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

En muchos casos, solo hay que proteger los valores at√≠picos, o hay que protegerlos m√°s. El m√©todo ``outdect'' a√±ade ruido solo a los valores at√≠picos, lo que se ilustra en el Bloque \ref{exm:bloque35jgm}. Los valores at√≠picos se identifican con m√©todos univariantes y multivariantes robustos basados en una distancia de Mahalanobis robusta calculada por el estimador MCD \citep{TMKC14}. Sin embargo, la adici√≥n de ruido no es el m√©todo m√°s adecuado para la protecci√≥n de los valores at√≠picos.

\hypertarget{section-9}{%
\subsubsection{}\label{section-9}}

\begin{example}
\protect\hypertarget{exm:bloque35jgm}{}{\label{exm:bloque35jgm} }Adici√≥n de ruido para los valores at√≠picos mediante el m√©todo ``outdect''
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sdcInitial <-}\StringTok{ }\KeywordTok{addNoise}\NormalTok{(}\DataTypeTok{obj =}\NormalTok{ sdcInitial, }\DataTypeTok{variables =} \KeywordTok{c}\NormalTok{(}\StringTok{"TFOODEXP"}\NormalTok{, }\StringTok{"TALCHEXP"}\NormalTok{, }\StringTok{"TCLTHEXP"}\NormalTok{, }\StringTok{"THOUSEXP"}\NormalTok{, }
                                                       \StringTok{"TFURNEXP"}\NormalTok{, }\StringTok{"THLTHEXP"}\NormalTok{, }\StringTok{"TTRANSEXP"}\NormalTok{, }\StringTok{"TCOMMEXP"}\NormalTok{, }
                                                       \StringTok{"TRECEXP"}\NormalTok{, }\StringTok{"TEDUEXP"}\NormalTok{, }\StringTok{"TRESTHOTEXP"}\NormalTok{, }\StringTok{"TMISCEXP"}\NormalTok{), }
                       \DataTypeTok{noise =} \FloatTok{0.5}\NormalTok{, }\DataTypeTok{method =} \StringTok{"outdect"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Si la adici√≥n de ruido se aplica a variables que son una proporci√≥n de un agregado, esta estructura puede verse seriamente alterada por la adici√≥n de ruido. Los ejemplos son los datos de ingresos y gastos con muchas categor√≠as de ingresos y gastos. Las categor√≠as suman el total de ingresos o el total de gastos. En los datos originales, los agregados coinciden con la suma de los componentes. Sin embargo, despu√©s de a√±adir ruido a sus componentes (por ejemplo, diferentes categor√≠as de gasto), sus nuevos agregados ya no coincidir√°n necesariamente con la suma de las categor√≠as. Una forma de mantener esta estructura es a√±adir ruido solo a los agregados y liberar los componentes como relaci√≥n de los agregados perturbados. El Bloque \ref{exm:bloque36jgm} ilustra esto a√±adiendo ruido al total de los gastos. Posteriormente, se utilizan los cocientes de las categor√≠as de gasto iniciales para cada individuo para reconstruir los valores perturbados de cada categor√≠a de gasto.

\hypertarget{section-10}{%
\subsubsection{}\label{section-10}}

\begin{example}
\protect\hypertarget{exm:bloque36jgm}{}{\label{exm:bloque36jgm} }Adici√≥n de ruido a agregados y sus componentes
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# a√±adir ruido a los totales (ingresos / gastos)}
\NormalTok{sdcInital <-}\StringTok{ }\KeywordTok{addNoise}\NormalTok{(}\DataTypeTok{noise =} \FloatTok{0.5}\NormalTok{, }\DataTypeTok{obj =}\NormalTok{ sdcInitial, }\DataTypeTok{variables=}\KeywordTok{c}\NormalTok{(}\StringTok{"TANHHEXP"}\NormalTok{, }\StringTok{"INCTOTGROSSHH"}\NormalTok{), }\DataTypeTok{method=}\StringTok{"additive"}\NormalTok{) }

\CommentTok{# multiplicar los totales anonimizados por los ratios para obtener los componentes anonimizados}
\NormalTok{compExp <-}\StringTok{  }\KeywordTok{c}\NormalTok{(}\StringTok{"TFOODEXP"}\NormalTok{, }\StringTok{"TALCHEXP"}\NormalTok{, }\StringTok{"TCLTHEXP"}\NormalTok{, }\StringTok{"THOUSEXP"}\NormalTok{, }
              \StringTok{"TFURNEXP"}\NormalTok{, }\StringTok{"THLTHEXP"}\NormalTok{, }\StringTok{"TTRANSEXP"}\NormalTok{, }\StringTok{"TCOMMEXP"}\NormalTok{, }
              \StringTok{"TRECEXP"}\NormalTok{, }\StringTok{"TEDUEXP"}\NormalTok{, }\StringTok{"TRESTHOTEXP"}\NormalTok{, }\StringTok{"TMISCEXP"}\NormalTok{)}

\NormalTok{sdcInital}\OperatorTok{@}\NormalTok{manipNumVars[,compExp] <-}\StringTok{ }\NormalTok{sdcInital }\OperatorTok{@}\NormalTok{manipNumVars[,}\StringTok{"TANHHEXP"}\NormalTok{] }\OperatorTok{*}\StringTok{ }
\StringTok{                                      }\NormalTok{sdcInital }\OperatorTok{@}\NormalTok{origData[,compExp]}\OperatorTok{/}\StringTok{ }\NormalTok{sdcInital}\OperatorTok{@}\NormalTok{origData[,}\StringTok{"TANHHEXP"}\NormalTok{]}

\CommentTok{# recalcular los riesgos despu√©s de cambiar manualmente los valores en el objeto sdcMicro}
\KeywordTok{calcRisks}\NormalTok{(sdcInital)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## The input dataset consists of 2000 rows and 40 variables.
##   --> Categorical key variables: URBRUR, REGION, HHSIZE, OWNAGLAND, RELIG
##   --> Numerical key variables: LANDSIZEHA, TANHHEXP, TFOODEXP, TALCHEXP, TCLTHEXP, THOUSEXP, TFURNEXP, THLTHEXP, TTRANSEXP, TCOMMEXP, TRECEXP, TEDUEXP, TRESTHOTEXP, TMISCEXP, INCTOTGROSSHH, INCRMT, INCWAGE, INCFARMBSN, INCNFARMBSN, INCRENT, INCFIN, INCPENSN, INCOTHER
##   --> Weight variable: WGTPOP
##   --> Strata variable(s): strata_region
## ----------------------------------------------------------------------
\end{verbatim}

\begin{verbatim}
## Information on categorical key variables:
## 
## Reported is the number, mean size and size of the smallest category >0 for recoded variables.
## In parenthesis, the same statistics are shown for the unmodified data.
## Note: NA (missings) are counted as seperate categories!
\end{verbatim}

\begin{verbatim}
##  Key Variable Number of categories      Mean size           
##        URBRUR                    2  (2)  1000.000 (1000.000)
##        REGION                    6  (6)   333.333  (333.333)
##        HHSIZE                   23 (23)    86.957   (86.957)
##     OWNAGLAND                    4  (4)   531.667  (531.667)
##         RELIG                    7  (7)   166.667  (166.667)
##  Size of smallest (>0)      
##                    684 (684)
##                    260 (260)
##                      1   (1)
##                    332 (332)
##                      7   (7)
\end{verbatim}

\begin{verbatim}
## ----------------------------------------------------------------------
\end{verbatim}

\begin{verbatim}
## Infos on 2/3-Anonymity:
## 
## Number of observations violating
##   - 2-anonymity: 115 (5.750%)
##   - 3-anonymity: 239 (11.950%)
##   - 5-anonymity: 497 (24.850%)
## 
## ----------------------------------------------------------------------
\end{verbatim}

\begin{verbatim}
## Numerical key variables: LANDSIZEHA, TANHHEXP, TFOODEXP, TALCHEXP, TCLTHEXP, THOUSEXP, TFURNEXP, THLTHEXP, TTRANSEXP, TCOMMEXP, TRECEXP, TEDUEXP, TRESTHOTEXP, TMISCEXP, INCTOTGROSSHH, INCRMT, INCWAGE, INCFARMBSN, INCNFARMBSN, INCRENT, INCFIN, INCPENSN, INCOTHER
## 
## Disclosure risk is currently between [0.00%; 65.45%]
## 
## Current Information Loss:
##   - IL1: 5502084.89
##   - Difference of Eigenvalues: -5707380515428431.000%
## ----------------------------------------------------------------------
\end{verbatim}

\begin{quote}
Lectura recomendada de adici√≥n de ruido:
- Brand, Ruth. 2002. ``Microdata Protection through Noise Addition.'' In Inference -Control in Statistical Databases - From Theory to Practice, edited byJosep Domingo-Ferrer. Lecture Notes in Computer Science Series 2316, 97-116. Berlin Heidelberg: Springer. \url{http://link.springer.com/chapter/10.1007\%2F3-540-47804-3_8}
- Kim, Jay J, and William W Winkler. 2003. ``Multiplicative Noise for Masking Continuous Data.'' Research Report Series (Statistical Research Division. US Bureau of the Census). \url{https://www.census.gov/srd/papers/pdf/rrs2003-01.pdf}
- Torra, Vicen√ß, and Isaac Cano. 2011. ``Edit Constraints on Microaggregation and Additive Noise.'' In Privacy and Security Issues in Data Mining and Machine Learning, edited by C. Dimitrakakis, A. Gkoulalas-Divanis, A. Mitrokotsa, V. S. Verykios, Y. Saygin. Lecture Notes in Computer Science Volume 6549, 1-14. Berlin Heidelberg: Springer. \url{http://link.springer.com/book/10.1007/978-3-642-19896-0}
- Mivule, K. 2013. ``Utilizing Noise Addition for Data Privacy, An Overview.'' Proceedings of the International Conference on Information and Knowledge Engineering (IKE 2012), (pp.65-71).Las Vegas, USA. \url{http://arxiv.org/ftp/arxiv/papers/1309/1309.3958.pdf}
\end{quote}

\hypertarget{rank-swapping-intercambio-de-rangos}{%
\subsection{Rank swapping (Intercambio de rangos)}\label{rank-swapping-intercambio-de-rangos}}

\emph{Rank swapping} se basa en intercambiar los valores de una determinada variable entre los registros. \emph{Rank swapping} es un tipo de intercambio de datos, que se define para las variables ordinales y continuas. Para \emph{Rank swapping}, los valores de la variable se ordenan primero. El n√∫mero posible de valores con los que se puede intercambiar una variable est√° limitado por los valores que se encuentran alrededor del valor original al ordenar los valores del conjunto de datos. El tama√±o de este vecindario puede especificarse, por ejemplo, como un porcentaje del n√∫mero total de observaciones. Esto tambi√©n significa que un valor puede ser intercambiado con valores iguales o muy similares. Esto es especialmente cierto si la vecindad es peque√±a o si solo hay unos pocos valores diferentes en la variable (variable ordinal). Un ejemplo es la variable ``educaci√≥n'' si tiene pocas categor√≠as: (``ninguna'', ``primaria'', ``secundaria'', ``terciaria''). En estos casos, \emph{Rank swapping} no es un m√©todo adecuado al encontrarse con pocas categor√≠as y limitarse por los valores que se encuentran alrededor, para que fuese adecuado, tendr√≠a que contar con un n√∫mero mayor de categor√≠as a intercambiar.

Si \emph{Rank swapping} se aplica a varias variables en simult√°neo, la estructura de correlaci√≥n entre las variables se mantiene. Por lo tanto, es importante comprobar si la estructura de correlaci√≥n en los datos es plausible. \emph{Rank swapping} se implementa en la funci√≥n \texttt{rankSwap()} de \texttt{sdcMicro}. Las variables que deben intercambiarse deben especificarse en el argumento ``variables''. Por defecto, los valores por debajo del percentil 5 y por encima del percentil 95 se codifican por arriba y por abajo y se sustituyen por su valor medio (v√©ase la secci√≥n Codificaci√≥n superior e inferior \ref{cod-sup-inf}). Especificando las opciones ``TopPercent'' y ``BottomPercent'' podemos elegir estos percentiles. El argumento ``p'' define el tama√±o de la vecindad como porcentaje del tama√±o de la muestra. Si el valor ``p'' es 0.05, el vecindario tendr√° un tama√±o de \(0.05 * n\), donde \(n\) es el tama√±o de la muestra. Dado que \emph{Rank swapping} es un m√©todo probabil√≠stico, es decir, el intercambio depende de un mecanismo generador de n√∫meros aleatorios, se recomienda especificar una semilla para el generador de n√∫meros aleatorios antes de utilizar \emph{Rank swapping} y as√≠ garantizar la reproducibilidad de los resultados. La semilla tambi√©n puede especificarse como argumento de la funci√≥n \texttt{rankSwap()}. El Bloque \ref{exm:bloque37jgm} muestra c√≥mo aplicar \emph{Rank swapping} con \texttt{sdcMicro}. Si las variables contienen valores perdidos (\texttt{NA} en R), la funci√≥n \texttt{rankSwap()} los recodificar√° autom√°ticamente con el valor especificado en el argumento ``missing''. Este valor no debe estar en el rango de valores de ninguna de las variables. Despu√©s de utilizar la funci√≥n \texttt{rankSwap()}, estos valores deber√≠an recodificarse como \texttt{NA}. Esto se muestra en el Bloque \ref{exm:bloque37jgm}.

\hypertarget{section-11}{%
\subsubsection{}\label{section-11}}

\begin{example}
\protect\hypertarget{exm:bloque37jgm}{}{\label{exm:bloque37jgm} }Rank swapping usando \texttt{sdcMicro}
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# establecer la semilla para el generador de n√∫meros aleatorios }
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{12345}\NormalTok{) }

\CommentTok{# comprobar la estructura de correlaci√≥n entre las variables}
\KeywordTok{cor}\NormalTok{(file}\OperatorTok{$}\NormalTok{THOUSEXP, file}\OperatorTok{$}\NormalTok{TFOODEXP)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.3811335
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# aplicar rank swapping}
\KeywordTok{rankSwap}\NormalTok{(sdcInitial, }\DataTypeTok{variables =} \KeywordTok{c}\NormalTok{(}\StringTok{"THOUSEXP"}\NormalTok{, }\StringTok{"TFOODEXP"}\NormalTok{), }\DataTypeTok{missing =} \OtherTok{NA}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## setting parameter R0 = 0.95 as no inputs have been specified.
\end{verbatim}

\begin{verbatim}
## The input dataset consists of 2000 rows and 40 variables.
##   --> Categorical key variables: URBRUR, REGION, HHSIZE, OWNAGLAND, RELIG
##   --> Numerical key variables: LANDSIZEHA, TANHHEXP, TFOODEXP, TALCHEXP, TCLTHEXP, THOUSEXP, TFURNEXP, THLTHEXP, TTRANSEXP, TCOMMEXP, TRECEXP, TEDUEXP, TRESTHOTEXP, TMISCEXP, INCTOTGROSSHH, INCRMT, INCWAGE, INCFARMBSN, INCNFARMBSN, INCRENT, INCFIN, INCPENSN, INCOTHER
##   --> Weight variable: WGTPOP
##   --> Strata variable(s): strata_region
## ----------------------------------------------------------------------
\end{verbatim}

\begin{verbatim}
## Information on categorical key variables:
## 
## Reported is the number, mean size and size of the smallest category >0 for recoded variables.
## In parenthesis, the same statistics are shown for the unmodified data.
## Note: NA (missings) are counted as seperate categories!
\end{verbatim}

\begin{verbatim}
##  Key Variable Number of categories      Mean size           
##        URBRUR                    2  (2)  1000.000 (1000.000)
##        REGION                    6  (6)   333.333  (333.333)
##        HHSIZE                   23 (23)    86.957   (86.957)
##     OWNAGLAND                    4  (4)   531.667  (531.667)
##         RELIG                    7  (7)   166.667  (166.667)
##  Size of smallest (>0)      
##                    684 (684)
##                    260 (260)
##                      1   (1)
##                    332 (332)
##                      7   (7)
\end{verbatim}

\begin{verbatim}
## ----------------------------------------------------------------------
\end{verbatim}

\begin{verbatim}
## Infos on 2/3-Anonymity:
## 
## Number of observations violating
##   - 2-anonymity: 115 (5.750%)
##   - 3-anonymity: 239 (11.950%)
##   - 5-anonymity: 497 (24.850%)
## 
## ----------------------------------------------------------------------
\end{verbatim}

\begin{verbatim}
## Numerical key variables: LANDSIZEHA, TANHHEXP, TFOODEXP, TALCHEXP, TCLTHEXP, THOUSEXP, TFURNEXP, THLTHEXP, TTRANSEXP, TCOMMEXP, TRECEXP, TEDUEXP, TRESTHOTEXP, TMISCEXP, INCTOTGROSSHH, INCRMT, INCWAGE, INCFARMBSN, INCNFARMBSN, INCRENT, INCFIN, INCPENSN, INCOTHER
## 
## Disclosure risk is currently between [0.00%; 0.00%]
## 
## Current Information Loss:
##   - IL1: 5547922.46
##   - Difference of Eigenvalues: -9431435872317076.000%
## ----------------------------------------------------------------------
\end{verbatim}

Se ha comprobado que \emph{Rank swapping} da buenos resultados con respecto al equilibrio entre la p√©rdida de informaci√≥n y la protecci√≥n de los datos \citep{DoTo01a}. \emph{Rank swapping} no es √∫til para variables con pocos valores diferentes o muchos valores perdidos, ya que el intercambio en ese caso no dar√° lugar a valores alterados. Adem√°s, si el intruso sabe a qui√©n pertenece el valor m√°s alto o m√°s bajo de una variable espec√≠fica (por ejemplo, los ingresos), el nivel de esta variable se revelar√° despu√©s de \emph{Rank swapping}, porque los valores en s√≠ no se alteran y los valores originales se revelan todos. Esto puede resolverse codificando por arriba y por abajo los valores m√°s bajos y/o m√°s altos.

\begin{quote}
Lectura recomendada de adici√≥n de Rank Swapping:
- Dalenius T. and Reiss S.P. 1978. Data-swapping: a technique for disclosure control (extended abstract). In Proc. ASA Section on Survey Research Methods. American Statistical Association, Washington DC, 191--194.
- Domingo-Ferrer J. and Torra V. 2001. ``A Quantitative Comparison of Disclosure Control Methods for Microdata.'' In Confidentiality, Disclosure and Data Access: Theory and Practical Applications for Statistical Agencies, edited by P. Doyle, J.I. Lane, J.J.M. Theeuwes, and L. Zayatz, 111--134. Amsterdam, North-Holland.
- Hundepool A., Van de Wetering A., Ramaswamy R., Franconi F., Polettini S., Capobianchi A., De Wolf P.-P., Domingo-Ferrer J., Torra V., Brand R. and Giessing S. 2007. Œº-Argus User's Manual version 4.1.
\end{quote}

\hypertarget{shuffling-barajado}{%
\subsection{Shuffling (Barajado)}\label{shuffling-barajado}}

El \emph{shuffling} introducido por \citep{MuSa06} es similar al \emph{swapping}, pero utiliza un modelo de regresi√≥n subyacente con las variables para determinar cu√°les se intercambian. El \emph{shuffling} puede utilizarse para variables continuas y es un m√©todo determinista. El \emph{shuffling} mantiene las distribuciones marginales en los datos barajados. Sin embargo, \emph{shuffling} requiere una clasificaci√≥n completa de los datos, que puede ser muy intensiva desde el punto de vista computacional para grandes conjuntos de datos con m√∫ltiples variables.

El m√©todo se explica en detalle en \citep{MuSa06}. La idea es clasificar a los individuos en funci√≥n de sus variables originales. A continuaci√≥n, se ajusta un modelo de regresi√≥n con las variables a proteger como regresores y un conjunto de variables que predicen bien esta variable (es decir, con las que est√°n correlacionadas) como regresores. Este modelo de regresi√≥n se utiliza para generar \(n\) valores sint√©ticos (predichos) para cada variable que hay que proteger. Estos valores generados tambi√©n se ranquean y cada valor original se sustituye por otro valor original con el rango que corresponde al ranking del valor generado. Esto significa que todos los valores originales estar√°n en los datos. La Tabla \ref{tab:Tabla19} presenta un ejemplo simplificado del m√©todo \emph{shuffling}. En este ejemplo no se especifican los regresores.

\begin{table}

\caption{\label{tab:Tabla19}\label{tab:Tabla19}M√©todos de agrupaci√≥n para la microagregaci√≥n que son implementados en `sdcMicro`}
\centering
\begin{tabular}[t]{llllll}
\toprule
ID & Ingreso (orig.) & Rango (orig.) & Ingreso (pred.) & Rango (pred.) & Valores barajados\\
\midrule
1 & 2,300 & 2 & 2,466.56 & 4 & 2,345\\
2 & 2,434 & 6 & 2,583.58 & 7 & 2,543\\
3 & 2,123 & 1 & 2,594.17 & 8 & 2,643\\
4 & 2,312 & 3 & 2,530.97 & 6 & 2,434\\
5 & 6,045 & 10 & 5,964.04 & 10 & 6,045\\
\addlinespace
6 & 2,345 & 4 & 2,513.45 & 5 & 2,365\\
7 & 2,543 & 7 & 2,116.16 & 1 & 2,123\\
8 & 2,854 & 9 & 2,624.32 & 9 & 2,854\\
9 & 2,365 & 5 & 2,203.45 & 2 & 2,300\\
10 & 2,643 & 8 & 2,358.29 & 3 & 2,312\\
\bottomrule
\end{tabular}
\end{table}

Se recomienda el uso del m√©todo ``ds'' (el m√©todo por defecto de \emph{shuffling} en \texttt{sdcMicro}) \citep{TeMK14}. En el argumento ``form'' debe especificarse una funci√≥n con regresores para las variables a proteger. Al menos dos regresores deben especificarse y estos deben tener poder predictivo para las variables a predecir. Esto puede comprobarse con medidas de bondad de ajuste como el \(R^2\) de la regresi√≥n. El \(R^2\) solo capta las relaciones lineales, pero estas son tambi√©n las √∫nicas relaciones que capta el modelo de regresi√≥n lineal utilizado para el \emph{shuffling}. A continuaci√≥n, se presenta un ejemplo para barajar las variables de gasto, que se predicen mediante el gasto total de los hogares y el tama√±o de estos.

\hypertarget{section-12}{%
\subsubsection{}\label{section-12}}

\begin{example}
\protect\hypertarget{exm:bloque38jgm}{}{\label{exm:bloque38jgm} }Shuffling usando una ecuaci√≥n de regresi√≥n especificada
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Evaluar el R-cuadrado (bondad de ajuste) del modelo de regresi√≥n}
\KeywordTok{summary}\NormalTok{(}\KeywordTok{lm}\NormalTok{(file, }\DataTypeTok{form =}\NormalTok{ TFOODEXP }\OperatorTok{+}\StringTok{ }\NormalTok{TALCHEXP }\OperatorTok{+}\StringTok{ }\NormalTok{TCLTHEXP }\OperatorTok{+}\StringTok{ }\NormalTok{THOUSEXP }\OperatorTok{+}\StringTok{ }\NormalTok{TFURNEXP }\OperatorTok{+}\StringTok{ }\NormalTok{THLTHEXP }\OperatorTok{+}\StringTok{ }\NormalTok{TTRANSEXP }\OperatorTok{+}\StringTok{ }\NormalTok{TCOMMEXP }\OperatorTok{+}\StringTok{ }\NormalTok{TRECEXP }\OperatorTok{+}\StringTok{ }\NormalTok{TEDUEXP }\OperatorTok{+}\StringTok{ }\NormalTok{TRESTHOTEXP }\OperatorTok{+}\StringTok{ }\NormalTok{TMISCEXP }\OperatorTok{~}\StringTok{ }\NormalTok{TANHHEXP }\OperatorTok{+}\StringTok{ }\NormalTok{HHSIZE)) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning in summary.lm(lm(file, form = TFOODEXP + TALCHEXP + TCLTHEXP + THOUSEXP
## + : essentially perfect fit: summary may be unreliable
\end{verbatim}

\begin{verbatim}
## 
## Call:
## lm(formula = TFOODEXP + TALCHEXP + TCLTHEXP + THOUSEXP + TFURNEXP + 
##     THLTHEXP + TTRANSEXP + TCOMMEXP + TRECEXP + TEDUEXP + TRESTHOTEXP + 
##     TMISCEXP ~ TANHHEXP + HHSIZE, data = file)
## 
## Residuals:
##        Min         1Q     Median         3Q        Max 
## -1.842e-09 -2.800e-13  2.000e-13  6.800e-13  2.526e-11 
## 
## Coefficients:
##               Estimate Std. Error    t value Pr(>|t|)    
## (Intercept) -1.811e-11  3.795e-13 -4.774e+01   <2e-16 ***
## TANHHEXP     1.000e+00  5.098e-18  1.961e+17   <2e-16 ***
## HHSIZE      -5.414e-14  5.155e-14 -1.050e+00    0.294    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1.799e-11 on 10571 degrees of freedom
## Multiple R-squared:      1,  Adjusted R-squared:      1 
## F-statistic: 2.213e+34 on 2 and 10571 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Shuffling utilizando la ecuaci√≥n de regresi√≥n especificada}
\NormalTok{sdcInitial <-}\StringTok{ }\KeywordTok{shuffle}\NormalTok{(sdcInitial, }\DataTypeTok{method=}\StringTok{"ds"}\NormalTok{, }
                      \DataTypeTok{form =}\NormalTok{ TFOODEXP }\OperatorTok{+}\StringTok{ }\NormalTok{TALCHEXP }\OperatorTok{+}\StringTok{ }\NormalTok{TCLTHEXP }\OperatorTok{+}\StringTok{ }\NormalTok{THOUSEXP }\OperatorTok{+}\StringTok{ }
\StringTok{                        }\NormalTok{TFURNEXP }\OperatorTok{+}\StringTok{ }\NormalTok{THLTHEXP }\OperatorTok{+}\StringTok{ }\NormalTok{TTRANSEXP }\OperatorTok{+}\StringTok{ }\NormalTok{TCOMMEXP }\OperatorTok{+}\StringTok{ }
\StringTok{                        }\NormalTok{TRECEXP }\OperatorTok{+}\StringTok{ }\NormalTok{TEDUEXP }\OperatorTok{+}\StringTok{ }\NormalTok{TRESTHOTEXP }\OperatorTok{+}\StringTok{ }\NormalTok{TMISCEXP }\OperatorTok{~}\StringTok{ }\NormalTok{TANHHEXP }\OperatorTok{+}\StringTok{ }\NormalTok{HHSIZE) }
\end{Highlighting}
\end{Shaded}

\begin{quote}
Lectura recomendada de shuffling:
- K. Muralidhar and R. Sarathy. 2006.''Data shuffling - A new masking approach for numerical data,'' Management Science, 52, 658-670.
\end{quote}

\hypertarget{comparaciuxf3n-de-pram-rank-swapping-y-shuffling}{%
\subsection{Comparaci√≥n de PRAM, Rank swapping y Shuffling}\label{comparaciuxf3n-de-pram-rank-swapping-y-shuffling}}

PRAM, Rank swapping y Shuffling son m√©todos perturbativos, es decir, cambian los valores de los registros individuales y se utilizan principalmente para las variables continuas. Tras el rank swapping y shuffling, todos los valores originales est√°n contenidos en el conjunto de datos tratado, pero pueden asignarse a otros registros. Esto implica que las tabulaciones univariantes no se modifican. Esto tambi√©n se mantiene en la expectativa de PRAM, si se elige una matriz de transici√≥n que tenga la propiedad invariante.

La elecci√≥n de un m√©todo se basa en la estructura a preservar en los datos. En los casos en los que el modelo de regresi√≥n se ajusta a los datos, el shuffling funcionar√≠a muy bien, ya que deber√≠a haber suficientes regresores (continuos) disponibles. El rank swapping funciona bien si hay suficientes categor√≠as en las variables. Se prefiere PRAM si el m√©todo de perturbaci√≥n debe aplicarse solo a una o pocas variables; la ventaja es la posibilidad de especificar restricciones en la matriz de transici√≥n y aplicar PRAM solo dentro de los estratos, que pueden ser definidos por el usuario.

\hypertarget{anonimizaciuxf3n-del-identificador-indirecto-de-tamauxf1o-del-hogar}{%
\section{Anonimizaci√≥n del identificador indirecto de tama√±o del hogar}\label{anonimizaciuxf3n-del-identificador-indirecto-de-tamauxf1o-del-hogar}}

El tama√±o de un hogar es un identificador importante, especialmente para los hogares grandes\footnote{En este caso, todos los grupos pueden tener diferentes tama√±os (es decir, n√∫mero de individuos en un grupo). En la pr√°ctica, la b√∫squeda de grupos homog√©neos se simplifica teniendo tama√±os de grupo iguales para todos los grupos.}. Sin embargo, la supresi√≥n de la variable de tama√±o real, si est√° disponible (por ejemplo, el n√∫mero de miembros del hogar), no basta para eliminar esta informaci√≥n del conjunto de datos, ya que un simple recuento de los miembros del hogar para un hogar concreto permitir√° reconstruir esta variable siempre que haya un identificador del hogar en los datos. En cualquier caso, los hogares de un tama√±o muy grande o con una clave √∫nica o especial (es decir, una combinaci√≥n de valores de identificadores indirectos) deben comprobarse manualmente. Una forma de tratarlos es eliminar estos hogares del conjunto de datos antes de su publicaci√≥n. Otra posibilidad es dividir los hogares, pero hay que tener cuidado de suprimir o cambiar los valores de estos hogares para evitar que un intruso entienda inmediatamente que estos hogares han sido divididos y los reconstruya combinando los dos hogares con los mismos valores.

\hypertarget{resumen-de-muxe9todos-sdc}{%
\section{Resumen de m√©todos SDC}\label{resumen-de-muxe9todos-sdc}}

\begin{table}

\caption{\label{tab:Tablaxx}\label{tab:Tablaxx}M√©todos de agrupaci√≥n para la microagregaci√≥n que son implementados en `sdcMicro`}
\centering
\begin{tabular}[t]{lllll}
\toprule
M√©todos & T√©cnicas & Ventajas & Desventajas & Tipo de datos\\
\midrule
Perturbativos & PRAM & - Aplicar a subgrupos del conjunto   de datos.
- Probabilidad positiva de un match con un individuo err√≥neo.
- Seleccionar la matriz de transici√≥n y probabilidad.
- √ötil con muchas variables y/o alta p√©rdida de informaci√≥n. & - Modificaci√≥n de datos originales, se intercambian caracter√≠sticas.
- Mayor complejidad y posibilidad de error (seleccionar estratos).
- Aparenta que no hay anonimizaci√≥n.
- En el caso de las encuestas por muestreo, cada observaci√≥n puede tener un   peso muestral diferente, por lo que, despu√©s de la generalizaci√≥n, no se garantiza la coherencia. & Categ√≥rico\\
Perturbativos & Microagregaci√≥n & - Sencilla de comprender y aplicar.
- Versi√≥n univariada implica baja p√©rdida de informaci√≥n.
- Versi√≥n multivariada permite disminuir bastante el riesgo.
- Todos los valores originales est√°n contenidos en la data tratada   (distribuciones univariadas no cambian).
- Evita la introducci√≥n de inconsistencias que requieran edici√≥n. & - Trade-off entre p√©rdida de   informaci√≥n y disminuci√≥n de riesgo seg√∫n si se aplica de forma univariado o   multivariada. & Continuo\\
Perturbativos & Adici√≥n de ruido & - Puede a√±adir ruido de forma univariada o bivariada.
- Sencilla de comprender y aplicar. & - Puede mantener niveles altos riesgos, no permite medir los riesgos post-aplicaci√≥n.
- Variable de n√∫mero enteros puede pasar a tener decimales (por ejemplo, 3,5   hijos).
- Puede incrementar rango de valores de variable.
- Necesaria edici√≥n posterior a la anonimizaci√≥n. & Continuo\\
Perturbativos & Shuffling (Barajado) & - Todos los valores originales est√°n contenidos en la data tratada   (distribuciones univariadas no cambian).
- Permite mantener relaciones multivariadas. & - Requiere una clasificaci√≥n completa de los datos, que puede ser computacionalmente muy intensiva para grandes conjuntos de datos con varias variables.
- Necesita regresi√≥n lineal (deben cumplirse supuestos y la recta ajustar bien)
- La t√©cnica requiere al menos dos variables cuantitativas en la f√≥rmula de   la funci√≥n. & Continuo\\
Perturbativos & Rank swapping (Intercambio de rangos) & - Todos los valores originales est√°n contenidos en la data tratada (distribuciones univariadas no   cambian).
- Sencilla de comprender y aplicar.
- Permite mantener relaciones multivariadas.
- Baja p√©rdida de informaci√≥n. & - Reduce rango de valores m√≠nimos y m√°ximos.
- Puede mantener niveles altos de riesgos. & Continuo\\
\addlinespace
No perturbativos & Supresi√≥n local & - Quitar datos at√≠picos.
- Seleccionar datos a eliminar seg√∫n importancia. & - No es √∫til para variables continuas ni con alto n√∫mero de categor√≠as.
- Con alto n√∫mero de variables o categor√≠as puede no lograr soluci√≥n.
- Limitaci√≥n de algoritmo en librer√≠a `sdcMicro`.
- Observaciones con variables suprimidas quedan con valor perdido. & Categ√≥rico\\
No perturbativos & Recodificaci√≥n Global & - Se disminuye informaci√≥n, pero   manteniendo estructura y relaciones. & - P√©rdida de informaci√≥n continua   al categorizar para estimaci√≥n de modelos.
- Cambia nivel de medici√≥n de variables continuas a ordinales o categ√≥ricas. & Continuo y categ√≥rico\\
No perturbativos & Codificaci√≥n superior e inferior & - Se pierde menos informaci√≥n que con recodificaci√≥n global, permite agrupar solo las colas de la distribuci√≥n. & - Menor nivel de anonimizaci√≥n, se requiere evaluar trade-off entre ambos m√©todos. & Continuo y categ√≥rico\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{mediciuxf3n-de-la-utilidad-y-la-puxe9rdida-de-informaciuxf3n}{%
\chapter{Medici√≥n de la utilidad y la p√©rdida de informaci√≥n}\label{mediciuxf3n-de-la-utilidad-y-la-puxe9rdida-de-informaciuxf3n}}

Hoy en d√≠a, resolver la tensi√≥n entre la protecci√≥n de la informaci√≥n personal y el suministro de datos es realmente un desaf√≠o que deben asumir las ONE. En esta situaci√≥n, tres motivaciones empujan a las ONE a preservar la confidencialidad.

SDC es un intercambio entre el riesgo de divulgaci√≥n versus la p√©rdida de utilidad de los datos (siempre buscando minimizar este √∫ltimo), al tiempo que reduce el riesgo de divulgaci√≥n a un nivel aceptable. La utilidad de los datos en este contexto significa la utilidad de los datos anonimizados para los an√°lisis estad√≠sticos de los usuarios finales, as√≠ como la validez de estos an√°lisis cuando se realizan con datos anonimizados. El riesgo de divulgaci√≥n y su medici√≥n se definir√°n m√°s adelante en \protect\hyperlink{mediciuxf3n-de-riesgos}{Medici√≥n de riesgos}.

Para lograr este equilibrio entre minimizar el riesgo de divulgaci√≥n y maximizar la utilidad de los datos para los usuarios finales, es necesario medir la utilidad de los datos despu√©s de la anonimizaci√≥n y compararla con la utilidad de los datos originales.

En esta secci√≥n se busca describir las medidas que se pueden usar para comparar la utilidad de los datos antes y despu√©s de la anonimizaci√≥n, as√≠ como tambi√©n cuantificar la p√©rdida de informaci√≥n. La p√©rdida de informaci√≥n es inversa a la utilidad de los datos: cuanto mayor sea la utilidad de los datos despu√©s de la anonimizaci√≥n, menor ser√° la p√©rdida de informaci√≥n.

\begin{quote}
\textbf{Nota}
1. Si los microdatos a anonimizar se basan en una muestra, los datos incurrir√°n en un error de muestreo. Tambi√©n pueden estar presentes otros errores en los datos, como un error de falta de respuesta.
2. Los m√©todos discutidos aqu√≠ solo miden la p√©rdida de informaci√≥n causada por el proceso de anonimizaci√≥n en relaci√≥n con los datos de la muestra original y no intentan medir el error causado por otras fuentes.
\end{quote}

La p√©rdida de informaci√≥n se eval√∫a con respecto a las necesidades y usos de los usuarios finales de los microdatos. Sin embargo, los diferentes usuarios de los datos anonimizados pueden tener usos muy diversos para los datos publicados y es posible que no sea posible recopilar una lista exhaustiva de los distintos usos. Es as√≠ que nos enfocaremos en la publicaci√≥n de un conjunto de datos para evitar la divulgaci√≥n no intencional. La publicaci√≥n de m√∫ltiples conjuntos de datos an√≥nimos para diferentes prop√≥sitos puede dar lugar a una divulgaci√≥n no intencionada.\footnote{Es posible liberar archivos de datos para diferentes grupos de usuarios, por ejemplo, PUF y SUF. Sin embargo, toda la informaci√≥n en el archivo menos detallado tambi√©n debe incluirse en el archivo m√°s detallado para evitar la divulgaci√≥n no deseada. Los conjuntos de datos publicados en enclaves de datos se pueden personalizar para el usuario, ya que el riesgo de que se combinen con otra versi√≥n es cero.}

El proceso SDC se caracteriza por el balance entre el riesgo de divulgaci√≥n y la utilidad de los datos para los usuarios finales. La escala riesgo-utilidad se extiende entre dos extremos:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  No se difunden datos (riesgo cero de divulgaci√≥n) y, por lo tanto, los usuarios no obtienen ninguna utilidad de los datos.
\item
  Los datos se difunden sin ning√∫n tratamiento y, por lo tanto, con el m√°ximo riesgo de divulgaci√≥n, pero con la m√°xima utilidad para el usuario (es decir, sin p√©rdida de informaci√≥n).
\end{enumerate}

El objetivo de un proceso SDC bien implementado es encontrar el punto √≥ptimo en el que la utilidad para los usuarios finales se maximice a un nivel de riesgo aceptable.

En el balance entre Riesgo y Utilidad que se muestra en la Figura @ref(fig:fig1\_sec05), por un extremo, el tri√°ngulo corresponde a los datos sin procesar, los que no tienen p√©rdida de informaci√≥n, pero generalmente tienen un riesgo de divulgaci√≥n m√°s alto que el nivel aceptable. El otro extremo es el cuadrado, que corresponde a la no publicaci√≥n de datos. En ese caso, no hay riesgo de divulgaci√≥n, pero tampoco hay utilidad de los datos para los usuarios. Los puntos intermedios corresponden a diferentes opciones de m√©todos SDC y/o par√°metros aplicados a diferentes variables. El proceso SDC busca
m√©todos y par√°metros, que son aplicados de una manera que produce una reducci√≥n del riesgo de forma muchas veces satisfactoria, minimiz√°ndose generalmente la p√©rdida de informaci√≥n.

\textbackslash{}begin\{figure\}

\{\centering \includegraphics[width=0.9\linewidth]{Imagenes/fig1}

\}

\caption{Balance riesgo-utilidad en un conjunto de datos.}

(\#fig:fig1\_sec05)
\textbackslash{}end\{figure\}

\textbf{Fuente:} Imagen extra√≠da de \citep{benschop2021}, p√°g.78.

En las siguientes secciones, primero proponemos medidas generales de utilidad independientes del uso de datos, y luego presentamos un ejemplo de una medida espec√≠fica √∫til para medir la p√©rdida de informaci√≥n con respecto a usos de datos espec√≠ficos. Finalmente, mostramos c√≥mo visualizar cambios en los datos causados por la anonimizaci√≥n y discutimos la selecci√≥n de medidas de utilidad para un conjunto de datos en particular.

\hypertarget{medidas-generales-de-utilidad-para-variables-continuas-y-categuxf3ricas}{%
\section{Medidas generales de utilidad para variables continuas y categ√≥ricas}\label{medidas-generales-de-utilidad-para-variables-continuas-y-categuxf3ricas}}

Las medidas generales de p√©rdida de informaci√≥n se pueden dividir en
aquellas que comparan los valores reales de los datos sin procesar y los
anonimizado, y aquellas que comparan las estad√≠sticas de ambos conjuntos
de datos. Todas las medidas son a posteriori, ya que miden la utilidad
despu√©s de la anonimizaci√≥n y requieren tanto los datos originales como
los anonimizados.

Las medidas de utilidad son diferentes para variables categ√≥ricas y para
las variables continuas.

\hypertarget{variables-categuxf3ricas}{%
\subsection{Variables categ√≥ricas}\label{variables-categuxf3ricas}}

\hypertarget{nuxfamero-de-valores-faltantes}{%
\subsubsection{N√∫mero de valores faltantes}\label{nuxfamero-de-valores-faltantes}}

Una medida informativa es comparar el n√∫mero de valores faltantes en los datos. Los valores faltantes a menudo se producen despu√©s de la supresi√≥n y a mayor cantidad de aplicaci√≥n de supresiones ser√° mayor el grado de p√©rdida de informaci√≥n. Despu√©s de usar la funci√≥n de supresi√≥n local en un objeto \texttt{sdcMicro} , la cantidad de supresiones para cada variable clave categ√≥rica se puede recuperar con la funci√≥n print(), como se muestra en el Bloque \ref{exm:bloque1lbn}\footnote{Aqu√≠, el objeto \texttt{sdcMicro} ``sdcIntial'' contiene un conjunto de datos con 2500 personas y 103 variables. Seleccionamos cuatro cuasi-identificadores categ√≥ricos: ``URBRUR'', ``REGION'', ``RELIG'' y ``MARITAL'' y varios cuasi-identificadores continuos relativos a ingresos y gastos. Para ilustrar la p√©rdida de utilidad, tambi√©n aplicamos varios m√©todos SDC a este objeto \texttt{sdcMicro} , como supresi√≥n local, PRAM y adici√≥n de ruido aditivo.}. El argumento `ls' en la funci√≥n \texttt{print()} es la supresi√≥n local. La salida muestra el n√∫mero absoluto y relativo de supresiones.

\begin{example}
\protect\hypertarget{exm:bloque1lbn}{}{\label{exm:bloque1lbn} }Uso de la funci√≥n print() para recuperar el n√∫mero total de supresiones para cada variable clave categ√≥rica
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sdcInitial <-}\StringTok{ }\KeywordTok{localSuppression}\NormalTok{(sdcInitial, }\DataTypeTok{k =} \DecValTok{5}\NormalTok{, }\DataTypeTok{importance =} \OtherTok{NULL}\NormalTok{)}

\KeywordTok{print}\NormalTok{(sdcInitial, }\StringTok{'ls'}\NormalTok{)}

\CommentTok{## Local Suppression:}
\CommentTok{##   KeyVar | Suppressions (#) | Suppressions (%)}
\CommentTok{##   URBRUR |                0 |            0.000}
\CommentTok{##   REGION |               81 |            4.050}
\CommentTok{##    RELIG |                0 |            0.000}
\CommentTok{##  MARITAL |                0 |            0.000}
\CommentTok{## --------------------------------------------------------------}
\end{Highlighting}
\end{Shaded}

Es posible contar y comparar el n√∫mero de valores faltantes en los datos originales y los datos tratados. Esto puede ser √∫til para ver el aumento proporcional en el n√∫mero de valores faltantes. Los valores faltantes
tambi√©n pueden tener otras fuentes, como la no respuesta. En el Bloque \ref{exm:bloque2lbn} se muestran los valores faltantes para cada una de las variables clave categ√≥ricas en un objeto \texttt{sdcMicro}. Aqu√≠ se utiliza el supuesto que todos los valores faltantes est√°n codificados como \texttt{NA}. Si los valores perdidos no est√°n codificados como \texttt{NA}, sino otro valor, se debe utilizar el c√≥digo de valores perdidos alternativo. Los resultados concuerdan con el n√∫mero de valores faltantes introducidos por la supresi√≥n local en el ejemplo anterior, pero tambi√©n muestran que la variable ``RELIG'' tiene 1000 valores faltantes en los datos originales.

\begin{example}
\protect\hypertarget{exm:bloque2lbn}{}{\label{exm:bloque2lbn} }N√∫mero de valores faltantes para cada variable clave categ√≥rica en un objeto \texttt{sdcMicro}
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Almacene los nombres de todas las variables clave categ√≥ricas en un vector}
\NormalTok{namesKeyVars <-}\StringTok{ }\KeywordTok{names}\NormalTok{(sdcInitial}\OperatorTok{@}\NormalTok{manipKeyVars)}

\CommentTok{# Elaborar una matriz para almacenar el n√∫mero de valores faltantes (NA) antes y despu√©s de la anonimizaci√≥n}
\NormalTok{NAcount <-}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\OtherTok{NA}\NormalTok{, }\DataTypeTok{nrow =} \DecValTok{2}\NormalTok{, }\DataTypeTok{ncol =} \KeywordTok{length}\NormalTok{(namesKeyVars))}
\KeywordTok{colnames}\NormalTok{(NAcount) <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\KeywordTok{paste0}\NormalTok{(}\StringTok{'NA'}\NormalTok{, namesKeyVars)) }\CommentTok{# column names}
\KeywordTok{rownames}\NormalTok{(NAcount) <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{'initial'}\NormalTok{, }\StringTok{'treated'}\NormalTok{) }\CommentTok{# row names}

\CommentTok{# Recuento de NA en todas las variables clave (NOTA: solo se cuentan las codificadas como NA)}
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\KeywordTok{length}\NormalTok{(namesKeyVars)) \{}
\NormalTok{  NAcount[}\DecValTok{1}\NormalTok{, i] <-}\StringTok{ }\KeywordTok{sum}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(sdcInitial}\OperatorTok{@}\NormalTok{origData[,namesKeyVars[i]]))}
\NormalTok{  NAcount[}\DecValTok{2}\NormalTok{, i] <-}\StringTok{ }\KeywordTok{sum}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(sdcInitial}\OperatorTok{@}\NormalTok{manipKeyVars[,i]))}
\NormalTok{\}}

\CommentTok{# Mostrar resultados}
\NormalTok{NAcount}
\CommentTok{## NAURBRUR NAREGION NARELIG NAMARITAL}
\CommentTok{## inicial 0 0 1000 51}
\CommentTok{## tratado 0 81 1000 51}
\end{Highlighting}
\end{Shaded}

\hypertarget{nuxfamero-de-registros-cambiados}{%
\subsubsection{N√∫mero de registros cambiados}\label{nuxfamero-de-registros-cambiados}}

Otra estad√≠stica √∫til es el n√∫mero de registros modificados por variable. Estos se pueden contabilizar de forma similar a los valores perdidos e incluyen supresiones (es decir, cambios en los valores perdidos/\texttt{NA} en \texttt{R} ). El n√∫mero de registros cambiados es un buen indicador del impacto de los m√©todos de anonimizaci√≥n en los datos. A
continuaci√≥n en el Bloque \ref{exm:bloque3lbn} se muestra c√≥mo calcular la cantidad de registros modificados para las variables PRAMmed.

\begin{example}
\protect\hypertarget{exm:bloque3lbn}{}{\label{exm:bloque3lbn} }C√°lculo del n√∫mero de registros modificados por variable
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Almacene los nombres de todas las variables del pram en un vector}
\NormalTok{namesPramVars <-}\StringTok{ }\KeywordTok{names}\NormalTok{(sdcInitial}\OperatorTok{@}\NormalTok{manipPramVars)}

\CommentTok{# Marco para guardar la cantidad de registros modificados}
\NormalTok{recChanged <-}\StringTok{ }\KeywordTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{, }\KeywordTok{length}\NormalTok{(namesPramVars))}
\KeywordTok{names}\NormalTok{(recChanged) <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\KeywordTok{paste0}\NormalTok{(}\StringTok{'RC'}\NormalTok{, namesPramVars))}

\CommentTok{# Cuenta del n√∫mero de registros cambiados}
\ControlFlowTok{for}\NormalTok{(j }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\KeywordTok{length}\NormalTok{(namesPramVars)) }\CommentTok{# para todas las  variables clave}
\NormalTok{\{}
\NormalTok{  comp <-}\StringTok{ }\NormalTok{sdcInitial}\OperatorTok{@}\NormalTok{origData[namesPramVars[j]] }\OperatorTok{!=}
\StringTok{                              }\NormalTok{sdcInitial}\OperatorTok{@}\NormalTok{manipPramVars[namesPramVars[j]]}
\NormalTok{  temp1 <-}\StringTok{ }\KeywordTok{sum}\NormalTok{(comp, }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{) }\CommentTok{# cambio en todas las variables sin NA}
\NormalTok{  temp2 <-}\StringTok{ }\KeywordTok{sum}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(comp))        }\CommentTok{# contabiliza los NA en el vector}
\NormalTok{  temp3 <-}\StringTok{ }\KeywordTok{sum}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(sdcInitial}\OperatorTok{@}\NormalTok{origData[namesPramVars[j]])}
               \OperatorTok{+}\StringTok{ }\KeywordTok{is.na}\NormalTok{(sdcInitial}\OperatorTok{@}\NormalTok{manipPramVars[namesPramVars[j]])}\OperatorTok{==}\DecValTok{2}\NormalTok{)}
  \CommentTok{# ambos NA, sin cambios, contabilizados en temp2}
\NormalTok{  recChanged[j] <-}\StringTok{ }\NormalTok{temp1 }\OperatorTok{+}\StringTok{ }\NormalTok{temp2 }\OperatorTok{-}\StringTok{ }\NormalTok{temp3}
\NormalTok{\}}

\CommentTok{# Mostrar resultados}
\NormalTok{recChanged}
\CommentTok{##  RCWATER   RCROOF RCTOILET}
\CommentTok{##      125       86      180}
\end{Highlighting}
\end{Shaded}

\hypertarget{comparaciuxf3n-de-tablas-de-contingencia}{%
\subsubsection{Comparaci√≥n de tablas de contingencia}\label{comparaciuxf3n-de-tablas-de-contingencia}}

Una forma √∫til de medir la p√©rdida de informaci√≥n en variables categ√≥ricas es comparar tabulaciones univariadas y, lo que es m√°s interesante, tablas de contingencia (tambi√©n tabulaciones cruzadas o tablas de doble entrada) entre pares de variables. Para mantener la validez anal√≠tica de un conjunto de datos, las tablas de contingencia
deben permanecer aproximadamente iguales. La funci√≥n \texttt{table()} produce tablas de contingencia de una o m√°s variables. El Bloque \ref{exm:bloque4lbn} a continuaci√≥n crea una tabla de contingencia de las variables ``REGION'' y ``URBRUR''. Observamos peque√±as diferencias entre las tablas antes y despu√©s de la anonimizaci√≥n.

\begin{example}
\protect\hypertarget{exm:bloque4lbn}{}{\label{exm:bloque4lbn} }Comparaci√≥n de tablas de contingencia de variables categ√≥ricas
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Tabla de contingencia (tabulaci√≥n cruzada) de las variables region y urban/rural}
 \KeywordTok{table}\NormalTok{(sdcInitial}\OperatorTok{@}\NormalTok{origData[, }\KeywordTok{c}\NormalTok{(}\StringTok{'REGION'}\NormalTok{, }\StringTok{'URBRUR'}\NormalTok{)]) }\CommentTok{# antes de la anonimizaci√≥n}
 \CommentTok{##       URBRUR}
 \CommentTok{## REGION   1   2}
 \CommentTok{##      1 235  89}
 \CommentTok{##      2 261  73}
 \CommentTok{##      3 295  76}
 \CommentTok{##      4 304  71}
 \CommentTok{##      5 121 139}
 \CommentTok{##      6 100 236}

 \KeywordTok{table}\NormalTok{(sdcInitial}\OperatorTok{@}\NormalTok{manipKeyVars[, }\KeywordTok{c}\NormalTok{(}\StringTok{'REGION'}\NormalTok{, }\StringTok{'URBRUR'}\NormalTok{)]) }\CommentTok{# despu√©s de la anonimizaci√≥n}
 \CommentTok{##       URBRUR}
 \CommentTok{## REGION   1   2}
 \CommentTok{##      1 235  89}
 \CommentTok{##      2 261  73}
 \CommentTok{##      3 295  76}
 \CommentTok{##      4 304  71}
 \CommentTok{##      5 105 130}
 \CommentTok{##      6  79 201}
\end{Highlighting}
\end{Shaded}

\citep{domingo-ferrer2001}proponen una medida de p√©rdida de informaci√≥n basada en tablas de contingencia, que cuantifica la distancia entre las tablas de contingencia en los datos originales y los tratados.
Alternativamente, se pueden usar visualizaciones de la tabla de contingencia con gr√°ficos de mosaico para comparar el impacto de los m√©todos de anonimizaci√≥n en las tabulaciones y tablas de contingencia (consulte la \protect\hyperlink{gruxe1ficos-de-mosaico}{Gr√°ficos de mosaico}).

\hypertarget{variables-continuas}{%
\subsection{Variables continuas}\label{variables-continuas}}

\hypertarget{estaduxedsticas-media-covarianza-correlaciuxf3n}{%
\subsubsection{Estad√≠sticas: media, covarianza, correlaci√≥n}\label{estaduxedsticas-media-covarianza-correlaciuxf3n}}

Las estad√≠sticas que caracterizan el conjunto de datos no deben cambiar despu√©s de la anonimizaci√≥n, como lo son la media, varianza, covarianza y la correlaci√≥n entre las variables m√°s importantes en el conjunto de
datos. \citep{domingo-ferrer2001} da una visi√≥n general de las estad√≠sticas que se pueden considerar. Para evaluar la p√©rdida de informaci√≥n causada por la anonimizaci√≥n, se deben comparar las estad√≠sticas apropiadas para las variables continuas antes y despu√©s de la anonimizaci√≥n.

Para evaluar la p√©rdida de utilidad se cuentan con varias formas de c√°lculo, por ejemplo, comparando medias y (co-)varianzas en los datos o comparando las distribuciones (multivariadas) de los datos. Especialmente los cambios en las correlaciones brindan informaci√≥n valiosa sobre la validez de los datos para las regresiones. Las
funciones del paquete base \texttt{R} o cualquier otro paquete estad√≠stico se pueden usar para hacer esto. Los siguientes son algunos ejemplos en \texttt{R}.

Para calcular la media de cada variable num√©rica usamos la funci√≥n \texttt{colMeans()}. Para ignorar los valores perdidos, es necesario utilizar la opci√≥n \texttt{na.rm\ =\ TRUE}. ``numVars'' es un vector con los nombres de las variables num√©ricas. El Bloque \ref{exm:bloque5lbn} muestra c√≥mo calcular las medias de todas las variables num√©ricas. Los datos no tratados se extraen de la ranura `origData' del objeto \texttt{sdcMicro} y los datos anonimizados del \emph{slot} `manipNumVars', que contiene las variables num√©ricas manipuladas. Observamos peque√±os cambios en cada una de las tres variables.

\begin{example}
\protect\hypertarget{exm:bloque5lbn}{}{\label{exm:bloque5lbn} }Comparando las medias de variables continuas
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# datos no tratados}
\KeywordTok{colMeans}\NormalTok{(sdcInitial}\OperatorTok{@}\NormalTok{origData[, numVars], }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{)}
\CommentTok{##       INC    INCRMT   INCWAGE}
\CommentTok{##  479.7710  961.0295 1158.1330}

\CommentTok{# datos anonimizados}
\KeywordTok{colMeans}\NormalTok{(sdcInitial}\OperatorTok{@}\NormalTok{manipNumVars[, numVars], }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{)}
\CommentTok{##       INC    INCRMT   INCWAGE}
\CommentTok{##  489.6030  993.8512 1168.7561}
\end{Highlighting}
\end{Shaded}

De la misma manera, se pueden calcular las matrices de correlaci√≥n y covarianza de las variables num√©ricas en el objeto \emph{sdcMicro} a partir de los datos no tratados y anonimizados. Esto se muestra en el Bloque \ref{exm:bloque6lbn}. Observamos que la varianza de cada variable (los elementos diagonales en la matriz de covarianza) ha aumentado por la anonimizaci√≥n. Estas funciones tambi√©n permiten calcular intervalos de confianza en el caso de muestras. Las medias y las covarianzas de los subconjuntos de los datos tampoco deber√≠an diferir. Un ejemplo es la media de ingresos por g√©nero, por grupo de edad o por regi√≥n. Este tipo de caracter√≠sticas de los datos son importantes para el an√°lisis.

\begin{example}
\protect\hypertarget{exm:bloque6lbn}{}{\label{exm:bloque6lbn} }Comparaci√≥n de estructuras de covarianza y matrices de correlaci√≥n de variables num√©ricas
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# datos no tratados}
\KeywordTok{cov}\NormalTok{(sdcInitial}\OperatorTok{@}\NormalTok{origData[, numVars])}
\CommentTok{##               INC    INCRMT  INCWAGE}
\CommentTok{## INC     1645926.1  586975.6  2378901}
\CommentTok{## INCRMT   586975.6 6984502.3  1664257}
\CommentTok{## INCWAGE 2378900.7 1664257.4 16169878}

\KeywordTok{cor}\NormalTok{(sdcInitial}\OperatorTok{@}\NormalTok{origData[, numVars])}

\CommentTok{##               INC    INCRMT   INCWAGE}
\CommentTok{## INC     1.0000000 0.1731200 0.4611241}
\CommentTok{## INCRMT  0.1731200 1.0000000 0.1566028}
\CommentTok{## INCWAGE 0.4611241 0.1566028 1.0000000}

\CommentTok{# datos anonimizados}
\KeywordTok{cov}\NormalTok{(sdcInitial}\OperatorTok{@}\NormalTok{manipNumVars[, numVars])}
\CommentTok{##               INC    INCRMT  INCWAGE}
\CommentTok{## INC     2063013.1  649937.5  2382447}
\CommentTok{## INCRMT   649937.5 8566169.1  1778985}
\CommentTok{## INCWAGE 2382447.4 1778985.1 19925870}

\KeywordTok{cor}\NormalTok{(sdcInitial}\OperatorTok{@}\NormalTok{manipNumVars[, numVars])}
\CommentTok{##               INC    INCRMT   INCWAGE}
\CommentTok{## INC     1.0000000 0.1546063 0.3715897}
\CommentTok{## INCRMT  0.1546063 1.0000000 0.1361665}
\CommentTok{## INCWAGE 0.3715897 0.1361665 1.0000000}
\end{Highlighting}
\end{Shaded}

\citep{domingo-ferrer2001} propone varias medidas para la diferencia entre las matrices de covarianza y las de correlaci√≥n. Estas medidas se basan en el error cuadr√°tico medio, el error absoluto medio o la variaci√≥n media de las celdas individuales. Nos referimos a \citep{domingo-ferrer2001} para obtener una descripci√≥n completa de estas medidas.

\hypertarget{medida-de-puxe9rdida-de-informaciuxf3n-il1s}{%
\subsubsection{Medida de p√©rdida de informaci√≥n IL1s}\label{medida-de-puxe9rdida-de-informaciuxf3n-il1s}}

Alternativamente, tambi√©n podemos comparar los datos reales y cuantificar la distancia entre el conjunto de datos original \(X\) y el conjunto de datos tratado \(Z\). Aqu√≠ \(X\) y \(Z\) contienen s√≥lo variables continuas. \citep{yancey2002} introduce la medida de distancia IL1s, que es la suma de las distancias absolutas entre las observaciones correspondientes en los conjuntos de datos sin procesar y an√≥nimos, que est√°n estandarizados por la desviaci√≥n est√°ndar de las variables en los datos originales. Para las variables continuas en el conjunto de datos,
la medida IL1s se define como:

\[IL1s=\frac{1}{pn}\sum_{j=1}^{p} \sum_{i=1}^{n} \frac{|xij‚àízij|} {\sqrt2S_1} \]

Donde \(p\) es el n√∫mero de variables continuas; \(n\) es el n√∫mero de registros en el conjunto de datos; \(xij\) y \(zij\), son los valores antes y despu√©s de la anonimizaci√≥n de la variable \(j\) e \(i\); Sj es la desviaci√≥n est√°ndar de la variable \(j\) en los datos originales \citep{yancey2002}.

Cuando se usa \texttt{sdcMicro}, la medida de utilidad de datos IL1s se pueden calcular para todos los cuasi-identificadores num√©ricos con la funci√≥n \texttt{dUtility()}, que se ilustra en el Bloque \ref{exm:bloque7lbn} a
continuaci√≥n. En caso de ser necesario, tambi√©n se puede calcular la medida en subconjuntos del conjunto completo de cuasi-identificadores num√©ricos. La funci√≥n se llama \texttt{dUtility()}, pero devuelve una medida de p√©rdida de informaci√≥n. El resultado se guarda en la ranura de utilidad del objeto \texttt{sdcMicro} . El Bloque \ref{exm:bloque7lbn} a continuaci√≥n ilustra c√≥mo llamar al resultado.

\begin{example}
\protect\hypertarget{exm:bloque7lbn}{}{\label{exm:bloque7lbn} }Uso de \texttt{dUtility()} para calcular la medida de utilidad de datos de IL1 en \texttt{sdcMicro}
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Evaluaci√≥n de la medida IL1s para las variables en sdcMicro object sdcInitial}
\NormalTok{sdcInitial <-}\StringTok{ }\KeywordTok{dUtility}\NormalTok{(sdcInitial)}

\CommentTok{# Mostrar los resultados de IL1s}
\NormalTok{sdcInitial}\OperatorTok{@}\NormalTok{utility}\OperatorTok{$}\NormalTok{il1}
\CommentTok{## [1] 0.2203791}

\CommentTok{# IL1s para un subconjunto num√©rico cuasi-identificadores}
\NormalTok{subset <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{'INCRMT'}\NormalTok{, }\StringTok{'INCWAGE'}\NormalTok{, }\StringTok{'INCFARMBSN'}\NormalTok{)}
\KeywordTok{dUtility}\NormalTok{(}\DataTypeTok{obj =}\NormalTok{ sdcInitial}\OperatorTok{@}\NormalTok{origData[,subset], }\DataTypeTok{xm =}\NormalTok{ sdcInitial}\OperatorTok{@}\NormalTok{manipNumVars[,subset],}
\DataTypeTok{method =} \StringTok{'IL1'}\NormalTok{)}
\CommentTok{## [1] 0.5641103}
\end{Highlighting}
\end{Shaded}

La medida es √∫til para comparar diferentes m√©todos. Cuanto menor sea el valor de la medida, m√°s cerca estar√°n los valores de los valores originales y mayor ser√° la utilidad.

\begin{quote}
\textbf{Nota}
Esta medida est√° relacionada con las medidas de riesgo basadas en distancia e intervalos (ver la secci√≥n \protect\hyperlink{medidas-de-riesgo-para-variables-continuas}{Medidas de riesgo para variables continuas})
Cuanto mayor sea la distancia entre los valores originales y anonimizados, menor ser√° la utilidad de los datos. Sin embargo, una mayor distancia tambi√©n reduce el riesgo de re-identificaci√≥n.
\end{quote}

\hypertarget{valores-propios}{%
\subsubsection{Valores propios}\label{valores-propios}}

Otra forma de evaluar la p√©rdida de informaci√≥n es comparar los valores propios robustos de los datos antes y despu√©s de la anonimizaci√≥n. El Bloque \ref{exm:bloque8lbn} ilustra c√≥mo usar este enfoque con \texttt{sdcMicro} . Aqu√≠ ``contVars'' es un vector con los nombres de las variables continuas que nos interesan. ``\texttt{obj}'' es el argumento que
especifica los datos no tratados y ``\texttt{xm}'' es el argumento que especifica los datos anonimizados. La salida de la funci√≥n es la diferencia en valores propios. Por lo tanto, el valor m√≠nimo es 0. Nuevamente, el uso principal es comparar diferentes m√©todos. Cuanto mayor sea el valor, mayores ser√°n los cambios en los datos y la p√©rdida de informaci√≥n.

\begin{example}
\protect\hypertarget{exm:bloque8lbn}{}{\label{exm:bloque8lbn} }Uso de \texttt{dUtility()} para calcular valores propios en \texttt{sdcMicro}
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Comparaci√≥n de valores para variables continuas}
\KeywordTok{dUtility}\NormalTok{(}\DataTypeTok{obj =}\NormalTok{ sdcInitial}\OperatorTok{@}\NormalTok{origData[,contVars],}
         \DataTypeTok{xm =}\NormalTok{ sdcInitial}\OperatorTok{@}\NormalTok{manipNumVars[,contVars], }\DataTypeTok{method =} \StringTok{'eigen'}\NormalTok{)}
\CommentTok{## [1] 2.482948}

\CommentTok{# Comparaci√≥n de valores propios robustos de variables continuas*}
\KeywordTok{dUtility}\NormalTok{(}\DataTypeTok{obj =}\NormalTok{ sdcInitial}\OperatorTok{@}\NormalTok{origData[,contVars],}
         \DataTypeTok{xm =}\NormalTok{ sdcInitial}\OperatorTok{@}\NormalTok{manipNumVars[,contVars], }\DataTypeTok{method =} \StringTok{'robeigen'}\NormalTok{)}
\CommentTok{## [1] -4.297621e+14}
\end{Highlighting}
\end{Shaded}

\hypertarget{medidas-de-utilidad-basadas-en-las-necesidades-del-usuario-final}{%
\subsection{Medidas de utilidad basadas en las necesidades del usuario final}\label{medidas-de-utilidad-basadas-en-las-necesidades-del-usuario-final}}

No se pueden catalogar todas las necesidades y usos de un determinado conjunto de datos. Sin embargo, algunos tipos de datos tienen usos similares o caracter√≠sticas importantes, que pueden evaluarse antes y despu√©s de la anonimizaci√≥n. Los ejemplos de ``indicadores de evaluaci√≥n comparativa'' \citep{templ2014} son diferentes para cada conjunto de datos. Los ejemplos incluyen medidas de pobreza para conjuntos de datos de ingresos y tasas de asistencia escolar. A menudo, las ideas para seleccionar dichos indicadores provienen de los informes que publican
los usuarios de datos basados en microdatos publicados anteriormente.

Como gu√≠a es necesario comparar los indicadores calculados sobre los datos no tratados y los datos despu√©s de la anonimizaci√≥n con diferentes m√©todos. Si las diferencias entre los indicadores no son demasiado grandes, el conjunto de datos anonimizados puede publicarse. Se debe tener en cuenta que los indicadores calculados sobre muestras son estimaciones con cierta varianza e intervalo de confianza. Por lo tanto, para datos de muestra, es informativo comparar la superposici√≥n de los intervalos de confianza y/o evaluar si la estimaci√≥n puntual calculada despu√©s de la anonimizaci√≥n est√° contenida dentro del intervalo de confianza de la estimaci√≥n original. Ejemplos de indicadores de referencia y sus intervalos de confianza y c√≥mo calcularlos en \texttt{R} se incluyen en los estudios de casos de estas directrices. Aqu√≠ damos el ejemplo del coeficiente GINI.

El coeficiente de GINI es una medida de dispersi√≥n estad√≠stica, que a menudo se utiliza para medir la desigualdad de ingresos. Una forma de medir la p√©rdida de informaci√≥n en los datos de ingresos es comparar la distribuci√≥n de ingresos, lo que se puede hacer f√°cilmente comparando los coeficientes de GINI. Varios paquetes de \texttt{R} tienen funciones para calcular el coeficiente GINI. Elegimos el paquete \texttt{laeken}, que calcula el coeficiente GINI como el √°rea entre la l√≠nea de 45 grados y la curva de Lorenz. Para usar la funci√≥n \texttt{gini()}, primero tenemos que instalar y cargar la paquete \texttt{laeken}. Para calcular el coeficiente de GINI para la variable, usamos los pesos de muestra en los datos. Esto se muestra en Bloque \ref{exm:bloque9lbn}. El coeficiente de GINI de los datos de la muestra es una variable aleatoria. Por lo tanto, es √∫til construir un intervalo de confianza alrededor del coeficiente para evaluar la importancia de cualquier cambio en el coeficiente despu√©s de la anonimizaci√≥n. La funci√≥n \texttt{gini()} calcula un intervalo de confianza de 1-alfa para el coeficiente de GINI mediante el uso de bootstrap.

\begin{example}
\protect\hypertarget{exm:bloque9lbn}{}{\label{exm:bloque9lbn} }C√°lculo del coeficiente de GINI a partir de la variable de ingresos para determinar la desigualdad de ingresos
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Coeficiente de Gini antes de la anonimizaci√≥n}
\KeywordTok{gini}\NormalTok{(}\DataTypeTok{inc =}\NormalTok{ sdcInitial}\OperatorTok{@}\NormalTok{origData[selInc,}\StringTok{'INC'}\NormalTok{],}
     \DataTypeTok{weights =}\NormalTok{  curW[selInc], }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{)}\OperatorTok{$}\NormalTok{value }\CommentTok{# antes}
\CommentTok{## [1] 34.05928}

\CommentTok{# Coeficiente de Gini despu√©s de la anonimizaci√≥n}
\KeywordTok{gini}\NormalTok{(}\DataTypeTok{inc =}\NormalTok{ sdcInitial}\OperatorTok{@}\NormalTok{manipNumVars[selInc,}\StringTok{'INC'}\NormalTok{],}
     \DataTypeTok{weights =}\NormalTok{ curW[selInc], }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{)}\OperatorTok{$}\NormalTok{value }\CommentTok{# despu√©s}
\CommentTok{## [1] 67.13218}
\end{Highlighting}
\end{Shaded}

\hypertarget{regresiuxf3n}{%
\subsection{Regresi√≥n}\label{regresiuxf3n}}

Adem√°s de comparar matrices de covarianza y correlaci√≥n, las regresiones son una herramienta √∫til para evaluar si la estructura de los datos se mantiene despu√©s de la anonimizaci√≥n. Al comparar los par√°metros de regresi√≥n, tambi√©n es posible comparar relaciones entre variables no continuas (por ejemplo, al introducir variables ficticias o regresi√≥n con variables ordinales). Si se sabe con qu√© prop√≥sito y en qu√© campo se usan los datos, se pueden usar regresiones para comparar el cambio en los coeficientes y los intervalos de confianza.

Un ejemplo de la regresi√≥n para evaluar la utilidad de los datos en los datos de ingresos es la ecuaci√≥n de Mincer. La ecuaci√≥n de Mincer explica los ingresos en funci√≥n de la educaci√≥n y la experiencia mientras controla otras variables. La ecuaci√≥n de Mincer se utiliza a menudo para evaluar la brecha salarial de g√©nero y la desigualdad salarial de g√©nero mediante la inclusi√≥n de una variable ficticia de g√©nero. Aqu√≠ mostramos c√≥mo evaluar el impacto de los m√©todos de anonimizaci√≥n en el coeficiente de g√©nero. Realizamos una regresi√≥n del
ingreso logar√≠tmico en una constante, una variable ficticia de g√©nero, a√±os de educaci√≥n, a√±os de experiencia, a√±os de experiencia al cuadrado y otros factores que influyen en el salario.

\[ln(wage)=Œ≤_0+Œ≤_1gender+Œ≤_2education+Œ≤_3experience+Œ≤_3experience^2+Œ≤X\]

El par√°metro de inter√©s aqu√≠ es \(Œ≤_1\), el efecto del g√©nero en el logaritmo del salario. \(X\) es una matriz con varios otros factores que influyen en el salario y \(Œ≤\) los coeficientes de estos factores. El Bloque \ref{exm:bloque10lbn} ilustra c√≥mo ejecutar una regresi√≥n de Mincer en \(R\) usando la funci√≥n \(ln()\) y la evaluaci√≥n de los coeficientes y los intervalos de confianza alrededor de los coeficientes. Realizamos la regresi√≥n como se especifica para los empleados asalariados con un salario positivo en los grupos de edad de
15 a 65 a√±os.

\begin{example}
\protect\hypertarget{exm:bloque10lbn}{}{\label{exm:bloque10lbn} }Estimaci√≥n de la ecuaci√≥n de Mincer (regresi√≥n) para evaluar la utilidad de los datos antes y despu√©s de la anonimizaci√≥n
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Variables de la ecuaci√≥n de Mincer antes de la anonimizaci√≥n}
\NormalTok{Mlwage    <-}\StringTok{ }\KeywordTok{log}\NormalTok{(sdcMincer}\OperatorTok{@}\NormalTok{origData}\OperatorTok{$}\NormalTok{wage) }\CommentTok{# salario de registro}
\CommentTok{# TRUE if 'paid employee', else FALSE or NA}
\NormalTok{Mempstat  <-}\StringTok{ }\NormalTok{sdcMincer}\OperatorTok{@}\NormalTok{origData}\OperatorTok{$}\NormalTok{empstat}\OperatorTok{==}\StringTok{'Paid employee'}
\NormalTok{Mage      <-}\StringTok{ }\NormalTok{sdcMincer}\OperatorTok{@}\NormalTok{origData}\OperatorTok{$}\NormalTok{age    }\CommentTok{# edad en a√±os}
\NormalTok{Meducy    <-}\StringTok{ }\NormalTok{sdcMincer}\OperatorTok{@}\NormalTok{origData}\OperatorTok{$}\NormalTok{educy  }\CommentTok{# educaci√≥n en a√±os}
\NormalTok{Mexp      <-}\StringTok{ }\NormalTok{sdcMincer}\OperatorTok{@}\NormalTok{origData}\OperatorTok{$}\NormalTok{exp    }\CommentTok{# experiencia en a√±os}
\NormalTok{Mexp2     <-}\StringTok{ }\NormalTok{Mexp}\OperatorTok{^}\DecValTok{2}                    \CommentTok{# experiencia al cuadrado}
\NormalTok{Mgender   <-}\StringTok{ }\NormalTok{sdcMincer}\OperatorTok{@}\NormalTok{origData}\OperatorTok{$}\NormalTok{gender }\CommentTok{# variable ficticia de g√©nero}
\NormalTok{Mwgt      <-}\StringTok{ }\NormalTok{sdcMincer}\OperatorTok{@}\NormalTok{origData}\OperatorTok{$}\NormalTok{wgt    }\CommentTok{# variable de g√©nero para la regresi√≥n}
\NormalTok{MfileB    <-}\StringTok{ }\KeywordTok{as.data.frame}\NormalTok{(}\KeywordTok{cbind}\NormalTok{(Mlwage, Mempstat, Mage, Meducy, Mexp, Mexp2,}
\NormalTok{                                 Mgender, Mwgt))}
\CommentTok{# Variables de la ecuaci√≥n de Mincer despu√©s de la anonimizaci√≥n}
\NormalTok{Mlwage    <-}\StringTok{ }\KeywordTok{log}\NormalTok{(sdcMincer}\OperatorTok{@}\NormalTok{manipNumVars}\OperatorTok{$}\NormalTok{wage) }\CommentTok{# salario de registro}
\NormalTok{Mempstat  <-}\StringTok{ }\NormalTok{sdcMincer}\OperatorTok{@}\NormalTok{manipKeyVars}\OperatorTok{$}\NormalTok{empstat}\OperatorTok{==}\StringTok{'Paid employee'}
\CommentTok{# TRUE if 'paid employee', else FALSE or NA}
\NormalTok{Mage      <-}\StringTok{ }\NormalTok{sdcMincer}\OperatorTok{@}\NormalTok{manipKeyVars}\OperatorTok{$}\NormalTok{age    }\CommentTok{# edad en a√±os}
\NormalTok{Meducy    <-}\StringTok{ }\NormalTok{sdcMincer}\OperatorTok{@}\NormalTok{manipKeyVars}\OperatorTok{$}\NormalTok{educy  }\CommentTok{# educaci√≥n en a√±os}
\NormalTok{Mexp      <-}\StringTok{ }\NormalTok{sdcMincer}\OperatorTok{@}\NormalTok{manipKeyVars}\OperatorTok{$}\NormalTok{exp    }\CommentTok{# experiencia en a√±os}
\NormalTok{Mexp2     <-}\StringTok{ }\NormalTok{Mexp}\OperatorTok{^}\DecValTok{2}                        \CommentTok{# experiencia al cuadrado}
\NormalTok{Mgender   <-}\StringTok{ }\NormalTok{sdcMincer}\OperatorTok{@}\NormalTok{manipKeyVars}\OperatorTok{$}\NormalTok{gender }\CommentTok{# variable ficticia de g√©nero}
\NormalTok{Mwgt      <-}\StringTok{ }\NormalTok{sdcMincer}\OperatorTok{@}\NormalTok{origData}\OperatorTok{$}\NormalTok{wgt        }\CommentTok{# variable de g√©nero para la regresi√≥n}
\NormalTok{MfileA    <-}\StringTok{ }\KeywordTok{as.data.frame}\NormalTok{(}\KeywordTok{cbind}\NormalTok{(Mlwage, Mempstat, Mage, Meducy, Mexp, Mexp2,}
\NormalTok{                                 Mgender, Mwgt))}

\CommentTok{# F√≥rmula de regresi√≥n}
\NormalTok{Mformula <-}\StringTok{ 'Mlwage ~ Meducy + Mexp + Mexp2 + Mgender'}

\CommentTok{# Regresi√≥n con la ecuaci√≥n de Mincer}
\NormalTok{mincer1565B <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(Mformula, }\DataTypeTok{data =} \KeywordTok{subset}\NormalTok{(MfileB,}
\NormalTok{MfileB}\OperatorTok{$}\NormalTok{Mage }\OperatorTok{>=}\StringTok{ }\DecValTok{15} \OperatorTok{&}\StringTok{ }\NormalTok{MfileB}\OperatorTok{$}\NormalTok{Mage }\OperatorTok{<=}\StringTok{ }\DecValTok{65} \OperatorTok{&}\StringTok{ }\NormalTok{MfileB}\OperatorTok{$}\NormalTok{Mempstat}\OperatorTok{==}\OtherTok{TRUE} \OperatorTok{&}
\NormalTok{MfileB}\OperatorTok{$}\NormalTok{Mlwage }\OperatorTok{!=}\StringTok{ }\OperatorTok{-}\OtherTok{Inf}\NormalTok{), }\DataTypeTok{na.action =}\NormalTok{ na.exclude, }\DataTypeTok{weights =}\NormalTok{ Mwgt) }\CommentTok{# antes}
\NormalTok{mincer1565A <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(Mformula,}
                  \DataTypeTok{data =} \KeywordTok{subset}\NormalTok{(MfileA,}
\NormalTok{                                                MfileA}\OperatorTok{$}\NormalTok{Mage }\OperatorTok{>=}\StringTok{ }\DecValTok{15} \OperatorTok{&}\StringTok{ }\NormalTok{MfileA}\OperatorTok{$}\NormalTok{Mage }\OperatorTok{<=}\StringTok{ }\DecValTok{65} \OperatorTok{&}
\StringTok{                                                }\NormalTok{MfileA}\OperatorTok{$}\NormalTok{Mempstat}\OperatorTok{==}\OtherTok{TRUE} \OperatorTok{&}
\StringTok{                                }\NormalTok{MfileA}\OperatorTok{$}\NormalTok{Mlwage }\OperatorTok{!=}\StringTok{ }\OperatorTok{-}\OtherTok{Inf}\NormalTok{),}
                  \DataTypeTok{na.action =}\NormalTok{ na.exclude, }\DataTypeTok{weights =}\NormalTok{ Mwgt) }\CommentTok{# despu√©s}

\CommentTok{# los objetos mincer1565B y mincer1565A con los resultados}
\CommentTok{# regresi√≥n antes y despu√©s de la anonimizaci√≥n}
\NormalTok{mincer1565B}\OperatorTok{$}\NormalTok{coefficients }\CommentTok{# antes}
\CommentTok{##   (Intercept)        Meducy          Mexp         Mexp2       Mgender}
\CommentTok{##  3.9532064886  0.0212367075  0.0255962570 -0.0005682651 -0.4931289413}

\NormalTok{mincer1565A}\OperatorTok{$}\NormalTok{coefficients }\CommentTok{# despu√©s}
\CommentTok{##   (Intercept)        Meducy          Mexp         Mexp2       Mgender}
\CommentTok{##  4.0526250282  0.0141090329  0.0326711056 -0.0007605492 -0.5393641862}

\CommentTok{# Intervalos de confianza al 95%}
\KeywordTok{confint}\NormalTok{(}\DataTypeTok{obj =}\NormalTok{ mincer1565B, }\DataTypeTok{level =} \FloatTok{0.95}\NormalTok{) }\CommentTok{# antes}
\CommentTok{##                    2.5 %        97.5 %}
\CommentTok{## (Intercept)  3.435759991  4.4706529860}
\CommentTok{## Meducy      -0.018860497  0.0613339120}
\CommentTok{## Mexp         0.004602597  0.0465899167}
\CommentTok{## Mexp2       -0.000971303 -0.0001652273}
\CommentTok{## Mgender     -0.658085143 -0.3281727396}

\KeywordTok{confint}\NormalTok{(}\DataTypeTok{obj =}\NormalTok{ mincer1565A, }\DataTypeTok{level =} \FloatTok{0.95}\NormalTok{) }\CommentTok{# despu√©s}
\CommentTok{##                   2.5 %        97.5 %}
\CommentTok{## (Intercept)  3.46800378  4.6372462758}
\CommentTok{## Meducy      -0.03305743  0.0612754964}
\CommentTok{## Mexp         0.01024867  0.0550935366}
\CommentTok{## Mexp2       -0.00119162 -0.0003294784}
\CommentTok{## Mgender     -0.71564602 -0.3630823543}
\end{Highlighting}
\end{Shaded}

Si las nuevas estimaciones caen dentro del intervalo de confianza original y los intervalos de confianza nuevos y originales se superponen en gran medida, los datos pueden considerarse v√°lidos para este tipo de regresi√≥n despu√©s de la anonimizaci√≥n. La Figura @ref(fig:fig2\_\_sec05) muestra las estimaciones puntuales y los intervalos de confianza para el coeficiente de g√©nero en este intercambio para un conjunto de datos de ingresos de muestra y varios m√©todos y par√°metros de SDC. El punto rojo y la barra de confianza (en la parte superior) corresponden a las estimaciones de los datos no tratados, mientras que las otras barras de confianza corresponden a los m√©todos SDC con diferentes par√°metros. La anonimizaci√≥n reduce el n√∫mero de re-identificaciones esperadas en los datos (eje izquierdo) y las estimaciones puntuales y los intervalos de confianza var√≠an mucho para los diferentes m√©todos SDC. Elegir√≠amos un m√©todo que reduzca el n√∫mero esperado de identificaciones, sin cambiar el coeficiente de g√©nero y con una gran superposici√≥n del intervalo de confianza con el intervalo de confianza estimado a partir de los datos originales.

\textbackslash{}begin\{figure\}

\{\centering \includegraphics[width=0.9\linewidth]{Imagenes/fig2}

\}

\caption{Efecto de la anonimizaci√≥n en las estimaciones puntuales e intervalo de confianza del coeficiente de g√©nero en la ecuaci√≥n de Mincer.}

(\#fig:fig2\_sec05)
\textbackslash{}end\{figure\}

\textbf{Fuente:} Imagen extra√≠da de \citep{benschop2021}, p√°g.90.

\hypertarget{evaluaciuxf3n-de-la-utilidad-de-los-datos-con-la-ayuda-de-visualizaciones-de-datos-en-r}{%
\section{\texorpdfstring{Evaluaci√≥n de la utilidad de los datos con la ayuda de visualizaciones de datos (en \texttt{R})}{Evaluaci√≥n de la utilidad de los datos con la ayuda de visualizaciones de datos (en R)}}\label{evaluaciuxf3n-de-la-utilidad-de-los-datos-con-la-ayuda-de-visualizaciones-de-datos-en-r}}

El uso de gr√°ficos y otras t√©cnicas de visualizaci√≥n, act√∫an como una buena forma de evaluar cu√°nto han cambiado los datos despu√©s de la anonimizaci√≥n ayudando a seleccionar las t√©cnicas de anonimizaci√≥n adecuadas para los datos. Las visualizaciones pueden ser una herramienta √∫til para evaluar el impacto en la utilidad de los datos de los m√©todos de anonimizaci√≥n ya que facilitan la elecci√≥n entre los m√©todos de anonimizaci√≥n. El lenguaje de programaci√≥n \texttt{R} proporciona varias funciones y paquetes que pueden ayudar a visualizar los resultados de la
anonimizaci√≥n. Esta secci√≥n enumera algunas de estas funciones y paquetes y proporciona ejemplos de c√≥digo para ilustrar c√≥mo implementarlos. Se mostrar√°n las siguientes formas:

\begin{itemize}
\tightlist
\item
  histogramas y gr√°ficos de densidad
\item
  diagrama de caja
\item
  gr√°fico en mosaico
\end{itemize}

Para hacer visualizaciones apropiadas, necesitamos usar los datos sin procesar y los datos anonimizados. Cuando se utiliza un objeto \texttt{sdcMicro} para el proceso de anonimizaci√≥n, los datos sin procesar se almacenan en la ranura ``origData'' del objeto y las variables anonimizadas est√°n en las ranuras ``manipKeyVars'', ``manipPramVars'', ``manipNumVars'' y ``manipStrataVar''. Consulte la secci√≥n \protect\hyperlink{objetos-de-la-clase-sdcmicroobj}{Objetos de la clase \texttt{sdcMicroObj}} para obtener m√°s informaci√≥n sobre los objetos \texttt{sdcMicro} , los \emph{slots} y c√≥mo acceder a ellos.

\hypertarget{histogramas-y-gruxe1ficos-de-densidad}{%
\subsubsection{Histogramas y gr√°ficos de densidad}\label{histogramas-y-gruxe1ficos-de-densidad}}

Son √∫tiles para realizar comparaciones r√°pidas de la distribuci√≥n de variables antes y despu√©s de la anonimizaci√≥n. La ventaja de los histogramas es que los resultados son exactos. Sin embargo, la
visualizaci√≥n depende de los anchos de las barras y el inicio de la primera barra. Los histogramas se pueden utilizar para variables continuas y semicontinuas. Los gr√°ficos de densidad muestran la densidad del kernel de los datos; por lo tanto, la gr√°fica depende del kernel que se elija y si los datos se ajustan bien al kernel. Sin embargo, los gr√°ficos de densidad son una buena herramienta para ilustrar el cambio de valores y rangos de valores de variables continuas.

Los histogramas se pueden trazar con la funci√≥n \texttt{hist()} y las densidades del kernel con las funciones \texttt{plot()} y \texttt{density()} en \texttt{R} . El Bloque \ref{exm:bloque11lbn} muestra ejemplos de c√≥mo utilizar estas funciones para ilustrar los cambios en la variable ``INC'', una variable de ingresos. La funci√≥n \texttt{hist()} necesita como argumento los puntos de ruptura del histograma. Los resultados se muestran en la Figura @ref(fig:fig3\_sec05) y la Figura @ref(fig:fig4\_sec05). Los histogramas y los gr√°ficos de densidad dan una indicaci√≥n clara de c√≥mo han cambiado los valores: la variabilidad de los datos ha aumentado y la forma de la distribuci√≥n ha cambiado.

\begin{example}
\protect\hypertarget{exm:bloque11lbn}{}{\label{exm:bloque11lbn} }Trazado de histogramas y densidades kernel
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Histograma}
\CommentTok{# gr√°fico de histograma antes de la anonimizaci√≥n}
\KeywordTok{hist}\NormalTok{(sdcInitial}\OperatorTok{@}\NormalTok{origData}\OperatorTok{$}\NormalTok{INC, }\DataTypeTok{breaks =}\NormalTok{ (}\DecValTok{0}\OperatorTok{:}\DecValTok{180}\NormalTok{)}\OperatorTok{*}\FloatTok{1e2}\NormalTok{,}
     \DataTypeTok{main =}  \StringTok{"Histogram income - original data"}\NormalTok{)}

\CommentTok{# gr√°fico de histograma despu√©s de la anonimizaci√≥n (adici√≥n de ruido)}
\KeywordTok{hist}\NormalTok{(sdcInitial}\OperatorTok{@}\NormalTok{manipNumVars}\OperatorTok{$}\NormalTok{INC, }\DataTypeTok{breaks =}\NormalTok{ (}\OperatorTok{-}\DecValTok{20}\OperatorTok{:}\DecValTok{190}\NormalTok{)}\OperatorTok{*}\FloatTok{1e2}\NormalTok{,}
     \DataTypeTok{main =} \StringTok{"Histogram income - anonymized data"}\NormalTok{)}

\CommentTok{# gr√°fico de densidades}
\CommentTok{# trazo de la curva de densidad original}
\KeywordTok{plot}\NormalTok{(}\KeywordTok{density}\NormalTok{(sdcInitial}\OperatorTok{@}\NormalTok{origData}\OperatorTok{$}\NormalTok{INC), }\DataTypeTok{xlim =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{8000}\NormalTok{), }\DataTypeTok{ylim =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{0.006}\NormalTok{),}
     \DataTypeTok{main =} \StringTok{"Density income"}\NormalTok{, }\DataTypeTok{xlab =} \StringTok{"income"}\NormalTok{)}
\KeywordTok{par}\NormalTok{ (}\DataTypeTok{new =} \OtherTok{TRUE}\NormalTok{)}

\CommentTok{# trazo de la curva de densidad despu√©s de la anonimizaci√≥n (adici√≥n de ruido)}
\KeywordTok{plot}\NormalTok{(}\KeywordTok{density}\NormalTok{(sdcInitial}\OperatorTok{@}\NormalTok{manipNumVars}\OperatorTok{$}\NormalTok{INC), }\DataTypeTok{xlim =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{8000}\NormalTok{), }\DataTypeTok{ylim =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{0.006}\NormalTok{),}
     \DataTypeTok{main =} \StringTok{"Density income"}\NormalTok{, }\DataTypeTok{xlab =} \StringTok{"income"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\textbackslash{}begin\{figure\}

\{\centering \includegraphics[width=0.9\linewidth]{Imagenes/fig3}

\}

\caption{Histogramas de ingresos antes y despu√©s de la anonimizaci√≥n.}

(\#fig:fig3\_sec05)
\textbackslash{}end\{figure\}

\textbf{Fuente:} Imagen extra√≠da de \citep{benschop2021}, p√°g.88.

\textbackslash{}begin\{figure\}

\{\centering \includegraphics[width=0.9\linewidth]{Imagenes/fig4}

\}

\caption{Gr√°ficas de densidad de ingresos antes y despu√©s de la anonimizaci√≥n.}

(\#fig:fig4\_sec05)
\textbackslash{}end\{figure\}

\textbf{Fuente:} Imagen extra√≠da de \citep{benschop2021}, p√°g.89.

\hypertarget{diagramas-de-caja}{%
\subsubsection{Diagramas de caja}\label{diagramas-de-caja}}

Los diagramas de caja brindan una descripci√≥n general r√°pida de los cambios en la dispersi√≥n y los valores at√≠picos de las variables continuas antes y despu√©s de la anonimizaci√≥n. El Bloque \ref{exm:bloque12lbn} a continuaci√≥n muestra c√≥mo generar diagramas de caja en \texttt{R} con la funci√≥n \texttt{boxplot()}. resultado de la figura
@ref(fig:fig5\_sec05) muestra un ejemplo de una variable de gasto despu√©s de agregar ruido. El diagrama de caja muestra claramente que la variabilidad en la variable gasto aument√≥ como resultado de los m√©todos de anonimizaci√≥n aplicados.

\begin{example}
\protect\hypertarget{exm:bloque12lbn}{}{\label{exm:bloque12lbn} }Creaci√≥n de diagramas de caja para variables continuas
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{boxplot}\NormalTok{(sdcObj}\OperatorTok{@}\NormalTok{origData}\OperatorTok{$}\NormalTok{TOTFOOD, sdcObj}\OperatorTok{@}\NormalTok{manipNumVars}\OperatorTok{$}\NormalTok{TOTFOOD,}
        \DataTypeTok{xaxt =} \StringTok{'n'}\NormalTok{, }\DataTypeTok{ylab =} \StringTok{"Expenditure"}\NormalTok{)}
\KeywordTok{axis}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DataTypeTok{at =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{labels =} \KeywordTok{c}\NormalTok{(}\StringTok{'before'}\NormalTok{, }\StringTok{'after'}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\textbackslash{}begin\{figure\}

\{\centering \includegraphics[width=0.9\linewidth]{Imagenes/fig5}

\}

\caption{Ejemplo de diagramas de caja de una variable de gasto antes y despu√©s de la anonimizaci√≥n.}

(\#fig:fig5\_sec05)
\textbackslash{}end\{figure\}

\textbf{Fuente:} Imagen extra√≠da de \citep{benschop2021}, p√°g.89.

\hypertarget{gruxe1ficos-de-mosaico}{%
\subsubsection{Gr√°ficos de mosaico}\label{gruxe1ficos-de-mosaico}}

Los gr√°ficos de mosaico univariados y multivariados son √∫tiles para mostrar cambios en las tabulaciones de variables categ√≥ricas, especialmente cuando se comparan varios ``escenarios'' uno al lado del otro. Un escenario aqu√≠ se refiere a la elecci√≥n de m√©todos de anonimizaci√≥n y sus par√°metros. Con gr√°ficos de mosaico podemos, por
ejemplo, ver r√°pidamente el efecto de diferentes niveles de k-anonimato o diferencias en los vectores de importancia en el algoritmo de supresi√≥n local (ver la Secci√≥n \protect\hyperlink{sup-loc}{Supresi√≥n local}.

Ilustramos los cambios en las tabulaciones con un ejemplo de la variable ``WATER'' antes y despu√©s de aplicar PRAM. Podemos usar gr√°ficos de mosaico para ver r√°pidamente los cambios de cada categor√≠a. El Bloque \ref{exm:bloque13lbn} muestra el c√≥digo en \texttt{R} . La funci√≥n \texttt{mosaicplot()} est√° disponible en el paquete base de \texttt{R}. Para graficar una tabulaci√≥n, primero se debe hacer la tabulaci√≥n con la funci√≥n \texttt{table()}. Para mostrar las etiquetas en \texttt{mosaicplot()}, cambiamos la clase de las variables a `factor'. Al observar el gr√°fico de mosaico en la Figura @ref(fig:fig6\_sec05), vemos que la PRAM invariante pr√°cticamente no tiene influencia en la distribuci√≥n univariante.

\begin{example}
\protect\hypertarget{exm:bloque13lbn}{}{\label{exm:bloque13lbn} }Creando mosaicos univariados
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Recopilaci√≥n de datos de la variable WATER antes y despu√©s de la anonimizaci√≥n}
\CommentTok{# asignaci√≥n de etiquetas al gr√°fico}
\NormalTok{dataWater <-}\StringTok{ }\KeywordTok{t}\NormalTok{(}\KeywordTok{cbind}\NormalTok{(}\KeywordTok{table}\NormalTok{(}\KeywordTok{factor}\NormalTok{(sdcHH}\OperatorTok{@}\NormalTok{origData}\OperatorTok{$}\NormalTok{WATER,}
                                  \DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{9}\NormalTok{),}
                                  \DataTypeTok{labels =} \KeywordTok{c}\NormalTok{(}\StringTok{"Pipe (own tap)"}\NormalTok{, }\StringTok{"Public standpipe"}\NormalTok{,}
                                             \StringTok{"Borehole"}\NormalTok{, }\StringTok{"Wells (protected)"}\NormalTok{,}
                                             \StringTok{"Wells (unprotected)"}\NormalTok{, }\StringTok{"Surface water"}\NormalTok{,}
                                             \StringTok{"Rain water"}\NormalTok{, }\StringTok{"Vendor/truck"}\NormalTok{, }\StringTok{"Other"}\NormalTok{))),}
                     \KeywordTok{table}\NormalTok{(}\KeywordTok{factor}\NormalTok{(sdcHH}\OperatorTok{@}\NormalTok{manipPramVars}\OperatorTok{$}\NormalTok{WATER,}
                                  \DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{9}\NormalTok{),}
                                  \DataTypeTok{labels =} \KeywordTok{c}\NormalTok{(}\StringTok{"Pipe (own tap)"}\NormalTok{, }\StringTok{"Public standpipe"}\NormalTok{,}
                                             \StringTok{"Borehole"}\NormalTok{, }\StringTok{"Wells (protected)"}\NormalTok{,}
                                             \StringTok{"Wells (unprotected)"}\NormalTok{, }\StringTok{"Surface water"}\NormalTok{,}
                                             \StringTok{"Rain water"}\NormalTok{, }\StringTok{"Vendor/truck"}\NormalTok{,}\StringTok{"Other"}\NormalTok{)))))}
\KeywordTok{rownames}\NormalTok{(dataWater) <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"before"}\NormalTok{, }\StringTok{"after"}\NormalTok{)}

\CommentTok{# gr√°fico de mosaico}
\KeywordTok{mosaicplot}\NormalTok{(dataWater, }\DataTypeTok{main =} \StringTok{""}\NormalTok{, }\DataTypeTok{color =} \DecValTok{2}\OperatorTok{:}\DecValTok{10}\NormalTok{, }\DataTypeTok{las =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\textbackslash{}begin\{figure\}

\{\centering \includegraphics[width=0.9\linewidth]{Imagenes/fig6}

\}

\caption{Gr√°fico de mosaico para ilustrar los cambios en la variable WATER.}

(\#fig:fig6\_sec05)
\textbackslash{}end\{figure\}

\textbf{Fuente:} Imagen extra√≠da de \citep{benschop2021}, p√°g.90.

Usamos las variables ``\emph{gender}'' y ``\emph{relationship status}'' para ilustrar el uso de gr√°ficos de mosaico para la ilustraci√≥n de cambios en las tabulaciones univariadas introducidas por varios conjuntos de m√©todos de anonimizaci√≥n. La Tabla \ref{tab:tbl3lbn} proporciona los m√©todos aplicados en cada escenario. El escenario 0, el escenario base, muestra las categor√≠as originales de las variables de g√©nero y estado civil, mientras que los escenarios 1 a 6 muestran cambios en las categor√≠as despu√©s de aplicar diferentes t√©cnicas de anonimizaci√≥n. La tabla muestra una descripci√≥n de los m√©todos de anonimizaci√≥n utilizados en cada escenario. En total, visualizamos el impacto de seis conjuntos diferentes de m√©todos de anonimizaci√≥n. Podemos usar gr√°ficos de mosaico para ver r√°pidamente qu√© conjunto de m√©todos tiene qu√© impacto en las variables de \emph{gender} y \emph{relationship status}, que se pueden usar para seleccionar el mejor escenario. Mirando los gr√°ficos de mosaico en la Figura @ref(fig:fig7\_sec05), vemos que los escenarios 2, 5 y 6 dan los cambios m√°s peque√±os para la variable de \emph{gender} y los escenarios 3 y 4 para la variable de \emph{relationship status}.

\begin{table}

\caption{\label{tab:tbl3lbn}Descripci√≥n de m√©todos de anonimizaci√≥n por escenario}
\begin{tabu} to \linewidth {>{\raggedright}X>{\raggedright}X}
\hline
Escenario & Descripci√≥n de los m√©todos de anonimizaci√≥n aplicados\\
\hline
\textbf{0 (base)} & Datos originales sin tratamiento\\
\hline
\textbf{1} & Recodificar¬†age¬†(intervalos de cinco a√±os), m√°s la supresi√≥n local (requerido k = 3, alta importancia en las variables de¬†water,¬†toilet¬†y¬†literacy)\\
\hline
\textbf{2} & Recodificar¬†age¬†(intervalos de cinco a√±os), m√°s supresi√≥n local (requerido k = 5, sin vector de importancia)\\
\hline
\textbf{3} & Recodificar la¬†age¬†(intervalos de cinco a√±os), m√°s la supresi√≥n local (requerido k = 3, alta importancia en¬†toilet), al mismo tiempo que se recodifican las variables¬†region,¬†urban,¬†education level¬†y¬†ocupation\\
\hline
\textbf{4} & Recodificar¬†age¬†(pasos de cinco a√±os), m√°s supresi√≥n local (requerido k = 5, alta importancia en¬†water,¬†toilet, y¬†education¬†level), al mismo tiempo que se recodifican variables de¬†region,¬†urban,¬†education¬†level¬†y¬†ocupation\\
\hline
\textbf{5} & Recodificar¬†age¬†(intervalos de cinco a√±os), m√°s supresi√≥n local (requerido k = 3, sin vector de importancia), microagregaci√≥n (wealth¬†index), al mismo tiempo que se recodifican variables de¬†region,¬†urban,¬†education¬†level¬†y¬†ocupation\\
\hline
\textbf{6} & Recodificar¬†age¬†(intervalos de cinco a√±os) m√°s supresi√≥n local (requerido k=3, sin vector de importancia),¬†literacy¬†PRAM, al mismo tiempo que se recodifican variables de¬†region,¬†urban,¬†education¬†level¬†y¬†ocupation\\
\hline
\end{tabu}
\end{table}

\textbackslash{}begin\{figure\}

\{\centering \includegraphics[width=0.9\linewidth]{Imagenes/fig7}

\}

\caption{Comparaci√≥n de variables de gender y relationship status tratadas versus no tratadas con gr√°ficos de mosaico.}

(\#fig:fig7\_sec05)
\textbackslash{}end\{figure\}

\textbf{Fuente:} Imagen extra√≠da de \citep{benschop2021}, p√°g.91

PRAM preserva las distribuciones univariadas. Por lo tanto, en este caso es m√°s interesante observar los gr√°ficos de mosaico multivariado. Los diagramas de mosaico tambi√©n son una herramienta poderosa para mostrar cambios en
tabulaciones cruzadas/tablas de contingencia. El Bloque \ref{exm:bloque14lbn} a continuaci√≥n muestra c√≥mo generar gr√°ficos de mosaico para dos variables. Para comparar los cambios, necesitamos comparar dos gr√°ficos diferentes. La Figura @ref(fig:fig8\_sec05) y la Figura @ref(fig:fig9\_sec05) ilustran que la PRAM no conserva las tablas
de doble entrada en este caso.

\begin{example}
\protect\hypertarget{exm:bloque14lbn}{}{\label{exm:bloque14lbn} }Creando mosaicos multivariados
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Antes de la anonimizaci√≥n: tabla de contingencia y gr√°fico de mosaico}
\NormalTok{ROOFTOILETbefore <-}\StringTok{ }\KeywordTok{t}\NormalTok{(}\KeywordTok{table}\NormalTok{(}\KeywordTok{factor}\NormalTok{(sdcHH}\OperatorTok{@}\NormalTok{origData}\OperatorTok{$}\NormalTok{ROOF, }\DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{9}\NormalTok{),}
                                   \DataTypeTok{labels =} \KeywordTok{c}\NormalTok{(}\StringTok{"Concrete/cement/ }\CharTok{\textbackslash{}n}\StringTok{ brick/stone"}\NormalTok{, }\StringTok{"Wood"}\NormalTok{,}
                                              \StringTok{"Bamboo/thatch"}\NormalTok{, }\StringTok{"Tiles/shingles"}\NormalTok{,}
                                              \StringTok{"Tin/metal sheets"}\NormalTok{, }\StringTok{"Other"}\NormalTok{)),}
                            \KeywordTok{factor}\NormalTok{(sdcHH}\OperatorTok{@}\NormalTok{origData}\OperatorTok{$}\NormalTok{TOILET, }\DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{9}\NormalTok{),}
                                   \DataTypeTok{labels =} \KeywordTok{c}\NormalTok{(}\StringTok{"Flush }\CharTok{\textbackslash{}n}\StringTok{ toilet"}\NormalTok{,}
                                              \StringTok{"Improved }\CharTok{\textbackslash{}n}\StringTok{ pit }\CharTok{\textbackslash{}n}\StringTok{ latrine"}\NormalTok{,}
                                              \StringTok{"Pit }\CharTok{\textbackslash{}n}\StringTok{ latrine"}\NormalTok{, }\StringTok{"No }\CharTok{\textbackslash{}n}\StringTok{ facility"}\NormalTok{,}
                                              \StringTok{"Other"}\NormalTok{))))}
\KeywordTok{mosaicplot}\NormalTok{(ROOFTOILETbefore, }\DataTypeTok{main =} \StringTok{""}\NormalTok{, }\DataTypeTok{las =} \DecValTok{2}\NormalTok{, }\DataTypeTok{color =} \DecValTok{2}\OperatorTok{:}\DecValTok{6}\NormalTok{)}

\CommentTok{# Despu√©s de la anonimizaci√≥n: tabla de contingencia y gr√°fico de mosaico}
\NormalTok{ROOFTOILETafter <-}\StringTok{ }\KeywordTok{t}\NormalTok{(}\KeywordTok{table}\NormalTok{(}\KeywordTok{factor}\NormalTok{(sdcHH}\OperatorTok{@}\NormalTok{manipPramVars}\OperatorTok{$}\NormalTok{ROOF, }\DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{9}\NormalTok{),}
                                  \DataTypeTok{labels =} \KeywordTok{c}\NormalTok{(}\StringTok{"Concrete/cement/ }\CharTok{\textbackslash{}n}\StringTok{ brick/stone"}\NormalTok{, }\StringTok{"Wood"}\NormalTok{,}
                                             \StringTok{"Bamboo/thatch"}\NormalTok{, }\StringTok{"Tiles/shingles"}\NormalTok{,}
                                             \StringTok{"Tin/metal sheets"}\NormalTok{, }\StringTok{"Other"}\NormalTok{)),}
                           \KeywordTok{factor}\NormalTok{(sdcHH}\OperatorTok{@}\NormalTok{manipPramVars}\OperatorTok{$}\NormalTok{TOILET, }\DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{9}\NormalTok{),}
                                  \DataTypeTok{labels =} \KeywordTok{c}\NormalTok{(}\StringTok{"Flush }\CharTok{\textbackslash{}n}\StringTok{ toilet"}\NormalTok{,}
                                             \StringTok{"Improved }\CharTok{\textbackslash{}\textbackslash{}}\StringTok{n pit }\CharTok{\textbackslash{}n}\StringTok{ latrine"}\NormalTok{,}
                                             \StringTok{"Pit }\CharTok{\textbackslash{}n}\StringTok{ latrine"}\NormalTok{, }\StringTok{"No }\CharTok{\textbackslash{}n}\StringTok{ facility"}\NormalTok{,}
                                             \StringTok{"Other"}\NormalTok{))))}
\KeywordTok{mosaicplot}\NormalTok{(ROOFTOILETafter, }\DataTypeTok{main =} \StringTok{""}\NormalTok{, }\DataTypeTok{las =} \DecValTok{2}\NormalTok{, }\DataTypeTok{color =} \DecValTok{2}\OperatorTok{:}\DecValTok{6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\textbackslash{}begin\{figure\}

\{\centering \includegraphics[width=0.9\linewidth]{Imagenes/fig8}

\}

\caption{Gr√°fico de mosaico de las variables ROOF e TOILET antes de la anonimizaci√≥n.}

(\#fig:fig8\_sec05)
\textbackslash{}end\{figure\}

\textbf{Fuente:} Imagen extra√≠da de \citep{benschop2021},p√°g. 92.

\textbackslash{}begin\{figure\}

\{\centering \includegraphics[width=0.9\linewidth]{Imagenes/fig9}

\}

\caption{Gr√°fico de mosaico de las variables ROOF e TOILET despu√©s de la anonimizaci√≥n.}

(\#fig:fig9\_sec05)
\textbackslash{}end\{figure\}

\textbf{Fuente:} Imagen extra√≠da de \citep{benschop2021}, p√°g.93.

\hypertarget{elecciuxf3n-de-la-medida-de-utilidad}{%
\subsection{Elecci√≥n de la medida de utilidad}\label{elecciuxf3n-de-la-medida-de-utilidad}}

Adem√°s de los requisitos de los usuarios sobre los datos, las medidas de utilidad deben elegirse de acuerdo con los tipos de variables y los m√©todos de anonimizaci√≥n empleados. Las medidas de utilidad empleadas pueden ser una combinaci√≥n de medidas generales y espec√≠ficas del usuario. Como se discuti√≥ anteriormente, se deben usar diferentes medidas de utilidad para datos continuos y categ√≥ricos. Adem√°s, algunas medidas de utilidad no son informativas despu√©s de que se hayan aplicado ciertos m√©todos de anonimizaci√≥n. Por ejemplo, despu√©s de aplicar
m√©todos perturbativos que intercambian valores de datos, la comparaci√≥n directa de valores no es √∫til porque dar√° la impresi√≥n de altos niveles de p√©rdida de informaci√≥n. En tales casos, es m√°s informativo observar
las medias, las covarianzas y los indicadores de evaluaci√≥n comparativa que se pueden calcular a partir de los datos. Es m√°s, es importante no solo centrarse en las caracter√≠sticas de las variables una por una, sino
tambi√©n en las interacciones entre las variables. Esto se puede hacer mediante tabulaciones cruzadas y regresiones. En general, al anonimizar datos muestreados, es recomendable calcular intervalos de confianza
alrededor de las estimaciones para interpretar la magnitud de los cambios.

\begin{quote}
\textbf{Nota:} Para material de lectura recomendado sobre la medici√≥n de la
utilidad y la p√©rdida de informaci√≥n ver \citep{dewaal1999}, \citep{domingo-ferrer2001} y \citep{domingo-ferrer2001}.
\end{quote}

\hypertarget{proceso-control-a-la-divulgaciuxf3n-estaduxedstica-sdc-ine-2021}{%
\chapter{Proceso Control a la Divulgaci√≥n Estad√≠stica (SDC) INE 2021}\label{proceso-control-a-la-divulgaciuxf3n-estaduxedstica-sdc-ine-2021}}

\hypertarget{introducciuxf3n-2}{%
\section{Introducci√≥n}\label{introducciuxf3n-2}}

Esta secci√≥n presenta el proceso SDC en una representaci√≥n paso a paso y se puede utilizar como gu√≠a para el proceso SDC real, de acuerdo con los lineamientos INE 2021 (ver \citep{ine2021}). Sin embargo, debe tenerse en cuenta que, a menudo, es necesario saltar de un paso a otro y volver a los pasos anteriores durante el proceso SDC real, ya que no es necesariamente un proceso lineal paso a paso. Esta gu√≠a re√∫ne las diferentes partes del proceso SDC como se discuti√≥ en las secciones anteriores y los enlaces a estas secciones. El estudio de caso en la siguiente secci√≥n sigue estos pasos. La Figura \ref{fig:esquemaSDC} al final de esta secci√≥n presenta todo el proceso de forma esquem√°tica.

\hypertarget{etapa-6.4.1-definiciones-previas-al-proceso-de-anonimizaciuxf3n}{%
\section{Etapa 6.4.1: Definiciones previas al proceso de anonimizaci√≥n}\label{etapa-6.4.1-definiciones-previas-al-proceso-de-anonimizaciuxf3n}}

El prop√≥sito de esta etapa es establecer los requerimientos necesarios para iniciar el subproceso de control a la divulgaci√≥n, que incluye la revisi√≥n de insumos, revisi√≥n de las necesidades de los usuarios y caracter√≠sticas estad√≠sticas prioritarias, y la determinaci√≥n de la necesidad de protecci√≥n de confidencialidad. Esto √∫ltimo, est√° estrechamente relacionado con la interpretaci√≥n de las leyes y normas sobre este tema en Chile.

Los procedimientos descritos para esta etapa aplican para todas las operaciones estad√≠sticas y productos relacionados cuyo levantamiento de informaci√≥n y/o publicaci√≥n sea realizado por el INE (muestras, censos, procesos de m√∫ltiples fuentes y registros estad√≠sticos) que dar√°n a conocer informaci√≥n al p√∫blico general u otros usuarios.
En esta etapa se debe revisar que no existan restricciones legales que impidan la publicaci√≥n de los microdatos.
Por otra parte, si el conjunto de datos no posee variables sensibles o variables de identificaci√≥n (directa o indirecta), se pasa a la \protect\hyperlink{etapa-6.4.5-generar-reportes-y-liberar-datos}{Etapa 6.4.5: Generar reportes y liberar datos}.

\hypertarget{definiciones-previas}{%
\subsection{Definiciones previas}\label{definiciones-previas}}

\begin{itemize}
\item
  \textbf{Organizaci√≥n del proceso y equipo de trabajo}: El trabajo del proceso SDC y los roles del equipo a cargo se deben organizar considerando las siguientes dos fases: diagn√≥stico e implementaci√≥n. La fase de diagn√≥stico corresponde a la evaluaci√≥n de riesgo de intrusi√≥n con los datos no tratados (originales o brutos), y permite juzgar si el conjunto de datos es lo suficientemente seguro para su publicaci√≥n, mientras que la fase de implementaci√≥n se refiere a la aplicaci√≥n de m√©todos SDC y su evaluaci√≥n, a fin de producir un conjunto de datos seguro para su publicaci√≥n.
\item
  \textbf{Revisi√≥n de insumos o productos estad√≠sticos necesarios que permiten la ejecuci√≥n del proceso}: Se debe revisar que los insumos o productos estad√≠sticos provenientes de los siguientes procesos en el mapa de procesos INE, segmento negocios\footnote{Disponible en \url{https://inechile.sharepoint.com/sites/Intranet/departamentodegestionestrategica/Mprocesos/Paginas/Segmento-Negocio.aspx}}: 2. ``Dise√±o y planificaci√≥n'', 5. ``Procesamiento'' y 6.3 ``Interpretar y explicar los resultados''; necesarios para la ejecuci√≥n de este subproceso, se encuentren completos y actualizados. Esto incluye la revisi√≥n de convenios, fichas metodol√≥gicas, manuales de usuarios, bases de datos, diccionario de variables, paquetes estad√≠sticos, infraestructura y seguridad, entre otros.
\end{itemize}

\hypertarget{determinaciuxf3n-de-la-necesidad-de-protecciuxf3n-de-la-confidencialidad}{%
\subsection{Determinaci√≥n de la necesidad de protecci√≥n de la confidencialidad}\label{determinaciuxf3n-de-la-necesidad-de-protecciuxf3n-de-la-confidencialidad}}

Antes de iniciar el proceso SDC para un conjunto de microdatos, se debe determinar la necesidad de protecci√≥n de la confidencialidad. Esto est√° estrechamente relacionado con la interpretaci√≥n de las leyes y reglamentos sobre este tema en Chile. Un primer paso es determinar las unidades estad√≠sticas en el conjunto de datos: si se trata de individuos, hogares o entidades legales, como empresas, es probable que sea necesario controlar la divulgaci√≥n. Tambi√©n hay ejemplos de microdatos para los que no hay necesidad de control de divulgaci√≥n. Los ejemplos podr√≠an ser datos con observaciones clim√°ticas y meteorol√≥gicas o datos con viviendas como unidades estad√≠sticas. Sin embargo, aunque las unidades estad√≠sticas primarias no sean personas f√≠sicas o jur√≠dicas, los datos pueden contener informaci√≥n confidencial sobre personas f√≠sicas o jur√≠dicas. Por ejemplo, un conjunto de datos con viviendas como unidades estad√≠sticas primarias tambi√©n puede contener informaci√≥n sobre las personas que viven en estas viviendas y sus ingresos o un conjunto de datos sobre hospitalizaciones puede incluir informaci√≥n sobre los pacientes hospitalizados. En estos casos, es probable que todav√≠a sea necesaria la protecci√≥n de la confidencialidad. Una opci√≥n para resolver esto es eliminar la informaci√≥n sobre las personas f√≠sicas y jur√≠dicas en los conjuntos de datos para su publicaci√≥n.

Un conjunto de datos tambi√©n puede contener m√°s de un tipo de unidad estad√≠stica. El ejemplo est√°ndar aqu√≠ es un conjunto de datos que contiene informaci√≥n sobre individuos y hogares. Otro ejemplo son los datos con empleados en empresas. Todos los tipos de unidades estad√≠sticas presentes en el conjunto de datos deben ser considerados para la necesidad de SDC. Esto es especialmente importante en caso de que los datos tengan una estructura jer√°rquica, como individuos en hogares o empleados en empresas.

Adem√°s, se debe evaluar si las variables contenidas en el conjunto de datos son de identificaci√≥n, confidenciales o sensibles. Qu√© variables son sensibles o confidenciales depende nuevamente de la legislaci√≥n aplicable y puede diferir sustancialmente de un pa√≠s a otro. En caso de que el conjunto de datos incluya variables sensibles o confidenciales, es probable que se requiera SDC. El conjunto de variables sensibles y variables de identificaci√≥n junto con las unidades estad√≠sticas en el conjunto de datos determinan la necesidad de control de divulgaci√≥n estad√≠stica.

Por otra parte, se debe realizar una revisi√≥n normativa que pueda afectar o impedir la publicaci√≥n de la informaci√≥n sujeta a anonimizar, esto incluye: identificar las restricciones actuales de publicaci√≥n de la informaci√≥n, identificar acuerdos y restricciones de las particularidades establecidas en los convenios del INE con fuentes externas.

Si no existen variables sensibles o variables de identificaci√≥n en el conjunto de datos, o restricciones desde el marco legal normativo, la decisi√≥n es pasar a la \protect\hyperlink{etapa-6.4.5-generar-reportes-y-liberar-datos}{Etapa 6.4.5: Generar reportes y liberar datos}, seg√∫n las caracter√≠sticas establecidas en la metodolog√≠a de la operaci√≥n estad√≠stica o convenio institucional, seg√∫n corresponda a lo establecido en el proceso 2. ``Dise√±o y planificaci√≥n''. Por el contrario, en caso de que el conjunto de datos contenga variables sensibles o variables de identificaci√≥n, y no haya restricciones desde el marco legal normativo, la decisi√≥n es llevar a cabo un proceso SDC.

\hypertarget{definiciuxf3n-de-las-caracteruxedsticas-de-las-bases-de-datos-a-preservar}{%
\subsection{Definici√≥n de las caracter√≠sticas de las bases de datos a preservar}\label{definiciuxf3n-de-las-caracteruxedsticas-de-las-bases-de-datos-a-preservar}}

En este paso, analizamos los principales usos de los datos por parte de los usuarios finales del archivo de microdatos publicado. Los datos deben ser √∫tiles para el tipo de an√°lisis estad√≠stico para el que se recopilaron y para el que se utilizan principalmente. Los usos y requisitos de los usuarios de datos ser√°n diferentes para los diferentes tipos de publicaci√≥n. Ponerse en contacto directamente con los usuarios de datos o buscar estudios y art√≠culos cient√≠ficos que utilicen datos similares puede resultar √∫til a la hora de recopilar esta informaci√≥n y realizar esta evaluaci√≥n. Adem√°s, es importante comprender qu√© nivel de precisi√≥n necesitan los usuarios de datos y qu√© tipos de categor√≠as se utilizan. Por ejemplo, en el caso de la recodificaci√≥n global de la edad en a√±os, uno podr√≠a recodificar la edad en grupos de 10 a√±os, por ejemplo, \(0 ‚Äì 9, 10 ‚Äì 19, 20 ‚Äì 29, ...\). Sin embargo, muchos indicadores relacionados con el mercado laboral usan categor√≠as que abarcan el rango 15 -- 65. Por lo tanto, construir categor√≠as que coincidan con las categor√≠as utilizadas para los indicadores hace que los datos sean mucho m√°s √∫tiles y, al mismo tiempo, reduce el riesgo de divulgaci√≥n de manera similar. Este conocimiento es importante para la selecci√≥n de medidas de utilidad apropiadas, que a su vez se utilizan para seleccionar los m√©todos SDC apropiados.

La anonimizaci√≥n siempre conducir√° a la p√©rdida de informaci√≥n y un archivo PUF tendr√° una utilidad reducida.

Las estad√≠sticas calculadas a partir del archivo de microdatos anonimizados y publicados deber√≠an producir resultados anal√≠ticos que concuerdan o casi concuerdan con las estad√≠sticas publicadas previamente a partir de los datos originales. Si, por ejemplo, se calcul√≥ el promedio de ingresos de los hogares chilenos previamente a partir de estos datos y se public√≥, el conjunto de datos an√≥nimos publicado deber√≠a producir un resultado muy similar al resultado publicado oficialmente. Como m√≠nimo, el resultado debe estar dentro de la regi√≥n de confianza del resultado publicado. Puede darse el caso de que no todas las estad√≠sticas publicadas puedan generarse a partir de los datos publicados. Si este es el caso, se debe elegir en qu√© indicadores y estad√≠sticas enfocarse, e informar a los usuarios sobre cu√°les se han seleccionado y por qu√©. Adem√°s, es importante definir porcentajes de variaci√≥n permitidos por variable y niveles de desagregaci√≥n geogr√°fica o tem√°tica para las caracter√≠sticas estad√≠sticas, a fin de medir la utilidad que compara los datos originales y los datos anonimizados, teniendo en cuenta la necesidad del usuario final para su an√°lisis.

Algunos ejemplos de caracter√≠sticas estad√≠sticas a preservar son las siguientes:

\begin{itemize}
\tightlist
\item
  Propiedades globales de las variables, como promedios.
\item
  Mantener cifras por nivel de desagregaci√≥n geogr√°fica o tem√°tica, como, por ejemplo, mantener para la variable grupos √©tnicos en los totales de cada categor√≠a a nivel regional.
\item
  Mantener correlaciones entre variables.
\item
  Mantener tendencias de las variables a trav√©s del tiempo, por ejemplo, si los ingresos promedio de los hogares chilenos ha presentado un comportamiento decreciente en el primer trimestre de 2021, al publicar la base de datos anonimizada el equipo de trabajo desea garantizar que esta tendencia se conserve.
\end{itemize}

Como se discuti√≥ en la Secci√≥n \protect\hyperlink{mediciuxf3n-de-la-utilidad-y-la-puxe9rdida-de-informaciuxf3n}{Medici√≥n de la utilidad y la p√©rdida de informaci√≥n}, es necesario calcular medidas generales de utilidad que comparen los datos sin procesar y anonimizados, teniendo en cuenta la necesidad del usuario final para su an√°lisis. En algunos casos, las medidas de utilidad pueden arrojar resultados contradictorios, por ejemplo, un determinado m√©todo SDC podr√≠a generar una menor p√©rdida de informaci√≥n para las cifras de la fuerza laboral pero una mayor p√©rdida de informaci√≥n para los √≠ndices relacionados con la educaci√≥n. En tales casos, es posible que sea necesario clasificar los usos de los datos en orden de importancia y se debe documentar claramente para el usuario que la priorizaci√≥n de ciertas m√©tricas sobre otras significa har√° que algunas m√©tricas ya no sean v√°lidas. Esto puede ser necesario, ya que no es posible liberar varios archivos para diferentes usuarios. Este problema se presenta especialmente en estudios polivalentes. Para obtener m√°s detalles sobre las medidas de utilidad, consulte la Secci√≥n \protect\hyperlink{mediciuxf3n-de-la-utilidad-y-la-puxe9rdida-de-informaciuxf3n}{Medici√≥n de la utilidad y la p√©rdida de informaci√≥n}.

\hypertarget{etapa-6.4.2-preparaciuxf3n-y-exploraciuxf3n-de-datos}{%
\section{Etapa 6.4.2: Preparaci√≥n y exploraci√≥n de datos}\label{etapa-6.4.2-preparaciuxf3n-y-exploraciuxf3n-de-datos}}

Despu√©s de evaluar la necesidad de un control de divulgaci√≥n estad√≠stica, debemos preparar los datos y, si hay varios, combinar y considerar todos los archivos de datos relacionados. Luego exploramos las caracter√≠sticas y la estructura de los datos, que son importantes para los usuarios de los datos. La compilaci√≥n de un inventario de estas caracter√≠sticas es importante para evaluar la utilidad de los datos despu√©s de la anonimizaci√≥n y producir un conjunto de datos anonimizados, que es √∫til para los usuarios finales.

El primer paso en la preparaci√≥n de datos es clasificar las variables como confidenciales o no confidenciales y eliminar identificadores directos como nombres completos, n√∫meros de pasaporte, direcciones, n√∫meros de tel√©fono y coordenadas GPS. En el caso de datos de encuestas, una inspecci√≥n del cuestionario de la encuesta es √∫til para clasificar las variables. Adem√°s, es necesario seleccionar las variables que contienen informaci√≥n relevante para los usuarios finales y deben incluirse en el conjunto de datos para su publicaci√≥n. En este punto, tambi√©n puede ser √∫til eliminar variables que no sean identificadores directos del conjunto de microdatos que se publicar√°. Un ejemplo puede ser una variable con muchos valores faltantes, por ejemplo, una variable registrada solo para un grupo selecto de personas elegibles para un m√≥dulo de encuesta en particular y valores faltantes para el resto. Tales variables pueden causar un alto nivel de riesgo de divulgaci√≥n y agregar poca informaci√≥n para los usuarios finales. Ejemplos son variables relacionadas con la educaci√≥n (grado actual), donde un valor faltante indica que la persona no est√° actualmente en la escuela, o variables relacionadas con el parto, donde un valor faltante indica que la persona no ha dado a luz en el per√≠odo de referencia. Los valores faltantes en s√≠ mismos pueden ser reveladores, especialmente si indican que la variable no es aplicable. A menudo, las variables a las que les faltan la mayor√≠a de los valores ya se eliminan en esta etapa. Otras variables que podr√≠an eliminarse en esta etapa son aquellas demasiado sensibles para anonimizarlas y difundirlas o aquellas que no son importantes para los usuarios de datos y que podr√≠an aumentar el riesgo de divulgaci√≥n.

Las relaciones pueden existir entre las variables en un conjunto de datos por una variedad de razones. Por ejemplo, las variables pueden ser mutuamente excluyentes en los casos en que se utilizan varias variables binarias para cada categor√≠a. Un individuo que no est√° en la fuerza laboral tendr√° un valor faltante para el sector en el que esta persona est√° empleada (o, m√°s precisamente, no aplicable). Las relaciones tambi√©n pueden existir si algunas variables son proporciones, sumas u otras funciones matem√°ticas de otras variables. Algunos ejemplos son la variable tama√±o del hogar (como un recuento de personas por hogar) o el gasto agregado (como la suma de todos los componentes del gasto). Un cierto valor en una variable tambi√©n puede reducir el n√∫mero de valores posibles o v√°lidos para otra variable; por ejemplo, la edad de una persona que asiste a la educaci√≥n primaria o el sexo de una persona que ha dado a luz. Estas relaciones son importantes por dos razones: 1) pueden ser utilizadas por intrusos para reconstruir valores anonimizados. Por ejemplo, si se suprime la edad pero otra variable indica que est√° en la escuela, a√∫n es posible inferir un rango de edad probable para ese individuo. Otro ejemplo es si se demuestra que un individuo est√° activo en el Sector B de la econom√≠a. Incluso si se suprime la condici√≥n laboral de este individuo, se puede inferir que esta persona est√° empleada. 2) las relaciones en los datos originales deben mantenerse en el conjunto de datos anonimizados y deben evitarse las inconsistencias (por ejemplo, los m√©todos SDC no deben crear ni√±os en edad escolar de 58 a√±os o ni√±os casados de 3 a√±os), o el conjunto de datos ser√° inv√°lido para el an√°lisis. Otro ejemplo es el caso de los gastos por categor√≠a, donde es importante que la suma de las categor√≠as sume el total. Una forma de garantizar esto es anonimizar los totales y luego recalcular las subcategor√≠as de acuerdo con las acciones originales de los totales an√≥nimos.

Tambi√©n es √∫til en esta etapa consolidar variables que brinden la misma informaci√≥n cuando sea posible, para reducir el n√∫mero de variables, reducir la probabilidad de inconsistencias y minimizar las variables que un intruso puede usar para reconstruir los datos. Esto es especialmente cierto si los microdatos provienen de un cuestionario elaborado y cada variable representa una (sub) pregunta que conduce a un conjunto de datos con cientos de variables. Como ejemplo, tomamos una encuesta con varias variables de fuerza laboral que indican si una persona est√° en la fuerza laboral, empleada o desempleada, y si est√° empleada, en qu√© sector. Los datos de la Tabla \ref{tab:tabProc1} ilustra este ejemplo. Es posible que cada tipo de sector tenga su propia variable binaria. En ese caso, este conjunto de variables se puede resumir en dos variables: una variable que indica si una persona est√° en la fuerza laboral y otra que indica la situaci√≥n laboral, as√≠ como el sector respectivo si una persona est√° empleada. Estas dos variables contienen toda la informaci√≥n contenida en las cinco variables anteriores y facilitan el proceso de anonimizaci√≥n. Si los usuarios de datos est√°n acostumbrados a un determinado formato de publicaci√≥n en el que la norma ha sido incluir las cinco variables, entonces es posible volver a transformar las variables despu√©s del proceso de anonimizaci√≥n en lugar de complicar el proceso de anonimizaci√≥n tratando de tratar m√°s variables de las necesarias.

\begin{table}

\caption{\label{tab:tabProc1}Ilustraci√≥n de la combinaci√≥n de variables sin p√©rdida de informaci√≥n para el proceso SDC.}
\centering
\begin{tabular}[t]{c|c|c|c|c|c|c}
\hline
FL-Orig & Empleado-Orig & Sector-A & Sector-B & Sector-C & FL-Nueva & Empleado-Nueva\\
\hline
S√≠ & S√≠ & NA & S√≠ & NA & S√≠ & B\\
\hline
No & No & NA & NA & NA & No & No\\
\hline
S√≠ & S√≠ & S√≠ & NA & NA & S√≠ & A\\
\hline
S√≠ & S√≠ & NA & S√≠ & NA & S√≠ & B\\
\hline
S√≠ & S√≠ & NA & NA & S√≠ & S√≠ & C\\
\hline
S√≠ & No & NA & NA & NA & S√≠ & No\\
\hline
\end{tabular}
\end{table}

\begin{quote}
\textbf{Nota sobre los pasos siguientes}:
Los siguientes pasos, \protect\hyperlink{etapa-6.4.3-mediciuxf3n-y-evaluaciuxf3n-de-riesgos-de-divulgaciuxf3n}{Etapa 6.4.3: Medici√≥n y evaluaci√≥n de riesgos de divulgaci√≥n}, \protect\hyperlink{etapa-6.4.4.1-selecciuxf3n-y-aplicaciuxf3n-de-muxe9todos-sdc}{Etapa 6.4.4.1: Selecci√≥n y aplicaci√≥n de m√©todos SDC} y \protect\hyperlink{etapa-6.4.4.2-evaluaciuxf3n-de-proceso-sdc}{Etapa 6.4.4.2: Evaluaci√≥n de proceso SDC}, deben repetirse si los datos tienen identificadores indirectos que se encuentran en diferentes niveles jer√°rquicos, por ejemplo, individuo y hogar. En ese caso, las variables del nivel jer√°rquico superior deben anonimizarse primero y luego fusionarse con las variables no tratadas del nivel inferior. Posteriormente, el conjunto de datos combinado debe anonimizarse. Este enfoque garantiza la consistencia en los datos tratados. Si descuidamos este procedimiento, los valores de las variables medidas en el nivel jer√°rquico superior podr√≠an recibir un tratamiento diferente para las observaciones de la misma unidad. Por ejemplo, la variable ``regi√≥n'' es la misma para todos los miembros del hogar. Si se suprimiera el valor `Valpara√≠so' para dos miembros pero no para los tres restantes, esto dar√≠a lugar a una divulgaci√≥n no intencionada; con la identificaci√≥n del hogar, la variable regi√≥n ser√≠a f√°cil de reconstruir para los dos valores suprimidos. Las secciones \protect\hyperlink{riesgo-jeruxe1rquico-o-del-hogar}{Riesgo jer√°rquico (o del hogar)} y \protect\hyperlink{estructura-del-hogar}{Estructura del hogar} brindan m√°s detalles sobre c√≥mo tratar los datos con la estructura del hogar en \texttt{R} y \texttt{sdcMicro} .
\end{quote}

\hypertarget{etapa-6.4.3-mediciuxf3n-y-evaluaciuxf3n-de-riesgos-de-divulgaciuxf3n}{%
\section{Etapa 6.4.3: Medici√≥n y evaluaci√≥n de riesgos de divulgaci√≥n}\label{etapa-6.4.3-mediciuxf3n-y-evaluaciuxf3n-de-riesgos-de-divulgaciuxf3n}}

El prop√≥sito de esta etapa es calcular medidas de riesgo sobre los datos originales o brutos y, en base a estas medidas, juzgar si un archivo de microdatos es lo suficientemente seguro para su publicaci√≥n.

Los procedimientos descritos para esta etapa aplican para todas las operaciones estad√≠sticas y productos relacionados cuyo levantamiento de informaci√≥n y/o publicaci√≥n sea realizado por el INE (encuestas, censos, procesos de m√∫ltiples fuentes y registros administrativos) que dar√°n a conocer informaci√≥n al p√∫blico general u otros usuarios.

En esta etapa solo se calculan las medidas de riesgo sobre los datos originales, que permiten decidir si el archivo de microdatos es lo suficientemente seguro para su publicaci√≥n, o si requiere la aplicaci√≥n de m√©todos SDC (ver \protect\hyperlink{etapa-6.4.4.1-selecciuxf3n-y-aplicaciuxf3n-de-muxe9todos-sdc}{Etapa 6.4.4.1: Selecci√≥n y aplicaci√≥n de m√©todos SDC}). La decisi√≥n sobre qu√© hacer con las unidades riesgosas (una vez aplicados los m√©todos SDC) se aborda en la \protect\hyperlink{etapa-6.4.4.2-evaluaciuxf3n-de-proceso-sdc}{Etapa 6.4.4.2: Evaluaci√≥n de proceso SDC}.

\hypertarget{definiciuxf3n-de-escenarios-de-divulgaciuxf3n-y-selecciuxf3n-de-identificadores-indirectos-cuasi-identificadores-o-variables-clave}{%
\subsection{Definici√≥n de escenarios de divulgaci√≥n y selecci√≥n de identificadores indirectos (cuasi-identificadores o variables clave)}\label{definiciuxf3n-de-escenarios-de-divulgaciuxf3n-y-selecciuxf3n-de-identificadores-indirectos-cuasi-identificadores-o-variables-clave}}

Despu√©s de determinar el tipo de publicaci√≥n de los datos, se deben examinar las posibilidades de c√≥mo un individuo en los microdatos podr√≠a (de manera realista) ser identificado por un intruso bajo ese tipo de publicaci√≥n. Para el lanzamiento de PUF, el enfoque est√° en el uso de conjuntos de datos externos de varias fuentes. Estas posibilidades se describen en escenarios de divulgaci√≥n o intrusi√≥n, que especifican a qu√© datos podr√≠a tener acceso un intruso y c√≥mo se pueden utilizar estos datos auxiliares para la divulgaci√≥n de identidad. Esto conduce a la especificaci√≥n de identificadores indirectos, que son un conjunto de variables que est√°n disponibles tanto en el conjunto de datos que se publicar√° como en conjuntos de datos auxiliares y necesitan protecci√≥n.

Esto es especialmente cierto para los lanzamientos de PUF. Los escenarios de divulgaci√≥n tambi√©n pueden ayudar a definir el nivel requerido de anonimizaci√≥n.

La redacci√≥n de escenarios de divulgaci√≥n requiere el apoyo de especialistas en la materia, suponiendo que el especialista en la materia no sea la misma persona que realiza la anonimizaci√≥n. Los conjuntos de datos auxiliares pueden contener informaci√≥n sobre la identidad de las personas y permitir la divulgaci√≥n de la identidad. Ejemplos de estos archivos de datos auxiliares son los registros de poblaci√≥n y los padrones electorales, registros de Servicio de Impuestos Internos, encuestas publicadas por el INE y datos censales, as√≠ como los datos recopilados por empresas especializadas, entre otras.

De entre los diferentes escenarios de divulgaci√≥n que pueden ser considerados, uno debe ser priorizado. La definici√≥n de este escenario puede responder a los siguientes criterios:

\begin{itemize}
\tightlist
\item
  Considerar escenarios realistas (probables). Las variables o conjuntos de datos pueden no coincidir perfectamente (por ejemplo, diferentes definiciones, variables m√°s o menos detalladas, diferentes per√≠odos de tiempo, etc.). Los registros externos podr√≠an no estar lo suficientemente actualizados y, por lo tanto, un \emph{matching} exacto con la base de datos a anonimizar, puede ser poco probable.
\item
  Algunos criterios para priorizar la selecci√≥n de los escenarios son: Probabilidad de datos disponibles para el intruso con m√°s variables y categor√≠as, y probabilidad de \emph{matching} exitoso, considerando combinaci√≥n de variables con mayor frecuencia.
\end{itemize}

\begin{quote}
** Notas **:
- Pueden ser especificados tanto identificadores indirectos categ√≥ricos como cuantitativos. - Considerar como m√≠nimo un identificador indirecto, pero sin n√∫mero m√°ximo.
- Considerar en la definici√≥n de los escenarios, variables que den cuenta de la desagregaci√≥n geogr√°fica. Por ejemplo, regi√≥n, provincia, comuna.
- Considerar el escenario de reconocimiento espont√°neo. Bajo este escenario, se debe verificar combinaciones raras o patrones inusuales en las variables. Ejemplos de variables que pueden conducir a reconocimiento espont√°neo son: n√∫mero de integrantes del hogar, √°rea de un terreno, n√∫mero de trabajadores de una empresa, ingresos y gastos, enfermedades, profesiones u oficios de baja prevalencia en el √°rea geogr√°fica circunscrita, entre otras.
- Si el n√∫mero de identificadores indirectos es alto, se recomienda reducir el conjunto de identificadores indirectos, eliminando algunas variables del conjunto de datos para su publicaci√≥n. Sin embargo, esta decisi√≥n debe estar fundada bajo los siguientes criterios: 1) La variable no posee alto valor anal√≠tico y se puede prescindir de ella, o 2) La variable tiene una alta contribuci√≥n al riesgo de divulgaci√≥n. Si esta variable no se puede tratar adecuadamente mediante los m√©todos SDC (es decir, a√∫n se mantienen altos niveles de riesgo), se debe quitar del conjunto de datos.
\end{quote}

\hypertarget{mediciuxf3n-y-evaluaciuxf3n-de-riesgos}{%
\subsection{Medici√≥n y evaluaci√≥n de riesgos}\label{mediciuxf3n-y-evaluaciuxf3n-de-riesgos}}

El siguiente paso es evaluar el riesgo de divulgaci√≥n de los datos no tratados (sin procesar). Aqu√≠ es importante distinguir entre datos muestrales y datos censales. En el caso de los datos del censo, es posible calcular directamente las medidas de riesgo cuando se supone que el conjunto de datos cubre a toda la poblaci√≥n. Si se trabaja con una muestra, o una muestra del censo (que es el caso m√°s com√∫n cuando se liberan datos de muestra), podemos usar los modelos discutidos en la Secci√≥n \protect\hyperlink{mediciuxf3n-de-riesgos}{Medici√≥n de riesgos} para estimar el riesgo en la poblaci√≥n. Las principales entradas para la medici√≥n del riesgo son el conjunto de identificadores indirectos determinados a partir de los escenarios de divulgaci√≥n en la secci√≥n anterior y los umbrales para los c√°lculos de riesgo (por ejemplo, el nivel de k-anonimato o el umbral por el cual un individuo se considera en riesgo). Si los datos tienen una estructura jer√°rquica (por ejemplo, una estructura de hogar), el riesgo debe medirse teniendo en cuenta esta estructura como se describe en la Secci√≥n \protect\hyperlink{riesgo-jeruxe1rquico-o-del-hogar}{Riesgo jer√°rquico (o del hogar)}.

Cada una de las diferentes medidas de riesgo descritas en la Secci√≥n \protect\hyperlink{mediciuxf3n-de-riesgos}{Medici√≥n de riesgos} tiene ventajas y desventajas. En general, el k-anonimato, el riesgo individual y el riesgo global se utilizan para producir una idea del riesgo de divulgaci√≥n. Estos valores pueden ser inicialmente muy altos, pero a menudo pueden reducirse muy f√°cilmente despu√©s de una recodificaci√≥n simple pero apropiada (consulte la \protect\hyperlink{etapa-6.4.4.1-selecciuxf3n-y-aplicaciuxf3n-de-muxe9todos-sdc}{Etapa 6.4.4.1: Selecci√≥n y aplicaci√≥n de m√©todos SDC}). Los umbrales son los establecidos por la instituci√≥n de acuerdo con el tipo de operaci√≥n estad√≠stica. Recuerde siempre, sin embargo, que al usar una muestra, las medidas de riesgo basadas en los modelos presentados en la literatura ofrecen el peor escenario de riesgo y, por lo tanto, podr√≠an ser una exageraci√≥n de los riesgos reales para algunos casos (consulte la Secci√≥n \protect\hyperlink{riesgo-individual}{Riesgo individual}).

\hypertarget{etapa-6.4.4.1-selecciuxf3n-y-aplicaciuxf3n-de-muxe9todos-sdc}{%
\section{Etapa 6.4.4.1: Selecci√≥n y aplicaci√≥n de m√©todos SDC}\label{etapa-6.4.4.1-selecciuxf3n-y-aplicaciuxf3n-de-muxe9todos-sdc}}

La selecci√≥n de los m√©todos SDC depende de la necesidad de protecci√≥n de datos (medida por el riesgo de divulgaci√≥n), la estructura de los datos y el tipo de variables. La influencia de los diferentes m√©todos sobre las caracter√≠sticas de los datos importantes para los usuarios o la utilidad de los datos tambi√©n debe tenerse en cuenta al seleccionar los m√©todos SDC. En la pr√°ctica, la elecci√≥n de los m√©todos SDC es parcialmente un proceso de prueba y error: despu√©s de aplicar un m√©todo elegido, el riesgo de divulgaci√≥n y la utilidad de los datos se miden y comparan con otras opciones de m√©todos y par√°metros. La elecci√≥n de los m√©todos est√° sujeta a la legislaci√≥n, por un lado, y a un compromiso entre utilidad y riesgo, por el otro.

La clasificaci√≥n de m√©todos que se presenta en la Tabla \ref{tab:tabProc2} ofrece una buena visi√≥n general para elegir los m√©todos apropiados. Los m√©todos deben elegirse seg√∫n el tipo de variable, continua o categ√≥rica, los requisitos de los usuarios y el tipo de liberaci√≥n. Para una descripci√≥n m√°s completa de estos m√©todos, consulte la Secci√≥n \protect\hyperlink{muxe9todos-sdc}{M√©todos SDC}.

\begin{table}

\caption{\label{tab:tabProc2}M√©todos SDC y funciones correspondientes en `sdcMicro`}
\centering
\begin{tabular}[t]{c|c|c|c}
\hline
M√©todo & Clasificaci√≥n & Tipo de datos & Funci√≥n en sdcMicro\\
\hline
Recodificaci√≥n global & No perturbativo, determin√≠stico & Continuo y categ√≥rico & `globalRecode`,`groupVars`\\
\hline
Codificaci√≥n superior e inferior & No perturbativo, determin√≠stico & Continuo y categ√≥rico & `topBotCoding`\\
\hline
Supresi√≥n local & No perturbativo, determin√≠stico & Categ√≥rico & `localSuppression`,`localSupp`\\
\hline
PRAM & Perturbativo, probabil√≠stico & Categ√≥rico & `pram`\\
\hline
Microagregaci√≥n & Perturbativo, probabil√≠stico & Continuo & `microaggregation`\\
\hline
Adici√≥n de ruido & Perturbativo, probabil√≠stico & Continuo & `addNoise`\\
\hline
Barajado & Perturbativo, probabil√≠stico & Continuo & `shuffle`\\
\hline
Intercambio de rango & Perturbativo, probabil√≠stico & Continuo & `rankSwap`\\
\hline
\end{tabular}
\end{table}

En general, para la anonimizaci√≥n de variables categ√≥ricas, es √∫til restringir el n√∫mero de supresiones aplicando primero una recodificaci√≥n global y/o eliminando variables del conjunto de microdatos. Cuando el n√∫mero requerido de supresiones para lograr el nivel de riesgo requerido es suficientemente bajo, las pocas unidades en riesgo pueden ser tratadas mediante supresi√≥n. Estos son generalmente valores at√≠picos. Cabe se√±alar que posiblemente no todas las variables se puedan publicar y algunas se deban eliminar del conjunto de datos (consulte la \protect\hyperlink{etapa-6.4.2-preparaciuxf3n-y-exploraciuxf3n-de-datos}{Etapa 6.4.2: Preparaci√≥n y exploraci√≥n de datos}). La recodificaci√≥n y el uso m√≠nimo de la supresi√≥n garantizan que las cifras ya publicadas de los datos sin procesar se puedan reproducir suficientemente bien a partir de los datos anonimizados. Si se aplica la supresi√≥n sin una recodificaci√≥n suficiente, el n√∫mero de supresiones puede ser muy alto y la estructura de los datos puede cambiar significativamente. Esto se debe a que la supresi√≥n afecta principalmente a las combinaciones que son raras en los datos.

Si los resultados de la recodificaci√≥n y la supresi√≥n no logran el resultado requerido, especialmente en los casos en que el n√∫mero de identificadores indirectos seleccionados es alto, una alternativa es usar m√©todos perturbativos. Estos se pueden utilizar sin una recodificaci√≥n previa de las variables. Estos m√©todos, sin embargo, preservan la estructura de datos solo parcialmente. El m√©todo preferido depende de los requisitos de los usuarios. Nos referimos a la Secci√≥n \protect\hyperlink{muxe9todos-sdc}{M√©todos SDC} y especialmente a la Secci√≥n \protect\hyperlink{muxe9todos-perturbativos}{M√©todos perturbativos} para una discusi√≥n de los m√©todos perturbativos implementados en \texttt{sdcMicro}.

Finalmente, la selecci√≥n de los m√©todos SDC depende de los datos utilizados, ya que los mismos m√©todos producen diferentes resultados en diferentes conjuntos de datos. Por lo tanto, la comparaci√≥n de resultados con respecto al riesgo y la utilidad (ver \protect\hyperlink{etapa-6.4.4.2-evaluaciuxf3n-de-proceso-sdc}{Etapa 6.4.4.2: Evaluaci√≥n de proceso SDC}) es clave para la elecci√≥n realizada. La mayor√≠a de los m√©todos se implementan en el paquete \texttt{sdcMicro}. Sin embargo, a veces es √∫til emplear soluciones a medida. En la secci√≥n \protect\hyperlink{muxe9todos-sdc}{M√©todos SDC} se presentan algunos ejemplos.

\hypertarget{etapa-6.4.4.2-evaluaciuxf3n-de-proceso-sdc}{%
\section{Etapa 6.4.4.2: Evaluaci√≥n de proceso SDC}\label{etapa-6.4.4.2-evaluaciuxf3n-de-proceso-sdc}}

El prop√≥sito de esta etapa es verificar si la base de datos anonimizada cumple con las condiciones para presentarse como versi√≥n final. Estas son: el nivel de riesgo definido en la \protect\hyperlink{etapa-6.4.3-mediciuxf3n-y-evaluaciuxf3n-de-riesgos-de-divulgaciuxf3n}{Etapa 6.4.3: Medici√≥n y evaluaci√≥n de riesgos de divulgaci√≥n} y la utilidad esperada definida en la \protect\hyperlink{etapa-6.4.1-definiciones-previas-al-proceso-de-anonimizaciuxf3n}{Etapa 6.4.1: Definiciones previas al proceso de anonimizaci√≥n}.

Su alcance considera la reevaluaci√≥n del riesgo y la medici√≥n de la utilidad, comparar con mediciones de los datos originales y decidir si la base cumple o no con los criterios establecidos.

\hypertarget{vuelva-a-medir-el-riesgo}{%
\subsection{Vuelva a medir el riesgo}\label{vuelva-a-medir-el-riesgo}}

En este paso, reevaluamos el riesgo de divulgaci√≥n con las medidas de riesgo elegidas en la \protect\hyperlink{etapa-6.4.3-mediciuxf3n-y-evaluaciuxf3n-de-riesgos-de-divulgaciuxf3n}{Etapa 6.4.3: Medici√≥n y evaluaci√≥n de riesgos de divulgaci√≥n} despu√©s de aplicar los m√©todos SDC. Adem√°s de estas medidas de riesgo, tambi√©n es importante observar a las unidades con alto riesgo y/o caracter√≠sticas especiales, combinaciones de valores o valores at√≠picos en los datos. Si el riesgo no est√° en un nivel aceptable, la \protect\hyperlink{etapa-6.4.3-mediciuxf3n-y-evaluaciuxf3n-de-riesgos-de-divulgaciuxf3n}{Etapa 6.4.3: Medici√≥n y evaluaci√≥n de riesgos de divulgaci√≥n} y \protect\hyperlink{etapa-6.4.4.1-selecciuxf3n-y-aplicaciuxf3n-de-muxe9todos-sdc}{Etapa 6.4.4.1: Selecci√≥n y aplicaci√≥n de m√©todos SDC} deben repetirse con diferentes m√©todos y/o par√°metros.

Medidas de riesgo basadas en conteos de frecuencia (k-anonimato, riesgo individual, riesgo global y riesgo del hogar) no se pueden utilizar despu√©s de aplicar m√©todos perturbativos ya que sus estimaciones de riesgo no son v√°lidas. Estos m√©todos se basan en introducir incertidumbre en el conjunto de datos y no en aumentar las frecuencias de las claves en los datos y, por lo tanto, sobreestimar√°n el riesgo.

\hypertarget{mida-la-utilidad}{%
\subsection{Mida la utilidad}\label{mida-la-utilidad}}

En este paso, volvemos a medir las medidas de utilidad definidas en la \protect\hyperlink{etapa-6.4.1-definiciones-previas-al-proceso-de-anonimizaciuxf3n}{Etapa 6.4.1: Definiciones previas al proceso de anonimizaci√≥n} y las comparamos con los resultados de los datos sin procesar. Adem√°s, aqu√≠ es √∫til construir intervalos de confianza alrededor de las estimaciones puntuales y comparar estos intervalos de confianza. La importancia del valor absoluto de una desviaci√≥n solo puede interpretarse conociendo la varianza de la estimaci√≥n. Adem√°s de estas medidas de utilidad espec√≠ficas, se deben evaluar las medidas de utilidad general, como se analiza en la Secci√≥n \protect\hyperlink{mediciuxf3n-de-la-utilidad-y-la-puxe9rdida-de-informaciuxf3n}{Medici√≥n de la utilidad y la p√©rdida de informaci√≥n}. Esto es especialmente importante si se han aplicado m√©todos perturbativos. Si los datos no cumplen con los requisitos del usuario y las desviaciones son demasiado grandes, repita la \protect\hyperlink{etapa-6.4.3-mediciuxf3n-y-evaluaciuxf3n-de-riesgos-de-divulgaciuxf3n}{Etapa 6.4.3: Medici√≥n y evaluaci√≥n de riesgos de divulgaci√≥n} y \protect\hyperlink{etapa-6.4.4.1-selecciuxf3n-y-aplicaciuxf3n-de-muxe9todos-sdc}{Etapa 6.4.4.1: Selecci√≥n y aplicaci√≥n de m√©todos SDC} con diferentes m√©todos y/o diferentes par√°metros.

La anonimizaci√≥n siempre conducir√° a al menos alguna p√©rdida de informaci√≥n.

\hypertarget{evaluaciuxf3n-de-reglas-de-validaciuxf3n-y-consistencia}{%
\subsection{Evaluaci√≥n de reglas de validaci√≥n y consistencia}\label{evaluaciuxf3n-de-reglas-de-validaciuxf3n-y-consistencia}}

Por √∫ltimo, se debe verificar que todas las relaciones en los datos anonimizados preserven todas las reglas de validaci√≥n y consistencia propias de la operaci√≥n estad√≠stica. Esto incluye:

\begin{itemize}
\tightlist
\item
  Variables que son sumas de otras variables o proporciones.
\item
  Relaciones de orden, por ejemplo, la variable X debe ser siempre menor a la variable Y.
\item
  Cualquier valor inusual causado por la anonimizaci√≥n debe ser detectado. Por ejemplo, los ingresos negativos, una persona de 14 a√±os en la fuerza laboral o un alumno en el vig√©simo grado de la escuela. Esto puede suceder despu√©s de aplicar m√©todos perturbativos de SDC.
\end{itemize}

Se debe verificar que los indicadores publicados previamente de los datos originales o brutos son reproducibles a partir de los datos que se van a publicar. Si este no es el caso, los usuarios de datos podr√≠an cuestionar la credibilidad del conjunto de datos anonimizados.

En la Figura \ref{fig:evalSDC} se presenta el flujo que resume las actividades que componen esta etapa y que, en consecuencia, permite juzgar la efectividad de los m√©todos SDC aplicados y la factibilidad de liberar el conjunto de microdatos.

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{Imagenes/Eval_Proc_SDC} 

}

\caption{Evaluaci√≥n de proceso SDC INE 2021.}\label{fig:evalSDC}
\end{figure}

\hypertarget{etapa-6.4.5-generar-reportes-y-liberar-datos}{%
\section{Etapa 6.4.5: Generar reportes y liberar datos}\label{etapa-6.4.5-generar-reportes-y-liberar-datos}}

El prop√≥sito de esta etapa es la generaci√≥n de reportes, tanto interno como externo, que acompa√±an la liberaci√≥n de datos.

Los informes internos contienen la descripci√≥n exacta de los m√©todos de anonimizaci√≥n utilizados, los par√°metros, pero tambi√©n las medidas de riesgo antes y despu√©s de la anonimizaci√≥n. Esto permite la replicaci√≥n del conjunto de datos anonimizados y es importante para las autoridades/organismos de control para garantizar que el proceso de anonimizaci√≥n sea suficiente para garantizar el anonimato de acuerdo con la legislaci√≥n aplicable.

Los informes externos informan al usuario que los datos han sido anonimizados, brindan informaci√≥n para un an√°lisis v√°lido de los datos y explican las limitaciones de los datos como resultado de la anonimizaci√≥n. Puede incluirse una breve descripci√≥n de los m√©todos utilizados. La publicaci√≥n de microdatos anonimizados debe ir acompa√±ada de los metadatos habituales de la encuesta (peso de la encuesta, estratos, metodolog√≠a de la encuesta), as√≠ como informaci√≥n sobre los m√©todos de anonimizaci√≥n que permiten a los investigadores realizar an√°lisis v√°lidos (por ejemplo, cantidad de ruido agregado, matriz de transici√≥n para PRAM).Se debe tener cuidado de que esta informaci√≥n no se pueda utilizar para la reidentificaci√≥n (por ejemplo, no se libera semilla aleatoria para PRAM).

Por otra parte, los metadatos deben actualizarse para cumplir con los datos anonimizados. Las descripciones de las variables o las etiquetas de valores pueden haber cambiado como resultado del proceso de anonimizaci√≥n. Adem√°s, la p√©rdida de informaci√≥n debido al proceso de anonimizaci√≥n debe explicarse en detalle a los usuarios para que sean conscientes de los l√≠mites de la validez de los datos y sus an√°lisis.

El √∫ltimo paso en el proceso de SDC es la publicaci√≥n real de los datos an√≥nimos. En el contexto INE, el tipo de publicaci√≥n factible es el PUF. Los cambios realizados en las variables en la \protect\hyperlink{etapa-6.4.2-preparaciuxf3n-y-exploraciuxf3n-de-datos}{Etapa 6.4.2: Preparaci√≥n y exploraci√≥n de datos}, como la fusi√≥n de variables, se pueden deshacer para generar un conjunto de datos √∫til para los usuarios.

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{Imagenes/Esquema_Proc_SDC} 

}

\caption{Esquema general de proceso SDC INE 2021.}\label{fig:esquemaSDC}
\end{figure}

\hypertarget{caso-de-estudio}{%
\chapter{Caso de estudio}\label{caso-de-estudio}}

El objetivo del siguiente proceso de anonimizaci√≥n es ilustrar el proceso SDC establecido en la GU√çA PARA EL CONTROL DE DIVULGACI√ìN ESTAD√çSTICA EN MICRODATOS propuesta por la Mesa de Anonimizaci√≥n INE. Los datos utilizados corresponden a una base de datos sint√©tica que se basa en el dise√±o de la 17a ENUSC 2020 \citep{manualbdenusc}.

El proceso SDC aqu√≠ implementado pretender generar un archivo de datos PUF (del ingl√©s, \emph{Public Use File}), que pueda ponerse a disposici√≥n de forma p√∫blica y para cualquier usuario que lo requiera. Para ello, el proceso SDC aplicado apunta al logro de los umbrales de riesgo establecido por la GU√çA PARA EL CONTROL DE DIVULGACI√ìN ESTAD√çSTICA EN MICRODATOS para encuestas de hogares \citep{manualsdcine}. Simult√°neamente, el ejercicio busca mantener la utilidad de los datos, intentando minimizar la intervenci√≥n de los mismos para que los usuarios puedan replicar las estad√≠sticas priorizadas por esta encuesta.

Los umbrales de riesgo establecidos son los siguientes:

\textbf{RIESGO GLOBAL}

\begin{itemize}
\tightlist
\item
  Riesgo global inferior al 10\%
\end{itemize}

\textbf{RIESGOS INDIVIDUALES}

\begin{itemize}
\tightlist
\item
  Hasta 20\% de observaciones con riesgo individual mayor al 1\%
\item
  Hasta 15\% de observaciones con riesgo individual mayor al 5\%
\item
  0\% de observaciones con riesgo individual mayor al 25\%
\end{itemize}

\textbf{K-ANONIMATO}

\begin{itemize}
\tightlist
\item
  0\% de observaciones violando k = 2
\item
  Hasta 5\% de observaciones violando k = 3
\item
  Hasta 10\% de observaciones violando k = 5
\end{itemize}

A continuaci√≥n, la gu√≠a presenta paso a paso como proceder con este conjunto de datos para lograr el cumplimiento de estos umbrales de riesgo.

\hypertarget{paso-uno-definiciones-previas-al-proceso-de-anonimizaciuxf3n}{%
\section{Paso Uno: Definiciones previas al proceso de anonimizaci√≥n}\label{paso-uno-definiciones-previas-al-proceso-de-anonimizaciuxf3n}}

\hypertarget{definiciuxf3n-del-equipo-de-trabajo}{%
\subsection{Definici√≥n del equipo de trabajo}\label{definiciuxf3n-del-equipo-de-trabajo}}

En esta primera etapa, se define el equipo de trabajo, el cual debe estar compuesto al menos por un encargado tem√°tico, encargado de los criterios para la selecci√≥n de variables claves y definici√≥n de escenarios, y un analista de anonimizaci√≥n, encargando de la implementaci√≥n de la misma a trav√©s de un \emph{script} como el aqu√≠ expuesto.

\hypertarget{insumos-yo-productos-necesarios-para-la-ejecuciuxf3n-del-proceso}{%
\subsection{Insumos y/o productos necesarios para la ejecuci√≥n del proceso}\label{insumos-yo-productos-necesarios-para-la-ejecuciuxf3n-del-proceso}}

En esta etapa se describe la metodolog√≠a del producto estad√≠stico, la revisi√≥n tem√°tica de la base de datos, su caracterizaci√≥n y clasificaci√≥n de variables, la infraestructura con que se cuenta para el proceso, entre otros elementos que se especifican en el documento adjunto.

\hypertarget{archivo-de-base-de-datos}{%
\subsubsection{Archivo de Base de datos}\label{archivo-de-base-de-datos}}

Antes de cargar los datos, declaramos el directorio de trabajo donde se ubican los archivos con que trabajaremos.

\begin{example}
\protect\hypertarget{exm:bloque1nbm}{}{\label{exm:bloque1nbm} }Indicar el directorio de trabajo
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{yourdirectory<-}\StringTok{"~/2023/SDC_traing_julio/simulacion"} 
\KeywordTok{setwd}\NormalTok{(yourdirectory)}
\end{Highlighting}
\end{Shaded}

Se trabaja con la base bruta de la ENUSC, que contiene todas las variables previo a la innominaci√≥n (en este caso es una base de datos sint√©tica).

\begin{example}
\protect\hypertarget{exm:bloque2nbm}{}{\label{exm:bloque2nbm} }Indicar el nombre del archivo de datos
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fname <-}\StringTok{ "BD_ENUSC_SINTETICA_ETIQUETADA.sav"}
\NormalTok{file <-}\StringTok{ }\NormalTok{haven}\OperatorTok{::}\KeywordTok{read_sav}\NormalTok{(fname)}
\end{Highlighting}
\end{Shaded}

\hypertarget{caracterizaciuxf3n-de-la-base-de-datos}{%
\subsubsection{Caracterizaci√≥n de la base de datos}\label{caracterizaciuxf3n-de-la-base-de-datos}}

Primero revisamos las dimensiones del archivo, es decir, cuantos registros y variables contiene. La base contiene 47.344 registros y 73 variables. Luego, revisamos el nombre de las variables contenido en la base de datos para verificar que se ajusta a la base con que se requiere trabajar.

\begin{example}
\protect\hypertarget{exm:bloque3nbm}{}{\label{exm:bloque3nbm} }Inspeccionar las dimensiones del conjunto de datos y los nombres de las columnas
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{dim}\NormalTok{(file)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 47344    73
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{names}\NormalTok{(file)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "enc_idr"                  "rph_ID"                  
##  [3] "enc_id"                   "enc_region"              
##  [5] "enc_rpc"                  "enc_distrito"            
##  [7] "enc_zona"                 "enc_manzana"             
##  [9] "enc_vivienda"             "IDC"                     
## [11] "enc_letraKish"            "enc_direccion"           
## [13] "enc_numero"               "enc_codfono"             
## [15] "enc_fono"                 "enc_Nombre_ID"           
## [17] "Enc_Fono_ID"              "Enc_Correo_ID"           
## [19] "enc_Nombre_K"             "enc_Edad_K"              
## [21] "Enc_Fono_K"               "Enc_Correo_K"            
## [23] "FECHA"                    "IH_residencia_habitual"  
## [25] "Hora_inicio_rph"          "rph_numeroLinea"         
## [27] "rph_nombrepila"           "rph_parentesco"          
## [29] "rph_dianacimiento"        "rph_mesnacimiento"       
## [31] "rph_agnonacimiento"       "rph_edad"                
## [33] "rph_sexo"                 "rph_idgen"               
## [35] "Kish"                     "rph_pertenencia_indigena"
## [37] "rph_nacionalidad"         "rph_migracion"           
## [39] "rph_p9"                   "rph_p10"                 
## [41] "rph_p11"                  "rph_p12"                 
## [43] "rph_p13"                  "rph_p14"                 
## [45] "Hora_termino_rph"         "P17"                     
## [47] "P24"                      "A1_1_1"                  
## [49] "A1_1_1_N_Veces"           "B1_1_1"                  
## [51] "B1_1_1_N_Veces"           "C1_1_1"                  
## [53] "C1_1_1_N_Veces"           "D1_1_1"                  
## [55] "D1_1_1_N_Veces"           "E1_1_1"                  
## [57] "E1_1_1_N_Veces"           "F1_1_1"                  
## [59] "G1_1_1"                   "G1_1_1_N_Veces"          
## [61] "H1_1_1"                   "H1_1_1_N_Veces"          
## [63] "VA_DC"                    "VP_DC"                   
## [65] "DEN_AGREG"                "RVA_DC"                  
## [67] "Hora_inicio_cc"           "Hora_termino_cc"         
## [69] "Fact_Pers"                "Fact_Hog"                
## [71] "VarStrat"                 "Conglomerado"            
## [73] "Fact_Ind"
\end{verbatim}

Es importante se√±alar que la base de datos se compone de variables de caracterizaci√≥n de los hogares y las personas (m√≥dulo de Registro de Personas en el Hogar o RPH) y variables tem√°ticas de la encuesta referidas a percepci√≥n de inseguridad y victimizaci√≥n.

Adicionalmente, la base de datos contiene pesos muestrales, que deben ser considerados durante la anonimizaci√≥n. Para el nivel hogar se utiliza Fact\_Hog, mientras que para el nivel persona se utiliza Fact\_Ind.

Adem√°s, la base de datos cuenta con variables de Conglomerado y VarStrat, que ser√°n utilizadas para declarar el dise√±o complejo y evaluar la utilidad de los datos antes y despu√©s del tratamiento de los mismos.

El archivo ``Diccionario de Variables.xlsx'' contiene la descripci√≥n de las variables contenidas en la base de datos.

\hypertarget{clasificaciuxf3n-de-variables-1}{%
\subsubsection{Clasificaci√≥n de variables}\label{clasificaciuxf3n-de-variables-1}}

Las potenciales variables clave, que podr√≠a permitir una re-identificaci√≥n, se ubican en el m√≥dulo de Registro de Personas en el Hogar (RPH), ya que permiten dar cuenta de atributos de las personas y hogares, como tambi√©n en la portada de la encuesta, donde se encuentran las variables de ubicaci√≥n geogr√°fica. Estas √∫ltimas coinciden en parte con la base de datos de Hoja de Ruta, no obstante esta base no se publica.

\hypertarget{libreruxedas-requeridas}{%
\subsubsection{Librer√≠as requeridas}\label{libreruxedas-requeridas}}

Se cargan las librer√≠as requeridas para el proceso. En caso de que no est√©n instaladas, deber√° instalarlas con la funci√≥n \texttt{install.packages()} como se muestra en el siguiente ejemplo:

\begin{example}
\protect\hypertarget{exm:bloque4nbm}{}{\label{exm:bloque4nbm} }Ejemplo de instalaci√≥n de librer√≠a
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#install.packages("nombre_libreria") }
\end{Highlighting}
\end{Shaded}

Luego, cargamos las librer√≠as:

\begin{example}
\protect\hypertarget{exm:bloque5nbm}{}{\label{exm:bloque5nbm} }Cargar librer√≠as
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(sdcMicro)  }\CommentTok{# paquete sdcMicro con funciones para el proceso SDC}
\KeywordTok{library}\NormalTok{(survey)    }\CommentTok{# para dise√±o complejo}
\KeywordTok{library}\NormalTok{(calidad)   }\CommentTok{# evaluaci√≥n de calidad de las estimaciones}
\KeywordTok{library}\NormalTok{(tidyverse) }\CommentTok{# herramientas para manipulaci√≥n de datos}
\KeywordTok{library}\NormalTok{(openxlsx)  }\CommentTok{# lectura/escritura de archivos xlsx}
\KeywordTok{library}\NormalTok{(stringr) }\CommentTok{# procesamiento de textos}
\end{Highlighting}
\end{Shaded}

\hypertarget{determinaciuxf3n-de-necesidades-de-protecciuxf3n-de-confidencialidad}{%
\subsection{Determinaci√≥n de necesidades de protecci√≥n de confidencialidad}\label{determinaciuxf3n-de-necesidades-de-protecciuxf3n-de-confidencialidad}}

En esta actividad se describen el marco normativo y convenios a tener en cuenta para la anonimizaci√≥n, las unidades estad√≠sticas contenidas en la base de datos, las variables sensibles contenidas en la base de datos, y el diagn√≥stico de necesidad de protecci√≥n de confidencialidad.

\hypertarget{unidades-estaduxedsticas}{%
\subsubsection{Unidades estad√≠sticas}\label{unidades-estaduxedsticas}}

Se verifica la cantidad de viviendas y de personas registradas en la base de datos. Para ello, se mide la cantidad de valores √∫nicos del folio de viviendas (\emph{enc\_idr}) y el folio de personas (\emph{rph\_ID}).

\textbf{Viviendas:} 18.766
\textbf{Personas:} 47.344

\begin{example}
\protect\hypertarget{exm:bloque6nbm}{}{\label{exm:bloque6nbm} }Contar la cantidad de folios a nivel de viviendas y personas
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{length}\NormalTok{(}\KeywordTok{unique}\NormalTok{(file}\OperatorTok{$}\NormalTok{enc_idr))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 18766
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{length}\NormalTok{(}\KeywordTok{unique}\NormalTok{(file}\OperatorTok{$}\NormalTok{rph_ID))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 47344
\end{verbatim}

De este modo, se da cuenta de la cantidad de unidades estad√≠sticas y de la estructura jer√°rquica de la base de datos.

\hypertarget{variables-sensibles}{%
\subsubsection{variables sensibles}\label{variables-sensibles}}

Se establecen como variables sensibles aquellas referidas a la tenencia de armas (P17), a elementos de seguridad en la vivienda (P24), y acerca de denuncia de delitos (DEN\_AGREG).

\begin{example}
\protect\hypertarget{exm:bloque7nbm}{}{\label{exm:bloque7nbm} }Guardar variables sensibles en un vector de texto
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sensibles <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{'P17'}\NormalTok{,}
               \StringTok{'P24'}\NormalTok{,}
               \StringTok{'DEN_AGREG'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Se verifica que las variables sensibles est√°n presentes en la base de datos. Se espera que esta funci√≥n devuelva el valor \emph{TRUE}.

\begin{example}
\protect\hypertarget{exm:bloque8nbm}{}{\label{exm:bloque8nbm} }Verificar presencia de variables sensibles
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{all}\NormalTok{(sensibles }\OperatorTok{%in%}\StringTok{ }\KeywordTok{names}\NormalTok{(file))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

\hypertarget{diagnuxf3stico-de-necesidad-de-protecciuxf3n-de-confidencialidad}{%
\subsubsection{Diagn√≥stico de necesidad de protecci√≥n de confidencialidad}\label{diagnuxf3stico-de-necesidad-de-protecciuxf3n-de-confidencialidad}}

Dado que las variables sensibles se encuentran presentes en el archivo de datos, corresponde aplicar el proceso SDC para asegurar la anonimizaci√≥n de los datos.

\hypertarget{propiedades-estaduxedsticas-a-preservar}{%
\subsection{Propiedades estad√≠sticas a preservar}\label{propiedades-estaduxedsticas-a-preservar}}

\hypertarget{usos-claves-de-los-datos}{%
\subsubsection{Usos claves de los datos}\label{usos-claves-de-los-datos}}

Se espera que los datos mantengan las siguientes propiedades:

\begin{itemize}
\item
  Se debe poder reproducir los indicadores principales de la encuesta con precisi√≥n, por lo que idealmente no deben modificarse, con un m√°ximo de diferencia en la estimaci√≥n no mayor a un punto porcentual (diferencia en t√©rminos absolutos, dado que las estimaciones de ENUSC son de proporci√≥n).
\item
  Adem√°s, se deben mantener las variables de desagregaci√≥n de tabulados de la encuesta, siendo estas sexo y regi√≥n. Es decir, no deben observarse valores perdidos en estas variables.
\end{itemize}

Dado que las variables tem√°ticas no corresponden a potenciales variables clave, se descuenta la posibilidad de modificar dichas variables, asegurando mantener sus propiedades estad√≠sticas.

Por ende, el foco debe estar en mantener las relaciones entre las variables de desagregaci√≥n que podr√≠an ser modificadas como sexo y regi√≥n, y las variables de los indicadores principales.

Un dato frecuentemente solicitado por transparencia es la variable comuna. Si bien el dise√±o muestral de ENUSC no permite realizar estimaciones a ese nivel de desagregaci√≥n, esta variable es de todos modos de inter√©s para los usuarios para an√°lisis a nivel descriptivo y referencial. En este sentido, es pertinente evaluar la posibilidad de mantener esta variable en la base de datos anonimizada.

Por otro lado, la variable de edad en versiones anteriores de la ENUSC se publicaba con todos los valores de la variable (semi-continua), siendo ahora publicada como tramos etarios. Dado que usuarios del mundo acad√©mico y otros investigadores dan uso a esta variable, es tambi√©n de inter√©s analizar la posibilidad de mantenerla como semi-continua

\hypertarget{indicadores-priorizados}{%
\subsubsection{Indicadores priorizados}\label{indicadores-priorizados}}

Los indicadores priorizados corresponden a:

\textbf{Victimizaci√≥n Agregada de Delitos Consumados}
Calculado en base a la variable VA\_DC, por lo que la base de datos anonimizada debe permitir calcular este indicador a nivel nacional y regional (corresponde a hogares, por lo que no es desagregable por sexo).

\textbf{Victimizaci√≥n Personal de Delitos Consumados}
Calculado en base a la variable VP\_DC, por lo que la base de datos anonimizada debe permitir calcular este indicador a nivel nacional, regional y seg√∫n sexo.

Finalmente, dado que la variable de edad es de inter√©s para el an√°lisis de c√≥mo distintos grupos etarios se ven afectados por la delincuencia, es de inter√©s que la relaci√≥n entre la variable de edad y la variable de victimizaci√≥n personal se mantenga. Esto se evaluar√° a trav√©s de un modelo de regresi√≥n log√≠stica simple.

\hypertarget{mediciuxf3n-de-utilidad}{%
\subsubsection{Medici√≥n de utilidad}\label{mediciuxf3n-de-utilidad}}

\hypertarget{reproducciuxf3n-de-estimaciones-y-desagregaciones}{%
\paragraph{Reproducci√≥n de estimaciones y desagregaciones}\label{reproducciuxf3n-de-estimaciones-y-desagregaciones}}

Dado que las variables de sexo, regi√≥n y de los indicadores principales no ser√°n modificadas se espera que estas mantengan las propiedades estad√≠sticas de la base de datos original o no tratada con la mayor fidelidad posible. Partiendo del supuesto de que estas variables no ser√°n modificadas, sino que el proceso SDC se aplicar√° sobre otras variables (principalmente otras variables del RPH), solo podr√≠a verse alteradas las estimaciones en caso de supresi√≥n de registros.

En este sentido, se espera que las estimaciones no difieran de la estimaci√≥n original en m√°s de un punto porcentual, en tanto diferencia en t√©rminos absolutos (todos los indicadores de ENUSC son de proporci√≥n).

A continuaci√≥n, se presentan las estimaciones de la ENUSC utilizando el paquete de calidad de las estimaciones desarrollado en el INE, ya que tambi√©n se espera que se mantengan los est√°ndares de calidad de las estimaciones.

Ahora, se trabaja con un conjunto que contiene solo a los informantes que respondieron la encuesta (\emph{file\_kish}), descartando al resto de los integrantes del hogar. Esto es un paso necesario para poder declarar el dise√±o complejo de la encuesta.

Se establece el dise√±o complejo para personas y para hogares:

\begin{example}
\protect\hypertarget{exm:bloque9nbm}{}{\label{exm:bloque9nbm} }Declarar el dise√±o complejo
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{file_kish <-}\StringTok{ }\NormalTok{file[file}\OperatorTok{$}\NormalTok{Kish  }\OperatorTok{%in%}\StringTok{ }\DecValTok{1}\NormalTok{,]}

\KeywordTok{options}\NormalTok{(}\DataTypeTok{survey.lonely.psu =} \StringTok{"certainty"}\NormalTok{)}

\NormalTok{dc_pers <-}\StringTok{ }\KeywordTok{svydesign}\NormalTok{(}\DataTypeTok{ids =} \OperatorTok{~}\NormalTok{Conglomerado, }
                     \DataTypeTok{strata =} \OperatorTok{~}\NormalTok{VarStrat, }
                     \DataTypeTok{data =}\NormalTok{ file_kish,}
                     \DataTypeTok{weights =} \OperatorTok{~}\NormalTok{Fact_Pers)}

\NormalTok{dc_hog <-}\StringTok{ }\KeywordTok{svydesign}\NormalTok{(}\DataTypeTok{ids =} \OperatorTok{~}\NormalTok{Conglomerado, }
                    \DataTypeTok{strata =} \OperatorTok{~}\NormalTok{VarStrat, }
                    \DataTypeTok{data =}\NormalTok{ file_kish,}
                    \DataTypeTok{weights =} \OperatorTok{~}\NormalTok{Fact_Hog)}
\end{Highlighting}
\end{Shaded}

Luego, realizamos las estimaciones desagregadas por regi√≥n y sexo, guardando las tablas para posterior evaluaci√≥n de la utilidad de los datos.

Victimizaci√≥n agregada de delitos consumados, desagregado por regi√≥n:

\begin{example}
\protect\hypertarget{exm:bloque10nbm}{}{\label{exm:bloque10nbm} }Estimar Victimizaci√≥n Agregada a nivel regional, con estandar de calidad INE
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{insumos_prop <-}\StringTok{ }\KeywordTok{create_prop}\NormalTok{(}\DataTypeTok{var =} \StringTok{'VA_DC'}\NormalTok{, }
                                   \DataTypeTok{domains =} \StringTok{'enc_region'}\NormalTok{, }
                                   \DataTypeTok{design =}\NormalTok{  dc_hog)}

\NormalTok{VA_DC_REG_PRE <-}\StringTok{ }\KeywordTok{assess}\NormalTok{(insumos_prop)}
\NormalTok{VA_DC_REG_PRE[}\DecValTok{1}\OperatorTok{:}\DecValTok{6}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    enc_region      stat         se   df    n         cv
## 1           1 0.5180939 0.01656239 1117 1283 0.03196793
## 2           2 0.4986086 0.02015781  701  834 0.04042813
## 3           3 0.5025207 0.01687235 1048 1224 0.03357544
## 4           4 0.5096128 0.01963187  763  892 0.03852312
## 5           5 0.5046148 0.01265927 1821 2106 0.02508700
## 6           6 0.4937284 0.01719661 1017 1169 0.03483011
## 7           7 0.5193102 0.01797112  920 1067 0.03460576
## 8           8 0.5170244 0.01427234 1474 1724 0.02760477
## 9           9 0.5070849 0.01951509  753  889 0.03848486
## 10         10 0.5261810 0.01672262 1085 1251 0.03178111
## 11         11 0.5240267 0.01849898  903 1066 0.03530160
## 12         12 0.5167737 0.01889486  796  932 0.03656313
## 13         13 0.5084057 0.02151621  604  731 0.04232094
## 14         14 0.5096388 0.01751652  975 1135 0.03437047
## 15         15 0.5026934 0.01590767 1191 1365 0.03164488
## 16         16 0.4899313 0.01751388  929 1098 0.03574763
\end{verbatim}

Victimizaci√≥n personal de delitos consumados, desagregado por sexo:

\begin{example}
\protect\hypertarget{exm:bloque11nbm}{}{\label{exm:bloque11nbm} }Estimar Victimizaci√≥n Personal seg√∫n sexo, con estandar de calidad INE
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{insumos_prop <-}\StringTok{ }\KeywordTok{create_prop}\NormalTok{(}\DataTypeTok{var =} \StringTok{'VP_DC'}\NormalTok{, }
                                   \DataTypeTok{domains =} \StringTok{'rph_sexo'}\NormalTok{, }
                                   \DataTypeTok{design =}\NormalTok{  dc_pers}
\NormalTok{                                )}

\NormalTok{VP_DC_SEXO_PRE <-}\StringTok{ }\KeywordTok{assess}\NormalTok{(insumos_prop)}
\NormalTok{VP_DC_SEXO_PRE[}\DecValTok{1}\OperatorTok{:}\DecValTok{6}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   rph_sexo      stat          se   df    n         cv
## 1        1 0.2526373 0.005327597 6721 9439 0.02108793
## 2        2 0.2447268 0.005269227 6590 9327 0.02153106
\end{verbatim}

Victimizaci√≥n personal de delitos consumados, desagregado por regi√≥n:

\begin{example}
\protect\hypertarget{exm:bloque12nbm}{}{\label{exm:bloque12nbm} }Estimar Victimizaci√≥n Personal a nivel regional, con estandar de calidad INE
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{insumos_prop <-}\StringTok{ }\KeywordTok{create_prop}\NormalTok{(}\DataTypeTok{var =} \StringTok{'VP_DC'}\NormalTok{, }
                                   \DataTypeTok{domains =} \StringTok{'enc_region'}\NormalTok{, }
                                   \DataTypeTok{design =}\NormalTok{  dc_pers)}

\NormalTok{VP_DC_REG_PRE <-}\StringTok{ }\KeywordTok{assess}\NormalTok{(insumos_prop)}
\NormalTok{VP_DC_REG_PRE[}\DecValTok{1}\OperatorTok{:}\DecValTok{6}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    enc_region      stat         se   df    n         cv
## 1           1 0.2568172 0.01420410 1117 1283 0.05530824
## 2           2 0.2313854 0.01700058  701  834 0.07347300
## 3           3 0.2379758 0.01447234 1048 1224 0.06081436
## 4           4 0.2475154 0.01704076  763  892 0.06884725
## 5           5 0.2422258 0.01087581 1821 2106 0.04489945
## 6           6 0.2521763 0.01503618 1017 1169 0.05962565
## 7           7 0.2685464 0.01612499  920 1067 0.06004546
## 8           8 0.2611829 0.01250193 1474 1724 0.04786657
## 9           9 0.2412502 0.01739434  753  889 0.07210085
## 10         10 0.2361271 0.01413669 1085 1251 0.05986900
## 11         11 0.2773473 0.01612302  903 1066 0.05813297
## 12         12 0.2396374 0.01618739  796  932 0.06754952
## 13         13 0.2462710 0.01884833  604  731 0.07653493
## 14         14 0.2527983 0.01529804  975 1135 0.06051481
## 15         15 0.2404411 0.01327941 1191 1365 0.05522937
## 16         16 0.2431671 0.01512454  929 1098 0.06219815
\end{verbatim}

Victimizaci√≥n personal de delitos consumados, desagregado por sexo y regi√≥n:

\begin{example}
\protect\hypertarget{exm:bloque13nbm}{}{\label{exm:bloque13nbm} }Estimar Victimizaci√≥n Personal a nivel regional y seg√∫n sexo, con estandar de calidad INE
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{insumos_prop <-}\StringTok{ }\KeywordTok{create_prop}\NormalTok{(}\DataTypeTok{var =} \StringTok{'VP_DC'}\NormalTok{, }
                                   \DataTypeTok{domains =} \StringTok{'rph_sexo+enc_region'}\NormalTok{, }
                                   \DataTypeTok{design =}\NormalTok{  dc_pers)}

\NormalTok{VP_DC_REG_SEXO_PRE <-}\StringTok{ }\KeywordTok{assess}\NormalTok{(insumos_prop)}
\NormalTok{VP_DC_REG_SEXO_PRE[}\DecValTok{1}\OperatorTok{:}\DecValTok{6}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    rph_sexo enc_region      stat         se  df    n
## 1         1          1 0.2612492 0.01993875 541  660
## 2         2          1 0.2522270 0.02020040 508  623
## 3         1          2 0.2138315 0.02274576 317  428
## 4         2          2 0.2493531 0.02527904 304  406
## 5         1          3 0.2392046 0.02068420 485  600
## 6         2          3 0.2367133 0.02041682 501  624
## 7         1          4 0.2571475 0.02439808 340  440
## 8         2          4 0.2388935 0.02367246 342  452
## 9         1          5 0.2582590 0.01563089 921 1067
## 10        2          5 0.2261775 0.01500918 889 1039
## 11        1          6 0.2557568 0.02147664 472  582
## 12        2          6 0.2486357 0.02088754 469  587
## 13        1          7 0.2751938 0.02324332 429  540
## 14        2          7 0.2616656 0.02226621 412  527
## 15        1          8 0.2826785 0.01822327 688  829
## 16        2          8 0.2408143 0.01715973 746  895
## 17        1          9 0.2479841 0.02381286 359  467
## 18        2          9 0.2333432 0.02543398 316  422
## 19        1         10 0.2458082 0.01995371 521  639
## 20        2         10 0.2262334 0.01988504 492  612
## 21        1         11 0.2660547 0.02254731 422  531
## 22        2         11 0.2894683 0.02341303 418  535
## 23        1         12 0.2383125 0.02254203 365  475
## 24        2         12 0.2410698 0.02307637 352  457
## 25        1         13 0.2515748 0.02693269 252  356
## 26        2         13 0.2411737 0.02646547 273  375
## 27        1         14 0.2533536 0.02087620 490  598
## 28        2         14 0.2521585 0.02282616 414  537
## 29        1         15 0.2408291 0.01870310 565  686
## 30        2         15 0.2400561 0.01891161 562  679
## 31        1         16 0.2262722 0.02063687 425  541
## 32        2         16 0.2592696 0.02167361 442  557
\end{verbatim}

Se espera que la base de datos anonimizada mantenga las propiedades aqu√≠ expuestas, por lo que se almacenan en objetos para su posterior comparaci√≥n con los datos tratados.

Por otro lado, dado que queremos mantener la utilidad de los datos en relaci√≥n con edad, se mide la relaci√≥n entre la variable edad y la variable VP\_DC, lo cual se deber√≠a mantener en caso que se deba recodificar la edad en tramos.

\hypertarget{relaciuxf3n-entre-variable-de-edad-y-victimizaciuxf3n-personal}{%
\paragraph{Relaci√≥n entre variable de edad y victimizaci√≥n personal}\label{relaciuxf3n-entre-variable-de-edad-y-victimizaciuxf3n-personal}}

Se genera un modelo \emph{logit} con la variable de Victimizaci√≥n Personal como dependiente y con la variable de edad como regresor. Se espera que los resultados aqu√≠ obtenidos sean similares con los datos tratados, lo que se evaluar√° al final del proceso de anonimizaci√≥n.

\textbf{Carga de datos}

Primero, se cargan los datos, y se filtran dejando solo al informante Kish.

\begin{example}
\protect\hypertarget{exm:bloque14nbm}{}{\label{exm:bloque14nbm} }Generar dataframe para modelo
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data <-}\StringTok{ }\NormalTok{file[file}\OperatorTok{$}\NormalTok{Kish }\OperatorTok{%in%}\StringTok{ }\DecValTok{1}\NormalTok{,]}
\end{Highlighting}
\end{Shaded}

\textbf{Dividir datos en \emph{training} y \emph{testing} sets}

Luego, se dividen los datos en sets de training y testing.

\begin{example}
\protect\hypertarget{exm:bloque15nbm}{}{\label{exm:bloque15nbm} }Dividir datos en \emph{training} y \emph{testing} sets
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(caTools)}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{2022}\NormalTok{)}

\NormalTok{ids_train <-}\StringTok{ }\KeywordTok{sample}\NormalTok{(data}\OperatorTok{$}\NormalTok{rph_ID, }\KeywordTok{nrow}\NormalTok{(data)}\OperatorTok{/}\DecValTok{3}\OperatorTok{*}\DecValTok{2}\NormalTok{)}
\NormalTok{training<-}\StringTok{ }\NormalTok{sjlabelled}\OperatorTok{::}\KeywordTok{remove_all_labels}\NormalTok{(data[data}\OperatorTok{$}\NormalTok{rph_ID }\OperatorTok{%in%}\StringTok{ }\NormalTok{ids_train,])}
\NormalTok{testing<-}\StringTok{ }\NormalTok{sjlabelled}\OperatorTok{::}\KeywordTok{remove_all_labels}\NormalTok{(data[}\OperatorTok{!}\NormalTok{data}\OperatorTok{$}\NormalTok{rph_ID }\OperatorTok{%in%}\StringTok{ }\NormalTok{ids_train,])}
\end{Highlighting}
\end{Shaded}

\textbf{Construir modelo}

Luego, construimos el modelo utilizando la funci√≥n \texttt{glm()}.

\begin{example}
\protect\hypertarget{exm:bloque16nbm}{}{\label{exm:bloque16nbm} }Construir modelo
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{modelo<-}\KeywordTok{glm}\NormalTok{(VP_DC}\OperatorTok{~}\NormalTok{rph_edad, }
            \DataTypeTok{data=}\NormalTok{training, }
            \DataTypeTok{family =} \StringTok{"binomial"}\NormalTok{)}
\KeywordTok{summary}\NormalTok{(modelo)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## glm(formula = VP_DC ~ rph_edad, family = "binomial", data = training)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -0.8025  -0.7661  -0.7320  -0.6980   1.7502  
## 
## Coefficients:
##               Estimate Std. Error z value Pr(>|z|)    
## (Intercept) -1.3401916  0.0525124  -25.52  < 2e-16 ***
## rph_edad     0.0034786  0.0007714    4.51  6.5e-06 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 13933  on 12509  degrees of freedom
## Residual deviance: 13912  on 12508  degrees of freedom
## AIC: 13916
## 
## Number of Fisher Scoring iterations: 4
\end{verbatim}

\textbf{Validaci√≥n de modelo}

Luego aplicamos el test de Hosmer Lemeshow para validar el modelo.

\begin{example}
\protect\hypertarget{exm:bloque17nbm}{}{\label{exm:bloque17nbm} }Validaci√≥n de modelo
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(ResourceSelection)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## ResourceSelection 0.3-5   2019-07-22
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{hoslem.test}\NormalTok{(modelo}\OperatorTok{$}\NormalTok{y,}\KeywordTok{fitted}\NormalTok{(modelo),}\DataTypeTok{g=}\DecValTok{10}\NormalTok{) }\CommentTok{# Test de Hosmer Lemeshow}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Hosmer and Lemeshow goodness of fit (GOF) test
## 
## data:  modelo$y, fitted(modelo)
## X-squared = 255.13, df = 8, p-value < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(pROC)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Type 'citation("pROC")' for a citation.
\end{verbatim}

\begin{verbatim}
## 
## Attaching package: 'pROC'
\end{verbatim}

\begin{verbatim}
## The following objects are masked from 'package:stats':
## 
##     cov, smooth, var
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{indiceC.trainig<-}\KeywordTok{roc}\NormalTok{(modelo}\OperatorTok{$}\NormalTok{y,}\KeywordTok{fitted}\NormalTok{(modelo))     }\CommentTok{# Curva ROC}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Setting levels: control = 0, case = 1
\end{verbatim}

\begin{verbatim}
## Setting direction: controls < cases
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{indiceC.trainig}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## roc.default(response = modelo$y, predictor = fitted(modelo))
## 
## Data: fitted(modelo) in 9444 controls (modelo$y 0) < 3066 cases (modelo$y 1).
## Area under the curve: 0.5272
\end{verbatim}

\textbf{Punto de corte √≥ptimo}

Se calcula el punto de corte √≥ptimo utilizando la funci√≥n \texttt{coords()}.

\begin{example}
\protect\hypertarget{exm:bloque18nbm}{}{\label{exm:bloque18nbm} }Calcular punto de corte √≥ptimo
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ptocorteop.training<-}\KeywordTok{coords}\NormalTok{(indiceC.trainig,}\DataTypeTok{x=}\StringTok{"best"}\NormalTok{,}
                            \DataTypeTok{input=}\StringTok{"threshold"}\NormalTok{,}
                            \DataTypeTok{best.method=}\StringTok{"youden"}\NormalTok{)}
\NormalTok{ptocorteop.training}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   threshold specificity sensitivity
## 1  0.270795   0.9431385   0.1457926
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(ROCR)}
\NormalTok{ROC.training<-}\KeywordTok{performance}\NormalTok{(}\DataTypeTok{prediction.obj =} \KeywordTok{prediction}\NormalTok{(}\DataTypeTok{predictions =} \KeywordTok{fitted}\NormalTok{(modelo),}
                                                      \DataTypeTok{labels =} \KeywordTok{as.factor}\NormalTok{(modelo}\OperatorTok{$}\NormalTok{y)),}
                          \StringTok{"tpr"}\NormalTok{,}
                          \StringTok{"fpr"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Luego, visualizamos el punto de corte √≥ptimo utilizando la funci√≥n \texttt{plot()}.

\begin{example}
\protect\hypertarget{exm:bloque19nbm}{}{\label{exm:bloque19nbm} }Visualizar punto de corte √≥ptimo
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(ROC.training, }\DataTypeTok{colorize=}\OtherTok{TRUE}\NormalTok{, }\DataTypeTok{print.cutoffs.at=}\KeywordTok{seq}\NormalTok{(}\FloatTok{0.1}\NormalTok{, }\DataTypeTok{by=}\FloatTok{0.1}\NormalTok{))}
\KeywordTok{abline}\NormalTok{(}\DataTypeTok{a=}\DecValTok{0}\NormalTok{,}\DataTypeTok{b=}\DecValTok{1}\NormalTok{)}
\KeywordTok{abline}\NormalTok{(}\DataTypeTok{v=}\NormalTok{ptocorteop.training}\OperatorTok{$}\NormalTok{threshold,}\DataTypeTok{col=}\StringTok{"red"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\includegraphics[width=0.9\linewidth]{bookdown-demo_files/figure-latex/unnamed-chunk-92-1} \caption{Punto de corte √≥ptimo con datos no tratados}\label{fig:unnamed-chunk-92}
\end{figure}

\textbf{Predicciones y matriz de confusi√≥n}

Se realizan predicciones y se genera una matriz de confusi√≥n.

\begin{example}
\protect\hypertarget{exm:bloque20nbm}{}{\label{exm:bloque20nbm} }Predicciones y matriz de confusi√≥n
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pred.training<-}\KeywordTok{predict}\NormalTok{(modelo, }\DataTypeTok{data=}\NormalTok{training, }\DataTypeTok{type=}\StringTok{"response"}\NormalTok{)}
\KeywordTok{table}\NormalTok{(}\DataTypeTok{ActualValue=}\NormalTok{training}\OperatorTok{$}\NormalTok{VP_DC, }
      \DataTypeTok{PredictValue=}\NormalTok{pred.training}\OperatorTok{>}\NormalTok{ptocorteop.training}\OperatorTok{$}\NormalTok{threshold)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##            PredictValue
## ActualValue FALSE TRUE
##           0  8907  537
##           1  2619  447
\end{verbatim}

A continuaci√≥n, se continua la evaluaci√≥n del modelo con datos de prueba.

\textbf{Validaci√≥n de modelo (con datos de prueba)}

Aplicamos nuevamente la validaci√≥n con el test de Hosmer Lemeshow, esta vez con los datos de prueba.

\begin{example}
\protect\hypertarget{exm:bloque21nbm}{}{\label{exm:bloque21nbm} }Validaci√≥n de modelo con datos de prueba
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{hoslem.test}\NormalTok{(testing}\OperatorTok{$}\NormalTok{VP_DC,}\KeywordTok{predict}\NormalTok{(modelo,}\DataTypeTok{newdata=}\NormalTok{testing,}\DataTypeTok{type=}\StringTok{"response"}\NormalTok{),}\DataTypeTok{g=}\DecValTok{5}\NormalTok{)   }\CommentTok{# Test de Hosmer Lemeshow}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Hosmer and Lemeshow goodness of fit (GOF) test
## 
## data:  testing$VP_DC, predict(modelo, newdata = testing, type = "response")
## X-squared = 60.369, df = 3, p-value = 4.903e-13
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{indiceC.testing=}\KeywordTok{roc}\NormalTok{(testing}\OperatorTok{$}\NormalTok{VP_DC,}\KeywordTok{predict}\NormalTok{(modelo,}\DataTypeTok{newdata=}\NormalTok{testing,}\DataTypeTok{type=}\StringTok{"response"}\NormalTok{)) }\CommentTok{# Curva ROC}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Setting levels: control = 0, case = 1
\end{verbatim}

\begin{verbatim}
## Setting direction: controls < cases
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{indiceC.testing}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## roc.default(response = testing$VP_DC, predictor = predict(modelo,     newdata = testing, type = "response"))
## 
## Data: predict(modelo, newdata = testing, type = "response") in 4666 controls (testing$VP_DC 0) < 1590 cases (testing$VP_DC 1).
## Area under the curve: 0.5203
\end{verbatim}

\textbf{Punto de corte √≥ptimo (con datos de prueba)}

Se calcula el punto de corte √≥ptimo utilizando la funci√≥n \texttt{coords()}.

\begin{example}
\protect\hypertarget{exm:bloque22nbm}{}{\label{exm:bloque22nbm} }Calcular de corte √≥ptimo con datos de prueba
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ptocorteop.testing<-}\KeywordTok{coords}\NormalTok{(indiceC.testing,}\DataTypeTok{x=}\StringTok{"best"}\NormalTok{,}\DataTypeTok{input=}\StringTok{"threshold"}\NormalTok{,}\DataTypeTok{best.method=}\StringTok{"youden"}\NormalTok{)}
\NormalTok{ptocorteop.testing}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   threshold specificity sensitivity
## 1 0.2633057   0.8317617   0.2440252
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ROC.testing<-}\KeywordTok{performance}\NormalTok{(}\KeywordTok{prediction}\NormalTok{(}\KeywordTok{predict}\NormalTok{(modelo,}\DataTypeTok{newdata=}\NormalTok{testing,}\DataTypeTok{type=}\StringTok{"response"}\NormalTok{),}
                                    \KeywordTok{as.factor}\NormalTok{(testing}\OperatorTok{$}\NormalTok{VP_DC)),}\StringTok{"tpr"}\NormalTok{,}\StringTok{"fpr"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Luego, visualizamos el punto de corte √≥ptimo utilizando la funci√≥n \texttt{plot()}.

\begin{example}
\protect\hypertarget{exm:bloque23nbm}{}{\label{exm:bloque23nbm} }Visualizar de corte √≥ptimo con datos de prueba
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(ROC.testing, }\DataTypeTok{colorize=}\OtherTok{TRUE}\NormalTok{, }\DataTypeTok{print.cutoffs.at=}\KeywordTok{seq}\NormalTok{(}\FloatTok{0.1}\NormalTok{, }\DataTypeTok{by=}\FloatTok{0.1}\NormalTok{))}
\KeywordTok{abline}\NormalTok{(}\DataTypeTok{a=}\DecValTok{0}\NormalTok{,}\DataTypeTok{b=}\DecValTok{1}\NormalTok{)}
\KeywordTok{abline}\NormalTok{(}\DataTypeTok{v=}\NormalTok{ptocorteop.testing}\OperatorTok{$}\NormalTok{threshold,}\DataTypeTok{col=}\StringTok{"red"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\includegraphics[width=0.9\linewidth]{bookdown-demo_files/figure-latex/unnamed-chunk-96-1} \caption{Punto de corte √≥ptimo con datos de prueba a partir de datos no tratados}\label{fig:unnamed-chunk-96}
\end{figure}

\textbf{Predicciones y matriz de confusi√≥n (con datos de prueba)}

Se realizan predicciones y se genera una matriz de confusi√≥n.

\begin{example}
\protect\hypertarget{exm:bloque24nbm}{}{\label{exm:bloque24nbm} }Predicciones y matriz de confusi√≥n con datos de prueba
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pred.testing<-}\KeywordTok{predict}\NormalTok{(modelo, testing, }\DataTypeTok{type=}\StringTok{"response"}\NormalTok{)}
\KeywordTok{table}\NormalTok{(}\DataTypeTok{ActualValue=}\NormalTok{testing}\OperatorTok{$}\NormalTok{VP_DC, }\DataTypeTok{PredictValue=}\NormalTok{pred.testing}\OperatorTok{>}\NormalTok{ptocorteop.testing}\OperatorTok{$}\NormalTok{threshold)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##            PredictValue
## ActualValue FALSE TRUE
##           0  3881  785
##           1  1202  388
\end{verbatim}

\textbf{Comparar √°rea bajo la curva, umbral, sensibilidad y especificidad}

Finalmente, comparamos el √°rea bajo la curva, umbral, sensibilidad y especificidad, a partir de los resultados del modelo con los datos de entrenamiento y con los datos de prueba.

\begin{example}
\protect\hypertarget{exm:bloque25nbm}{}{\label{exm:bloque25nbm} }Comparar √°rea bajo la curva, umbral, sensibilidad y especificidad
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{auc    <-indiceC.trainig}\OperatorTok{$}\NormalTok{auc              }\OperatorTok{-}\StringTok{ }\NormalTok{indiceC.testing}\OperatorTok{$}\NormalTok{auc}
\NormalTok{corte  <-ptocorteop.training}\OperatorTok{$}\NormalTok{threshold    }\OperatorTok{-}\StringTok{ }\NormalTok{ptocorteop.testing}\OperatorTok{$}\NormalTok{threshold}
\NormalTok{sens   <-}\StringTok{ }\NormalTok{ptocorteop.training}\OperatorTok{$}\NormalTok{sensitivity }\OperatorTok{-}\StringTok{ }\NormalTok{ptocorteop.testing}\OperatorTok{$}\NormalTok{sensitivity}
\NormalTok{spe    <-}\StringTok{ }\NormalTok{ptocorteop.training}\OperatorTok{$}\NormalTok{specificity }\OperatorTok{-}\StringTok{ }\NormalTok{ptocorteop.testing}\OperatorTok{$}\NormalTok{specificity}
\end{Highlighting}
\end{Shaded}

\hypertarget{paso-dos-preparar-y-explorar-datos-originales}{%
\section{Paso Dos: Preparar y explorar datos originales}\label{paso-dos-preparar-y-explorar-datos-originales}}

\hypertarget{preparaciuxf3n-de-datos}{%
\subsection{Preparaci√≥n de datos}\label{preparaciuxf3n-de-datos}}

\hypertarget{integraciuxf3n-de-datos}{%
\subsubsection{Integraci√≥n de datos}\label{integraciuxf3n-de-datos}}

La base de datos ENUSC ya se encuentra integrada y no se combina con ninguna otra base producida para este producto estad√≠stico.

\hypertarget{eliminaciuxf3n-de-identificadores-directos}{%
\subsubsection{Eliminaci√≥n de identificadores directos}\label{eliminaciuxf3n-de-identificadores-directos}}

Se registra nombres de identificadores directos y otras variables internas del proyecto que no son publicadas.

\begin{example}
\protect\hypertarget{exm:bloque26nbm}{}{\label{exm:bloque26nbm} }Almacenar indicadores directos y otras variables excluidas en un vector de texto
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{identificadores_directos <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{'enc_id'}\NormalTok{,}\StringTok{'enc_distrito'}\NormalTok{,}
                              \StringTok{'enc_zona'}\NormalTok{,}\StringTok{'enc_manzana'}\NormalTok{,}\StringTok{'enc_vivienda'}\NormalTok{,}\StringTok{'FECHA'}\NormalTok{,}
                              \StringTok{'enc_Nombre_ID'}\NormalTok{,}
                              \StringTok{'enc_Nombre_K'}\NormalTok{,}\StringTok{'enc_Edad_K'}\NormalTok{,}
                              \StringTok{'rph_dianacimiento'}\NormalTok{,}\StringTok{'rph_mesnacimiento'}\NormalTok{,}
                              \StringTok{'rph_agnonacimiento'}\NormalTok{,}
                              \StringTok{'rph_nombrepila'}\NormalTok{,}\StringTok{'Hora_inicio_rph'}\NormalTok{,}
                              \StringTok{'Hora_termino_rph'}\NormalTok{,}\StringTok{'Hora_inicio_cc'}\NormalTok{,}\StringTok{'Hora_termino_cc'}\NormalTok{,}
                              \StringTok{'IDC'}\NormalTok{,}\StringTok{'enc_letraKish'}\NormalTok{,}
                              \StringTok{'enc_direccion'}\NormalTok{,}\StringTok{'enc_numero'}\NormalTok{,}\StringTok{'enc_codfono'}\NormalTok{,}
                              \StringTok{'enc_fono'}\NormalTok{,}\StringTok{'Enc_Fono_ID'}\NormalTok{,}\StringTok{'Enc_Correo_ID'}\NormalTok{,}
                              \StringTok{'Enc_Fono_K'}\NormalTok{,}\StringTok{'Enc_Correo_K'}\NormalTok{)}

\KeywordTok{all}\NormalTok{(identificadores_directos }\OperatorTok{%in%}\StringTok{ }\KeywordTok{names}\NormalTok{(file))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

Luego, se quitan estas variables de la base de datos.

\begin{example}
\protect\hypertarget{exm:bloque27nbm}{}{\label{exm:bloque27nbm} }Filtrar columnas excluidas
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{file <-}\StringTok{ }\NormalTok{file[,}\OperatorTok{!}\KeywordTok{names}\NormalTok{(file) }\OperatorTok{%in%}\StringTok{ }\NormalTok{identificadores_directos]}
\end{Highlighting}
\end{Shaded}

Tambi√©n, se quitan las variables de cadena con registros de observaciones, que tampoco corresponde publicar (en caso de que las hubiera). Estas corresponden a variables de texto que registran observaciones de terreno del encuestador y relatos de los delitos brindados por los informantes, informaci√≥n utilizada para el procesamiento de la base de datos, pero que no se consideran para su publicaci√≥n.

\begin{example}
\protect\hypertarget{exm:bloque28nbm}{}{\label{exm:bloque28nbm} }Filtrar columnas de texto y observaciones de terreno
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{file <-}\StringTok{ }\NormalTok{file[,}\OperatorTok{!}\KeywordTok{str_detect}\NormalTok{(}\KeywordTok{names}\NormalTok{(file),}\StringTok{'^Obs|Obs$'}\NormalTok{)]}
\end{Highlighting}
\end{Shaded}

\hypertarget{selecciuxf3n-de-variables}{%
\subsubsection{Selecci√≥n de Variables}\label{selecciuxf3n-de-variables}}

En principio, todas las variables restantes son pertinentes de publicar, en la medida que se cumplan los requerimientos de anonimizaci√≥n de los datos.

Para efectos de los an√°lisis siguientes y para la medici√≥n del riesgo, solo se considerar√° el siguiente listado de variables, que se considera que pueden ser utilizadas como variables clave para la re-identificaci√≥n de los informantes. Todas estas corresponden a variables de ubicaci√≥n o del RPH.

\begin{longtable}[]{@{}ll@{}}
\toprule
\begin{minipage}[b]{0.47\columnwidth}\raggedright
Variable\strut
\end{minipage} & \begin{minipage}[b]{0.47\columnwidth}\raggedright
Etiqueta\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.47\columnwidth}\raggedright
enc\_rpc\strut
\end{minipage} & \begin{minipage}[t]{0.47\columnwidth}\raggedright
Identificador de comuna\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.47\columnwidth}\raggedright
enc\_region\strut
\end{minipage} & \begin{minipage}[t]{0.47\columnwidth}\raggedright
Identificador de regi√≥n\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.47\columnwidth}\raggedright
IH\_residencia\_habitual\strut
\end{minipage} & \begin{minipage}[t]{0.47\columnwidth}\raggedright
N√∫mero de residentes habituales\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.47\columnwidth}\raggedright
rph\_edad\strut
\end{minipage} & \begin{minipage}[t]{0.47\columnwidth}\raggedright
Edad\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.47\columnwidth}\raggedright
rph\_sexo\strut
\end{minipage} & \begin{minipage}[t]{0.47\columnwidth}\raggedright
Sexo\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.47\columnwidth}\raggedright
rph\_idgen\strut
\end{minipage} & \begin{minipage}[t]{0.47\columnwidth}\raggedright
Identidad de G√©nero\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.47\columnwidth}\raggedright
rph\_pertenencia\_indigena\strut
\end{minipage} & \begin{minipage}[t]{0.47\columnwidth}\raggedright
Pertenencia a pueblos ind√≠genas\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.47\columnwidth}\raggedright
rph\_nacionalidad\strut
\end{minipage} & \begin{minipage}[t]{0.47\columnwidth}\raggedright
Nacionalidad\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.47\columnwidth}\raggedright
rph\_p14\strut
\end{minipage} & \begin{minipage}[t]{0.47\columnwidth}\raggedright
Raz√≥n para no buscar un empleo o iniciar una actividad por cuenta propia\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

El resto de las variables que no son clave, pero se consideran para la publicaci√≥n, se mantienen en el archivo de datos (variables tem√°ticas sobre percepci√≥n de inseguridad y victimizaci√≥n).

\hypertarget{consolidaciuxf3n-de-variables}{%
\subsubsection{Consolidaci√≥n de variables}\label{consolidaciuxf3n-de-variables}}

De las variables reci√©n descritas, la variable comuna se encuentra anidada en la variable de regi√≥n, por lo que hay redundancia al mantener ambas. Dado que comuna (enc\_rpc) tiene mayor nivel de informaci√≥n, se utilizar√° primero esta variable para los siguientes an√°lisis y la medici√≥n de riesgo, incluyendo regi√≥n solo en caso de que sea necesario retirar la variable de comuna.

A continuaci√≥n, se transforman y consolidan variables para poder aplicar adecuadamente los an√°lisis.

Primero, las variables de comparte gastos y n√∫mero de grupos se excluyen del an√°lisis, ya que son redundantes con la cantidad de residentes habituales y cantidad de hogares, siendo utilizadas solo estas √∫ltimas dos.

Se fusionan categor√≠as trans y otros, dado que son poco frecuentes.

\begin{example}
\protect\hypertarget{exm:bloque29nbm}{}{\label{exm:bloque29nbm} }Consolidar categor√≠as de identidad de g√©nero y sus valores perdidos
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{file}\OperatorTok{$}\NormalTok{rph_idgen[file}\OperatorTok{$}\NormalTok{rph_idgen }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{)] <-}\StringTok{ }\DecValTok{3}
\NormalTok{file}\OperatorTok{$}\NormalTok{rph_idgen[file}\OperatorTok{$}\NormalTok{rph_idgen }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{88}\NormalTok{,}\DecValTok{99}\NormalTok{,}\DecValTok{96}\NormalTok{)] <-}\StringTok{ }\OtherTok{NA}
\end{Highlighting}
\end{Shaded}

Se recodifican perdidos en diversas variables clave.

\begin{example}
\protect\hypertarget{exm:bloque30nbm}{}{\label{exm:bloque30nbm} }Recodificar valores perdidos de pertenencia ind√≠gena
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{file}\OperatorTok{$}\NormalTok{rph_pertenencia_indigena[file}\OperatorTok{$}\NormalTok{rph_pertenencia_indigena }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{88}\NormalTok{,}\DecValTok{99}\NormalTok{,}\DecValTok{96}\NormalTok{)] <-}\StringTok{ }\OtherTok{NA}
\NormalTok{file}\OperatorTok{$}\NormalTok{rph_nacionalidad[file}\OperatorTok{$}\NormalTok{rph_nacionalidad }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{88}\NormalTok{,}\DecValTok{99}\NormalTok{,}\DecValTok{96}\NormalTok{)] <-}\StringTok{ }\OtherTok{NA}
\NormalTok{file}\OperatorTok{$}\NormalTok{rph_p14[file}\OperatorTok{$}\NormalTok{rph_p14 }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{88}\NormalTok{,}\DecValTok{99}\NormalTok{,}\DecValTok{96}\NormalTok{)] <-}\StringTok{ }\OtherTok{NA}
\end{Highlighting}
\end{Shaded}

Consolidamos variable de situaci√≥n ocupacional, ya que de otro modo tiene muchos valores perdidos por flujo, y apuntan a una sola clasificaci√≥n con tres categor√≠as que es lo m√°s relevante.

\begin{example}
\protect\hypertarget{exm:bloque31nbm}{}{\label{exm:bloque31nbm} }Consolidar situaci√≥n ocupacional
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Generamos variable vac√≠a}
\NormalTok{file}\OperatorTok{$}\NormalTok{rph_situacion_ocupacional <-}\StringTok{ }\OtherTok{NA}

\CommentTok{# Ocupados}
\NormalTok{file}\OperatorTok{$}\NormalTok{rph_situacion_ocupacional[file}\OperatorTok{$}\NormalTok{rph_p9 }\OperatorTok{%in%}\StringTok{ }\DecValTok{1} \OperatorTok{|}\StringTok{ }\NormalTok{file}\OperatorTok{$}\NormalTok{rph_p10 }\OperatorTok{%in%}\StringTok{ }\DecValTok{1}\NormalTok{] <-}\StringTok{ }\DecValTok{1}

\CommentTok{# Desocupados}
\NormalTok{file}\OperatorTok{$}\NormalTok{rph_situacion_ocupacional[file}\OperatorTok{$}\NormalTok{rph_p12 }\OperatorTok{%in%}\StringTok{ }\DecValTok{1} \OperatorTok{&}\StringTok{ }\NormalTok{file}\OperatorTok{$}\NormalTok{rph_p13 }\OperatorTok{%in%}\StringTok{ }\DecValTok{1}\NormalTok{] <-}\StringTok{ }\DecValTok{2}

\CommentTok{# Inactivos}
\NormalTok{file}\OperatorTok{$}\NormalTok{rph_situacion_ocupacional[file}\OperatorTok{$}\NormalTok{rph_p12 }\OperatorTok{%in%}\StringTok{ }\DecValTok{2} \OperatorTok{|}\StringTok{ }\NormalTok{file}\OperatorTok{$}\NormalTok{rph_p13 }\OperatorTok{%in%}\StringTok{ }\DecValTok{2}\NormalTok{] <-}\StringTok{ }\DecValTok{3}

\CommentTok{# Revisamos}
\KeywordTok{table}\NormalTok{(file}\OperatorTok{$}\NormalTok{rph_situacion_ocupacional)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##     1     2     3 
## 30364  2470  7498
\end{verbatim}

Luego, integramos algunas categor√≠as de inactivos con la condici√≥n de inactividad, ya que esto especifica subtipos de los inactivos que pueden ser relevantes para la re-identificaci√≥n. Se agrupan las categor√≠as que no son claves para re-identificar.

\begin{example}
\protect\hypertarget{exm:bloque32nbm}{}{\label{exm:bloque32nbm} }Consolidar situaci√≥n ocupacional con categor√≠as de inactivos.
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Inactivo - Otros}
\NormalTok{file}\OperatorTok{$}\NormalTok{rph_situacion_ocupacional[file}\OperatorTok{$}\NormalTok{rph_situacion_ocupacional }\OperatorTok{%in%}\StringTok{ }\DecValTok{3} \OperatorTok{&}
\StringTok{                                 }\NormalTok{(file}\OperatorTok{$}\NormalTok{rph_p14 }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{7}\NormalTok{) }\OperatorTok{|}\StringTok{ }\KeywordTok{is.na}\NormalTok{(file}\OperatorTok{$}\NormalTok{rph_p14))] <-}\StringTok{ }\DecValTok{3} 

\CommentTok{# Inactivo - Estudiante}
\NormalTok{file}\OperatorTok{$}\NormalTok{rph_situacion_ocupacional[file}\OperatorTok{$}\NormalTok{rph_situacion_ocupacional }\OperatorTok{%in%}\StringTok{ }\DecValTok{3} \OperatorTok{&}
\StringTok{                                 }\NormalTok{file}\OperatorTok{$}\NormalTok{rph_p14 }\OperatorTok{%in%}\StringTok{ }\DecValTok{3}\NormalTok{] <-}\StringTok{ }\DecValTok{4} 

\CommentTok{# Inactivo - Jubilado, pensionado o rentista}
\NormalTok{file}\OperatorTok{$}\NormalTok{rph_situacion_ocupacional[file}\OperatorTok{$}\NormalTok{rph_situacion_ocupacional }\OperatorTok{%in%}\StringTok{ }\DecValTok{3} \OperatorTok{&}
\StringTok{                                 }\NormalTok{file}\OperatorTok{$}\NormalTok{rph_p14 }\OperatorTok{%in%}\StringTok{ }\DecValTok{4}\NormalTok{] <-}\StringTok{ }\DecValTok{5} 

\CommentTok{# Inactivo - Motivos de salud permanentes}
\NormalTok{file}\OperatorTok{$}\NormalTok{rph_situacion_ocupacional[file}\OperatorTok{$}\NormalTok{rph_situacion_ocupacional }\OperatorTok{%in%}\StringTok{ }\DecValTok{3} \OperatorTok{&}
\StringTok{                                 }\NormalTok{file}\OperatorTok{$}\NormalTok{rph_p14 }\OperatorTok{%in%}\StringTok{ }\DecValTok{5}\NormalTok{] <-}\StringTok{ }\DecValTok{6} 

\CommentTok{# Revisamos}
\KeywordTok{table}\NormalTok{(file}\OperatorTok{$}\NormalTok{rph_situacion_ocupacional)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##     1     2     3     4     5     6 
## 30364  2470  5358   730   718   692
\end{verbatim}

Finalmente, se convierten las variables categ√≥ricas a tipo factor, quit√°ndole el etiquetado de \texttt{haven}, ya que causa problemas con \texttt{sdcMicro}.

\begin{example}
\protect\hypertarget{exm:bloque33nbm}{}{\label{exm:bloque33nbm} }Convertir variables clave a factor
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{file}\OperatorTok{$}\NormalTok{enc_region <-}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(}\KeywordTok{as.numeric}\NormalTok{(file}\OperatorTok{$}\NormalTok{enc_region))}
\NormalTok{file}\OperatorTok{$}\NormalTok{enc_rpc <-}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(}\KeywordTok{as.numeric}\NormalTok{(file}\OperatorTok{$}\NormalTok{enc_rpc))}
\NormalTok{file}\OperatorTok{$}\NormalTok{rph_sexo <-}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(}\KeywordTok{as.numeric}\NormalTok{(file}\OperatorTok{$}\NormalTok{rph_sexo ))}
\NormalTok{file}\OperatorTok{$}\NormalTok{rph_idgen <-}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(}\KeywordTok{as.numeric}\NormalTok{(file}\OperatorTok{$}\NormalTok{rph_idgen))}
\NormalTok{file}\OperatorTok{$}\NormalTok{rph_pertenencia_indigena <-}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(}\KeywordTok{as.numeric}\NormalTok{(file}\OperatorTok{$}\NormalTok{rph_pertenencia_indigena))}
\NormalTok{file}\OperatorTok{$}\NormalTok{rph_nacionalidad <-}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(}\KeywordTok{as.numeric}\NormalTok{(file}\OperatorTok{$}\NormalTok{rph_nacionalidad))}
\NormalTok{file}\OperatorTok{$}\NormalTok{rph_situacion_ocupacional <-}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(}\KeywordTok{as.numeric}\NormalTok{(file}\OperatorTok{$}\NormalTok{rph_situacion_ocupacional))}
\end{Highlighting}
\end{Shaded}

\hypertarget{exploraciuxf3n-del-conjunto-de-datos}{%
\subsection{Exploraci√≥n del conjunto de datos}\label{exploraciuxf3n-del-conjunto-de-datos}}

Primero, revisamos cu√°les variables tenemos en la base de datos en este punto del proceso.

\begin{example}
\protect\hypertarget{exm:bloque34nbm}{}{\label{exm:bloque34nbm} }Revisar nuevamente variables presente en conjunto de datos
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{names}\NormalTok{(file)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "enc_idr"                   "rph_ID"                   
##  [3] "enc_region"                "enc_rpc"                  
##  [5] "IH_residencia_habitual"    "rph_numeroLinea"          
##  [7] "rph_parentesco"            "rph_edad"                 
##  [9] "rph_sexo"                  "rph_idgen"                
## [11] "Kish"                      "rph_pertenencia_indigena" 
## [13] "rph_nacionalidad"          "rph_migracion"            
## [15] "rph_p9"                    "rph_p10"                  
## [17] "rph_p11"                   "rph_p12"                  
## [19] "rph_p13"                   "rph_p14"                  
## [21] "P17"                       "P24"                      
## [23] "A1_1_1"                    "A1_1_1_N_Veces"           
## [25] "B1_1_1"                    "B1_1_1_N_Veces"           
## [27] "C1_1_1"                    "C1_1_1_N_Veces"           
## [29] "D1_1_1"                    "D1_1_1_N_Veces"           
## [31] "E1_1_1"                    "E1_1_1_N_Veces"           
## [33] "F1_1_1"                    "G1_1_1"                   
## [35] "G1_1_1_N_Veces"            "H1_1_1"                   
## [37] "H1_1_1_N_Veces"            "VA_DC"                    
## [39] "VP_DC"                     "DEN_AGREG"                
## [41] "RVA_DC"                    "Fact_Pers"                
## [43] "Fact_Hog"                  "VarStrat"                 
## [45] "Conglomerado"              "Fact_Ind"                 
## [47] "rph_situacion_ocupacional"
\end{verbatim}

\hypertarget{cuxe1lculo-de-porcentaje-de-valores-perdidos-en-las-variables}{%
\subsubsection{C√°lculo de porcentaje de valores perdidos en las variables}\label{cuxe1lculo-de-porcentaje-de-valores-perdidos-en-las-variables}}

Luego, calculamos el porcentaje de valores perdidos en las variables, considerando las celdas v√°lidas seg√∫n flujo de la encuesta (no se cuentan como valores perdidos las celdas vac√≠as por saltos en el cuestionario). Aquellas variables que contengan m√°s de un 50\% de celdas perdidas, se excluyen del proceso de anonimizaci√≥n (pero s√≠ deben incluirse en el archivo final de datos).

Se observa que no hay variables clave que tengan valores perdidos.

\begin{example}
\protect\hypertarget{exm:bloque35nbm}{}{\label{exm:bloque35nbm} }Chequear valores perdidos
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{any}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(file}\OperatorTok{$}\NormalTok{enc_region))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{any}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(file}\OperatorTok{$}\NormalTok{enc_rpc))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{any}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(file}\OperatorTok{$}\NormalTok{IH_residencia_habitual))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{any}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(file}\OperatorTok{$}\NormalTok{rph_sexo))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{any}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(file}\OperatorTok{$}\NormalTok{rph_edad))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{any}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(file}\OperatorTok{$}\NormalTok{rph_pertenencia_indigena)) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{any}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(file}\OperatorTok{$}\NormalTok{rph_nacionalidad)) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{any}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(file}\OperatorTok{$}\NormalTok{rph_situacion_ocupacional[file}\OperatorTok{$}\NormalTok{rph_edad }\OperatorTok{>}\StringTok{ }\DecValTok{14}\NormalTok{])) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] FALSE
\end{verbatim}

Se concluye que todas las variables cumplen con las condiciones para incluirse en el proceso de anonimizaci√≥n.

\hypertarget{cuxe1lculo-de-estaduxedsticas-de-resumen}{%
\subsubsection{C√°lculo de estad√≠sticas de resumen}\label{cuxe1lculo-de-estaduxedsticas-de-resumen}}

Por √∫ltimo, se revisan frecuencias para variables categ√≥ricas y estad√≠sticos de resumen para num√©ricas. Esto permite visualizar que variables tienen categor√≠as infrecuentes, lo que puede ser relevante m√°s adelante para la toma de decisi√≥n de cu√°les m√©todos aplicar y sobre cu√°les variables.

\begin{example}
\protect\hypertarget{exm:bloque36nbm}{}{\label{exm:bloque36nbm} }Tablas de frecuencia de variables clave
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{table}\NormalTok{(file}\OperatorTok{$}\NormalTok{enc_region)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##    1    2    3    4    5    6    7    8    9   10   11   12   13   14   15   16 
## 3223 2061 3115 2264 5269 2938 2648 4393 2241 3138 2693 2401 1842 2944 3368 2806
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{table}\NormalTok{(file}\OperatorTok{$}\NormalTok{enc_rpc)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  1101  1102  1103  1104  1105  1106  2101  2102  2103  2104  2105  2106  3101 
##   561   601   522   500   533   506   326   355   350   358   343   329   524 
##  3102  3103  3104  3105  3106  4101  4102  4103  4104  4105  4106  5101  5102 
##   564   493   461   514   559   393   416   342   436   351   326   889   926 
##  5103  5104  5105  5106  6101  6102  6103  6104  6105  6106  7101  7102  7103 
##   890   862   812   890   495   471   455   507   522   488   434   470   395 
##  7104  7105  7106  8101  8102  8103  8104  8105  8106  9101  9102  9103  9104 
##   463   409   477   698   720   774   700   724   777   402   380   337   385 
##  9105  9106 10101 10102 10103 10104 10105 10106 11101 11102 11103 11104 11105 
##   344   393   539   519   495   525   492   568   340   350   380   446   375 
## 11106 11107 12101 12102 12103 12104 12105 12106 12107 13101 13102 13103 13104 
##   432   370   322   302   382   411   340   362   282   251   273   270   234 
## 13105 13106 13107 14101 14102 14103 14104 14105 14106 14107 15101 15102 15103 
##   214   293   307   419   447   410   373   427   444   424   443   483   511 
## 15104 15105 15106 15107 16101 16102 16103 16104 16105 16106 16107 
##   467   544   438   482   448   362   397   351   371   431   446
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{table}\NormalTok{(file}\OperatorTok{$}\NormalTok{rph_sexo)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##     1     2 
## 23694 23650
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{table}\NormalTok{(file}\OperatorTok{$}\NormalTok{rph_idgen)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##     1     2     3 
## 10116 10030 20186
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{table}\NormalTok{(file}\OperatorTok{$}\NormalTok{rph_pertenencia_indigena)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##    1    2    3    4    5    6    7    8    9   10   11 
## 4341 4276 4315 4368 4265 4322 4403 4317 4217 4239 4281
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{table}\NormalTok{(file}\OperatorTok{$}\NormalTok{rph_nacionalidad)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##     1     2     3     4     5     6     7     8     9 
## 38923  1049  1010  1060  1025  1048  1035  1125  1069
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{table}\NormalTok{(file}\OperatorTok{$}\NormalTok{rph_situacion_ocupacional)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##     1     2     3     4     5     6 
## 30364  2470  5358   730   718   692
\end{verbatim}

\begin{example}
\protect\hypertarget{exm:bloque37nbm}{}{\label{exm:bloque37nbm} }Estad√≠sticos de resumen de variables clave
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(file}\OperatorTok{$}\NormalTok{IH_residencia_habitual)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   1.000   2.000   3.000   2.942   4.000   4.000
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(file}\OperatorTok{$}\NormalTok{rph_edad)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##    0.00   25.00   53.00   53.06   80.00  107.00
\end{verbatim}

\hypertarget{paso-tres-mediciuxf3n-y-evaluaciuxf3n-del-riesgo-de-divulgaciuxf3n}{%
\section{Paso Tres: Medici√≥n y evaluaci√≥n del riesgo de divulgaci√≥n}\label{paso-tres-mediciuxf3n-y-evaluaciuxf3n-del-riesgo-de-divulgaciuxf3n}}

\hypertarget{definiciuxf3n-de-escenarios-de-divulgaciuxf3n}{%
\subsection{Definici√≥n de escenarios de divulgaci√≥n}\label{definiciuxf3n-de-escenarios-de-divulgaciuxf3n}}

Las variables escogidas en su gran mayor√≠a se encuentran contenidas tambi√©n en otros productos estad√≠sticos del INE y otras entidades p√∫blicas, ya que refieren a variables b√°sicas de ubicaci√≥n y caracterizaci√≥n sociodemogr√°fica. Se destaca la coincidencia de variables de caracterizaci√≥n de personas de los hogares con CASEN y EPF, como ejemplos de fuentes internas. En el caso de fuentes externas, la ENPG de SENDA se considera una encuesta que contiene variables similares para hacer \emph{match}.

Por este motivo, se toma un √∫nico escenario conservador, en que todas estas variables son potencialmente utilizables en combinaci√≥n por un intruso, siendo posibles de enlazar a otras base de datos p√∫blicas y/o privadas, habilitando una posible re-identificaci√≥n de registros.

En este sentido, y considerando las variables ya fusionadas/consolidadas, se mantiene el siguiente listado de variables para la medici√≥n del riesgo:

\begin{longtable}[]{@{}ll@{}}
\toprule
Variable & Etiqueta\tabularnewline
\midrule
\endhead
enc\_rpc & Identificador de comuna\tabularnewline
enc\_region & Identificador de regi√≥n\tabularnewline
IH\_residencia\_habitual & N√∫mero de residentes habituales\tabularnewline
rph\_edad & Edad\tabularnewline
rph\_sexo & Sexo\tabularnewline
rph\_idgen & Identidad de g√©nero\tabularnewline
rph\_pertenencia\_indigena & Pertenencia a pueblos ind√≠genas\tabularnewline
rph\_nacionalidad & Nacionalidad\tabularnewline
rph\_situacion\_ocupacional & Situaci√≥n ocupacional\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{mediciuxf3n-de-riesgos-de-divulgaciuxf3n}{%
\subsection{Medici√≥n de riesgos de divulgaci√≥n}\label{mediciuxf3n-de-riesgos-de-divulgaciuxf3n}}

Para medir el riesgo se considerar√°n las medidas de riesgo global, riesgo individual, \emph{l-diversity} y k-anonimato,considerando adem√°s la estructura jer√°rquica de la base. Por este motivo, primero se mide el riesgo a nivel de vivienda/hogar, para luego medir a nivel individual.

\hypertarget{mediciuxf3n-de-riesgos-de-divulgaciuxf3n-a-nivel-viviendahogar}{%
\subsubsection{Medici√≥n de riesgos de divulgaci√≥n a nivel vivienda/hogar}\label{mediciuxf3n-de-riesgos-de-divulgaciuxf3n-a-nivel-viviendahogar}}

En los siguientes pasos, se seleccionan las variables del nivel jer√°rquico superior y se genera el objeto \texttt{sdcMicro} en base al cual se realizan las estimaciones.

Primero, se generan vectores con las variables claves y las variables num√©ricas en el conjunto de datos (nivel hogar). Luego, opcionalmente se pueden declarar variables para el m√©todo PRAM (en este caso se genera un vector vac√≠o ya que no se utilizar√° el m√©todo PRAM).

\begin{example}
\protect\hypertarget{exm:bloque38nbm}{}{\label{exm:bloque38nbm} }Generar vectores con variables claves categ√≥ricas, num√©ricas y variables PRAM
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Selecci√≥n de variables para la anonimizaci√≥n a nivel de hogar}
\NormalTok{selectedKeyVarsHH <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"enc_rpc"}\NormalTok{)}

\CommentTok{# variables numericas}
\NormalTok{numVarsHH <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"IH_residencia_habitual"}\NormalTok{)}

\CommentTok{# No se declaran variables para m√©todo PRAM}
\NormalTok{pramVarsHH <-}\StringTok{ }\KeywordTok{c}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

A continuaci√≥n, se genera un vector con la variable de ponderaci√≥n de hogares.

\begin{example}
\protect\hypertarget{exm:bloque39nbm}{}{\label{exm:bloque39nbm} }Asignar variables de ponderaci√≥n a nivel hogar
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Se indican las variables de ponderaci√≥n de hogares}
\NormalTok{weightVarsHH <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Fact_Hog"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Ahora, reunimos todas estas variables en un vector denominado \emph{HHVars}

\begin{example}
\protect\hypertarget{exm:bloque40nbm}{}{\label{exm:bloque40nbm} }Generar vector con variables del nivel hogar
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Luego se genera un vector con todas las variables del nivel de hogar}
\NormalTok{HHVars <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{'enc_idr'}\NormalTok{,selectedKeyVarsHH, pramVarsHH, numVarsHH, weightVarsHH)}
\NormalTok{variables <-}\StringTok{ }\NormalTok{HHVars}
\NormalTok{todas_variables <-}\StringTok{ }\KeywordTok{names}\NormalTok{(file)}
\NormalTok{HHVars <-}\StringTok{ }\KeywordTok{intersect}\NormalTok{(todas_variables,variables)}
\end{Highlighting}
\end{Shaded}

Luego, generamos un conjunto de datos con solo las columnas y filas que corresponden. En este caso son las variables del nivel hogar y las filas que corresponden al informante Kish, de manera tal que haya un caso por hogar.

\begin{example}
\protect\hypertarget{exm:bloque41nbm}{}{\label{exm:bloque41nbm} }Filtrar un caso por vivienda
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Creamos un subconjunto de datos de file con hogares y variables HH}
\NormalTok{fileHH <-}\StringTok{ }\NormalTok{file[,HHVars]}
\NormalTok{fileHH}\OperatorTok{$}\NormalTok{Kish <-}\StringTok{ }\NormalTok{file}\OperatorTok{$}\NormalTok{Kish}

\CommentTok{# Se deja un caso por cada hogar asignado en fileHH}
\NormalTok{fileHH <-}\StringTok{ }\NormalTok{fileHH[fileHH}\OperatorTok{$}\NormalTok{Kish }\OperatorTok{%in%}\StringTok{ }\DecValTok{1}\NormalTok{,]}
\NormalTok{fileHH <-}\StringTok{ }\NormalTok{dplyr}\OperatorTok{::}\KeywordTok{select}\NormalTok{(fileHH, }\OperatorTok{-}\NormalTok{Kish)}
\end{Highlighting}
\end{Shaded}

Luego, se verifican las dimensiones del conjunto de datos con la funci√≥n \texttt{dim()}.

\begin{example}
\protect\hypertarget{exm:bloque42nbm}{}{\label{exm:bloque42nbm} }Construir e inspeccionar dataframe de hogares
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Se genera el dataset para medici√≥n de riesgo}
\NormalTok{fileHH <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{enc_idr =}\NormalTok{ fileHH}\OperatorTok{$}\NormalTok{enc_idr,}
                     \DataTypeTok{enc_rpc =}\NormalTok{ fileHH}\OperatorTok{$}\NormalTok{enc_rpc,}
                     \DataTypeTok{IH_residencia_habitual =}\NormalTok{ fileHH}\OperatorTok{$}\NormalTok{IH_residencia_habitual,}
                     \DataTypeTok{Fact_Hog =}\NormalTok{ fileHH}\OperatorTok{$}\NormalTok{Fact_Hog)}

\CommentTok{# Se verifican dimensiones del conjunto de datos}
\KeywordTok{dim}\NormalTok{(fileHH)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 18766     4
\end{verbatim}

Y se genera el objeto SDC a nivel de hogar.

\begin{example}
\protect\hypertarget{exm:bloque43nbm}{}{\label{exm:bloque43nbm} }Crear objeto SDC
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Se crea objeto SDC inicial para variables de nivel de hogar}
\NormalTok{sdcHH <-}\StringTok{ }\KeywordTok{createSdcObj}\NormalTok{(}\DataTypeTok{dat =}\NormalTok{ fileHH, }\DataTypeTok{keyVars =}\NormalTok{ selectedKeyVarsHH,}
                      \DataTypeTok{numVars =}\NormalTok{ numVarsHH, }\DataTypeTok{weightVar =}\NormalTok{ weightVarsHH)}
\end{Highlighting}
\end{Shaded}

Por √∫ltimo, se guarda en un vector la cantidad de hogares para uso posterior.

\begin{example}
\protect\hypertarget{exm:bloque44nbm}{}{\label{exm:bloque44nbm} }Almacenar n√∫mero de hogares
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Se genera variable con n√∫mero de hogares}
\NormalTok{numHH <-}\StringTok{ }\KeywordTok{length}\NormalTok{(fileHH[,}\DecValTok{1}\NormalTok{]) }\CommentTok{# n√∫mero de hogares }
\end{Highlighting}
\end{Shaded}

Primero, revisamos las medidas globales de riesgo. Se observa que no hay hasta el momento observaciones que tengan un riesgo superior que la mayor√≠a de los datos.

\begin{example}
\protect\hypertarget{exm:bloque45nbm}{}{\label{exm:bloque45nbm} }Medidas globales de riesgo
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{print}\NormalTok{(sdcHH, }\StringTok{"risk"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Risk measures:
## 
## Number of observations with higher risk than the main part of the data: 0
## Expected number of re-identifications: 0.16 (0.00 %)
\end{verbatim}

Ahora medimos el riesgo de manera individual. Se observan 0 casos con riesgo sobre el 1\%.
\begin{example}
\protect\hypertarget{exm:bloque46nbm}{}{\label{exm:bloque46nbm} }Riesgo individual
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Observations with risk above certain threshold (0.01)}
\KeywordTok{nrow}\NormalTok{(fileHH[sdcHH}\OperatorTok{@}\NormalTok{risk}\OperatorTok{$}\NormalTok{individual[, }\StringTok{"risk"}\NormalTok{] }\OperatorTok{>}\StringTok{ }\FloatTok{0.01}\NormalTok{,])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0
\end{verbatim}

Revisamos el k-anonimato para los casos ponderados.No hay casos que violen ning√∫n nivel de k-anonimato. Para ello, se usa la funci√≥n \texttt{kAnon\_violations()}, indicando \emph{TRUE} (T) como argumento para el par√°metro de pesos (\emph{weighted}) y el valor de \emph{k} a evaluar.

\begin{example}
\protect\hypertarget{exm:bloque47nbm}{}{\label{exm:bloque47nbm} }K-anonimato
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{kAnon_violations}\NormalTok{(sdcHH, }\DataTypeTok{weighted =}\NormalTok{ T, }\DataTypeTok{k =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0
## attr(,"k")
## [1] 2
## attr(,"weighted")
## [1] TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{kAnon_violations}\NormalTok{(sdcHH, }\DataTypeTok{weighted =}\NormalTok{ T, }\DataTypeTok{k =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0
## attr(,"k")
## [1] 3
## attr(,"weighted")
## [1] TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{kAnon_violations}\NormalTok{(sdcHH, }\DataTypeTok{weighted =}\NormalTok{ T, }\DataTypeTok{k =} \DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0
## attr(,"k")
## [1] 5
## attr(,"weighted")
## [1] TRUE
\end{verbatim}

En resumen, se observa que para el nivel hogar los riesgos ya cumplen con los umbrales establecidos por el est√°ndar de anonimizaci√≥n. Por lo que se prosigue analizando el riesgo a nivel de personas.

\hypertarget{mediciuxf3n-de-riesgos-de-divulgaciuxf3n-a-nivel-persona}{%
\subsubsection{Medici√≥n de riesgos de divulgaci√≥n a nivel persona}\label{mediciuxf3n-de-riesgos-de-divulgaciuxf3n-a-nivel-persona}}

En este siguiente paso, se procede a seleccionar todas las variables de ambos niveles, para crear el objeto \texttt{sdcMicro} considerando la estructura jer√°rquica hasta el nivel persona.

\begin{example}
\protect\hypertarget{exm:bloque48nbm}{}{\label{exm:bloque48nbm} }Comandos para construir el objeto SDC a nivel de persona
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Se indican variables clave (nivel individual)}
\NormalTok{selectedKeyVarsIND <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{'enc_rpc'}\NormalTok{,}
                        \StringTok{'rph_edad'}\NormalTok{,}
                        \StringTok{'rph_sexo'}\NormalTok{,}
                        \StringTok{'rph_idgen'}\NormalTok{,}
                        \StringTok{'rph_pertenencia_indigena'}\NormalTok{, }
                       \StringTok{'rph_nacionalidad'}\NormalTok{,}
                       \StringTok{'rph_situacion_ocupacional'}\NormalTok{) }

\CommentTok{# Se indica factor de expansi√≥n de personas}
\NormalTok{WeightVarIND <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{'Fact_Ind'}\NormalTok{)}

\CommentTok{# ID Hogares}
\NormalTok{selectedHouseholdID <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{'enc_idr'}\NormalTok{)}

\CommentTok{# Recombinaci√≥n de conjuntos de datos HH an√≥nimos y variables de nivel individuales}
\NormalTok{indVars <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"enc_idr"}\NormalTok{, }\StringTok{"rph_ID"}\NormalTok{, selectedKeyVarsIND,WeightVarIND,sensibles) }\CommentTok{# HID and all non HH variables}

\NormalTok{fileInd <-}\StringTok{ }\NormalTok{file[indVars] }\CommentTok{# subset of file without HHVars}

\NormalTok{fileCombined <-}\StringTok{ }\NormalTok{dplyr}\OperatorTok{::}\KeywordTok{inner_join}\NormalTok{(fileInd, }\KeywordTok{select}\NormalTok{(fileHH, }\OperatorTok{-}\NormalTok{enc_rpc), }\DataTypeTok{by=} \KeywordTok{c}\NormalTok{(}\StringTok{'enc_idr'}\NormalTok{))}

\KeywordTok{dim}\NormalTok{(fileCombined)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 47344    15
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Objetos SDC con todas las variables y variables HH tratadas para}
\CommentTok{# anonimizaci√≥n de variables de nivel individual}
\NormalTok{sdcCombined <-}\StringTok{ }\KeywordTok{createSdcObj}\NormalTok{(}\DataTypeTok{dat =}\NormalTok{ fileCombined, }\DataTypeTok{keyVars =}\NormalTok{ selectedKeyVarsIND,}
                            \DataTypeTok{hhId =}\NormalTok{ selectedHouseholdID, }\DataTypeTok{weightVar =}\NormalTok{ WeightVarIND,}
                            \DataTypeTok{sensibleVar =}\NormalTok{ sensibles)}
\end{Highlighting}
\end{Shaded}

Primero, revisamos las medidas globales de riesgo. Se observa una cantidad relevante de observaciones con riesgo alto, y tambi√©n un porcentaje alto de re-identificaciones esperadas, lo que se acent√∫a al considerar la estructura jer√°rquica. Esta supera el umbral establecido de no m√°s del 10\%.

\begin{example}
\protect\hypertarget{exm:bloque49nbm}{}{\label{exm:bloque49nbm} }Medidas globales de riesgo
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{print}\NormalTok{(sdcCombined, }\StringTok{"risk"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Risk measures:
## 
## Number of observations with higher risk than the main part of the data: 3108
## Expected number of re-identifications: 2048.36 (4.33 %)
## 
## Information on hierarchical risk:
## Expected number of re-identifications: 5412.30 (11.43 %)
## ----------------------------------------------------------------------
\end{verbatim}

Ahora medimos el riesgo de manera individual. Para ello, se revisa la cantidad de observaciones con riesgo mayor a cada umbral de riesgo individual. Se observa que casi todos los casos presentan un riesgo superior al 1\%, lo que incumple el umbral establecido. Al filtrar por porcentajes de riesgo m√°s alto, se observa a√∫n una cantidad muy alta de observaciones con riesgo alt√≠simo, con 261 observaciones con riesgo superior al 50\%.

\begin{example}
\protect\hypertarget{exm:bloque50nbm}{}{\label{exm:bloque50nbm} }Riesgo individual
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Observaciones con riesgo individual superior al 1%:}
\KeywordTok{nrow}\NormalTok{(fileCombined[sdcCombined}\OperatorTok{@}\NormalTok{risk}\OperatorTok{$}\NormalTok{individual[, }\StringTok{"risk"}\NormalTok{] }\OperatorTok{>}\StringTok{ }\FloatTok{0.01}\NormalTok{,])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 43123
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Observaciones con riesgo individual superior al 5%:}
\KeywordTok{nrow}\NormalTok{(fileCombined[sdcCombined}\OperatorTok{@}\NormalTok{risk}\OperatorTok{$}\NormalTok{individual[, }\StringTok{"risk"}\NormalTok{] }\OperatorTok{>}\StringTok{ }\FloatTok{0.05}\NormalTok{,]) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 8862
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Observaciones con riesgo individual superior al 25%:}
\KeywordTok{nrow}\NormalTok{(fileCombined[sdcCombined}\OperatorTok{@}\NormalTok{risk}\OperatorTok{$}\NormalTok{individual[, }\StringTok{"risk"}\NormalTok{] }\OperatorTok{>}\StringTok{ }\FloatTok{0.25}\NormalTok{,]) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 812
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Observaciones con riesgo individual superior al 50%:}
\KeywordTok{nrow}\NormalTok{(fileCombined[sdcCombined}\OperatorTok{@}\NormalTok{risk}\OperatorTok{$}\NormalTok{individual[, }\StringTok{"risk"}\NormalTok{] }\OperatorTok{>}\StringTok{ }\FloatTok{0.5}\NormalTok{,]) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 261
\end{verbatim}

Luego, revisamos el k-anonimato para los casos ponderados. Se detectan casos que incumplen el k-anonimato, incluso con ponderaci√≥n.

\begin{example}
\protect\hypertarget{exm:bloque51nbm}{}{\label{exm:bloque51nbm} }K-anonimato
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# 2-anonimato}
\KeywordTok{kAnon_violations}\NormalTok{(sdcCombined, }\DataTypeTok{weighted =}\NormalTok{ T, }\DataTypeTok{k =} \DecValTok{2}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 153
## attr(,"k")
## [1] 2
## attr(,"weighted")
## [1] TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# 3-anonimato}
\KeywordTok{kAnon_violations}\NormalTok{(sdcCombined, }\DataTypeTok{weighted =}\NormalTok{ T, }\DataTypeTok{k =} \DecValTok{3}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 225
## attr(,"k")
## [1] 3
## attr(,"weighted")
## [1] TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# 5-anonimato}
\KeywordTok{kAnon_violations}\NormalTok{(sdcCombined, }\DataTypeTok{weighted =}\NormalTok{ T, }\DataTypeTok{k =} \DecValTok{5}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 388
## attr(,"k")
## [1] 5
## attr(,"weighted")
## [1] TRUE
\end{verbatim}

Finalmente, medimos el \emph{l-diversity}, que es una medida complementaria al k-anonimato. Esta indica cuantos valores de respuesta tienen las variables sensibles para cada combinaci√≥n de las variables clave. Se espera obtener valores superiores a 1, dado que este valor indica que hay una √∫nica respuesta para cada combinaci√≥n, lo que implica que un intruso podr√≠a saber el valor de respuesta a pesar de que se cumplan los umbrales de k-anonimato. En este sentido, esta m√©trica de riesgo es complementaria y da respaldo a lo evaluado a partir del k-anonimato.

\begin{example}
\protect\hypertarget{exm:bloque52nbm}{}{\label{exm:bloque52nbm} }L-Diversity
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Generamos el objeto de l-diversity}
\NormalTok{med_riesgo <-}\StringTok{ }\KeywordTok{ldiversity}\NormalTok{(sdcCombined, }\DataTypeTok{ldiv_index =}\NormalTok{ sensibles,}
                         \DataTypeTok{l_recurs_c =} \DecValTok{2}\NormalTok{, }\DataTypeTok{missing =} \OtherTok{NA}\NormalTok{)}

\CommentTok{# revisamos las medidas de riesgo de l-diversity}
\NormalTok{med_riesgo}\OperatorTok{@}\NormalTok{risk}\OperatorTok{$}\NormalTok{ldiversity}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## --------------------------
\end{verbatim}

\begin{verbatim}
## L-Diversity Measures
\end{verbatim}

\begin{verbatim}
## --------------------------
\end{verbatim}

\begin{verbatim}
##  P17_Distinct_Ldiversity P24_Distinct_Ldiversity DEN_AGREG_Distinct_Ldiversity
##  Min.   :1.000           Min.   :1.000           Min.   :1.000                
##  1st Qu.:1.000           1st Qu.:1.000           1st Qu.:1.000                
##  Median :1.000           Median :1.000           Median :1.000                
##  Mean   :1.021           Mean   :1.024           Mean   :1.022                
##  3rd Qu.:1.000           3rd Qu.:1.000           3rd Qu.:1.000                
##  Max.   :3.000           Max.   :3.000           Max.   :3.000
\end{verbatim}

Como se se√±al√≥ previamente, el valor 1 indica un m√≠nimo nivel de diversidad en las variables sensibles para cada
combinaci√≥n de variables clave. En este sentido, el que la media y promedio del \emph{l-diversity} se aproximen a 1 nos indica que tenemos pocas combinaciones, lo que es se√±al de un mayor riesgo de que el intruso logre llegar al valor de las variables sensibles.

\hypertarget{evaluaciuxf3n-de-riesgos-de-divulgaciuxf3n}{%
\subsection{Evaluaci√≥n de riesgos de divulgaci√≥n}\label{evaluaciuxf3n-de-riesgos-de-divulgaciuxf3n}}

\textbf{CONCLUSI√ìN DE LA EVALUACI√ìN DE RIESGOS}

Dado que, a nivel jer√°rquico, considerando hasta el nivel de persona, se incumplen los umbrales requeridos por el est√°ndar de anonimizaci√≥n a nivel global, individual y de k-anonimato, adem√°s de que se observa un valor riesgoso en el \emph{l-diversity}, se confirma la necesidad de aplicar m√©todos SDC para asegurar la confidencialidad de los datos.

Estos m√©todos se contin√∫an aplicando sobre el nivel de personas del conjunto de datos, dado que a nivel hogares ya se cumplen los umbrales requeridos.

\hypertarget{paso-cuatro-selecciuxf3n-y-aplicaciuxf3n-de-muxe9todos-sdc}{%
\section{Paso Cuatro: Selecci√≥n y aplicaci√≥n de m√©todos SDC}\label{paso-cuatro-selecciuxf3n-y-aplicaciuxf3n-de-muxe9todos-sdc}}

En esta secci√≥n se aplicar√°n iterativamente m√©todos SDC intentando alcanzar los umbrales de riesgo requeridos. Como veremos, al ser un proceso iterativo, tambi√©n considerar√° de forma recurrente la re-medici√≥n del riesgo, que corresponde en estricto rigor a la primera parte del paso cinco. Esto es necesario para ir evaluando si es necesario aplicar m√©todos adicionales o distintos.

\hypertarget{primer-conjunto-de-muxe9todos-sdc}{%
\subsection{Primer conjunto de m√©todos SDC}\label{primer-conjunto-de-muxe9todos-sdc}}

El primer m√©todo a aplicar es la recodificaci√≥n global para la variable de edad,pasando de semi continua a ordinal. Los tramos etarios escogidos corresponden a una adaptaci√≥n m√°s desagregada de los tramos etarios utilizados en la publicaci√≥n de tabulados en versiones anteriores de la encuesta.

Se procede con este m√©todo primero dado que, por experiencia de los analistas de la encuesta, es uno de los que tiene mayor impacto en la reducci√≥n de riesgos.

Para ello, aplicamos la funci√≥n \texttt{globalRecode()}. Esta funci√≥n implementa el m√©todo de recodificaci√≥n global descrito en la gu√≠a de anonimizaci√≥n. El m√©todo toma cuatro argumentos: el objeto SDC, la columna a recodificar, los l√≠mites de los intervalos a generar, y las etiquetas que debe asignar a cada tramo.

\begin{example}
\protect\hypertarget{exm:bloque53nbm}{}{\label{exm:bloque53nbm} }Recodificar edad
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sdcCombined <-}\StringTok{ }\KeywordTok{globalRecode}\NormalTok{(sdcCombined,}
                            \DataTypeTok{column =} \StringTok{"rph_edad"}\NormalTok{,}
                            \DataTypeTok{breaks=}\KeywordTok{c}\NormalTok{(}\OperatorTok{-}\DecValTok{1}\NormalTok{,}\DecValTok{14}\NormalTok{,}\DecValTok{19}\NormalTok{,}\DecValTok{24}\NormalTok{,}\DecValTok{29}\NormalTok{,}\DecValTok{39}\NormalTok{,}\DecValTok{49}\NormalTok{,}\DecValTok{59}\NormalTok{,}\DecValTok{69}\NormalTok{,}\DecValTok{79}\NormalTok{,}\DecValTok{89}\NormalTok{,}\DecValTok{120}\NormalTok{),}
                            \DataTypeTok{labels=}\DecValTok{0}\OperatorTok{:}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Alternativamente, se podr√≠a simplemente haber ocupado otras funciones de \texttt{R\ base} o de \texttt{Tidyverse} para recodificar esta variable en tramos, como, por ejemplo, las funciones \texttt{ifelse()} o \texttt{case\_when()}. Sin embargo, esta aproximaci√≥n tiene la desventaja de que requiere generar nuevamente el objeto SDC por completo, por lo que se pierde la trazabilidad de las ediciones realizadas y de la reducci√≥n del riesgo desde la l√≠nea base inicial. Por este motivo, es que se recomienda usar \texttt{globalRecode()}.

Luego de haber aplicado este m√©todo SDC, procedemos a medir el impacto de esta modificaci√≥n en las medidas de riesgo.

\hypertarget{re-mediciuxf3n-del-riesgo-para-primer-conjunto-de-muxe9todos}{%
\subsection{Re-medici√≥n del riesgo para primer conjunto de m√©todos}\label{re-mediciuxf3n-del-riesgo-para-primer-conjunto-de-muxe9todos}}

Primero, revisamos las medidas globales de riesgo con los datos tratados. Se observa una mejora en los resultados, llegando a umbrales aceptables (\textless{}10\%). No obstante, es necesario revisar el resto de las m√©tricas, donde se est√° m√°s lejos de cumplir con los est√°ndares requeridos.

\begin{example}
\protect\hypertarget{exm:bloque54nbm}{}{\label{exm:bloque54nbm} }Riesgo global
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{print}\NormalTok{(sdcCombined, }\StringTok{"risk"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Risk measures:
## 
## Number of observations with higher risk than the main part of the data: 
##   in modified data: 2169
##   in original data: 3108
## Expected number of re-identifications: 
##   in modified data: 1488.69 (3.14 %)
##   in original data: 2048.36 (4.33 %)
## 
## Information on hierarchical risk:
## Expected number of re-identifications: 
##   in modified data: 4006.48 (8.46 %)
##   in original data: 5412.30 (11.43 %)
## ----------------------------------------------------------------------
\end{verbatim}

Ahora medimos el riesgo de manera individual. Se observa que 30.922 de los casos tiene un riesgo superior al 1\%. Al filtrar por porcentajes de riesgo m√°s alto, se observa a√∫n una cantidad importante de observaciones con riesgo alt√≠simo, con 189 observaciones con riesgo superior al 50\%, lo que a√∫n es demasiado alto.

\begin{example}
\protect\hypertarget{exm:bloque55nbm}{}{\label{exm:bloque55nbm} }Riesgo individual
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Observaciones con riesgo individual superior al 1%:}
\KeywordTok{nrow}\NormalTok{(fileCombined[sdcCombined}\OperatorTok{@}\NormalTok{risk}\OperatorTok{$}\NormalTok{individual[, }\StringTok{"risk"}\NormalTok{] }\OperatorTok{>}\StringTok{ }\FloatTok{0.01}\NormalTok{,])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 30922
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Observaciones con riesgo individual superior al 5%:}
\KeywordTok{nrow}\NormalTok{(fileCombined[sdcCombined}\OperatorTok{@}\NormalTok{risk}\OperatorTok{$}\NormalTok{individual[, }\StringTok{"risk"}\NormalTok{] }\OperatorTok{>}\StringTok{ }\FloatTok{0.05}\NormalTok{,])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 6169
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Observaciones con riesgo individual superior al 25%:}
\KeywordTok{nrow}\NormalTok{(fileCombined[sdcCombined}\OperatorTok{@}\NormalTok{risk}\OperatorTok{$}\NormalTok{individual[, }\StringTok{"risk"}\NormalTok{] }\OperatorTok{>}\StringTok{ }\FloatTok{0.25}\NormalTok{,])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 569
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Observaciones con riesgo individual superior al 50%:}
\KeywordTok{nrow}\NormalTok{(fileCombined[sdcCombined}\OperatorTok{@}\NormalTok{risk}\OperatorTok{$}\NormalTok{individual[, }\StringTok{"risk"}\NormalTok{] }\OperatorTok{>}\StringTok{ }\FloatTok{0.5}\NormalTok{,])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 189
\end{verbatim}

Revisamos el k-anonimato para los casos ponderados. A√∫n se observan 116 casos que incumplen el 2-anonimato.

\begin{example}
\protect\hypertarget{exm:bloque56nbm}{}{\label{exm:bloque56nbm} }K-anonimato
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# 2-anonimato}
\KeywordTok{kAnon_violations}\NormalTok{(sdcCombined, }\DataTypeTok{weighted =}\NormalTok{ T, }\DataTypeTok{k =} \DecValTok{2}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 116
## attr(,"k")
## [1] 2
## attr(,"weighted")
## [1] TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# 3-anonimato}
\KeywordTok{kAnon_violations}\NormalTok{(sdcCombined, }\DataTypeTok{weighted =}\NormalTok{ T, }\DataTypeTok{k =} \DecValTok{3}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 166
## attr(,"k")
## [1] 3
## attr(,"weighted")
## [1] TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# 5-anonimato}
\KeywordTok{kAnon_violations}\NormalTok{(sdcCombined, }\DataTypeTok{weighted =}\NormalTok{ T, }\DataTypeTok{k =} \DecValTok{5}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 280
## attr(,"k")
## [1] 5
## attr(,"weighted")
## [1] TRUE
\end{verbatim}

Luego medimos el \emph{l-diversity}, donde observamos a√∫n valores muy cercanos a 1, para las tres variables sensibles.

\begin{example}
\protect\hypertarget{exm:bloque57nbm}{}{\label{exm:bloque57nbm} }L-diveristy
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Generamos el objeto de l-diversity}
\NormalTok{med_riesgo <-}\StringTok{ }\KeywordTok{ldiversity}\NormalTok{(sdcCombined, }\DataTypeTok{ldiv_index =}\NormalTok{ sensibles,}
                         \DataTypeTok{l_recurs_c =} \DecValTok{2}\NormalTok{, }\DataTypeTok{missing =} \OtherTok{NA}\NormalTok{)}

\CommentTok{# revisamos las medidas de riesgo de l-diversity}
\NormalTok{med_riesgo}\OperatorTok{@}\NormalTok{risk}\OperatorTok{$}\NormalTok{ldiversity}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## --------------------------
\end{verbatim}

\begin{verbatim}
## L-Diversity Measures
\end{verbatim}

\begin{verbatim}
## --------------------------
\end{verbatim}

\begin{verbatim}
##  P17_Distinct_Ldiversity P24_Distinct_Ldiversity DEN_AGREG_Distinct_Ldiversity
##  Min.   :1.000           Min.   :1.000           Min.   :1.000                
##  1st Qu.:1.000           1st Qu.:1.000           1st Qu.:1.000                
##  Median :1.000           Median :1.000           Median :1.000                
##  Mean   :1.219           Mean   :1.252           Mean   :1.229                
##  3rd Qu.:1.000           3rd Qu.:1.000           3rd Qu.:1.000                
##  Max.   :6.000           Max.   :6.000           Max.   :6.000
\end{verbatim}

En conclusi√≥n, si bien se cumplen los umbrales a nivel global, los umbrales a nivel individual, el k-anonimato y el \emph{l-diversity} nos indican que se requiere aplicar m√°s m√©todos SDC para asegurar la anonimizaci√≥n de los datos.

\hypertarget{segundo-conjunto-de-muxe9todos-sdc}{%
\subsection{Segundo conjunto de m√©todos SDC}\label{segundo-conjunto-de-muxe9todos-sdc}}

El hecho de estar aplicando nuevamente el paso 4 nos indica una caracter√≠stica fundamental de los procesos de anonimizaci√≥n, que es que estos son procesos iterativos, donde es necesario ir aplicando m√©todos progresivamente y monitorear los niveles de riesgo en cada iteraci√≥n. Como veremos en este ejercicio aplicado, ser√°n varias iteraciones antes de llegar a un resultado satisfactorio de niveles de riesgo.

Retomando el proceso, el segundo m√©todo a aplicar es la eliminaci√≥n de la variable de comuna. En cambio, se incluye la variable de regi√≥n, ya que deja de ser redundante. Esto, dado que previamente se hab√≠a retirado en el paso de consolidaci√≥n de variables puesto que la comuna es una variable anidada en la variable de regi√≥n.

Los pasos aplicados en el siguiente bloque de c√≥digo son los mismos que se aplicaron la primera vez que se construy√≥ el objeto \emph{sdcCombined}. La √∫nica diferencia es que se reemplaza la variable \emph{enc\_rpc} por \emph{enc\_region} dentro del vector de variables clave \emph{selectedKeyVarsIND}.

\begin{example}
\protect\hypertarget{exm:bloque58nbm}{}{\label{exm:bloque58nbm} }Reconstruir el objeto SDC a nivel persona con variable regi√≥n
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Se indican variables clave (nivel individual)}
\NormalTok{selectedKeyVarsIND <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{'enc_region'}\NormalTok{,}
                        \StringTok{'rph_edad'}\NormalTok{,}
                        \StringTok{'rph_sexo'}\NormalTok{,}
                        \StringTok{'rph_idgen'}\NormalTok{,}
                        \StringTok{'rph_pertenencia_indigena'}\NormalTok{, }
                       \StringTok{'rph_nacionalidad'}\NormalTok{,}
                       \StringTok{'rph_situacion_ocupacional'}\NormalTok{) }

\CommentTok{# Se indica factor de expansi√≥n de personas}
\NormalTok{WeightVarIND <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{'Fact_Ind'}\NormalTok{)}

\CommentTok{# ID Hogares}
\NormalTok{selectedHouseholdID <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{'enc_idr'}\NormalTok{)}

\CommentTok{# Recombinaci√≥n de conjuntos de datos HH an√≥nimos y variables de nivel individuales}
\NormalTok{indVars <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"enc_idr"}\NormalTok{, }\StringTok{"rph_ID"}\NormalTok{, selectedKeyVarsIND,WeightVarIND,sensibles) }\CommentTok{# HID and all non HH variables}

\NormalTok{fileInd <-}\StringTok{ }\NormalTok{file[indVars] }\CommentTok{# subset of file without HHVars}

\NormalTok{fileCombined <-}\StringTok{ }\NormalTok{dplyr}\OperatorTok{::}\KeywordTok{inner_join}\NormalTok{(fileInd, }\KeywordTok{select}\NormalTok{(fileHH, }\OperatorTok{-}\NormalTok{enc_rpc), }\DataTypeTok{by=} \KeywordTok{c}\NormalTok{(}\StringTok{'enc_idr'}\NormalTok{))}

\KeywordTok{dim}\NormalTok{(fileCombined)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 47344    15
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Objetos SDC con todas las variables y variables HH tratadas para}
\CommentTok{# anonimizaci√≥n de variables de nivel individual}
\NormalTok{sdcCombined <-}\StringTok{ }\KeywordTok{createSdcObj}\NormalTok{(}\DataTypeTok{dat =}\NormalTok{ fileCombined, }\DataTypeTok{keyVars =}\NormalTok{ selectedKeyVarsIND,}
                            \DataTypeTok{hhId =}\NormalTok{ selectedHouseholdID, }\DataTypeTok{weightVar =}\NormalTok{ WeightVarIND,}
                            \DataTypeTok{sensibleVar =}\NormalTok{ sensibles)}
\end{Highlighting}
\end{Shaded}

Adem√°s, como en este caso fue necesario crear nuevamente el objeto SDC, hay que aplicar nuevamente la recodificaci√≥n de la variable edad con la funci√≥n \texttt{globalRecode()}.

\begin{example}
\protect\hypertarget{exm:bloque59nbm}{}{\label{exm:bloque59nbm} }Recodificar edad nuevamente
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sdcCombined <-}\StringTok{ }\KeywordTok{globalRecode}\NormalTok{(sdcCombined,}
                            \DataTypeTok{column =} \StringTok{"rph_edad"}\NormalTok{,}
                            \DataTypeTok{breaks=}\KeywordTok{c}\NormalTok{(}\OperatorTok{-}\DecValTok{1}\NormalTok{,}\DecValTok{14}\NormalTok{,}\DecValTok{19}\NormalTok{,}\DecValTok{24}\NormalTok{,}\DecValTok{29}\NormalTok{,}\DecValTok{39}\NormalTok{,}\DecValTok{49}\NormalTok{,}\DecValTok{59}\NormalTok{,}\DecValTok{69}\NormalTok{,}\DecValTok{79}\NormalTok{,}\DecValTok{89}\NormalTok{,}\DecValTok{120}\NormalTok{),}
                            \DataTypeTok{labels=}\DecValTok{0}\OperatorTok{:}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{re-mediciuxf3n-del-riesgo-para-segundo-conjunto-de-muxe9todos}{%
\subsection{Re-medici√≥n del riesgo para segundo conjunto de m√©todos}\label{re-mediciuxf3n-del-riesgo-para-segundo-conjunto-de-muxe9todos}}

Nuevamente, revisamos las medidas globales de riesgo. Se observa que a nivel global obtenemos valores aceptables de riesgo, ya que se hab√≠an logrado en la primera iteraci√≥n.

\begin{example}
\protect\hypertarget{exm:bloque60nbm}{}{\label{exm:bloque60nbm} }Riesgo global
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{print}\NormalTok{(sdcCombined, }\StringTok{"risk"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Risk measures:
## 
## Number of observations with higher risk than the main part of the data: 
##   in modified data: 1035
##   in original data: 2471
## Expected number of re-identifications: 
##   in modified data: 762.14 (1.61 %)
##   in original data: 1683.54 (3.56 %)
## 
## Information on hierarchical risk:
## Expected number of re-identifications: 
##   in modified data: 2216.99 (4.68 %)
##   in original data: 4524.60 (9.56 %)
## ----------------------------------------------------------------------
\end{verbatim}

Ahora medimos el riesgo de manera individual. Se observa que 15.463 de los casos (32,7\% del total) presentan un riesgo superior al 1\%, lo que a√∫n incumple el umbral establecido, que indica el 20\% de los casos. Por otro lado, se observa que 3.000 de las personas (6,3\% del total) presentan un riesgo mayor al 5\%, lo que cumple con el umbral (no m√°s de 15\%). Por otro lado, se observa que 286 y un 92 de los casos tienen riesgos superiores al 25\% y 50\%, respectivamente. Esto incumple con los umbrales establecidos ya que se espera que no haya observaciones con estos niveles de riesgo.

\begin{example}
\protect\hypertarget{exm:bloque61nbm}{}{\label{exm:bloque61nbm} }Riesgo individual
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Observaciones con riesgo individual superior al 1%:}
\KeywordTok{nrow}\NormalTok{(fileCombined[sdcCombined}\OperatorTok{@}\NormalTok{risk}\OperatorTok{$}\NormalTok{individual[, }\StringTok{"risk"}\NormalTok{] }\OperatorTok{>}\StringTok{ }\FloatTok{0.01}\NormalTok{,])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 15463
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Observaciones con riesgo individual superior al 5%:}
\KeywordTok{nrow}\NormalTok{(fileCombined[sdcCombined}\OperatorTok{@}\NormalTok{risk}\OperatorTok{$}\NormalTok{individual[, }\StringTok{"risk"}\NormalTok{] }\OperatorTok{>}\StringTok{ }\FloatTok{0.05}\NormalTok{,])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3000
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Observaciones con riesgo individual superior al 25%:}
\KeywordTok{nrow}\NormalTok{(fileCombined[sdcCombined}\OperatorTok{@}\NormalTok{risk}\OperatorTok{$}\NormalTok{individual[, }\StringTok{"risk"}\NormalTok{] }\OperatorTok{>}\StringTok{ }\FloatTok{0.25}\NormalTok{,])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 286
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Observaciones con riesgo individual superior al 50%:}
\KeywordTok{nrow}\NormalTok{(fileCombined[sdcCombined}\OperatorTok{@}\NormalTok{risk}\OperatorTok{$}\NormalTok{individual[, }\StringTok{"risk"}\NormalTok{] }\OperatorTok{>}\StringTok{ }\FloatTok{0.5}\NormalTok{,])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 92
\end{verbatim}

Revisamos el k-anonimato para los casos ponderados. A√∫n hay 54 casos que incumplen el 2-anonimato.

\begin{example}
\protect\hypertarget{exm:bloque62nbm}{}{\label{exm:bloque62nbm} }K-anonimato
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# 2-anonimato}
\KeywordTok{kAnon_violations}\NormalTok{(sdcCombined, }\DataTypeTok{weighted =}\NormalTok{ T, }\DataTypeTok{k =} \DecValTok{2}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 54
## attr(,"k")
## [1] 2
## attr(,"weighted")
## [1] TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# 3-anonimato}
\KeywordTok{kAnon_violations}\NormalTok{(sdcCombined, }\DataTypeTok{weighted =}\NormalTok{ T, }\DataTypeTok{k =} \DecValTok{3}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 85
## attr(,"k")
## [1] 3
## attr(,"weighted")
## [1] TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# 5-anonimato}
\KeywordTok{kAnon_violations}\NormalTok{(sdcCombined, }\DataTypeTok{weighted =}\NormalTok{ T, }\DataTypeTok{k =} \DecValTok{5}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 132
## attr(,"k")
## [1] 5
## attr(,"weighted")
## [1] TRUE
\end{verbatim}

Luego medimos el \emph{l-diversity}. Se observa una leve mejora en el \emph{l-diversity}, al observarse ahora una diversidad de 2 en promedio para las distintas combinaciones de variables clave en relaci√≥n con las variables sensibles.

\begin{example}
\protect\hypertarget{exm:bloque63nbm}{}{\label{exm:bloque63nbm} }L-diversity
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Generamos el objeto de l-diversity}
\NormalTok{med_riesgo <-}\StringTok{ }\KeywordTok{ldiversity}\NormalTok{(sdcCombined, }\DataTypeTok{ldiv_index =}\NormalTok{ sensibles,}
                         \DataTypeTok{l_recurs_c =} \DecValTok{2}\NormalTok{, }\DataTypeTok{missing =} \OtherTok{NA}\NormalTok{)}

\CommentTok{# revisamos las medidas de riesgo de l-diversity}
\NormalTok{med_riesgo}\OperatorTok{@}\NormalTok{risk}\OperatorTok{$}\NormalTok{ldiversity}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## --------------------------
\end{verbatim}

\begin{verbatim}
## L-Diversity Measures
\end{verbatim}

\begin{verbatim}
## --------------------------
\end{verbatim}

\begin{verbatim}
##  P17_Distinct_Ldiversity P24_Distinct_Ldiversity DEN_AGREG_Distinct_Ldiversity
##  Min.   : 1.0            Min.   : 1.0            Min.   : 1.00                
##  1st Qu.: 1.0            1st Qu.: 1.0            1st Qu.: 1.00                
##  Median : 1.0            Median : 2.0            Median : 1.00                
##  Mean   : 2.2            Mean   : 2.4            Mean   : 2.27                
##  3rd Qu.: 3.0            3rd Qu.: 3.0            3rd Qu.: 3.00                
##  Max.   :13.0            Max.   :14.0            Max.   :13.00
\end{verbatim}

En suma, debido a los riesgos individuales, k-anonimato y \emph{l-diversity}, a√∫n se requiere seguir aplicando m√©todos SDC.

\hypertarget{tercer-conjunto-de-muxe9todos-sdc}{%
\subsection{Tercer conjunto de m√©todos SDC}\label{tercer-conjunto-de-muxe9todos-sdc}}

Como tercera iteraci√≥n, se aplican varios m√©todos para poder reducir los riesgos individuales y el incumplimiento de 2-anonimato, que son las m√©tricas que han presentado mayor dificultad para disminuir.

Primero, se recodifican globalmente las variables de pertenencia ind√≠gena y nacionalidad. Para esto se ocupa una funci√≥n distinta, \texttt{groupAndRename()}, que permite tambi√©n recodificar variables categ√≥ricas. Tambi√©n se fusionan categor√≠as de situaci√≥n laboral, lo que equivale a posteriormente eliminar la variable de raz√≥n de inactividad de la base de datos. Esto porque esta variable corresponde a una consolidaci√≥n de variables (revisar paso 2.1.4).

\begin{example}
\protect\hypertarget{exm:bloque64nbm}{}{\label{exm:bloque64nbm} }Recodificar de variables
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Recodificamos pertenencia ind√≠gena}
\NormalTok{sdcCombined <-}\StringTok{ }\KeywordTok{groupAndRename}\NormalTok{(sdcCombined, }\DataTypeTok{var=}\StringTok{"rph_pertenencia_indigena"}\NormalTok{,}
                              \DataTypeTok{before=}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{9}\NormalTok{), }\DataTypeTok{after=}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{))}

\NormalTok{sdcCombined <-}\StringTok{ }\KeywordTok{groupAndRename}\NormalTok{(sdcCombined, }\DataTypeTok{var=}\StringTok{"rph_pertenencia_indigena"}\NormalTok{,}
                              \DataTypeTok{before=}\KeywordTok{c}\NormalTok{(}\DecValTok{10}\NormalTok{), }\DataTypeTok{after=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{))}

\CommentTok{# Recodificamos nacionalidad}
\NormalTok{sdcCombined <-}\StringTok{ }\KeywordTok{groupAndRename}\NormalTok{(sdcCombined, }\DataTypeTok{var=}\StringTok{"rph_nacionalidad"}\NormalTok{,}
                              \DataTypeTok{before=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\OperatorTok{:}\DecValTok{9}\NormalTok{), }\DataTypeTok{after=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Luego, se aplica supresi√≥n local en las variables de menor prioridad. Se seleccionan estas variables cuidadosamente, dado que se aplicar√° un m√©todo dr√°stico como es la supresi√≥n local, teniendo como criterio las propiedades estad√≠sticas que se buscan preservar en la base de datos.

Por otro lado, los umbrales que se entregan como argumento a esta funci√≥n en el par√°metro \emph{threshold} dependen de la data y se debe probar iterativamente hasta lograr los umbrales deseados. Se debe introducir en los argumentos umbrales de riesgo no tan bajos, evitando sobre-anonimizar, dado que esto nos llevar√≠a a perder m√°s utilidad de la necesaria. En este caso, se indican umbrales de 0.1, es decir, del 10\% de riesgo individual como objetivo.

\begin{example}
\protect\hypertarget{exm:bloque65nbm}{}{\label{exm:bloque65nbm} }Supresi√≥n local
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# supresi√≥n local para riesgos globales e individuales}
\NormalTok{sdcCombined <-}\StringTok{ }\KeywordTok{localSupp}\NormalTok{(sdcCombined, }\DataTypeTok{keyVar=}\StringTok{'rph_idgen'}\NormalTok{, }\DataTypeTok{threshold=}\FloatTok{0.1}\NormalTok{)}
\NormalTok{sdcCombined <-}\StringTok{ }\KeywordTok{localSupp}\NormalTok{(sdcCombined, }\DataTypeTok{keyVar=}\StringTok{'rph_pertenencia_indigena'}\NormalTok{, }\DataTypeTok{threshold=}\FloatTok{0.1}\NormalTok{)}
\NormalTok{sdcCombined <-}\StringTok{ }\KeywordTok{localSupp}\NormalTok{(sdcCombined, }\DataTypeTok{keyVar=}\StringTok{'rph_nacionalidad'}\NormalTok{, }\DataTypeTok{threshold=}\FloatTok{0.1}\NormalTok{)}
\NormalTok{sdcCombined <-}\StringTok{ }\KeywordTok{localSupp}\NormalTok{(sdcCombined, }\DataTypeTok{keyVar=}\StringTok{'rph_situacion_ocupacional'}\NormalTok{, }\DataTypeTok{threshold=}\FloatTok{0.1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Como veremos en el siguiente paso,los m√©todos aplicados en esta tercera iteraci√≥n logran alcanzar los umbrales requeridos. Con esto, podemos pasar al Paso Cinco y evaluar de forma completa el proceso SDC, consirando tanto la evaluaci√≥n del riesgo como de la utilidad.

\hypertarget{paso-cinco-evaluar-proceso-sdc}{%
\section{Paso Cinco: Evaluar proceso SDC}\label{paso-cinco-evaluar-proceso-sdc}}

\hypertarget{re-mediciuxf3n-del-riesgo}{%
\subsection{Re-medici√≥n del riesgo}\label{re-mediciuxf3n-del-riesgo}}

Primero, revisamos las medidas globales de riesgo. Se observa, valores mucho menores de riesgo global, aun cuando esto ya cumpl√≠a previamente con los niveles esperados.

\begin{example}
\protect\hypertarget{exm:bloque66nbm}{}{\label{exm:bloque66nbm} }Riesgo global
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{print}\NormalTok{(sdcCombined, }\StringTok{"risk"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Risk measures:
## 
## Number of observations with higher risk than the main part of the data: 
##   in modified data: 0
##   in original data: 2471
## Expected number of re-identifications: 
##   in modified data: 151.03 (0.32 %)
##   in original data: 1683.54 (3.56 %)
## 
## Information on hierarchical risk:
## Expected number of re-identifications: 
##   in modified data: 459.40 (0.97 %)
##   in original data: 4524.60 (9.56 %)
## ----------------------------------------------------------------------
\end{verbatim}

Ahora medimos el riesgo de manera individual. Se observa que el 19,3\% de los casos presentan un riesgo superior al 1\%, lo que cumple el umbral establecido, que indica el 20\% de los casos. Por otro lado, se observa que hay 1.078 registros con riesgo individual superior al 5\%, lo que equivale al 2,3\% de los casos, lo que cumple con el umbral establecido (\textless{}15\%). Finalmente, no se observan casos con riesgo individual superior al 25\%.

\begin{example}
\protect\hypertarget{exm:bloque67nbm}{}{\label{exm:bloque67nbm} }Riesgo individual
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Observaciones con riesgo individual superior al 1%:}
\KeywordTok{nrow}\NormalTok{(fileCombined[sdcCombined}\OperatorTok{@}\NormalTok{risk}\OperatorTok{$}\NormalTok{individual[, }\StringTok{"risk"}\NormalTok{] }\OperatorTok{>}\StringTok{ }\FloatTok{0.01}\NormalTok{,])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3970
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Observaciones con riesgo individual superior al 5%:}
\KeywordTok{nrow}\NormalTok{(fileCombined[sdcCombined}\OperatorTok{@}\NormalTok{risk}\OperatorTok{$}\NormalTok{individual[, }\StringTok{"risk"}\NormalTok{] }\OperatorTok{>}\StringTok{ }\FloatTok{0.05}\NormalTok{,])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 480
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Observaciones con riesgo individual superior al 25%:}
\KeywordTok{nrow}\NormalTok{(fileCombined[sdcCombined}\OperatorTok{@}\NormalTok{risk}\OperatorTok{$}\NormalTok{individual[, }\StringTok{"risk"}\NormalTok{] }\OperatorTok{>}\StringTok{ }\FloatTok{0.25}\NormalTok{,])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Observaciones con riesgo individual superior al 50%:}
\KeywordTok{nrow}\NormalTok{(fileCombined[sdcCombined}\OperatorTok{@}\NormalTok{risk}\OperatorTok{$}\NormalTok{individual[, }\StringTok{"risk"}\NormalTok{] }\OperatorTok{>}\StringTok{ }\FloatTok{0.5}\NormalTok{,])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0
\end{verbatim}

Revisamos el k-anonimato para los casos ponderados. Ahora, no hay casos que violen ning√∫n nivel de k-anonimato, por lo que se cumplir√≠a de buena forma lo planteado para estos umbrales.

\begin{example}
\protect\hypertarget{exm:bloque68nbm}{}{\label{exm:bloque68nbm} }K-anonimato
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# 2-anonimato}
\KeywordTok{kAnon_violations}\NormalTok{(sdcCombined, }\DataTypeTok{weighted =}\NormalTok{ T, }\DataTypeTok{k =} \DecValTok{2}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0
## attr(,"k")
## [1] 2
## attr(,"weighted")
## [1] TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# 3-anonimato}
\KeywordTok{kAnon_violations}\NormalTok{(sdcCombined, }\DataTypeTok{weighted =}\NormalTok{ T, }\DataTypeTok{k =} \DecValTok{3}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0
## attr(,"k")
## [1] 3
## attr(,"weighted")
## [1] TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# 5-anonimato}
\KeywordTok{kAnon_violations}\NormalTok{(sdcCombined, }\DataTypeTok{weighted =}\NormalTok{ T, }\DataTypeTok{k =} \DecValTok{5}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0
## attr(,"k")
## [1] 5
## attr(,"weighted")
## [1] TRUE
\end{verbatim}

Luego medimos el \emph{l-diversity}. Se observa que los valores de promedio y mediana de \emph{l-diversity} son levemente superiores, lo que indican un menor nivel de riesgo de que el intruso logre acertar a los valores de las variables sensibles. Si bien estos no son valores ideales, se decide no proseguir con m√©todos SDC para no perder m√°s utilidad de los datos.

\begin{example}
\protect\hypertarget{exm:bloque69nbm}{}{\label{exm:bloque69nbm} }L-diversity
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Generamos el objeto de l-diversity}
\NormalTok{med_riesgo <-}\StringTok{ }\KeywordTok{ldiversity}\NormalTok{(sdcCombined, }\DataTypeTok{ldiv_index =}\NormalTok{ sensibles,}
                         \DataTypeTok{l_recurs_c =} \DecValTok{2}\NormalTok{, }\DataTypeTok{missing =} \OtherTok{NA}\NormalTok{)}

\CommentTok{# revisamos las medidas de riesgo de l-diversity}
\NormalTok{med_riesgo}\OperatorTok{@}\NormalTok{risk}\OperatorTok{$}\NormalTok{ldiversity}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## --------------------------
\end{verbatim}

\begin{verbatim}
## L-Diversity Measures
\end{verbatim}

\begin{verbatim}
## --------------------------
\end{verbatim}

\begin{verbatim}
##  P17_Distinct_Ldiversity P24_Distinct_Ldiversity DEN_AGREG_Distinct_Ldiversity
##  Min.   : 1.000          Min.   : 1.000          Min.   : 1.000               
##  1st Qu.: 1.000          1st Qu.: 1.000          1st Qu.: 1.000               
##  Median : 5.000          Median : 6.000          Median : 5.000               
##  Mean   : 9.127          Mean   : 9.608          Mean   : 9.429               
##  3rd Qu.:14.000          3rd Qu.:14.000          3rd Qu.:14.000               
##  Max.   :70.000          Max.   :71.000          Max.   :71.000
\end{verbatim}

Los resultados aqu√≠ expuestos cumplen con los umbrales, por lo que ahora corresponde volver a medir la utilidad.

\hypertarget{evaluar-proceso-sdc---volver-a-medir-utilidad}{%
\subsection{Evaluar proceso SDC - Volver a medir utilidad}\label{evaluar-proceso-sdc---volver-a-medir-utilidad}}

\hypertarget{extracciuxf3n-de-datos-tratados-y-mediciuxf3n-de-perdida-de-informaciuxf3n.}{%
\subsubsection{Extracci√≥n de datos tratados y medici√≥n de perdida de informaci√≥n.}\label{extracciuxf3n-de-datos-tratados-y-mediciuxf3n-de-perdida-de-informaciuxf3n.}}

Primero, extraemos la data tratada. Para ello se usa la funci√≥n \texttt{extractManipData()}.

\begin{example}
\protect\hypertarget{exm:bloque70nbm}{}{\label{exm:bloque70nbm} }Extraer datos tratados
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fileTratada <-}\StringTok{ }\KeywordTok{extractManipData}\NormalTok{(sdcCombined)}
\end{Highlighting}
\end{Shaded}

Luego evaluamos cu√°ntos valores perdidos tenemos debido a la supresi√≥n local. Para ello, imprimimos el porcentaje de celdas perdidas pre y post anonimizaci√≥n.

Primero vemos que, por flujo algunas variables tienen celdas vac√≠as. La comparaci√≥n consiste en ver si luego estos porcentajes aumentan.

\begin{example}
\protect\hypertarget{exm:bloque71nbm}{}{\label{exm:bloque71nbm} }Celdas vac√≠as previo a anomizaci√≥n
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# % de celdas vac√≠as pre-anonimizaci√≥n}
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\KeywordTok{length}\NormalTok{(}\KeywordTok{names}\NormalTok{(fileCombined)))\{}
  \KeywordTok{print}\NormalTok{(}\KeywordTok{names}\NormalTok{(fileCombined)[i])}
  \KeywordTok{print}\NormalTok{(}\KeywordTok{sum}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(fileCombined[[}\KeywordTok{names}\NormalTok{(fileCombined)[i]]]))}\OperatorTok{/}\KeywordTok{nrow}\NormalTok{(fileCombined)}\OperatorTok{*}\DecValTok{100}\NormalTok{)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "enc_idr"
## [1] 0
## [1] "rph_ID"
## [1] 0
## [1] "enc_region"
## [1] 0
## [1] "rph_edad"
## [1] 0
## [1] "rph_sexo"
## [1] 0
## [1] "rph_idgen"
## [1] 14.81075
## [1] "rph_pertenencia_indigena"
## [1] 0
## [1] "rph_nacionalidad"
## [1] 0
## [1] "rph_situacion_ocupacional"
## [1] 14.81075
## [1] "Fact_Ind"
## [1] 0
## [1] "P17"
## [1] 60.36245
## [1] "P24"
## [1] 60.36245
## [1] "DEN_AGREG"
## [1] 60.36245
## [1] "IH_residencia_habitual"
## [1] 0
## [1] "Fact_Hog"
## [1] 0
\end{verbatim}

Ac√° vemos los porcentajes de valores perdidos en los datos tratados. Vemos que en las variables de identidad de g√©nero (\emph{rph\_idgen}), pertenencia ind√≠gena (\emph{rph\_pertenencia\_indigena}) y nacionalidad (\emph{rph\_nacionalidad}), hay un leve aumento de celdas en blanco. Esto es muy marginal, siendo menos de 2\% de celdas vac√≠as adicionales en identidad de g√©nero y menos de 1\% adicional de celdas vac√≠as en las otras dos variables. Adem√°s, se observa que para el caso de situaci√≥n ocupacional (\emph{rph\_situacion\_ocupacional}), el algoritmo de supresi√≥n local no elimin√≥ valores, dado que los umbrales ya se hab√≠an cumplido.

\begin{example}
\protect\hypertarget{exm:bloque72nbm}{}{\label{exm:bloque72nbm} }Celdas vac√≠as despu√©s de anomizaci√≥n
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\KeywordTok{length}\NormalTok{(}\KeywordTok{names}\NormalTok{(fileTratada)))\{}
  \KeywordTok{print}\NormalTok{(}\KeywordTok{names}\NormalTok{(fileTratada)[i])}
  \KeywordTok{print}\NormalTok{(}\KeywordTok{sum}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(fileTratada[[}\KeywordTok{names}\NormalTok{(fileTratada)[i]]]))}\OperatorTok{/}\KeywordTok{nrow}\NormalTok{(fileTratada)}\OperatorTok{*}\DecValTok{100}\NormalTok{)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "enc_idr"
## [1] 0
## [1] "rph_ID"
## [1] 0
## [1] "enc_region"
## [1] 0
## [1] "rph_edad"
## [1] 0
## [1] "rph_sexo"
## [1] 0
## [1] "rph_idgen"
## [1] 15.40216
## [1] "rph_pertenencia_indigena"
## [1] 0.2513518
## [1] "rph_nacionalidad"
## [1] 0.084488
## [1] "rph_situacion_ocupacional"
## [1] 14.83821
## [1] "Fact_Ind"
## [1] 0
## [1] "P17"
## [1] 60.36245
## [1] "P24"
## [1] 60.36245
## [1] "DEN_AGREG"
## [1] 60.36245
## [1] "IH_residencia_habitual"
## [1] 0
## [1] "Fact_Hog"
## [1] 0
\end{verbatim}

En el resto de las variables, no hay p√©rdida de informaci√≥n.

\hypertarget{propiedades-estaduxedsticas-priorizadas}{%
\subsubsection{Propiedades estad√≠sticas priorizadas}\label{propiedades-estaduxedsticas-priorizadas}}

Ahora, se procede a evaluar si se mantienen las propiedades estad√≠sticas priorizadas de los datos.

Primero, se genera una variable de edad a partir de la marca de clase de los tramos etarios, para evaluar si se mantiene la relaci√≥n con los indicadores principales. Esto no se evaluar√° inmediatamente, pero se genera para uso posterior. Es importante aclarar que esta recodificaci√≥n se realiza solo con fines anal√≠ticos para determinar la utilidad de los datos anonimizados, no siendo utilizada para los datos a liberar (en estos se mantienen los tramos etarios).

\begin{example}
\protect\hypertarget{exm:bloque73nbm}{}{\label{exm:bloque73nbm} }Generar variable de marcas de clase de edad
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fileTratada}\OperatorTok{$}\NormalTok{rph_edad_mc <-}\StringTok{ }\NormalTok{dplyr}\OperatorTok{::}\KeywordTok{case_when}\NormalTok{(}
\NormalTok{  fileTratada}\OperatorTok{$}\NormalTok{rph_edad }\OperatorTok{==}\StringTok{ }\DecValTok{1} \OperatorTok{~}\StringTok{ }\FloatTok{7.5}\NormalTok{,}
\NormalTok{  fileTratada}\OperatorTok{$}\NormalTok{rph_edad }\OperatorTok{==}\StringTok{ }\DecValTok{2} \OperatorTok{~}\StringTok{ }\DecValTok{17}\NormalTok{,}
\NormalTok{  fileTratada}\OperatorTok{$}\NormalTok{rph_edad }\OperatorTok{==}\StringTok{ }\DecValTok{3} \OperatorTok{~}\StringTok{ }\DecValTok{22}\NormalTok{,}
\NormalTok{  fileTratada}\OperatorTok{$}\NormalTok{rph_edad }\OperatorTok{==}\StringTok{ }\DecValTok{4} \OperatorTok{~}\StringTok{ }\DecValTok{27}\NormalTok{,}
\NormalTok{  fileTratada}\OperatorTok{$}\NormalTok{rph_edad }\OperatorTok{==}\StringTok{ }\DecValTok{5} \OperatorTok{~}\StringTok{ }\FloatTok{34.5}\NormalTok{,}
\NormalTok{  fileTratada}\OperatorTok{$}\NormalTok{rph_edad }\OperatorTok{==}\StringTok{ }\DecValTok{6} \OperatorTok{~}\StringTok{ }\FloatTok{44.5}\NormalTok{,}
\NormalTok{  fileTratada}\OperatorTok{$}\NormalTok{rph_edad }\OperatorTok{==}\StringTok{ }\DecValTok{7} \OperatorTok{~}\StringTok{ }\FloatTok{54.5}\NormalTok{,}
\NormalTok{  fileTratada}\OperatorTok{$}\NormalTok{rph_edad }\OperatorTok{==}\StringTok{ }\DecValTok{8} \OperatorTok{~}\StringTok{ }\FloatTok{64.5}\NormalTok{,}
\NormalTok{  fileTratada}\OperatorTok{$}\NormalTok{rph_edad }\OperatorTok{==}\StringTok{ }\DecValTok{9} \OperatorTok{~}\StringTok{ }\FloatTok{74.5}\NormalTok{,}
\NormalTok{  fileTratada}\OperatorTok{$}\NormalTok{rph_edad }\OperatorTok{==}\StringTok{ }\DecValTok{10} \OperatorTok{~}\StringTok{ }\FloatTok{84.5}\NormalTok{,}
\NormalTok{  fileTratada}\OperatorTok{$}\NormalTok{rph_edad }\OperatorTok{==}\StringTok{ }\DecValTok{11} \OperatorTok{~}\StringTok{ }\DecValTok{90}
\NormalTok{)}

\NormalTok{fileTratada}\OperatorTok{$}\NormalTok{rph_edad_mc <-}\StringTok{ }\KeywordTok{as.numeric}\NormalTok{(fileTratada}\OperatorTok{$}\NormalTok{rph_edad_mc)}
\KeywordTok{table}\NormalTok{(fileTratada}\OperatorTok{$}\NormalTok{rph_edad_mc)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  7.5   17   22   27 34.5 44.5 54.5 64.5 74.5 84.5   90 
## 7012 2216 2228 2114 4324 4282 4274 4304 4397 4348 7845
\end{verbatim}

Luego, se pegan las variables de dise√±o muestral e indicadores a evaluar, ya que no se encuentran dentro del conjunto de datos con que se trabaj√≥ durante el proceso de anonimizaci√≥n.

\begin{example}
\protect\hypertarget{exm:bloque74nbm}{}{\label{exm:bloque74nbm} }A√±adir variables de dise√±o muestral
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fileTratada <-}\StringTok{ }\NormalTok{dplyr}\OperatorTok{::}\KeywordTok{left_join}\NormalTok{(fileTratada,}
\NormalTok{                                file[,}\KeywordTok{c}\NormalTok{(}\StringTok{'rph_ID'}\NormalTok{,}\StringTok{'Fact_Pers'}\NormalTok{,}\StringTok{'Fact_Hog'}\NormalTok{,}
                                        \StringTok{'Conglomerado'}\NormalTok{,}\StringTok{'VarStrat'}\NormalTok{,}
                                        \StringTok{'VA_DC'}\NormalTok{,}\StringTok{'VP_DC'}\NormalTok{,}\StringTok{'Kish'}\NormalTok{)])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Joining with `by = join_by(rph_ID, Fact_Hog)`
\end{verbatim}

A continuaci√≥n, se comparan los resultados de los datos originales con los tratados en lo que refiere al c√°lculo de indicadores principales con desagregaciones.

Para ello, primero se establece el dise√±o complejo para personas y para hogares.

\begin{example}
\protect\hypertarget{exm:bloque75nbm}{}{\label{exm:bloque75nbm} }Declarar dise√±o complejo
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# generamos un conjunto de datos tratados donde solo tenemos las filas del informante Kish}
\NormalTok{fileTratada_kish <-}\StringTok{ }\NormalTok{fileTratada[fileTratada}\OperatorTok{$}\NormalTok{Kish  }\OperatorTok{%in%}\StringTok{ }\DecValTok{1}\NormalTok{,]}

\CommentTok{# fijamos las opciones del dise√±o complejo}
\KeywordTok{options}\NormalTok{(}\DataTypeTok{survey.lonely.psu =} \StringTok{"certainty"}\NormalTok{)}

\CommentTok{# generamos el dise√±o complejo para el factor de expansi√≥n de personas}
\NormalTok{dc_pers_trat <-}\StringTok{ }\KeywordTok{svydesign}\NormalTok{(}\DataTypeTok{ids =} \OperatorTok{~}\NormalTok{Conglomerado, }
                     \DataTypeTok{strata =} \OperatorTok{~}\NormalTok{VarStrat, }
                     \DataTypeTok{data =}\NormalTok{ fileTratada_kish,}
                     \DataTypeTok{weights =} \OperatorTok{~}\NormalTok{Fact_Pers)}

\CommentTok{# generamos el dise√±o complejo para el factor de expansi√≥n de hogares}
\NormalTok{dc_hog_trat <-}\StringTok{ }\KeywordTok{svydesign}\NormalTok{(}\DataTypeTok{ids =} \OperatorTok{~}\NormalTok{Conglomerado, }
                    \DataTypeTok{strata =} \OperatorTok{~}\NormalTok{VarStrat, }
                    \DataTypeTok{data =}\NormalTok{ fileTratada_kish,}
                    \DataTypeTok{weights =} \OperatorTok{~}\NormalTok{Fact_Hog)}
\end{Highlighting}
\end{Shaded}

Previamente, calculamos estas desagregaciones con los datos no tratados. A continuaci√≥n, se recalculan con los datos tratados y se comparan los resultados calculando la diferencia. Esta se visualiza a trav√©s de la funci√≥n \texttt{summary()}.

Victimizaci√≥n agregada de delitos consumados, desagregado por regi√≥n:

\begin{example}
\protect\hypertarget{exm:bloque76nbm}{}{\label{exm:bloque76nbm} }Estimar Victimizaci√≥n Agregada a nivel regional, con estandar de calidad INE
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{insumos_prop <-}\StringTok{ }\KeywordTok{create_prop}\NormalTok{(}\DataTypeTok{var =} \StringTok{'VA_DC'}\NormalTok{, }
                                   \DataTypeTok{domains =} \StringTok{'enc_region'}\NormalTok{, }
                                   \DataTypeTok{design =}\NormalTok{  dc_hog_trat)}


\NormalTok{VA_DC_REG_TRAT <-}\StringTok{ }\KeywordTok{assess}\NormalTok{(insumos_prop)}

\KeywordTok{summary}\NormalTok{(VA_DC_REG_PRE}\OperatorTok{$}\NormalTok{objetivo }\OperatorTok{-}\StringTok{ }\NormalTok{VA_DC_REG_TRAT}\OperatorTok{$}\NormalTok{objetivo)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
## 
\end{verbatim}

Victimizaci√≥n personal de delitos consumados, desagregado por sexo:

\begin{example}
\protect\hypertarget{exm:bloque77nbm}{}{\label{exm:bloque77nbm} }Estimar Victimizaci√≥n Personal seg√∫n sexo, con estandar de calidad INE
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{insumos_prop <-}\StringTok{ }\KeywordTok{create_prop}\NormalTok{(}\DataTypeTok{var =} \StringTok{'VP_DC'}\NormalTok{, }
                                   \DataTypeTok{domains =} \StringTok{'rph_sexo'}\NormalTok{, }
                                   \DataTypeTok{design =}\NormalTok{  dc_pers_trat)}

\NormalTok{VP_DC_SEXO_TRAT <-}\StringTok{ }\KeywordTok{assess}\NormalTok{(insumos_prop)}

\KeywordTok{summary}\NormalTok{(VP_DC_SEXO_PRE}\OperatorTok{$}\NormalTok{objetivo }\OperatorTok{-}\StringTok{ }\NormalTok{VP_DC_SEXO_TRAT}\OperatorTok{$}\NormalTok{objetivo)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
## 
\end{verbatim}

Victimizaci√≥n personal de delitos consumados, desagregado por regi√≥n:

\begin{example}
\protect\hypertarget{exm:bloque78nbm}{}{\label{exm:bloque78nbm} }Estimar Victimizaci√≥n Personal a nivel regional, con estandar de calidad INE
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{insumos_prop <-}\StringTok{ }\KeywordTok{create_prop}\NormalTok{(}\DataTypeTok{var =} \StringTok{'VP_DC'}\NormalTok{, }
                                   \DataTypeTok{domains =} \StringTok{'enc_region'}\NormalTok{, }
                                   \DataTypeTok{design =}\NormalTok{  dc_pers_trat)}

\NormalTok{VP_DC_REG_TRAT <-}\StringTok{ }\KeywordTok{assess}\NormalTok{(insumos_prop)}

\KeywordTok{summary}\NormalTok{(VP_DC_REG_PRE}\OperatorTok{$}\NormalTok{objetivo }\OperatorTok{-}\StringTok{ }\NormalTok{VP_DC_REG_TRAT}\OperatorTok{$}\NormalTok{objetivo)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
## 
\end{verbatim}

Victimizaci√≥n personal de delitos consumados, desagregado por sexo y regi√≥n:

\begin{example}
\protect\hypertarget{exm:bloque79nbm}{}{\label{exm:bloque79nbm} }Estimar Victimizaci√≥n Personal a nivel regional y seg√∫n sexo, con estandar de calidad INE
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{insumos_prop <-}\StringTok{ }\KeywordTok{create_prop}\NormalTok{(}\DataTypeTok{var =} \StringTok{'VP_DC'}\NormalTok{, }
                                   \DataTypeTok{domains =} \StringTok{'rph_sexo+enc_region'}\NormalTok{, }
                                   \DataTypeTok{design =}\NormalTok{  dc_pers_trat)}

\NormalTok{VP_DC_REG_SEXO_TRAT <-}\StringTok{ }\KeywordTok{assess}\NormalTok{(insumos_prop)}

\KeywordTok{summary}\NormalTok{(VP_DC_REG_SEXO_PRE}\OperatorTok{$}\NormalTok{objetivo }\OperatorTok{-}\StringTok{ }\NormalTok{VP_DC_REG_SEXO_TRAT}\OperatorTok{$}\NormalTok{objetivo)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
## 
\end{verbatim}

En resumen, se cumple para todos los casos que no hay diferencias en las estimaciones al calcular con los datos originales y los tratados.

Por √∫ltimo, se eval√∫a si se mantiene la relaci√≥n entre la variable de edad y el indicador de Victimizaci√≥n Personal, utilizando las marcas de clase de los tramos etarios presentes en los datos tratados.

Si bien, los modelos obtenidos no son buenos predictores de la victimizaci√≥n, ya que es un fen√≥meno influenciado por m√∫ltiples factores y ac√° solo se est√° considerando la edad, si se aprecia que los resultados son similares a los de los datos sin tratar. En particular el coeficiente beta de la variable de edad en el modelo \emph{logit} de victimizaci√≥n personal es pr√°cticamente el mismo que en los datos no tratados.

\textbf{Se genera un dataframe ``data'' para trabajar con el modelo}

Primero, se cargan los datos, y se filtran dejando solo al informante Kish.

\begin{example}
\protect\hypertarget{exm:bloque80nbm}{}{\label{exm:bloque80nbm} }Generar dataframe para modelo
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data <-}\StringTok{ }\NormalTok{fileTratada_kish}
\end{Highlighting}
\end{Shaded}

\textbf{Dividir datos en \emph{training} and \emph{testing} sets}

Luego, se dividen los datos en sets de training y testing.

\begin{example}
\protect\hypertarget{exm:bloque81nbm}{}{\label{exm:bloque81nbm} }Dividir datos en \emph{training} y \emph{testing} sets
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(caTools)}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{2022}\NormalTok{)}

\NormalTok{ids_train <-}\StringTok{ }\KeywordTok{sample}\NormalTok{(data}\OperatorTok{$}\NormalTok{rph_ID, }\KeywordTok{nrow}\NormalTok{(data)}\OperatorTok{/}\DecValTok{3}\OperatorTok{*}\DecValTok{2}\NormalTok{)}
\NormalTok{training<-}\StringTok{ }\NormalTok{sjlabelled}\OperatorTok{::}\KeywordTok{remove_all_labels}\NormalTok{(data[data}\OperatorTok{$}\NormalTok{rph_ID }\OperatorTok{%in%}\StringTok{ }\NormalTok{ids_train,])}
\NormalTok{testing<-}\StringTok{ }\NormalTok{sjlabelled}\OperatorTok{::}\KeywordTok{remove_all_labels}\NormalTok{(data[}\OperatorTok{!}\NormalTok{data}\OperatorTok{$}\NormalTok{rph_ID }\OperatorTok{%in%}\StringTok{ }\NormalTok{ids_train,])}
\end{Highlighting}
\end{Shaded}

\textbf{Construir modelo}

Luego, construimos el modelo utilizando la funci√≥n \texttt{glm()}.

\begin{example}
\protect\hypertarget{exm:bloque82nbm}{}{\label{exm:bloque82nbm} }Construir modelo
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{modelo<-}\KeywordTok{glm}\NormalTok{(VP_DC}\OperatorTok{~}\NormalTok{rph_edad_mc, }
            \DataTypeTok{data=}\NormalTok{training, }
            \DataTypeTok{family =} \StringTok{"binomial"}\NormalTok{)}
\KeywordTok{summary}\NormalTok{(modelo)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## glm(formula = VP_DC ~ rph_edad_mc, family = "binomial", data = training)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -0.7857  -0.7670  -0.7317  -0.7004   1.7468  
## 
## Coefficients:
##               Estimate Std. Error z value Pr(>|z|)    
## (Intercept) -1.3416201  0.0556848 -24.093  < 2e-16 ***
## rph_edad_mc  0.0036047  0.0008517   4.232 2.31e-05 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 13933  on 12509  degrees of freedom
## Residual deviance: 13915  on 12508  degrees of freedom
## AIC: 13919
## 
## Number of Fisher Scoring iterations: 4
\end{verbatim}

\textbf{Validaci√≥n de modelo}

Luego aplicamos el test de Hosmer Lemeshow para validar el modelo.

\begin{example}
\protect\hypertarget{exm:bloque83nbm}{}{\label{exm:bloque83nbm} }Validaci√≥n de modelo
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(ResourceSelection)}
\KeywordTok{hoslem.test}\NormalTok{(modelo}\OperatorTok{$}\NormalTok{y,}\KeywordTok{fitted}\NormalTok{(modelo),}\DataTypeTok{g=}\DecValTok{10}\NormalTok{) }\CommentTok{# Test de Hosmer Lemeshow}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Hosmer and Lemeshow goodness of fit (GOF) test
## 
## data:  modelo$y, fitted(modelo)
## X-squared = 156.47, df = 8, p-value < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(pROC)}
\NormalTok{indiceC.trainig<-}\KeywordTok{roc}\NormalTok{(modelo}\OperatorTok{$}\NormalTok{y,}\KeywordTok{fitted}\NormalTok{(modelo))     }\CommentTok{# Curva ROC}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Setting levels: control = 0, case = 1
\end{verbatim}

\begin{verbatim}
## Setting direction: controls < cases
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{indiceC.trainig}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## roc.default(response = modelo$y, predictor = fitted(modelo))
## 
## Data: fitted(modelo) in 9444 controls (modelo$y 0) < 3066 cases (modelo$y 1).
## Area under the curve: 0.5302
\end{verbatim}

\textbf{Punto de corte √≥ptimo}

Se calcula el punto de corte √≥ptimo utilizando la funci√≥n \texttt{coords()}.

\begin{example}
\protect\hypertarget{exm:bloque84nbm}{}{\label{exm:bloque84nbm} }Calcular punto de corte √≥ptimo
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ptocorteop.training<-}\KeywordTok{coords}\NormalTok{(indiceC.trainig,}\DataTypeTok{x=}\StringTok{"best"}\NormalTok{,}
                            \DataTypeTok{input=}\StringTok{"threshold"}\NormalTok{,}
                            \DataTypeTok{best.method=}\StringTok{"youden"}\NormalTok{)}
\NormalTok{ptocorteop.training}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   threshold specificity sensitivity
## 1 0.2636494   0.8235917   0.2524462
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(ROCR)}
\NormalTok{ROC.training<-}\KeywordTok{performance}\NormalTok{(}\DataTypeTok{prediction.obj =} \KeywordTok{prediction}\NormalTok{(}\DataTypeTok{predictions =} \KeywordTok{fitted}\NormalTok{(modelo),}
                                                      \DataTypeTok{labels =} \KeywordTok{as.factor}\NormalTok{(modelo}\OperatorTok{$}\NormalTok{y)),}
                          \StringTok{"tpr"}\NormalTok{,}
                          \StringTok{"fpr"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Luego, visualizamos el punto de corte √≥ptimo utilizando la funci√≥n \texttt{plot()}.

\begin{example}
\protect\hypertarget{exm:bloque85nbm}{}{\label{exm:bloque85nbm} }Visualizar punto de corte √≥ptimo
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(ROC.training, }\DataTypeTok{colorize=}\OtherTok{TRUE}\NormalTok{, }\DataTypeTok{print.cutoffs.at=}\KeywordTok{seq}\NormalTok{(}\FloatTok{0.1}\NormalTok{, }\DataTypeTok{by=}\FloatTok{0.1}\NormalTok{))}
\KeywordTok{abline}\NormalTok{(}\DataTypeTok{a=}\DecValTok{0}\NormalTok{,}\DataTypeTok{b=}\DecValTok{1}\NormalTok{)}
\KeywordTok{abline}\NormalTok{(}\DataTypeTok{v=}\NormalTok{ptocorteop.training}\OperatorTok{$}\NormalTok{threshold,}\DataTypeTok{col=}\StringTok{"red"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\includegraphics[width=0.9\linewidth]{bookdown-demo_files/figure-latex/unnamed-chunk-158-1} \caption{Punto de corte √≥ptimo con datos tratados}\label{fig:unnamed-chunk-158}
\end{figure}

\textbf{Predicciones y matriz de confusi√≥n}

Se realizan predicciones y se genera una matriz de confusi√≥n.

\begin{example}
\protect\hypertarget{exm:bloque86nbm}{}{\label{exm:bloque86nbm} }Predicciones y matriz de confusi√≥n
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pred.training<-}\KeywordTok{predict}\NormalTok{(modelo, }\DataTypeTok{data=}\NormalTok{training, }\DataTypeTok{type=}\StringTok{"response"}\NormalTok{)}
\KeywordTok{table}\NormalTok{(}\DataTypeTok{ActualValue=}\NormalTok{training}\OperatorTok{$}\NormalTok{VP_DC, }
      \DataTypeTok{PredictValue=}\NormalTok{pred.training}\OperatorTok{>}\NormalTok{ptocorteop.training}\OperatorTok{$}\NormalTok{threshold)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##            PredictValue
## ActualValue FALSE TRUE
##           0  7778 1666
##           1  2292  774
\end{verbatim}

A continuaci√≥n, se continua la evaluaci√≥n del modelo con datos de prueba.

\textbf{Validaci√≥n de modelo (con datos de prueba)}

Aplicamos nuevamente la validaci√≥n con el test de Hosmer Lemeshow, esta vez con los datos de prueba.

\begin{example}
\protect\hypertarget{exm:bloque87nbm}{}{\label{exm:bloque87nbm} }Validaci√≥n de modelo con datos de prueba
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{hoslem.test}\NormalTok{(testing}\OperatorTok{$}\NormalTok{VP_DC,}\KeywordTok{predict}\NormalTok{(modelo,}\DataTypeTok{newdata=}\NormalTok{testing,}\DataTypeTok{type=}\StringTok{"response"}\NormalTok{),}\DataTypeTok{g=}\DecValTok{5}\NormalTok{)   }\CommentTok{# Test de Hosmer Lemeshow}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Hosmer and Lemeshow goodness of fit (GOF) test
## 
## data:  testing$VP_DC, predict(modelo, newdata = testing, type = "response")
## X-squared = 66.467, df = 3, p-value = 2.431e-14
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{indiceC.testing=}\KeywordTok{roc}\NormalTok{(testing}\OperatorTok{$}\NormalTok{VP_DC,}\KeywordTok{predict}\NormalTok{(modelo,}\DataTypeTok{newdata=}\NormalTok{testing,}\DataTypeTok{type=}\StringTok{"response"}\NormalTok{)) }\CommentTok{# Curva ROC}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Setting levels: control = 0, case = 1
\end{verbatim}

\begin{verbatim}
## Setting direction: controls < cases
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{indiceC.testing}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## roc.default(response = testing$VP_DC, predictor = predict(modelo,     newdata = testing, type = "response"))
## 
## Data: predict(modelo, newdata = testing, type = "response") in 4666 controls (testing$VP_DC 0) < 1590 cases (testing$VP_DC 1).
## Area under the curve: 0.5243
\end{verbatim}

\textbf{Punto de corte √≥ptimo (con datos de prueba)}

Se calcula el punto de corte √≥ptimo utilizando la funci√≥n \texttt{coords()}.

\begin{example}
\protect\hypertarget{exm:bloque88nbm}{}{\label{exm:bloque88nbm} }Calcular de corte √≥ptimo con datos de prueba
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ptocorteop.testing<-}\KeywordTok{coords}\NormalTok{(indiceC.testing,}\DataTypeTok{x=}\StringTok{"best"}\NormalTok{,}\DataTypeTok{input=}\StringTok{"threshold"}\NormalTok{,}\DataTypeTok{best.method=}\StringTok{"youden"}\NormalTok{)}
\NormalTok{ptocorteop.testing}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   threshold specificity sensitivity
## 1 0.2636494   0.8317617   0.2440252
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ROC.testing<-}\KeywordTok{performance}\NormalTok{(}\KeywordTok{prediction}\NormalTok{(}\KeywordTok{predict}\NormalTok{(modelo,}\DataTypeTok{newdata=}\NormalTok{testing,}\DataTypeTok{type=}\StringTok{"response"}\NormalTok{),}
                                    \KeywordTok{as.factor}\NormalTok{(testing}\OperatorTok{$}\NormalTok{VP_DC)),}\StringTok{"tpr"}\NormalTok{,}\StringTok{"fpr"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Luego, visualizamos el punto de corte √≥ptimo utilizando la funci√≥n \texttt{plot()}.

\begin{example}
\protect\hypertarget{exm:bloque89nbm}{}{\label{exm:bloque89nbm} }Visualizar de corte √≥ptimo con datos de prueba
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(ROC.testing, }\DataTypeTok{colorize=}\OtherTok{TRUE}\NormalTok{, }\DataTypeTok{print.cutoffs.at=}\KeywordTok{seq}\NormalTok{(}\FloatTok{0.1}\NormalTok{, }\DataTypeTok{by=}\FloatTok{0.1}\NormalTok{))}
\KeywordTok{abline}\NormalTok{(}\DataTypeTok{a=}\DecValTok{0}\NormalTok{,}\DataTypeTok{b=}\DecValTok{1}\NormalTok{)}
\KeywordTok{abline}\NormalTok{(}\DataTypeTok{v=}\NormalTok{ptocorteop.testing}\OperatorTok{$}\NormalTok{threshold,}\DataTypeTok{col=}\StringTok{"red"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\includegraphics[width=0.9\linewidth]{bookdown-demo_files/figure-latex/unnamed-chunk-162-1} \caption{Punto de corte √≥ptimo con datos de prueba a partir de datos tratados}\label{fig:unnamed-chunk-162}
\end{figure}

\textbf{Predicciones y matriz de confusi√≥n (con datos de prueba)}

Se realizan predicciones y se genera una matriz de confusi√≥n.

\begin{example}
\protect\hypertarget{exm:bloque90nbm}{}{\label{exm:bloque90nbm} }Predicciones y matriz de confusi√≥n con datos de prueba
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pred.testing<-}\KeywordTok{predict}\NormalTok{(modelo, testing, }\DataTypeTok{type=}\StringTok{"response"}\NormalTok{)}
\KeywordTok{table}\NormalTok{(}\DataTypeTok{ActualValue=}\NormalTok{testing}\OperatorTok{$}\NormalTok{VP_DC, }\DataTypeTok{PredictValue=}\NormalTok{pred.testing}\OperatorTok{>}\NormalTok{ptocorteop.testing}\OperatorTok{$}\NormalTok{threshold)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##            PredictValue
## ActualValue FALSE TRUE
##           0  3881  785
##           1  1202  388
\end{verbatim}

\textbf{Compara √°rea bajo la curva, umbral, sensibilidad y especificidad}

Finalmente, comparamos el √°rea bajo la curva, umbral, sensibilidad y especificidad, a partir de los resultados del modelo con los datos de entrenamiento y con los datos de prueba.

\begin{example}
\protect\hypertarget{exm:bloque91nbm}{}{\label{exm:bloque91nbm} }Comparar √°rea bajo la curva, umbral, sensibilidad y especificidad
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{auc    <-indiceC.trainig}\OperatorTok{$}\NormalTok{auc              }\OperatorTok{-}\StringTok{ }\NormalTok{indiceC.testing}\OperatorTok{$}\NormalTok{auc}
\NormalTok{corte  <-ptocorteop.training}\OperatorTok{$}\NormalTok{threshold    }\OperatorTok{-}\StringTok{ }\NormalTok{ptocorteop.testing}\OperatorTok{$}\NormalTok{threshold}
\NormalTok{sens   <-}\StringTok{ }\NormalTok{ptocorteop.training}\OperatorTok{$}\NormalTok{sensitivity }\OperatorTok{-}\StringTok{ }\NormalTok{ptocorteop.testing}\OperatorTok{$}\NormalTok{sensitivity}
\NormalTok{spe    <-}\StringTok{ }\NormalTok{ptocorteop.training}\OperatorTok{$}\NormalTok{specificity }\OperatorTok{-}\StringTok{ }\NormalTok{ptocorteop.testing}\OperatorTok{$}\NormalTok{specificity}
\end{Highlighting}
\end{Shaded}

La siguiente tabla muestra las estimaciones del coeficiente beta de la variable independiente de edad en los modelos, para los datos originales y los datos tratados. Se observa que ambas estimaciones son equivalentes, sin diferencias estad√≠sticamente significativas a partir de su intervalo de confianza:

\begin{longtable}[]{@{}llll@{}}
\toprule
Datos & Estimaci√≥n & Lim. Inf. & Lim. Sup.\tabularnewline
\midrule
\endhead
Originales & 0,0035 & 0,0020 & 0,0050\tabularnewline
Tratados & 0,0036 & 0,0019 & 0,0053\tabularnewline
\bottomrule
\end{longtable}

En suma, se observa que se mantienen las propiedades estad√≠sticas priorizadas de la base de datos, por lo que cumple con las condiciones para su liberaci√≥n.

\hypertarget{paso-seis-generar-reportes-y-liberar-datos}{%
\section{Paso Seis: Generar Reportes y Liberar Datos}\label{paso-seis-generar-reportes-y-liberar-datos}}

\hypertarget{reportes}{%
\subsection{Reportes}\label{reportes}}

Al realizar un ejercicio de anonimizaci√≥n como el reci√©n expuesto, se debe elaborar un reporte que documente el proceso de anonimizaci√≥n, con sus antecedentes y resultados. Para ello, debe basarse en el modelo de reporte de anonimizaci√≥n descrito en la gu√≠a de anonimizaci√≥n.

\hypertarget{liberaciuxf3n-de-datos}{%
\subsection{Liberaci√≥n de datos}\label{liberaciuxf3n-de-datos}}

A partir del objeto \emph{file}, que son los datos originales, se genera un objeto data.frame para su exportaci√≥n como archivo de datos que ser√° liberado.

Primero se verifica que el orden de registros sea id√©ntico entra datos originales y tratados. Esto permite sobre-escribir columnas completas, sabiendo que los registros coincidir√°n bien. En este caso, es importante usar el folio que corresponde a persona, ya que cada fila es una persona (en contraposici√≥n al folio de viviendas que cubre varias filas dependiendo de las personas que las componen).

\begin{example}
\protect\hypertarget{exm:bloque92nbm}{}{\label{exm:bloque92nbm} }Verificar coincidencia de folios
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Se espera que esta funci√≥n regrese TRUE}
\KeywordTok{all}\NormalTok{(file}\OperatorTok{$}\NormalTok{rph_ID }\OperatorTok{==}\StringTok{ }\NormalTok{fileTratada}\OperatorTok{$}\NormalTok{rph_ID)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

Luego, se reemplazan variables tratadas en datos originales y se eliminan las variables que est√°n de m√°s. Estas son, comuna y raz√≥n de inactividad, ya que esta √∫ltima permitir√≠a deshacer la recodificaci√≥n que se realiz√≥ en la variable consolidada de situaci√≥n ocupacional.

\begin{example}
\protect\hypertarget{exm:bloque93nbm}{}{\label{exm:bloque93nbm} }Eliminar variables
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{file}\OperatorTok{$}\NormalTok{enc_rpc <-}\StringTok{ }\OtherTok{NULL}
\NormalTok{file}\OperatorTok{$}\NormalTok{rph_p14 <-}\StringTok{ }\OtherTok{NULL}
\end{Highlighting}
\end{Shaded}

Luego, se reemplazan variables tratadas de edad, identidad de g√©nero, pertenencia ind√≠gena y nacionalidad.

\begin{example}
\protect\hypertarget{exm:bloque94nbm}{}{\label{exm:bloque94nbm} }Reemplazar variables originales por variables tratadas
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{file}\OperatorTok{$}\NormalTok{rph_edad <-}\StringTok{ }\NormalTok{fileTratada}\OperatorTok{$}\NormalTok{rph_edad}
\NormalTok{file}\OperatorTok{$}\NormalTok{rph_idgen <-}\StringTok{ }\NormalTok{fileTratada}\OperatorTok{$}\NormalTok{rph_idgen}
\NormalTok{file}\OperatorTok{$}\NormalTok{rph_pertenencia_indigena <-}\StringTok{ }\NormalTok{fileTratada}\OperatorTok{$}\NormalTok{rph_pertenencia_indigena}
\NormalTok{file}\OperatorTok{$}\NormalTok{rph_nacionalidad <-}\StringTok{ }\NormalTok{fileTratada}\OperatorTok{$}\NormalTok{rph_nacionalidad}
\end{Highlighting}
\end{Shaded}

Se eliminan los valores de rph\_p9 a rph\_p13 para los casos suprimidos en situaci√≥n ocupacional

\begin{example}
\protect\hypertarget{exm:bloque95nbm}{}{\label{exm:bloque95nbm} }Suprimir valores
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# se eliminan los valores que corresponden}
\NormalTok{file}\OperatorTok{$}\NormalTok{rph_p9[}\KeywordTok{is.na}\NormalTok{(fileTratada}\OperatorTok{$}\NormalTok{rph_situacion_ocupacional)] <-}\StringTok{ }\OtherTok{NA}
\NormalTok{file}\OperatorTok{$}\NormalTok{rph_p10[}\KeywordTok{is.na}\NormalTok{(fileTratada}\OperatorTok{$}\NormalTok{rph_situacion_ocupacional)] <-}\StringTok{ }\OtherTok{NA}
\NormalTok{file}\OperatorTok{$}\NormalTok{rph_p11[}\KeywordTok{is.na}\NormalTok{(fileTratada}\OperatorTok{$}\NormalTok{rph_situacion_ocupacional)] <-}\StringTok{ }\OtherTok{NA}
\NormalTok{file}\OperatorTok{$}\NormalTok{rph_p12[}\KeywordTok{is.na}\NormalTok{(fileTratada}\OperatorTok{$}\NormalTok{rph_situacion_ocupacional)] <-}\StringTok{ }\OtherTok{NA}
\NormalTok{file}\OperatorTok{$}\NormalTok{rph_p13[}\KeywordTok{is.na}\NormalTok{(fileTratada}\OperatorTok{$}\NormalTok{rph_situacion_ocupacional)] <-}\StringTok{ }\OtherTok{NA}

\CommentTok{# Luego eliminamos situaci√≥n ocupacional ya que no se usar√° m√°s}
\NormalTok{file}\OperatorTok{$}\NormalTok{rph_situacion_ocupacional <-}\StringTok{ }\OtherTok{NULL}
\end{Highlighting}
\end{Shaded}

Luego, se elimina los valores de rph\_migraci√≥n que son acompa√±ados de un NA en nacionalidad, ya que ser√≠a un error de flujo de la encuesta mantenerlos.

\begin{example}
\protect\hypertarget{exm:bloque96nbm}{}{\label{exm:bloque96nbm} }Suprimir valores en nacionalidad
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{file}\OperatorTok{$}\NormalTok{rph_migracion[}\KeywordTok{is.na}\NormalTok{(file}\OperatorTok{$}\NormalTok{rph_nacionalidad)] <-}\StringTok{ }\OtherTok{NA}
\end{Highlighting}
\end{Shaded}

Por √∫ltimo, se exporta archivo de datos ocupando la librer√≠a \texttt{haven}.

\begin{example}
\protect\hypertarget{exm:bloque97nbm}{}{\label{exm:bloque97nbm} }Ejemplo de c√≥digo para exportar datos anonimizados
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#haven::write_sav(file, 'ENUSC2020_anonimizada.sav')}
\end{Highlighting}
\end{Shaded}

\hypertarget{anexo-tablas-de-indicadores-con-desagregaciones}{%
\subsection{Anexo : Tablas de indicadores con desagregaciones}\label{anexo-tablas-de-indicadores-con-desagregaciones}}

Se deja como anexo los tabulados con datos tratados y no tratados por si se considera necesario compararlos de forma manual.

\begin{example}
\protect\hypertarget{exm:bloque98nbm}{}{\label{exm:bloque98nbm} }Ejemplo de c√≥digo para exportar datos de indicadores con datos tratados y no tratados
\end{example}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#anexo <- list('P1 Regional Original' = P1_REG_PRE,}
\CommentTok{#              'P1 Regional Tratado' = P1_REG_TRAT,}
\CommentTok{#              'P1 Sexo Original' = P1_SEXO_PRE,}
\CommentTok{#              'P1 Sexo Tratado' = P1_SEXO_TRAT,}
\CommentTok{#              'P1 Regional Sexo Original' = P1_REG_SEXO_PRE,}
\CommentTok{#              'P1 Regional Sexo Tratado' = P1_REG_SEXO_TRAT,}
\CommentTok{#              'Vict. Pers. Regional Original' = VP_DC_REG_PRE,}
\CommentTok{#              'Vict. Pers. Regional Tratado' = VP_DC_REG_TRAT,}
\CommentTok{#              'Vict. Pers. Sexo Original' = VP_DC_SEXO_PRE,}
\CommentTok{#              'Vict. Pers. Sexo Tratado' = VP_DC_SEXO_TRAT,}
\CommentTok{#              'Vict. Pers. Regional Sexo Original' = VP_DC_REG_SEXO_PRE,}
\CommentTok{#              'Vict. Pers. Regional Sexo Tratado' = VP_DC_REG_SEXO_TRAT,}
\CommentTok{#              'Vict. Agr. Regional Original' = VA_DC_REG_PRE,}
\CommentTok{#              'Vict. Agr. Regional Tratado' = VA_DC_REG_TRAT)}
\CommentTok{#}
\CommentTok{#openxlsx::write.xlsx(anexo, "Anexo_Medicion_Utilidad.xlsx")}
\end{Highlighting}
\end{Shaded}

\bibliography{references.bib,packages.bib}

\end{document}
